{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "690b8182",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from src.data.ingestion import load_tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ffe0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8739f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = load_tickets(\"../data/raw/support_tickets.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35b7f28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Ticket(ticket_id='TK-2024-000001', created_at=datetime.datetime(2023, 11, 2, 12, 30, 10, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 2, 15, 30, 46, tzinfo=datetime.timezone.utc), customer_id='CUST-02387', customer_tier='starter', organization_id='ORG-234', product='CloudBackup Enterprise', product_version='4.5.10', product_module='encryption_layer', category='Feature Request', subcategory='Documentation', priority='critical', severity='P2', channel='portal', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=9, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 11, 2, 15, 30, 46, tzinfo=datetime.timezone.utc), agent_id='AGENT-044', agent_actions=['consulted_kb', 'contacted_customer'], escalated=True, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['error', 'api', 'integration', 'timeout', 'bug'], environment='production', business_impact='high', affected_users=222, language='de', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000002', created_at=datetime.datetime(2023, 2, 10, 16, 31, 31, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 12, 9, 59, 43, tzinfo=datetime.timezone.utc), customer_id='CUST-03724', customer_tier='free', organization_id='ORG-435', product='DataSync Pro', product_version='4.1.11', product_module='data_validator', category='Account Management', subcategory='Upgrade', priority='medium', severity='P4', channel='chat', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-02-10T16:31:31 WARN Rate limit approaching threshold\\n2023-02-10T16:31:31 ERROR ERROR_DISK_FULL: Rate limit exceeded\\n2023-02-10T16:31:33 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='grateful', previous_tickets=4, resolution='Applied hotfix version 3.2.2 to address the ERROR_DISK_FULL. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 2, 12, 9, 59, 43, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['viewed_logs', 'consulted_kb', 'updated_documentation', 'ran_diagnostics', 'verified_resolution'], escalated=True, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['database', 'bug', 'authentication', 'data', 'error'], environment='production', business_impact='medium', affected_users=18, language='ja', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000003', created_at=datetime.datetime(2024, 9, 30, 7, 43, 47, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 30, 11, 58, 47, tzinfo=datetime.timezone.utc), customer_id='CUST-00600', customer_tier='enterprise', organization_id='ORG-208', product='API Gateway', product_version='3.1.4', product_module='request_router', category='Feature Request', subcategory='New Feature', priority='high', severity='P1', channel='phone', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-09-30T07:43:47 DEBUG Processing request ID-12345\\n2024-09-30T07:43:47 ERROR ERROR_DISK_FULL: Invalid request format\\n2024-09-30T07:43:48 INFO Request rejected', stack_trace='Stack trace:\\n  request_router::processData() at request_router.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='frustrated', previous_tickets=1, resolution='Root cause identified as New Feature issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 9, 30, 11, 58, 47, tzinfo=datetime.timezone.utc), agent_id='AGENT-016', agent_actions=['escalated_to_specialist', 'consulted_kb'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['configuration', 'error', 'sync', 'performance'], environment='staging', business_impact='medium', affected_users=591, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000004', created_at=datetime.datetime(2024, 11, 27, 18, 17, 26, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 30, 22, 7, 50, tzinfo=datetime.timezone.utc), customer_id='CUST-04795', customer_tier='starter', organization_id='ORG-231', product='CloudBackup Enterprise', product_version='3.4.15', product_module='backup_service', category='Account Management', subcategory='Upgrade', priority='low', severity='P4', channel='portal', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-11-27T18:17:26 ERROR ERROR_SERVER_500: Connection timeout after 30s\\n2024-11-27T18:17:27 RETRY_FAILED: Max retries exceeded', stack_trace='Stack trace:\\n  backup_service::processData() at backup_service.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='confused', previous_tickets=5, resolution='Applied hotfix version 3.2.2 to address the ERROR_SERVER_500. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 11, 30, 22, 7, 50, tzinfo=datetime.timezone.utc), agent_id='AGENT-034', agent_actions=['escalated_to_specialist', 'updated_documentation', 'checked_config', 'applied_fix', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=False, tags=['authentication', 'api', 'performance'], environment='production', business_impact='critical', affected_users=34, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000005', created_at=datetime.datetime(2024, 3, 9, 15, 41, 2, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 10, 10, 53, 38, tzinfo=datetime.timezone.utc), customer_id='CUST-01101', customer_tier='starter', organization_id='ORG-241', product='StreamProcessor', product_version='2.8.8', product_module='monitoring', category='Feature Request', subcategory='API', priority='high', severity='P2', channel='slack', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-03-09T15:41:02 ERROR ERROR_RATELIMIT_429: Connection timeout after 30s\\n2024-03-09T15:41:03 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='angry', previous_tickets=5, resolution='Root cause identified as API issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 3, 10, 10, 53, 38, tzinfo=datetime.timezone.utc), agent_id='AGENT-038', agent_actions=['created_workaround', 'escalated_to_specialist', 'ran_diagnostics', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['data', 'integration', 'security', 'authentication'], environment='development', business_impact='medium', affected_users=325, language='de', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000006', created_at=datetime.datetime(2024, 3, 20, 4, 25, 55, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 23, 6, 42, 7, tzinfo=datetime.timezone.utc), customer_id='CUST-00597', customer_tier='premium', organization_id='ORG-030', product='StreamProcessor', product_version='3.7.1', product_module='batch_processor', category='Security', subcategory='Compliance', priority='low', severity='P3', channel='email', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Getting ERROR_VALIDATION errors. We need to ensure our system meets compliance requirements.', error_logs='2024-03-20T04:25:55 ERROR ERROR_VALIDATION: Connection timeout after 30s\\n2024-03-20T04:25:56 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'batch_processor.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='neutral', previous_tickets=10, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 3, 23, 6, 42, 7, tzinfo=datetime.timezone.utc), agent_id='AGENT-029', agent_actions=['contacted_customer', 'consulted_kb', 'checked_config', 'ran_diagnostics', 'verified_resolution', 'created_workaround'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['error', 'authentication'], environment='staging', business_impact='high', affected_users=41, language='fr', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000007', created_at=datetime.datetime(2023, 2, 2, 4, 58, 34, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 2, 16, 25, 34, tzinfo=datetime.timezone.utc), customer_id='CUST-00617', customer_tier='premium', organization_id='ORG-176', product='Analytics Dashboard', product_version='4.3.5', product_module='data_aggregator', category='Data Issue', subcategory='Corruption', priority='high', severity='P2', channel='api', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_INVALID_400 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-02-02T04:58:34 ERROR ERROR_INVALID_400: Connection timeout after 30s\\n2023-02-02T04:58:35 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'data_aggregator.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='confused', previous_tickets=10, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 2, 2, 16, 25, 34, tzinfo=datetime.timezone.utc), agent_id='AGENT-037', agent_actions=['created_workaround', 'applied_fix'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['timeout', 'performance'], environment='test', business_impact='medium', affected_users=962, language='zh', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000008', created_at=datetime.datetime(2024, 11, 6, 15, 7, 34, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 6, 20, 47, 10, tzinfo=datetime.timezone.utc), customer_id='CUST-01059', customer_tier='premium', organization_id='ORG-311', product='API Gateway', product_version='2.7.10', product_module='cache_layer', category='Feature Request', subcategory='API', priority='critical', severity='P2', channel='api', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-11-06T15:07:34 WARN Rate limit approaching threshold\\n2024-11-06T15:07:34 ERROR ERROR_DEADLOCK: Rate limit exceeded\\n2024-11-06T15:07:36 INFO Backing off for 60 seconds', stack_trace='Stack trace:\\n  cache_layer::processData() at cache_layer.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='frustrated', previous_tickets=7, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 11, 6, 20, 47, 10, tzinfo=datetime.timezone.utc), agent_id='AGENT-049', agent_actions=['escalated_to_specialist', 'checked_config', 'applied_fix'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['timeout', 'authentication'], environment='development', business_impact='medium', affected_users=581, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000009', created_at=datetime.datetime(2023, 12, 25, 19, 32, 58, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 26, 9, 21, 34, tzinfo=datetime.timezone.utc), customer_id='CUST-02971', customer_tier='premium', organization_id='ORG-156', product='DataSync Pro', product_version='3.1.1', product_module='scheduler', category='Feature Request', subcategory='Enhancement', priority='low', severity='P1', channel='api', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-12-25T19:32:58 WARN Rate limit approaching threshold\\n2023-12-25T19:32:58 ERROR ERROR_INVALID_400: Rate limit exceeded\\n2023-12-25T19:33:00 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='neutral', previous_tickets=8, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 12, 26, 9, 21, 34, tzinfo=datetime.timezone.utc), agent_id='AGENT-021', agent_actions=['consulted_kb', 'updated_documentation'], escalated=False, transferred_count=1, satisfaction_score=1, resolution_helpful=True, tags=['database', 'bug'], environment='development', business_impact='critical', affected_users=42, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000010', created_at=datetime.datetime(2024, 11, 18, 4, 10, 2, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 18, 22, 33, 26, tzinfo=datetime.timezone.utc), customer_id='CUST-03899', customer_tier='starter', organization_id='ORG-286', product='Analytics Dashboard', product_version='4.2.2', product_module='data_aggregator', category='Data Issue', subcategory='Sync Error', priority='critical', severity='P4', channel='email', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_CONNECTION_REFUSED appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-11-18T04:10:02 WARN Rate limit approaching threshold\\n2024-11-18T04:10:02 ERROR ERROR_CONNECTION_REFUSED: Rate limit exceeded\\n2024-11-18T04:10:04 INFO Backing off for 60 seconds', stack_trace='ERROR: data_aggregator.service.ServiceException: Failed to process request\\n\\tat data_aggregator.handler.process(data_aggregator.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='neutral', previous_tickets=2, resolution='Root cause identified as Sync Error issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 11, 18, 22, 33, 26, tzinfo=datetime.timezone.utc), agent_id='AGENT-029', agent_actions=['created_workaround', 'consulted_kb', 'checked_config', 'applied_fix', 'contacted_customer'], escalated=True, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['security', 'integration', 'authentication', 'bug'], environment='staging', business_impact='low', affected_users=292, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000011', created_at=datetime.datetime(2023, 8, 27, 8, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 29, 2, 55, 48, tzinfo=datetime.timezone.utc), customer_id='CUST-01180', customer_tier='enterprise', organization_id='ORG-288', product='CloudBackup Enterprise', product_version='3.0.9', product_module='backup_service', category='Feature Request', subcategory='Documentation', priority='critical', severity='P4', channel='chat', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-08-27T08:45:00 DEBUG Processing request ID-12345\\n2023-08-27T08:45:00 ERROR ERROR_MEMORY_OOM: Invalid request format\\n2023-08-27T08:45:01 INFO Request rejected', stack_trace=\"Traceback (most recent call last):\\n  File 'backup_service.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='confused', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 8, 29, 2, 55, 48, tzinfo=datetime.timezone.utc), agent_id='AGENT-028', agent_actions=['ran_diagnostics', 'applied_fix', 'created_workaround', 'consulted_kb'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['data', 'security'], environment='staging', business_impact='medium', affected_users=216, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000012', created_at=datetime.datetime(2023, 12, 14, 21, 56, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 15, 0, 24, 14, tzinfo=datetime.timezone.utc), customer_id='CUST-01170', customer_tier='premium', organization_id='ORG-406', product='CloudBackup Enterprise', product_version='2.8.13', product_module='encryption_layer', category='Feature Request', subcategory='UI/UX', priority='critical', severity='P0', channel='api', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-12-14T21:56:38 ERROR ERROR_INVALID_400: Database connection lost\\n2023-12-14T21:56:39 INFO Attempting to reconnect...\\n2023-12-14T21:56:41 ERROR Connection failed', stack_trace='ERROR: encryption_layer.service.ServiceException: Failed to process request\\n\\tat encryption_layer.handler.process(encryption_layer.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='angry', previous_tickets=1, resolution='Applied hotfix version 3.2.2 to address the ERROR_INVALID_400. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 12, 15, 0, 24, 14, tzinfo=datetime.timezone.utc), agent_id='AGENT-021', agent_actions=['contacted_customer', 'checked_config', 'viewed_logs', 'applied_fix', 'escalated_to_specialist'], escalated=True, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['database', 'data', 'error', 'configuration'], environment='staging', business_impact='medium', affected_users=275, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000013', created_at=datetime.datetime(2024, 3, 30, 20, 41, 31, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 30, 21, 7, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-03842', customer_tier='free', organization_id='ORG-488', product='DataSync Pro', product_version='2.1.14', product_module='data_validator', category='Feature Request', subcategory='API', priority='critical', severity='P0', channel='portal', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-03-30T20:41:31 ERROR ERROR_MEMORY_OOM: Database connection lost\\n2024-03-30T20:41:32 INFO Attempting to reconnect...\\n2024-03-30T20:41:34 ERROR Connection failed', stack_trace='', customer_sentiment='angry', previous_tickets=9, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 3, 30, 21, 7, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-027', agent_actions=['applied_fix', 'viewed_logs', 'created_workaround'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['bug', 'database'], environment='test', business_impact='medium', affected_users=962, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000014', created_at=datetime.datetime(2024, 2, 16, 8, 26, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 17, 20, 2, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-02409', customer_tier='starter', organization_id='ORG-261', product='CloudBackup Enterprise', product_version='4.5.5', product_module='compression_engine', category='Feature Request', subcategory='Documentation', priority='critical', severity='P4', channel='slack', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-02-16T08:26:39 DEBUG Processing request ID-12345\\n2024-02-16T08:26:39 ERROR ERROR_NOTFOUND_404: Invalid request format\\n2024-02-16T08:26:40 INFO Request rejected', stack_trace='', customer_sentiment='angry', previous_tickets=2, resolution='Root cause identified as Documentation issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 2, 17, 20, 2, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-020', agent_actions=['applied_fix', 'created_workaround', 'updated_documentation', 'viewed_logs', 'escalated_to_specialist'], escalated=True, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['sync', 'configuration', 'bug'], environment='test', business_impact='critical', affected_users=518, language='it', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000015', created_at=datetime.datetime(2024, 9, 15, 20, 49, 16, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 15, 21, 45, 4, tzinfo=datetime.timezone.utc), customer_id='CUST-00908', customer_tier='enterprise', organization_id='ORG-057', product='API Gateway', product_version='3.7.1', product_module='cache_layer', category='Security', subcategory='Compliance', priority='medium', severity='P0', channel='chat', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=8, resolution='Root cause identified as Compliance issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 9, 15, 21, 45, 4, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['applied_fix', 'viewed_logs'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['database', 'bug', 'data', 'configuration', 'error'], environment='sandbox', business_impact='high', affected_users=21, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000016', created_at=datetime.datetime(2024, 1, 22, 11, 0, 56, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 23, 10, 32, 8, tzinfo=datetime.timezone.utc), customer_id='CUST-00064', customer_tier='enterprise', organization_id='ORG-436', product='CloudBackup Enterprise', product_version='4.6.8', product_module='encryption_layer', category='Feature Request', subcategory='API', priority='critical', severity='P3', channel='api', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-01-22T11:00:56 ERROR ERROR_RATELIMIT_429: Database connection lost\\n2024-01-22T11:00:57 INFO Attempting to reconnect...\\n2024-01-22T11:00:59 ERROR Connection failed', stack_trace='', customer_sentiment='angry', previous_tickets=9, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 1, 23, 10, 32, 8, tzinfo=datetime.timezone.utc), agent_id='AGENT-006', agent_actions=['checked_config', 'ran_diagnostics'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['error', 'bug', 'sync'], environment='test', business_impact='low', affected_users=592, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000017', created_at=datetime.datetime(2023, 3, 19, 12, 22, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 19, 14, 49, 3, tzinfo=datetime.timezone.utc), customer_id='CUST-00512', customer_tier='free', organization_id='ORG-439', product='Analytics Dashboard', product_version='3.2.6', product_module='data_aggregator', category='Data Issue', subcategory='Import/Export', priority='critical', severity='P1', channel='chat', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_NOTFOUND_404 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-03-19T12:22:39 ERROR ERROR_NOTFOUND_404: Database connection lost\\n2023-03-19T12:22:40 INFO Attempting to reconnect...\\n2023-03-19T12:22:42 ERROR Connection failed', stack_trace='', customer_sentiment='grateful', previous_tickets=7, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 3, 19, 14, 49, 3, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['contacted_customer', 'consulted_kb', 'verified_resolution'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['bug', 'performance', 'database'], environment='test', business_impact='high', affected_users=785, language='es', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000018', created_at=datetime.datetime(2024, 2, 19, 13, 10, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 19, 17, 4, 38, tzinfo=datetime.timezone.utc), customer_id='CUST-03147', customer_tier='free', organization_id='ORG-176', product='Analytics Dashboard', product_version='4.8.13', product_module='data_aggregator', category='Feature Request', subcategory='API', priority='medium', severity='P0', channel='chat', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-02-19T13:10:38 WARN Rate limit approaching threshold\\n2024-02-19T13:10:38 ERROR ERROR_SSL_CERT: Rate limit exceeded\\n2024-02-19T13:10:40 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='neutral', previous_tickets=5, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 2, 19, 17, 4, 38, tzinfo=datetime.timezone.utc), agent_id='AGENT-019', agent_actions=['ran_diagnostics', 'verified_resolution', 'updated_documentation', 'contacted_customer', 'checked_config'], escalated=True, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['performance', 'security', 'error', 'sync'], environment='production', business_impact='critical', affected_users=22, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000019', created_at=datetime.datetime(2023, 7, 25, 19, 31, 23, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 28, 23, 9, 11, tzinfo=datetime.timezone.utc), customer_id='CUST-02173', customer_tier='enterprise', organization_id='ORG-011', product='Analytics Dashboard', product_version='4.2.7', product_module='data_aggregator', category='Data Issue', subcategory='Sync Error', priority='medium', severity='P4', channel='email', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_CONNECTION_REFUSED appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-07-25T19:31:23 ERROR ERROR_CONNECTION_REFUSED: Database connection lost\\n2023-07-25T19:31:24 INFO Attempting to reconnect...\\n2023-07-25T19:31:26 ERROR Connection failed', stack_trace='', customer_sentiment='angry', previous_tickets=8, resolution='Applied hotfix version 3.2.2 to address the ERROR_CONNECTION_REFUSED. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 7, 28, 23, 9, 11, tzinfo=datetime.timezone.utc), agent_id='AGENT-037', agent_actions=['consulted_kb', 'escalated_to_specialist', 'applied_fix', 'created_workaround', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'database', 'data'], environment='sandbox', business_impact='medium', affected_users=48, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000020', created_at=datetime.datetime(2023, 2, 25, 3, 44, 58, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 25, 5, 47, 22, tzinfo=datetime.timezone.utc), customer_id='CUST-00389', customer_tier='starter', organization_id='ORG-131', product='Analytics Dashboard', product_version='4.3.4', product_module='export_module', category='Technical Issue', subcategory='Bug', priority='critical', severity='P0', channel='email', subject='Performance degradation in Analytics Dashboard', description=\"The Analytics Dashboard has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_TIMEOUT_429 in the logs. This is affecting our entire team's productivity.\", error_logs='2023-02-25T03:44:58 WARN Rate limit approaching threshold\\n2023-02-25T03:44:58 ERROR ERROR_TIMEOUT_429: Rate limit exceeded\\n2023-02-25T03:45:00 INFO Backing off for 60 seconds', stack_trace='Stack trace:\\n  export_module::processData() at export_module.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='satisfied', previous_tickets=8, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 2, 25, 5, 47, 22, tzinfo=datetime.timezone.utc), agent_id='AGENT-041', agent_actions=['escalated_to_specialist', 'viewed_logs', 'contacted_customer', 'applied_fix'], escalated=True, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['timeout', 'security', 'database', 'integration'], environment='sandbox', business_impact='low', affected_users=954, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000021', created_at=datetime.datetime(2023, 2, 22, 9, 20, 14, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 23, 8, 56, 14, tzinfo=datetime.timezone.utc), customer_id='CUST-00506', customer_tier='free', organization_id='ORG-455', product='Analytics Dashboard', product_version='2.4.7', product_module='visualization', category='Account Management', subcategory='Access Control', priority='medium', severity='P2', channel='api', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-02-22T09:20:14 ERROR ERROR_CORRUPTION: Connection timeout after 30s\\n2023-02-22T09:20:15 RETRY_FAILED: Max retries exceeded', stack_trace='ERROR: visualization.service.ServiceException: Failed to process request\\n\\tat visualization.handler.process(visualization.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='neutral', previous_tickets=5, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 2, 23, 8, 56, 14, tzinfo=datetime.timezone.utc), agent_id='AGENT-042', agent_actions=['applied_fix', 'created_workaround', 'verified_resolution', 'escalated_to_specialist'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['data', 'security', 'bug'], environment='test', business_impact='medium', affected_users=23, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000022', created_at=datetime.datetime(2023, 12, 30, 12, 12, 27, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 31, 20, 10, 3, tzinfo=datetime.timezone.utc), customer_id='CUST-02518', customer_tier='professional', organization_id='ORG-419', product='API Gateway', product_version='2.7.8', product_module='rate_limiter', category='Data Issue', subcategory='Sync Error', priority='low', severity='P3', channel='api', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=5, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 12, 31, 20, 10, 3, tzinfo=datetime.timezone.utc), agent_id='AGENT-044', agent_actions=['applied_fix', 'consulted_kb'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['sync', 'timeout', 'error', 'security'], environment='test', business_impact='critical', affected_users=21, language='it', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000023', created_at=datetime.datetime(2024, 10, 23, 16, 54, 4, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 23, 23, 57, 40, tzinfo=datetime.timezone.utc), customer_id='CUST-01392', customer_tier='free', organization_id='ORG-040', product='API Gateway', product_version='4.4.13', product_module='auth_service', category='Security', subcategory='Vulnerability', priority='critical', severity='P2', channel='email', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_CONFLICT_409 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-10-23T16:54:04 ERROR ERROR_CONFLICT_409: Database connection lost\\n2024-10-23T16:54:05 INFO Attempting to reconnect...\\n2024-10-23T16:54:07 ERROR Connection failed', stack_trace='', customer_sentiment='neutral', previous_tickets=6, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 10, 23, 23, 57, 40, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['viewed_logs', 'escalated_to_specialist', 'updated_documentation'], escalated=True, transferred_count=0, satisfaction_score=2, resolution_helpful=True, tags=['database', 'data', 'security', 'timeout'], environment='sandbox', business_impact='medium', affected_users=667, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000024', created_at=datetime.datetime(2024, 4, 13, 13, 3, 54, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 15, 4, 58, 30, tzinfo=datetime.timezone.utc), customer_id='CUST-03133', customer_tier='free', organization_id='ORG-433', product='CloudBackup Enterprise', product_version='3.8.3', product_module='restore_module', category='Security', subcategory='Authentication', priority='high', severity='P4', channel='api', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Getting ERROR_NOTFOUND_404 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-04-13T13:03:54 ERROR ERROR_NOTFOUND_404: Database connection lost\\n2024-04-13T13:03:55 INFO Attempting to reconnect...\\n2024-04-13T13:03:57 ERROR Connection failed', stack_trace=\"Traceback (most recent call last):\\n  File 'restore_module.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='grateful', previous_tickets=4, resolution='Applied hotfix version 3.2.2 to address the ERROR_NOTFOUND_404. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 4, 15, 4, 58, 30, tzinfo=datetime.timezone.utc), agent_id='AGENT-023', agent_actions=['created_workaround', 'verified_resolution'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['database', 'timeout'], environment='staging', business_impact='medium', affected_users=197, language='it', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000025', created_at=datetime.datetime(2024, 5, 22, 1, 5, 42, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 22, 1, 26, 42, tzinfo=datetime.timezone.utc), customer_id='CUST-02044', customer_tier='premium', organization_id='ORG-300', product='DataSync Pro', product_version='3.1.5', product_module='data_validator', category='Account Management', subcategory='Billing', priority='high', severity='P0', channel='phone', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-05-22T01:05:42 WARN Rate limit approaching threshold\\n2024-05-22T01:05:42 ERROR ERROR_TIMEOUT_429: Rate limit exceeded\\n2024-05-22T01:05:44 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='confused', previous_tickets=4, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 5, 22, 1, 26, 42, tzinfo=datetime.timezone.utc), agent_id='AGENT-013', agent_actions=['verified_resolution', 'checked_config'], escalated=False, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['authentication', 'security', 'sync', 'api'], environment='production', business_impact='high', affected_users=306, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000026', created_at=datetime.datetime(2024, 8, 19, 2, 24, 10, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 24, 5, 19, 22, tzinfo=datetime.timezone.utc), customer_id='CUST-03544', customer_tier='free', organization_id='ORG-368', product='Analytics Dashboard', product_version='2.3.9', product_module='report_builder', category='Feature Request', subcategory='Documentation', priority='low', severity='P4', channel='email', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=7, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 8, 24, 5, 19, 22, tzinfo=datetime.timezone.utc), agent_id='AGENT-017', agent_actions=['escalated_to_specialist', 'viewed_logs', 'checked_config', 'consulted_kb'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['api', 'performance'], environment='production', business_impact='medium', affected_users=9, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000027', created_at=datetime.datetime(2023, 11, 7, 9, 19, 6, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 7, 21, 39, 30, tzinfo=datetime.timezone.utc), customer_id='CUST-04601', customer_tier='starter', organization_id='ORG-110', product='API Gateway', product_version='2.6.14', product_module='request_router', category='Technical Issue', subcategory='Integration', priority='low', severity='P1', channel='slack', subject='API Gateway throwing ERROR_VALIDATION during operation', description=\"We're experiencing issues with API Gateway. The system is throwing ERROR_VALIDATION when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-11-07T09:19:06 ERROR ERROR_VALIDATION: Database connection lost\\n2023-11-07T09:19:07 INFO Attempting to reconnect...\\n2023-11-07T09:19:09 ERROR Connection failed', stack_trace='at request_router.execute(request_router.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='confused', previous_tickets=6, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 11, 7, 21, 39, 30, tzinfo=datetime.timezone.utc), agent_id='AGENT-049', agent_actions=['contacted_customer', 'created_workaround', 'consulted_kb'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['authentication', 'data', 'bug', 'api', 'configuration'], environment='sandbox', business_impact='high', affected_users=37, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000028', created_at=datetime.datetime(2023, 7, 14, 12, 32, 1, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 14, 18, 30, 49, tzinfo=datetime.timezone.utc), customer_id='CUST-00644', customer_tier='premium', organization_id='ORG-012', product='CloudBackup Enterprise', product_version='4.0.6', product_module='restore_module', category='Technical Issue', subcategory='Configuration', priority='medium', severity='P1', channel='slack', subject='CloudBackup Enterprise throwing errors during operation', description=\"We're experiencing issues with CloudBackup Enterprise. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=7, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 7, 14, 18, 30, 49, tzinfo=datetime.timezone.utc), agent_id='AGENT-028', agent_actions=['created_workaround', 'verified_resolution'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['performance', 'data', 'timeout'], environment='production', business_impact='critical', affected_users=6, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000029', created_at=datetime.datetime(2024, 2, 4, 21, 32, 14, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 5, 8, 52, 2, tzinfo=datetime.timezone.utc), customer_id='CUST-00950', customer_tier='starter', organization_id='ORG-479', product='CloudBackup Enterprise', product_version='3.5.6', product_module='backup_service', category='Feature Request', subcategory='Documentation', priority='low', severity='P1', channel='phone', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-02-04T21:32:14 WARN Rate limit approaching threshold\\n2024-02-04T21:32:14 ERROR ERROR_SSL_CERT: Rate limit exceeded\\n2024-02-04T21:32:16 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'backup_service.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='grateful', previous_tickets=1, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 2, 5, 8, 52, 2, tzinfo=datetime.timezone.utc), agent_id='AGENT-036', agent_actions=['checked_config', 'applied_fix'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['bug', 'security', 'timeout', 'integration'], environment='production', business_impact='high', affected_users=26, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000030', created_at=datetime.datetime(2024, 3, 7, 10, 19, 5, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 7, 20, 36, 29, tzinfo=datetime.timezone.utc), customer_id='CUST-04107', customer_tier='free', organization_id='ORG-085', product='DataSync Pro', product_version='4.5.8', product_module='api_connector', category='Technical Issue', subcategory='Performance', priority='critical', severity='P2', channel='slack', subject='Performance degradation in DataSync Pro', description=\"The DataSync Pro has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=10, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 3, 7, 20, 36, 29, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['checked_config', 'verified_resolution'], escalated=True, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['data', 'performance', 'authentication', 'error'], environment='sandbox', business_impact='critical', affected_users=352, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000031', created_at=datetime.datetime(2024, 8, 26, 11, 16, 54, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 26, 17, 13, 18, tzinfo=datetime.timezone.utc), customer_id='CUST-02785', customer_tier='starter', organization_id='ORG-440', product='DataSync Pro', product_version='2.2.0', product_module='sync_engine', category='Account Management', subcategory='Upgrade', priority='high', severity='P1', channel='api', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-08-26T11:16:54 DEBUG Processing request ID-12345\\n2024-08-26T11:16:54 ERROR ERROR_CONFLICT_409: Invalid request format\\n2024-08-26T11:16:55 INFO Request rejected', stack_trace='at sync_engine.execute(sync_engine.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='angry', previous_tickets=7, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 8, 26, 17, 13, 18, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['checked_config', 'consulted_kb'], escalated=True, transferred_count=3, satisfaction_score=3, resolution_helpful=False, tags=['database', 'configuration', 'integration'], environment='sandbox', business_impact='critical', affected_users=676, language='pt', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000032', created_at=datetime.datetime(2024, 9, 17, 16, 8, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 17, 19, 0, 21, tzinfo=datetime.timezone.utc), customer_id='CUST-02671', customer_tier='free', organization_id='ORG-273', product='Analytics Dashboard', product_version='4.5.1', product_module='report_builder', category='Security', subcategory='Compliance', priority='critical', severity='P1', channel='phone', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=1, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 9, 17, 19, 0, 21, tzinfo=datetime.timezone.utc), agent_id='AGENT-032', agent_actions=['contacted_customer', 'created_workaround', 'escalated_to_specialist', 'verified_resolution'], escalated=True, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['security', 'authentication'], environment='development', business_impact='high', affected_users=264, language='es', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000033', created_at=datetime.datetime(2024, 12, 13, 18, 41, 53, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 13, 23, 5, 53, tzinfo=datetime.timezone.utc), customer_id='CUST-03216', customer_tier='free', organization_id='ORG-306', product='CloudBackup Enterprise', product_version='4.3.4', product_module='compression_engine', category='Data Issue', subcategory='Sync Error', priority='medium', severity='P1', channel='chat', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_MEMORY_OOM appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-12-13T18:41:53 DEBUG Processing request ID-12345\\n2024-12-13T18:41:53 ERROR ERROR_MEMORY_OOM: Invalid request format\\n2024-12-13T18:41:54 INFO Request rejected', stack_trace='at compression_engine.execute(compression_engine.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='grateful', previous_tickets=6, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 12, 13, 23, 5, 53, tzinfo=datetime.timezone.utc), agent_id='AGENT-029', agent_actions=['applied_fix', 'checked_config', 'ran_diagnostics'], escalated=False, transferred_count=3, satisfaction_score=1, resolution_helpful=True, tags=['error', 'api'], environment='test', business_impact='medium', affected_users=37, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000034', created_at=datetime.datetime(2023, 6, 19, 5, 20, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 22, 21, 26, 38, tzinfo=datetime.timezone.utc), customer_id='CUST-03854', customer_tier='starter', organization_id='ORG-339', product='StreamProcessor', product_version='2.3.1', product_module='monitoring', category='Account Management', subcategory='Access Control', priority='medium', severity='P4', channel='chat', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-06-19T05:20:38 DEBUG Processing request ID-12345\\n2023-06-19T05:20:38 ERROR ERROR_CONFLICT_409: Invalid request format\\n2023-06-19T05:20:39 INFO Request rejected', stack_trace='', customer_sentiment='frustrated', previous_tickets=7, resolution='Root cause identified as Access Control issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 6, 22, 21, 26, 38, tzinfo=datetime.timezone.utc), agent_id='AGENT-036', agent_actions=['contacted_customer', 'ran_diagnostics', 'applied_fix', 'viewed_logs', 'created_workaround'], escalated=True, transferred_count=2, satisfaction_score=1, resolution_helpful=True, tags=['configuration', 'error', 'database'], environment='sandbox', business_impact='critical', affected_users=43, language='it', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000035', created_at=datetime.datetime(2023, 9, 9, 8, 53, 7, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 9, 12, 10, 31, tzinfo=datetime.timezone.utc), customer_id='CUST-01434', customer_tier='premium', organization_id='ORG-222', product='Analytics Dashboard', product_version='4.3.2', product_module='export_module', category='Technical Issue', subcategory='Performance', priority='critical', severity='P2', channel='api', subject='Performance degradation in Analytics Dashboard', description=\"The Analytics Dashboard has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_PERMISSION_403 in the logs. This is affecting our entire team's productivity.\", error_logs='2023-09-09T08:53:07 WARN Rate limit approaching threshold\\n2023-09-09T08:53:07 ERROR ERROR_PERMISSION_403: Rate limit exceeded\\n2023-09-09T08:53:09 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'export_module.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='frustrated', previous_tickets=6, resolution='Root cause identified as Performance issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 9, 9, 12, 10, 31, tzinfo=datetime.timezone.utc), agent_id='AGENT-025', agent_actions=['consulted_kb', 'updated_documentation', 'applied_fix', 'contacted_customer'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['integration', 'security', 'data'], environment='development', business_impact='medium', affected_users=875, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000036', created_at=datetime.datetime(2024, 2, 24, 19, 16, 47, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 26, 8, 17, 59, tzinfo=datetime.timezone.utc), customer_id='CUST-01693', customer_tier='professional', organization_id='ORG-313', product='StreamProcessor', product_version='4.7.0', product_module='batch_processor', category='Feature Request', subcategory='UI/UX', priority='high', severity='P3', channel='chat', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=8, resolution='Root cause identified as UI/UX issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 2, 26, 8, 17, 59, tzinfo=datetime.timezone.utc), agent_id='AGENT-050', agent_actions=['ran_diagnostics', 'created_workaround', 'viewed_logs', 'contacted_customer', 'verified_resolution'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['data', 'integration', 'timeout', 'api', 'sync'], environment='staging', business_impact='medium', affected_users=956, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000037', created_at=datetime.datetime(2024, 2, 1, 11, 4, 50, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 1, 15, 37, 14, tzinfo=datetime.timezone.utc), customer_id='CUST-01827', customer_tier='professional', organization_id='ORG-295', product='DataSync Pro', product_version='2.6.13', product_module='api_connector', category='Feature Request', subcategory='UI/UX', priority='medium', severity='P0', channel='slack', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=1, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 2, 1, 15, 37, 14, tzinfo=datetime.timezone.utc), agent_id='AGENT-009', agent_actions=['checked_config', 'consulted_kb', 'viewed_logs'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['data', 'api'], environment='staging', business_impact='low', affected_users=37, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000038', created_at=datetime.datetime(2024, 2, 27, 19, 53, 3, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 27, 22, 36, 15, tzinfo=datetime.timezone.utc), customer_id='CUST-01393', customer_tier='enterprise', organization_id='ORG-038', product='API Gateway', product_version='4.6.4', product_module='auth_service', category='Security', subcategory='Encryption', priority='high', severity='P1', channel='chat', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_CONFLICT_409 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-02-27T19:53:03 ERROR ERROR_CONFLICT_409: Database connection lost\\n2024-02-27T19:53:04 INFO Attempting to reconnect...\\n2024-02-27T19:53:06 ERROR Connection failed', stack_trace='Stack trace:\\n  auth_service::processData() at auth_service.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='satisfied', previous_tickets=1, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 2, 27, 22, 36, 15, tzinfo=datetime.timezone.utc), agent_id='AGENT-024', agent_actions=['applied_fix', 'created_workaround', 'viewed_logs', 'checked_config', 'contacted_customer'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=False, tags=['sync', 'database', 'api', 'authentication', 'error'], environment='development', business_impact='low', affected_users=453, language='zh', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000039', created_at=datetime.datetime(2024, 5, 27, 17, 34, 27, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 28, 5, 16, 27, tzinfo=datetime.timezone.utc), customer_id='CUST-02146', customer_tier='premium', organization_id='ORG-187', product='Analytics Dashboard', product_version='3.1.8', product_module='report_builder', category='Security', subcategory='Encryption', priority='low', severity='P1', channel='api', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_RATELIMIT_429 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-05-27T17:34:27 ERROR ERROR_RATELIMIT_429: Database connection lost\\n2024-05-27T17:34:28 INFO Attempting to reconnect...\\n2024-05-27T17:34:30 ERROR Connection failed', stack_trace='', customer_sentiment='neutral', previous_tickets=3, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 5, 28, 5, 16, 27, tzinfo=datetime.timezone.utc), agent_id='AGENT-040', agent_actions=['checked_config', 'contacted_customer', 'verified_resolution'], escalated=True, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['sync', 'performance', 'integration', 'security', 'data'], environment='test', business_impact='medium', affected_users=33, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000040', created_at=datetime.datetime(2023, 10, 4, 22, 20, 54, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 6, 8, 29, 54, tzinfo=datetime.timezone.utc), customer_id='CUST-04497', customer_tier='premium', organization_id='ORG-020', product='CloudBackup Enterprise', product_version='3.6.11', product_module='backup_service', category='Security', subcategory='Encryption', priority='high', severity='P3', channel='phone', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=9, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 10, 6, 8, 29, 54, tzinfo=datetime.timezone.utc), agent_id='AGENT-005', agent_actions=['verified_resolution', 'viewed_logs'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['bug', 'data', 'security'], environment='development', business_impact='critical', affected_users=672, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000041', created_at=datetime.datetime(2024, 4, 3, 20, 59, 42, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 4, 14, 23, 42, tzinfo=datetime.timezone.utc), customer_id='CUST-02014', customer_tier='free', organization_id='ORG-013', product='DataSync Pro', product_version='2.3.12', product_module='scheduler', category='Technical Issue', subcategory='Integration', priority='low', severity='P2', channel='portal', subject='DataSync Pro throwing ERROR_CORRUPTION during operation', description=\"We're experiencing issues with DataSync Pro. The system is throwing ERROR_CORRUPTION when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-04-03T20:59:42 ERROR ERROR_CORRUPTION: Connection timeout after 30s\\n2024-04-03T20:59:43 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='frustrated', previous_tickets=7, resolution='Root cause identified as Integration issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 4, 4, 14, 23, 42, tzinfo=datetime.timezone.utc), agent_id='AGENT-009', agent_actions=['viewed_logs', 'updated_documentation'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['data', 'sync'], environment='staging', business_impact='high', affected_users=1, language='zh', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000042', created_at=datetime.datetime(2024, 3, 27, 4, 5, 29, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 29, 16, 26, 29, tzinfo=datetime.timezone.utc), customer_id='CUST-02508', customer_tier='enterprise', organization_id='ORG-472', product='CloudBackup Enterprise', product_version='4.8.11', product_module='compression_engine', category='Technical Issue', subcategory='Bug', priority='low', severity='P3', channel='chat', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_SSL_CERT in the logs. This is affecting our entire team's productivity.\", error_logs='2024-03-27T04:05:29 WARN Rate limit approaching threshold\\n2024-03-27T04:05:29 ERROR ERROR_SSL_CERT: Rate limit exceeded\\n2024-03-27T04:05:31 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='confused', previous_tickets=8, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 3, 29, 16, 26, 29, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['checked_config', 'contacted_customer'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['bug', 'database', 'sync', 'authentication'], environment='sandbox', business_impact='low', affected_users=37, language='en', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000043', created_at=datetime.datetime(2024, 2, 19, 18, 39, 26, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 19, 20, 35, 14, tzinfo=datetime.timezone.utc), customer_id='CUST-03417', customer_tier='premium', organization_id='ORG-477', product='DataSync Pro', product_version='4.5.14', product_module='scheduler', category='Account Management', subcategory='License', priority='high', severity='P0', channel='api', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-02-19T18:39:26 DEBUG Processing request ID-12345\\n2024-02-19T18:39:26 ERROR ERROR_DEADLOCK: Invalid request format\\n2024-02-19T18:39:27 INFO Request rejected', stack_trace='', customer_sentiment='angry', previous_tickets=1, resolution='Applied hotfix version 3.2.2 to address the ERROR_DEADLOCK. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 2, 19, 20, 35, 14, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['viewed_logs', 'created_workaround'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=False, tags=['bug', 'timeout', 'data', 'sync', 'error'], environment='test', business_impact='high', affected_users=934, language='zh', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000044', created_at=datetime.datetime(2024, 3, 24, 12, 29, 10, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 24, 16, 36, 58, tzinfo=datetime.timezone.utc), customer_id='CUST-01349', customer_tier='starter', organization_id='ORG-393', product='StreamProcessor', product_version='4.8.10', product_module='event_handler', category='Security', subcategory='Compliance', priority='low', severity='P0', channel='slack', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=2, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 3, 24, 16, 36, 58, tzinfo=datetime.timezone.utc), agent_id='AGENT-017', agent_actions=['ran_diagnostics', 'checked_config', 'verified_resolution', 'applied_fix', 'consulted_kb'], escalated=False, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['authentication', 'integration', 'bug', 'timeout'], environment='production', business_impact='critical', affected_users=41, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000045', created_at=datetime.datetime(2023, 12, 12, 22, 1, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 14, 19, 8, 49, tzinfo=datetime.timezone.utc), customer_id='CUST-02636', customer_tier='premium', organization_id='ORG-470', product='Analytics Dashboard', product_version='4.7.5', product_module='export_module', category='Security', subcategory='Authorization', priority='critical', severity='P4', channel='api', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_SSL_CERT errors. We need to ensure our system meets compliance requirements.', error_logs='2023-12-12T22:01:37 ERROR ERROR_SSL_CERT: Connection timeout after 30s\\n2023-12-12T22:01:38 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'export_module.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='grateful', previous_tickets=4, resolution='Applied hotfix version 3.2.2 to address the ERROR_SSL_CERT. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 12, 14, 19, 8, 49, tzinfo=datetime.timezone.utc), agent_id='AGENT-018', agent_actions=['ran_diagnostics', 'contacted_customer', 'viewed_logs', 'created_workaround'], escalated=True, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['bug', 'api', 'integration', 'error', 'timeout'], environment='staging', business_impact='medium', affected_users=589, language='pt', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000046', created_at=datetime.datetime(2024, 2, 1, 8, 13, 2, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 1, 21, 38, 50, tzinfo=datetime.timezone.utc), customer_id='CUST-00547', customer_tier='premium', organization_id='ORG-037', product='Analytics Dashboard', product_version='4.1.13', product_module='export_module', category='Account Management', subcategory='License', priority='medium', severity='P2', channel='api', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-02-01T08:13:02 ERROR ERROR_CONNECTION_REFUSED: Database connection lost\\n2024-02-01T08:13:03 INFO Attempting to reconnect...\\n2024-02-01T08:13:05 ERROR Connection failed', stack_trace='', customer_sentiment='neutral', previous_tickets=5, resolution='Applied hotfix version 3.2.2 to address the ERROR_CONNECTION_REFUSED. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 2, 1, 21, 38, 50, tzinfo=datetime.timezone.utc), agent_id='AGENT-021', agent_actions=['verified_resolution', 'updated_documentation'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'integration', 'data', 'database', 'security'], environment='development', business_impact='low', affected_users=15, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000047', created_at=datetime.datetime(2024, 9, 18, 9, 25, 5, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 18, 14, 7, 41, tzinfo=datetime.timezone.utc), customer_id='CUST-03098', customer_tier='free', organization_id='ORG-215', product='API Gateway', product_version='4.3.15', product_module='cache_layer', category='Account Management', subcategory='Access Control', priority='high', severity='P2', channel='api', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=9, resolution='Root cause identified as Access Control issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 9, 18, 14, 7, 41, tzinfo=datetime.timezone.utc), agent_id='AGENT-050', agent_actions=['applied_fix', 'verified_resolution', 'viewed_logs'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['integration', 'configuration', 'performance'], environment='production', business_impact='medium', affected_users=115, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000048', created_at=datetime.datetime(2023, 11, 20, 19, 8, 53, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 22, 1, 0, 29, tzinfo=datetime.timezone.utc), customer_id='CUST-01617', customer_tier='premium', organization_id='ORG-287', product='DataSync Pro', product_version='2.8.0', product_module='api_connector', category='Account Management', subcategory='License', priority='low', severity='P2', channel='phone', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=8, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 11, 22, 1, 0, 29, tzinfo=datetime.timezone.utc), agent_id='AGENT-018', agent_actions=['checked_config', 'viewed_logs', 'updated_documentation', 'applied_fix', 'consulted_kb', 'created_workaround'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['error', 'data', 'database', 'bug'], environment='staging', business_impact='low', affected_users=22, language='fr', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000049', created_at=datetime.datetime(2023, 6, 21, 22, 22, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 24, 10, 7, 38, tzinfo=datetime.timezone.utc), customer_id='CUST-03086', customer_tier='starter', organization_id='ORG-010', product='Analytics Dashboard', product_version='2.4.13', product_module='export_module', category='Security', subcategory='Encryption', priority='low', severity='P3', channel='phone', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_MEMORY_OOM errors. We need to ensure our system meets compliance requirements.', error_logs='2023-06-21T22:22:38 DEBUG Processing request ID-12345\\n2023-06-21T22:22:38 ERROR ERROR_MEMORY_OOM: Invalid request format\\n2023-06-21T22:22:39 INFO Request rejected', stack_trace='', customer_sentiment='grateful', previous_tickets=5, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 6, 24, 10, 7, 38, tzinfo=datetime.timezone.utc), agent_id='AGENT-046', agent_actions=['consulted_kb', 'contacted_customer'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['api', 'security', 'integration', 'data', 'sync'], environment='development', business_impact='low', affected_users=26, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000050', created_at=datetime.datetime(2023, 1, 31, 15, 40, 31, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 2, 20, 52, 31, tzinfo=datetime.timezone.utc), customer_id='CUST-02218', customer_tier='free', organization_id='ORG-032', product='StreamProcessor', product_version='2.0.13', product_module='monitoring', category='Feature Request', subcategory='Documentation', priority='high', severity='P3', channel='api', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-01-31T15:40:31 DEBUG Processing request ID-12345\\n2023-01-31T15:40:31 ERROR ERROR_RATELIMIT_429: Invalid request format\\n2023-01-31T15:40:32 INFO Request rejected', stack_trace='', customer_sentiment='frustrated', previous_tickets=6, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 2, 2, 20, 52, 31, tzinfo=datetime.timezone.utc), agent_id='AGENT-023', agent_actions=['checked_config', 'applied_fix', 'contacted_customer', 'viewed_logs'], escalated=True, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['error', 'authentication', 'api', 'timeout'], environment='sandbox', business_impact='high', affected_users=237, language='es', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000051', created_at=datetime.datetime(2024, 2, 18, 13, 5, 25, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 22, 1, 23, 25, tzinfo=datetime.timezone.utc), customer_id='CUST-02084', customer_tier='starter', organization_id='ORG-391', product='CloudBackup Enterprise', product_version='4.2.1', product_module='compression_engine', category='Account Management', subcategory='License', priority='low', severity='P3', channel='slack', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-02-18T13:05:25 ERROR ERROR_RATELIMIT_429: Connection timeout after 30s\\n2024-02-18T13:05:26 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='satisfied', previous_tickets=10, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 2, 22, 1, 23, 25, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['applied_fix', 'contacted_customer'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['data', 'configuration'], environment='staging', business_impact='critical', affected_users=31, language='pt', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000052', created_at=datetime.datetime(2024, 8, 7, 19, 43, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 8, 23, 17, 17, tzinfo=datetime.timezone.utc), customer_id='CUST-03897', customer_tier='free', organization_id='ORG-307', product='Analytics Dashboard', product_version='3.8.9', product_module='report_builder', category='Feature Request', subcategory='UI/UX', priority='medium', severity='P3', channel='portal', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-08-07T19:43:41 DEBUG Processing request ID-12345\\n2024-08-07T19:43:41 ERROR ERROR_MEMORY_OOM: Invalid request format\\n2024-08-07T19:43:42 INFO Request rejected', stack_trace=\"Traceback (most recent call last):\\n  File 'report_builder.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='satisfied', previous_tickets=6, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 8, 8, 23, 17, 17, tzinfo=datetime.timezone.utc), agent_id='AGENT-040', agent_actions=['verified_resolution', 'viewed_logs', 'applied_fix', 'created_workaround', 'updated_documentation'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['data', 'security', 'configuration'], environment='production', business_impact='high', affected_users=27, language='it', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000053', created_at=datetime.datetime(2023, 12, 18, 6, 39, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 19, 9, 42, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-03647', customer_tier='professional', organization_id='ORG-154', product='StreamProcessor', product_version='4.6.13', product_module='event_handler', category='Security', subcategory='Encryption', priority='critical', severity='P3', channel='api', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Getting ERROR_NOTFOUND_404 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-12-18T06:39:39 ERROR ERROR_NOTFOUND_404: Connection timeout after 30s\\n2023-12-18T06:39:40 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='angry', previous_tickets=2, resolution='Root cause identified as Encryption issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 12, 19, 9, 42, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-042', agent_actions=['created_workaround', 'verified_resolution'], escalated=True, transferred_count=2, satisfaction_score=4, resolution_helpful=False, tags=['security', 'authentication', 'bug', 'sync', 'performance'], environment='development', business_impact='low', affected_users=2, language='en', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000054', created_at=datetime.datetime(2023, 10, 2, 5, 6, 1, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 3, 12, 49, 49, tzinfo=datetime.timezone.utc), customer_id='CUST-02173', customer_tier='enterprise', organization_id='ORG-011', product='StreamProcessor', product_version='2.0.9', product_module='monitoring', category='Feature Request', subcategory='UI/UX', priority='medium', severity='P3', channel='slack', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-10-02T05:06:01 DEBUG Processing request ID-12345\\n2023-10-02T05:06:01 ERROR ERROR_CONNECTION_REFUSED: Invalid request format\\n2023-10-02T05:06:02 INFO Request rejected', stack_trace='', customer_sentiment='confused', previous_tickets=1, resolution='Root cause identified as UI/UX issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 10, 3, 12, 49, 49, tzinfo=datetime.timezone.utc), agent_id='AGENT-041', agent_actions=['escalated_to_specialist', 'checked_config'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'error', 'timeout', 'data', 'database'], environment='sandbox', business_impact='critical', affected_users=46, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000055', created_at=datetime.datetime(2024, 8, 15, 14, 20, 4, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 15, 21, 10, 28, tzinfo=datetime.timezone.utc), customer_id='CUST-03378', customer_tier='starter', organization_id='ORG-249', product='API Gateway', product_version='3.1.8', product_module='request_router', category='Data Issue', subcategory='Corruption', priority='low', severity='P1', channel='api', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=10, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 8, 15, 21, 10, 28, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['applied_fix', 'verified_resolution'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['error', 'configuration', 'sync', 'api', 'timeout'], environment='sandbox', business_impact='high', affected_users=5, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000056', created_at=datetime.datetime(2023, 11, 2, 10, 41, 13, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 3, 5, 10, 1, tzinfo=datetime.timezone.utc), customer_id='CUST-04958', customer_tier='professional', organization_id='ORG-414', product='API Gateway', product_version='2.9.12', product_module='auth_service', category='Technical Issue', subcategory='Configuration', priority='critical', severity='P3', channel='api', subject='API Gateway throwing ERROR_SERVER_500 during operation', description=\"We're experiencing issues with API Gateway. The system is throwing ERROR_SERVER_500 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-11-02T10:41:13 ERROR ERROR_SERVER_500: Connection timeout after 30s\\n2023-11-02T10:41:14 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='frustrated', previous_tickets=4, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 11, 3, 5, 10, 1, tzinfo=datetime.timezone.utc), agent_id='AGENT-022', agent_actions=['created_workaround', 'checked_config', 'updated_documentation'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['database', 'bug', 'timeout', 'configuration', 'data'], environment='development', business_impact='low', affected_users=161, language='de', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000057', created_at=datetime.datetime(2023, 12, 4, 12, 45, 49, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 4, 16, 59, 1, tzinfo=datetime.timezone.utc), customer_id='CUST-00528', customer_tier='free', organization_id='ORG-103', product='StreamProcessor', product_version='2.9.7', product_module='error_handler', category='Technical Issue', subcategory='Integration', priority='critical', severity='P1', channel='chat', subject='StreamProcessor throwing errors during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=2, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 12, 4, 16, 59, 1, tzinfo=datetime.timezone.utc), agent_id='AGENT-016', agent_actions=['escalated_to_specialist', 'contacted_customer'], escalated=True, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['security', 'configuration'], environment='test', business_impact='high', affected_users=871, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000058', created_at=datetime.datetime(2023, 11, 17, 6, 57, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 18, 3, 18, tzinfo=datetime.timezone.utc), customer_id='CUST-04087', customer_tier='free', organization_id='ORG-329', product='Analytics Dashboard', product_version='2.6.9', product_module='data_aggregator', category='Account Management', subcategory='Billing', priority='critical', severity='P3', channel='portal', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-11-17T06:57:00 ERROR ERROR_MEMORY_OOM: Database connection lost\\n2023-11-17T06:57:01 INFO Attempting to reconnect...\\n2023-11-17T06:57:03 ERROR Connection failed', stack_trace='', customer_sentiment='neutral', previous_tickets=3, resolution='Applied hotfix version 3.2.2 to address the ERROR_MEMORY_OOM. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 11, 18, 3, 18, tzinfo=datetime.timezone.utc), agent_id='AGENT-018', agent_actions=['verified_resolution', 'contacted_customer', 'consulted_kb', 'created_workaround', 'applied_fix'], escalated=True, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['performance', 'authentication', 'api', 'configuration', 'data'], environment='test', business_impact='low', affected_users=354, language='pt', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000059', created_at=datetime.datetime(2023, 6, 19, 18, 34, 12, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 20, 8, 31, 12, tzinfo=datetime.timezone.utc), customer_id='CUST-00005', customer_tier='starter', organization_id='ORG-217', product='API Gateway', product_version='4.5.14', product_module='request_router', category='Feature Request', subcategory='Documentation', priority='critical', severity='P3', channel='email', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=1, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 6, 20, 8, 31, 12, tzinfo=datetime.timezone.utc), agent_id='AGENT-012', agent_actions=['updated_documentation', 'escalated_to_specialist'], escalated=True, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['performance', 'authentication', 'api', 'sync'], environment='staging', business_impact='high', affected_users=243, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000060', created_at=datetime.datetime(2023, 5, 3, 13, 48, 32, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 3, 17, 27, 32, tzinfo=datetime.timezone.utc), customer_id='CUST-03593', customer_tier='professional', organization_id='ORG-307', product='DataSync Pro', product_version='2.2.6', product_module='data_validator', category='Feature Request', subcategory='Documentation', priority='high', severity='P0', channel='api', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-05-03T13:48:32 WARN Rate limit approaching threshold\\n2023-05-03T13:48:32 ERROR ERROR_PARSING: Rate limit exceeded\\n2023-05-03T13:48:34 INFO Backing off for 60 seconds', stack_trace='Stack trace:\\n  data_validator::processData() at data_validator.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='neutral', previous_tickets=0, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 5, 3, 17, 27, 32, tzinfo=datetime.timezone.utc), agent_id='AGENT-041', agent_actions=['updated_documentation', 'created_workaround', 'ran_diagnostics', 'checked_config', 'verified_resolution'], escalated=True, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['configuration', 'security', 'bug'], environment='production', business_impact='critical', affected_users=831, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000061', created_at=datetime.datetime(2023, 5, 25, 9, 30, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 25, 10, 34, 15, tzinfo=datetime.timezone.utc), customer_id='CUST-01282', customer_tier='enterprise', organization_id='ORG-246', product='DataSync Pro', product_version='3.5.4', product_module='api_connector', category='Technical Issue', subcategory='Compatibility', priority='critical', severity='P0', channel='portal', subject='Performance degradation in DataSync Pro', description=\"The DataSync Pro has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_SSL_CERT in the logs. This is affecting our entire team's productivity.\", error_logs='2023-05-25T09:30:39 WARN Rate limit approaching threshold\\n2023-05-25T09:30:39 ERROR ERROR_SSL_CERT: Rate limit exceeded\\n2023-05-25T09:30:41 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'api_connector.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='frustrated', previous_tickets=4, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 5, 25, 10, 34, 15, tzinfo=datetime.timezone.utc), agent_id='AGENT-033', agent_actions=['escalated_to_specialist', 'updated_documentation', 'ran_diagnostics', 'consulted_kb', 'verified_resolution', 'contacted_customer'], escalated=False, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['authentication', 'performance', 'sync', 'security'], environment='development', business_impact='high', affected_users=821, language='es', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000062', created_at=datetime.datetime(2023, 3, 12, 8, 10, 25, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 14, 5, 7, 25, tzinfo=datetime.timezone.utc), customer_id='CUST-02587', customer_tier='premium', organization_id='ORG-130', product='StreamProcessor', product_version='2.4.5', product_module='monitoring', category='Technical Issue', subcategory='Compatibility', priority='high', severity='P4', channel='phone', subject='StreamProcessor throwing ERROR_SSL_CERT during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing ERROR_SSL_CERT when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-03-12T08:10:25 ERROR ERROR_SSL_CERT: Connection timeout after 30s\\n2023-03-12T08:10:26 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'monitoring.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='neutral', previous_tickets=7, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 3, 14, 5, 7, 25, tzinfo=datetime.timezone.utc), agent_id='AGENT-036', agent_actions=['created_workaround', 'ran_diagnostics', 'verified_resolution'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=True, tags=['api', 'configuration'], environment='test', business_impact='critical', affected_users=798, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000063', created_at=datetime.datetime(2023, 11, 25, 20, 27, 51, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 25, 23, 9, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-04227', customer_tier='enterprise', organization_id='ORG-307', product='API Gateway', product_version='3.1.11', product_module='auth_service', category='Feature Request', subcategory='Documentation', priority='critical', severity='P1', channel='email', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-11-25T20:27:51 DEBUG Processing request ID-12345\\n2023-11-25T20:27:51 ERROR ERROR_PERMISSION_403: Invalid request format\\n2023-11-25T20:27:52 INFO Request rejected', stack_trace='at auth_service.execute(auth_service.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='grateful', previous_tickets=4, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 11, 25, 23, 9, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['checked_config', 'viewed_logs', 'verified_resolution'], escalated=True, transferred_count=0, satisfaction_score=4, resolution_helpful=False, tags=['api', 'database', 'data', 'sync', 'bug'], environment='development', business_impact='medium', affected_users=664, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000064', created_at=datetime.datetime(2024, 7, 1, 7, 13, 8, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 3, 15, 59, 20, tzinfo=datetime.timezone.utc), customer_id='CUST-02331', customer_tier='free', organization_id='ORG-468', product='Analytics Dashboard', product_version='2.0.8', product_module='export_module', category='Account Management', subcategory='Billing', priority='low', severity='P4', channel='phone', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-07-01T07:13:08 WARN Rate limit approaching threshold\\n2024-07-01T07:13:08 ERROR ERROR_CONNECTION_REFUSED: Rate limit exceeded\\n2024-07-01T07:13:10 INFO Backing off for 60 seconds', stack_trace='at export_module.execute(export_module.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='confused', previous_tickets=8, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 7, 3, 15, 59, 20, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['viewed_logs', 'contacted_customer', 'consulted_kb', 'escalated_to_specialist', 'applied_fix', 'created_workaround'], escalated=True, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['error', 'timeout', 'security', 'sync', 'performance'], environment='test', business_impact='low', affected_users=26, language='zh', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000065', created_at=datetime.datetime(2024, 12, 8, 14, 50, 21, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 8, 17, 40, 9, tzinfo=datetime.timezone.utc), customer_id='CUST-03329', customer_tier='enterprise', organization_id='ORG-161', product='StreamProcessor', product_version='4.3.2', product_module='event_handler', category='Feature Request', subcategory='Enhancement', priority='medium', severity='P0', channel='phone', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=1, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 12, 8, 17, 40, 9, tzinfo=datetime.timezone.utc), agent_id='AGENT-035', agent_actions=['escalated_to_specialist', 'ran_diagnostics', 'checked_config', 'updated_documentation'], escalated=True, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['api', 'sync', 'performance'], environment='production', business_impact='low', affected_users=24, language='en', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000066', created_at=datetime.datetime(2023, 7, 22, 21, 47, 20, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 22, 22, 27, 32, tzinfo=datetime.timezone.utc), customer_id='CUST-01519', customer_tier='professional', organization_id='ORG-372', product='Analytics Dashboard', product_version='2.4.4', product_module='data_aggregator', category='Security', subcategory='Authorization', priority='critical', severity='P0', channel='phone', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=5, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 7, 22, 22, 27, 32, tzinfo=datetime.timezone.utc), agent_id='AGENT-028', agent_actions=['created_workaround', 'escalated_to_specialist', 'contacted_customer', 'checked_config', 'viewed_logs', 'consulted_kb'], escalated=True, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['api', 'timeout', 'sync'], environment='development', business_impact='critical', affected_users=348, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000067', created_at=datetime.datetime(2023, 11, 9, 5, 8, 8, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 11, 3, 5, 8, tzinfo=datetime.timezone.utc), customer_id='CUST-00055', customer_tier='starter', organization_id='ORG-065', product='StreamProcessor', product_version='4.6.13', product_module='event_handler', category='Security', subcategory='Vulnerability', priority='medium', severity='P4', channel='api', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Getting ERROR_CORRUPTION errors. We need to ensure our system meets compliance requirements.', error_logs='2023-11-09T05:08:08 ERROR ERROR_CORRUPTION: Database connection lost\\n2023-11-09T05:08:09 INFO Attempting to reconnect...\\n2023-11-09T05:08:11 ERROR Connection failed', stack_trace='', customer_sentiment='grateful', previous_tickets=9, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 11, 11, 3, 5, 8, tzinfo=datetime.timezone.utc), agent_id='AGENT-024', agent_actions=['applied_fix', 'contacted_customer', 'escalated_to_specialist'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['api', 'error', 'bug'], environment='test', business_impact='medium', affected_users=7, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000068', created_at=datetime.datetime(2024, 4, 8, 14, 31, 7, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 10, 13, 14, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-03963', customer_tier='premium', organization_id='ORG-073', product='DataSync Pro', product_version='3.7.7', product_module='scheduler', category='Feature Request', subcategory='UI/UX', priority='low', severity='P3', channel='phone', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-04-08T14:31:07 ERROR ERROR_MEMORY_OOM: Connection timeout after 30s\\n2024-04-08T14:31:08 RETRY_FAILED: Max retries exceeded', stack_trace='at scheduler.execute(scheduler.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='frustrated', previous_tickets=9, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 4, 10, 13, 14, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-029', agent_actions=['contacted_customer', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['api', 'database', 'data', 'bug', 'timeout'], environment='development', business_impact='critical', affected_users=36, language='de', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000069', created_at=datetime.datetime(2023, 4, 23, 7, 40, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 23, 21, 13, 2, tzinfo=datetime.timezone.utc), customer_id='CUST-04958', customer_tier='professional', organization_id='ORG-414', product='Analytics Dashboard', product_version='2.9.4', product_module='visualization', category='Security', subcategory='Authorization', priority='critical', severity='P4', channel='email', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_MEMORY_OOM errors. We need to ensure our system meets compliance requirements.', error_logs='2023-04-23T07:40:38 ERROR ERROR_MEMORY_OOM: Connection timeout after 30s\\n2023-04-23T07:40:39 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='frustrated', previous_tickets=10, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 4, 23, 21, 13, 2, tzinfo=datetime.timezone.utc), agent_id='AGENT-009', agent_actions=['viewed_logs', 'contacted_customer', 'applied_fix', 'verified_resolution', 'consulted_kb'], escalated=True, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['integration', 'database'], environment='production', business_impact='medium', affected_users=65, language='de', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000070', created_at=datetime.datetime(2023, 12, 25, 17, 26, 14, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 25, 18, 14, 14, tzinfo=datetime.timezone.utc), customer_id='CUST-01893', customer_tier='free', organization_id='ORG-011', product='CloudBackup Enterprise', product_version='3.2.3', product_module='backup_service', category='Account Management', subcategory='Subscription', priority='medium', severity='P0', channel='slack', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-12-25T17:26:14 ERROR ERROR_CONFLICT_409: Connection timeout after 30s\\n2023-12-25T17:26:15 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='neutral', previous_tickets=5, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 12, 25, 18, 14, 14, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['escalated_to_specialist', 'verified_resolution', 'consulted_kb', 'checked_config'], escalated=True, transferred_count=0, satisfaction_score=5, resolution_helpful=False, tags=['configuration', 'bug', 'error', 'sync'], environment='production', business_impact='high', affected_users=26, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000071', created_at=datetime.datetime(2024, 11, 19, 16, 27, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 22, 2, 32, 29, tzinfo=datetime.timezone.utc), customer_id='CUST-00254', customer_tier='starter', organization_id='ORG-214', product='StreamProcessor', product_version='2.5.13', product_module='batch_processor', category='Feature Request', subcategory='UI/UX', priority='medium', severity='P4', channel='portal', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-11-19T16:27:41 WARN Rate limit approaching threshold\\n2024-11-19T16:27:41 ERROR ERROR_PERMISSION_403: Rate limit exceeded\\n2024-11-19T16:27:43 INFO Backing off for 60 seconds', stack_trace='at batch_processor.execute(batch_processor.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='grateful', previous_tickets=5, resolution='Applied hotfix version 3.2.2 to address the ERROR_PERMISSION_403. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 11, 22, 2, 32, 29, tzinfo=datetime.timezone.utc), agent_id='AGENT-006', agent_actions=['contacted_customer', 'updated_documentation', 'ran_diagnostics'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['authentication', 'security', 'sync', 'integration'], environment='staging', business_impact='medium', affected_users=34, language='de', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000072', created_at=datetime.datetime(2023, 3, 17, 23, 23, 56, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 18, 14, 28, 44, tzinfo=datetime.timezone.utc), customer_id='CUST-03084', customer_tier='enterprise', organization_id='ORG-141', product='DataSync Pro', product_version='4.8.7', product_module='api_connector', category='Data Issue', subcategory='Sync Error', priority='critical', severity='P4', channel='email', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=1, resolution='Root cause identified as Sync Error issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 3, 18, 14, 28, 44, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['escalated_to_specialist', 'checked_config', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['performance', 'timeout'], environment='development', business_impact='critical', affected_users=451, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000073', created_at=datetime.datetime(2024, 12, 11, 22, 33, 22, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 12, 20, 24, 58, tzinfo=datetime.timezone.utc), customer_id='CUST-01777', customer_tier='starter', organization_id='ORG-374', product='CloudBackup Enterprise', product_version='2.0.2', product_module='encryption_layer', category='Technical Issue', subcategory='Bug', priority='high', severity='P4', channel='api', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_TIMEOUT_429 in the logs. This is affecting our entire team's productivity.\", error_logs='2024-12-11T22:33:22 ERROR ERROR_TIMEOUT_429: Connection timeout after 30s\\n2024-12-11T22:33:23 RETRY_FAILED: Max retries exceeded', stack_trace='ERROR: encryption_layer.service.ServiceException: Failed to process request\\n\\tat encryption_layer.handler.process(encryption_layer.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='grateful', previous_tickets=10, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 12, 12, 20, 24, 58, tzinfo=datetime.timezone.utc), agent_id='AGENT-005', agent_actions=['consulted_kb', 'viewed_logs'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['api', 'database', 'integration'], environment='staging', business_impact='medium', affected_users=311, language='ja', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000074', created_at=datetime.datetime(2023, 7, 16, 21, 11, 20, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 17, 10, 55, 44, tzinfo=datetime.timezone.utc), customer_id='CUST-00572', customer_tier='enterprise', organization_id='ORG-499', product='API Gateway', product_version='2.5.9', product_module='request_router', category='Account Management', subcategory='License', priority='critical', severity='P3', channel='email', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=3, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 7, 17, 10, 55, 44, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['contacted_customer', 'created_workaround'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['error', 'bug', 'performance'], environment='staging', business_impact='low', affected_users=655, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000075', created_at=datetime.datetime(2023, 11, 29, 14, 53, 10, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 2, 8, 50, 10, tzinfo=datetime.timezone.utc), customer_id='CUST-03962', customer_tier='premium', organization_id='ORG-036', product='StreamProcessor', product_version='4.0.11', product_module='error_handler', category='Data Issue', subcategory='Import/Export', priority='low', severity='P4', channel='chat', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_MEMORY_OOM appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-11-29T14:53:10 ERROR ERROR_MEMORY_OOM: Connection timeout after 30s\\n2023-11-29T14:53:11 RETRY_FAILED: Max retries exceeded', stack_trace='ERROR: error_handler.service.ServiceException: Failed to process request\\n\\tat error_handler.handler.process(error_handler.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='frustrated', previous_tickets=10, resolution='Root cause identified as Import/Export issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 12, 2, 8, 50, 10, tzinfo=datetime.timezone.utc), agent_id='AGENT-035', agent_actions=['ran_diagnostics', 'updated_documentation', 'consulted_kb', 'verified_resolution', 'checked_config'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['authentication', 'timeout', 'data', 'sync', 'performance'], environment='staging', business_impact='medium', affected_users=19, language='pt', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000076', created_at=datetime.datetime(2024, 5, 8, 13, 36, 8, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 10, 19, 3, 8, tzinfo=datetime.timezone.utc), customer_id='CUST-00631', customer_tier='free', organization_id='ORG-395', product='DataSync Pro', product_version='2.7.3', product_module='sync_engine', category='Security', subcategory='Vulnerability', priority='high', severity='P4', channel='phone', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_VALIDATION errors. We need to ensure our system meets compliance requirements.', error_logs='2024-05-08T13:36:08 ERROR ERROR_VALIDATION: Connection timeout after 30s\\n2024-05-08T13:36:09 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='neutral', previous_tickets=4, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 5, 10, 19, 3, 8, tzinfo=datetime.timezone.utc), agent_id='AGENT-028', agent_actions=['created_workaround', 'ran_diagnostics', 'checked_config'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['configuration', 'timeout', 'bug', 'security', 'integration'], environment='staging', business_impact='low', affected_users=379, language='de', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000077', created_at=datetime.datetime(2023, 2, 20, 21, 6, 43, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 22, 3, 26, 31, tzinfo=datetime.timezone.utc), customer_id='CUST-04164', customer_tier='free', organization_id='ORG-342', product='StreamProcessor', product_version='4.4.9', product_module='error_handler', category='Feature Request', subcategory='UI/UX', priority='low', severity='P2', channel='slack', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-02-20T21:06:43 ERROR ERROR_RATELIMIT_429: Connection timeout after 30s\\n2023-02-20T21:06:44 RETRY_FAILED: Max retries exceeded', stack_trace='Stack trace:\\n  error_handler::processData() at error_handler.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='neutral', previous_tickets=3, resolution='Applied hotfix version 3.2.2 to address the ERROR_RATELIMIT_429. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 2, 22, 3, 26, 31, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['escalated_to_specialist', 'ran_diagnostics', 'contacted_customer', 'applied_fix', 'verified_resolution'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=True, tags=['configuration', 'timeout', 'database'], environment='staging', business_impact='high', affected_users=14, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000078', created_at=datetime.datetime(2023, 7, 13, 1, 20, 30, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 13, 1, 46, 18, tzinfo=datetime.timezone.utc), customer_id='CUST-04791', customer_tier='enterprise', organization_id='ORG-015', product='API Gateway', product_version='2.5.10', product_module='rate_limiter', category='Security', subcategory='Vulnerability', priority='critical', severity='P0', channel='slack', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=8, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 7, 13, 1, 46, 18, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['updated_documentation', 'ran_diagnostics'], escalated=True, transferred_count=2, satisfaction_score=1, resolution_helpful=True, tags=['error', 'sync'], environment='development', business_impact='low', affected_users=826, language='zh', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000079', created_at=datetime.datetime(2024, 12, 8, 8, 37, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 9, 2, 5, 53, tzinfo=datetime.timezone.utc), customer_id='CUST-01117', customer_tier='premium', organization_id='ORG-192', product='StreamProcessor', product_version='2.6.3', product_module='error_handler', category='Data Issue', subcategory='Import/Export', priority='medium', severity='P2', channel='api', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_PARSING appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-12-08T08:37:41 WARN Rate limit approaching threshold\\n2024-12-08T08:37:41 ERROR ERROR_PARSING: Rate limit exceeded\\n2024-12-08T08:37:43 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'error_handler.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='satisfied', previous_tickets=0, resolution='Root cause identified as Import/Export issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 12, 9, 2, 5, 53, tzinfo=datetime.timezone.utc), agent_id='AGENT-047', agent_actions=['viewed_logs', 'escalated_to_specialist'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['integration', 'timeout'], environment='sandbox', business_impact='high', affected_users=31, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000080', created_at=datetime.datetime(2023, 10, 7, 18, 20, 54, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 7, 21, 0, 30, tzinfo=datetime.timezone.utc), customer_id='CUST-01998', customer_tier='professional', organization_id='ORG-107', product='Analytics Dashboard', product_version='4.7.8', product_module='visualization', category='Data Issue', subcategory='Sync Error', priority='medium', severity='P0', channel='phone', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_TIMEOUT_429 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-10-07T18:20:54 WARN Rate limit approaching threshold\\n2023-10-07T18:20:54 ERROR ERROR_TIMEOUT_429: Rate limit exceeded\\n2023-10-07T18:20:56 INFO Backing off for 60 seconds', stack_trace='at visualization.execute(visualization.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='satisfied', previous_tickets=5, resolution='Root cause identified as Sync Error issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 10, 7, 21, 0, 30, tzinfo=datetime.timezone.utc), agent_id='AGENT-010', agent_actions=['applied_fix', 'viewed_logs', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['security', 'error'], environment='sandbox', business_impact='critical', affected_users=21, language='en', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000081', created_at=datetime.datetime(2024, 4, 8, 12, 16, 28, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 9, 1, 45, 52, tzinfo=datetime.timezone.utc), customer_id='CUST-04927', customer_tier='professional', organization_id='ORG-049', product='CloudBackup Enterprise', product_version='3.6.13', product_module='backup_service', category='Technical Issue', subcategory='Configuration', priority='medium', severity='P2', channel='chat', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_NOTFOUND_404 in the logs. This is affecting our entire team's productivity.\", error_logs='2024-04-08T12:16:28 ERROR ERROR_NOTFOUND_404: Database connection lost\\n2024-04-08T12:16:29 INFO Attempting to reconnect...\\n2024-04-08T12:16:31 ERROR Connection failed', stack_trace=\"Traceback (most recent call last):\\n  File 'backup_service.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='angry', previous_tickets=6, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 4, 9, 1, 45, 52, tzinfo=datetime.timezone.utc), agent_id='AGENT-048', agent_actions=['consulted_kb', 'contacted_customer', 'verified_resolution'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['bug', 'integration'], environment='development', business_impact='medium', affected_users=44, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000082', created_at=datetime.datetime(2024, 3, 8, 12, 51, 43, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 9, 19, 22, 19, tzinfo=datetime.timezone.utc), customer_id='CUST-03055', customer_tier='professional', organization_id='ORG-418', product='DataSync Pro', product_version='4.8.7', product_module='scheduler', category='Security', subcategory='Vulnerability', priority='low', severity='P2', channel='chat', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=1, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 3, 9, 19, 22, 19, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['contacted_customer', 'ran_diagnostics', 'checked_config', 'verified_resolution', 'viewed_logs'], escalated=True, transferred_count=1, satisfaction_score=1, resolution_helpful=False, tags=['error', 'timeout', 'performance', 'authentication', 'integration'], environment='test', business_impact='high', affected_users=20, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000083', created_at=datetime.datetime(2023, 8, 26, 11, 34, 55, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 26, 21, 52, 19, tzinfo=datetime.timezone.utc), customer_id='CUST-04344', customer_tier='premium', organization_id='ORG-206', product='DataSync Pro', product_version='3.9.6', product_module='sync_engine', category='Security', subcategory='Vulnerability', priority='critical', severity='P2', channel='email', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_DISK_FULL errors. We need to ensure our system meets compliance requirements.', error_logs='2023-08-26T11:34:55 DEBUG Processing request ID-12345\\n2023-08-26T11:34:55 ERROR ERROR_DISK_FULL: Invalid request format\\n2023-08-26T11:34:56 INFO Request rejected', stack_trace='', customer_sentiment='angry', previous_tickets=9, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 8, 26, 21, 52, 19, tzinfo=datetime.timezone.utc), agent_id='AGENT-037', agent_actions=['ran_diagnostics', 'escalated_to_specialist', 'contacted_customer', 'verified_resolution', 'created_workaround'], escalated=True, transferred_count=2, satisfaction_score=1, resolution_helpful=True, tags=['integration', 'security', 'authentication', 'sync', 'database'], environment='sandbox', business_impact='high', affected_users=877, language='es', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000084', created_at=datetime.datetime(2024, 1, 6, 20, 39, 17, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 6, 23, 59, 5, tzinfo=datetime.timezone.utc), customer_id='CUST-02274', customer_tier='starter', organization_id='ORG-398', product='API Gateway', product_version='2.0.14', product_module='rate_limiter', category='Account Management', subcategory='Billing', priority='high', severity='P1', channel='chat', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-01-06T20:39:17 DEBUG Processing request ID-12345\\n2024-01-06T20:39:17 ERROR ERROR_DEADLOCK: Invalid request format\\n2024-01-06T20:39:18 INFO Request rejected', stack_trace='ERROR: rate_limiter.service.ServiceException: Failed to process request\\n\\tat rate_limiter.handler.process(rate_limiter.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='grateful', previous_tickets=7, resolution='Applied hotfix version 3.2.2 to address the ERROR_DEADLOCK. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 1, 6, 23, 59, 5, tzinfo=datetime.timezone.utc), agent_id='AGENT-029', agent_actions=['viewed_logs', 'created_workaround', 'verified_resolution', 'ran_diagnostics'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['api', 'authentication', 'security', 'data', 'integration'], environment='sandbox', business_impact='medium', affected_users=797, language='ja', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000085', created_at=datetime.datetime(2024, 6, 13, 5, 10, 13, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 13, 18, 31, 49, tzinfo=datetime.timezone.utc), customer_id='CUST-03807', customer_tier='enterprise', organization_id='ORG-240', product='Analytics Dashboard', product_version='4.4.0', product_module='data_aggregator', category='Security', subcategory='Authorization', priority='high', severity='P3', channel='chat', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_AUTH_401 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-06-13T05:10:13 WARN Rate limit approaching threshold\\n2024-06-13T05:10:13 ERROR ERROR_AUTH_401: Rate limit exceeded\\n2024-06-13T05:10:15 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='angry', previous_tickets=4, resolution='Applied hotfix version 3.2.2 to address the ERROR_AUTH_401. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 6, 13, 18, 31, 49, tzinfo=datetime.timezone.utc), agent_id='AGENT-028', agent_actions=['consulted_kb', 'escalated_to_specialist', 'checked_config'], escalated=True, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['performance', 'authentication', 'bug'], environment='sandbox', business_impact='medium', affected_users=587, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000086', created_at=datetime.datetime(2024, 11, 30, 21, 56, 28, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 1, 3, 6, 40, tzinfo=datetime.timezone.utc), customer_id='CUST-02462', customer_tier='professional', organization_id='ORG-477', product='Analytics Dashboard', product_version='4.2.14', product_module='visualization', category='Feature Request', subcategory='Enhancement', priority='low', severity='P0', channel='portal', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=10, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 12, 1, 3, 6, 40, tzinfo=datetime.timezone.utc), agent_id='AGENT-027', agent_actions=['viewed_logs', 'ran_diagnostics'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=False, tags=['sync', 'api', 'timeout'], environment='production', business_impact='high', affected_users=44, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000087', created_at=datetime.datetime(2024, 6, 20, 16, 41, 3, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 20, 17, 48, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-04187', customer_tier='starter', organization_id='ORG-166', product='API Gateway', product_version='2.3.14', product_module='auth_service', category='Data Issue', subcategory='Validation', priority='critical', severity='P1', channel='email', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_MEMORY_OOM appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-06-20T16:41:03 WARN Rate limit approaching threshold\\n2024-06-20T16:41:03 ERROR ERROR_MEMORY_OOM: Rate limit exceeded\\n2024-06-20T16:41:05 INFO Backing off for 60 seconds', stack_trace='ERROR: auth_service.service.ServiceException: Failed to process request\\n\\tat auth_service.handler.process(auth_service.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='angry', previous_tickets=5, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 6, 20, 17, 48, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-016', agent_actions=['contacted_customer', 'checked_config', 'viewed_logs', 'applied_fix', 'escalated_to_specialist', 'ran_diagnostics'], escalated=True, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['authentication', 'api', 'configuration', 'security'], environment='development', business_impact='low', affected_users=737, language='zh', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000088', created_at=datetime.datetime(2023, 8, 23, 16, 21, 4, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 24, 23, 54, 40, tzinfo=datetime.timezone.utc), customer_id='CUST-02649', customer_tier='starter', organization_id='ORG-240', product='Analytics Dashboard', product_version='2.4.7', product_module='export_module', category='Data Issue', subcategory='Corruption', priority='low', severity='P3', channel='phone', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_AUTH_401 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-08-23T16:21:04 ERROR ERROR_AUTH_401: Connection timeout after 30s\\n2023-08-23T16:21:05 RETRY_FAILED: Max retries exceeded', stack_trace='ERROR: export_module.service.ServiceException: Failed to process request\\n\\tat export_module.handler.process(export_module.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='frustrated', previous_tickets=7, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 8, 24, 23, 54, 40, tzinfo=datetime.timezone.utc), agent_id='AGENT-033', agent_actions=['viewed_logs', 'applied_fix', 'checked_config'], escalated=True, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['performance', 'security'], environment='test', business_impact='medium', affected_users=31, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000089', created_at=datetime.datetime(2024, 8, 29, 4, 48, 48, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 29, 7, 26, tzinfo=datetime.timezone.utc), customer_id='CUST-03328', customer_tier='enterprise', organization_id='ORG-229', product='CloudBackup Enterprise', product_version='2.8.5', product_module='compression_engine', category='Data Issue', subcategory='Import/Export', priority='critical', severity='P1', channel='portal', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=8, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 8, 29, 7, 26, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['contacted_customer', 'consulted_kb', 'viewed_logs', 'ran_diagnostics'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['performance', 'bug', 'sync', 'error'], environment='production', business_impact='low', affected_users=543, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000090', created_at=datetime.datetime(2024, 6, 27, 16, 31, 49, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 30, 9, 2, 25, tzinfo=datetime.timezone.utc), customer_id='CUST-04414', customer_tier='premium', organization_id='ORG-216', product='Analytics Dashboard', product_version='2.5.1', product_module='visualization', category='Technical Issue', subcategory='Integration', priority='low', severity='P3', channel='email', subject='Analytics Dashboard throwing ERROR_PERMISSION_403 during operation', description=\"We're experiencing issues with Analytics Dashboard. The system is throwing ERROR_PERMISSION_403 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-06-27T16:31:49 DEBUG Processing request ID-12345\\n2024-06-27T16:31:49 ERROR ERROR_PERMISSION_403: Invalid request format\\n2024-06-27T16:31:50 INFO Request rejected', stack_trace='', customer_sentiment='angry', previous_tickets=0, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 6, 30, 9, 2, 25, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['updated_documentation', 'created_workaround', 'checked_config'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['sync', 'data', 'database', 'authentication'], environment='sandbox', business_impact='low', affected_users=34, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000091', created_at=datetime.datetime(2024, 1, 10, 13, 12, 25, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 12, 22, 2, 13, tzinfo=datetime.timezone.utc), customer_id='CUST-03506', customer_tier='starter', organization_id='ORG-192', product='DataSync Pro', product_version='2.5.12', product_module='api_connector', category='Data Issue', subcategory='Import/Export', priority='medium', severity='P4', channel='chat', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_INVALID_400 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-01-10T13:12:25 ERROR ERROR_INVALID_400: Connection timeout after 30s\\n2024-01-10T13:12:26 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='confused', previous_tickets=3, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 1, 12, 22, 2, 13, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['applied_fix', 'escalated_to_specialist', 'updated_documentation', 'verified_resolution'], escalated=True, transferred_count=0, satisfaction_score=2, resolution_helpful=True, tags=['timeout', 'security'], environment='development', business_impact='critical', affected_users=46, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000092', created_at=datetime.datetime(2023, 2, 18, 8, 46, 23, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 18, 10, 51, 47, tzinfo=datetime.timezone.utc), customer_id='CUST-01974', customer_tier='professional', organization_id='ORG-214', product='CloudBackup Enterprise', product_version='4.3.9', product_module='compression_engine', category='Account Management', subcategory='Upgrade', priority='high', severity='P0', channel='email', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=0, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 2, 18, 10, 51, 47, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['contacted_customer', 'ran_diagnostics', 'updated_documentation', 'escalated_to_specialist', 'viewed_logs', 'checked_config'], escalated=True, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['security', 'data', 'performance', 'error', 'authentication'], environment='staging', business_impact='medium', affected_users=719, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000093', created_at=datetime.datetime(2024, 7, 9, 0, 31, 30, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 10, 4, 55, 30, tzinfo=datetime.timezone.utc), customer_id='CUST-02566', customer_tier='starter', organization_id='ORG-094', product='API Gateway', product_version='3.3.0', product_module='rate_limiter', category='Security', subcategory='Encryption', priority='critical', severity='P4', channel='api', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_MEMORY_OOM errors. We need to ensure our system meets compliance requirements.', error_logs='2024-07-09T00:31:30 ERROR ERROR_MEMORY_OOM: Database connection lost\\n2024-07-09T00:31:31 INFO Attempting to reconnect...\\n2024-07-09T00:31:33 ERROR Connection failed', stack_trace='', customer_sentiment='neutral', previous_tickets=7, resolution='Root cause identified as Encryption issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 7, 10, 4, 55, 30, tzinfo=datetime.timezone.utc), agent_id='AGENT-042', agent_actions=['consulted_kb', 'escalated_to_specialist'], escalated=True, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['data', 'timeout', 'bug'], environment='development', business_impact='medium', affected_users=986, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000094', created_at=datetime.datetime(2023, 2, 26, 16, 11, 12, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 27, 12, 23, 48, tzinfo=datetime.timezone.utc), customer_id='CUST-04393', customer_tier='free', organization_id='ORG-104', product='Analytics Dashboard', product_version='3.9.6', product_module='data_aggregator', category='Technical Issue', subcategory='Configuration', priority='medium', severity='P2', channel='email', subject='Performance degradation in Analytics Dashboard', description=\"The Analytics Dashboard has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 2, 27, 12, 23, 48, tzinfo=datetime.timezone.utc), agent_id='AGENT-024', agent_actions=['checked_config', 'ran_diagnostics', 'updated_documentation'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['authentication', 'database', 'api'], environment='production', business_impact='medium', affected_users=31, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000095', created_at=datetime.datetime(2024, 10, 18, 13, 52, 22, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 18, 16, 47, 34, tzinfo=datetime.timezone.utc), customer_id='CUST-01681', customer_tier='enterprise', organization_id='ORG-131', product='Analytics Dashboard', product_version='2.4.4', product_module='visualization', category='Feature Request', subcategory='UI/UX', priority='low', severity='P0', channel='chat', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=3, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 10, 18, 16, 47, 34, tzinfo=datetime.timezone.utc), agent_id='AGENT-040', agent_actions=['consulted_kb', 'verified_resolution'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['error', 'authentication'], environment='staging', business_impact='low', affected_users=2, language='it', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000096', created_at=datetime.datetime(2024, 8, 24, 18, 59, 50, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 24, 22, 44, 50, tzinfo=datetime.timezone.utc), customer_id='CUST-02543', customer_tier='premium', organization_id='ORG-329', product='StreamProcessor', product_version='3.3.12', product_module='monitoring', category='Data Issue', subcategory='Import/Export', priority='high', severity='P1', channel='portal', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=10, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 8, 24, 22, 44, 50, tzinfo=datetime.timezone.utc), agent_id='AGENT-016', agent_actions=['created_workaround', 'viewed_logs', 'verified_resolution', 'checked_config', 'ran_diagnostics'], escalated=True, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['data', 'authentication', 'api', 'database', 'bug'], environment='sandbox', business_impact='low', affected_users=320, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000097', created_at=datetime.datetime(2023, 5, 14, 11, 40, 12, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 14, 16, 36, 36, tzinfo=datetime.timezone.utc), customer_id='CUST-01339', customer_tier='free', organization_id='ORG-040', product='StreamProcessor', product_version='3.6.13', product_module='error_handler', category='Data Issue', subcategory='Sync Error', priority='low', severity='P1', channel='phone', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_NOTFOUND_404 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-05-14T11:40:12 ERROR ERROR_NOTFOUND_404: Connection timeout after 30s\\n2023-05-14T11:40:13 RETRY_FAILED: Max retries exceeded', stack_trace='at error_handler.execute(error_handler.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='frustrated', previous_tickets=10, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 5, 14, 16, 36, 36, tzinfo=datetime.timezone.utc), agent_id='AGENT-024', agent_actions=['viewed_logs', 'created_workaround'], escalated=True, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['configuration', 'error', 'database', 'data'], environment='test', business_impact='medium', affected_users=29, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000098', created_at=datetime.datetime(2023, 11, 21, 21, 5, 5, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 22, 8, 14, 5, tzinfo=datetime.timezone.utc), customer_id='CUST-00876', customer_tier='premium', organization_id='ORG-329', product='StreamProcessor', product_version='2.5.14', product_module='monitoring', category='Technical Issue', subcategory='Integration', priority='low', severity='P2', channel='portal', subject='Performance degradation in StreamProcessor', description=\"The StreamProcessor has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_SSL_CERT in the logs. This is affecting our entire team's productivity.\", error_logs='2023-11-21T21:05:05 ERROR ERROR_SSL_CERT: Database connection lost\\n2023-11-21T21:05:06 INFO Attempting to reconnect...\\n2023-11-21T21:05:08 ERROR Connection failed', stack_trace='', customer_sentiment='angry', previous_tickets=6, resolution='Applied hotfix version 3.2.2 to address the ERROR_SSL_CERT. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 11, 22, 8, 14, 5, tzinfo=datetime.timezone.utc), agent_id='AGENT-009', agent_actions=['escalated_to_specialist', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['api', 'security', 'timeout', 'error'], environment='production', business_impact='medium', affected_users=37, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000099', created_at=datetime.datetime(2023, 12, 26, 19, 7, 12, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 29, 7, 24, 36, tzinfo=datetime.timezone.utc), customer_id='CUST-04974', customer_tier='free', organization_id='ORG-237', product='CloudBackup Enterprise', product_version='3.6.9', product_module='restore_module', category='Data Issue', subcategory='Import/Export', priority='high', severity='P4', channel='portal', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_TIMEOUT_429 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-12-26T19:07:12 ERROR ERROR_TIMEOUT_429: Connection timeout after 30s\\n2023-12-26T19:07:13 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'restore_module.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='confused', previous_tickets=6, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 12, 29, 7, 24, 36, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['contacted_customer', 'created_workaround', 'ran_diagnostics', 'checked_config'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['database', 'bug'], environment='sandbox', business_impact='medium', affected_users=40, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000100', created_at=datetime.datetime(2024, 1, 4, 14, 37, 59, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 5, 2, 43, 59, tzinfo=datetime.timezone.utc), customer_id='CUST-00448', customer_tier='free', organization_id='ORG-487', product='StreamProcessor', product_version='2.6.8', product_module='error_handler', category='Data Issue', subcategory='Corruption', priority='critical', severity='P2', channel='chat', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_INVALID_400 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-01-04T14:37:59 WARN Rate limit approaching threshold\\n2024-01-04T14:37:59 ERROR ERROR_INVALID_400: Rate limit exceeded\\n2024-01-04T14:38:01 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='angry', previous_tickets=6, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 1, 5, 2, 43, 59, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['viewed_logs', 'escalated_to_specialist', 'ran_diagnostics'], escalated=True, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['authentication', 'error', 'performance', 'api'], environment='sandbox', business_impact='critical', affected_users=689, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000101', created_at=datetime.datetime(2023, 3, 5, 10, 52, 52, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 5, 12, 43, 52, tzinfo=datetime.timezone.utc), customer_id='CUST-02158', customer_tier='starter', organization_id='ORG-208', product='API Gateway', product_version='3.7.4', product_module='rate_limiter', category='Feature Request', subcategory='Documentation', priority='high', severity='P0', channel='phone', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-03-05T10:52:52 DEBUG Processing request ID-12345\\n2023-03-05T10:52:52 ERROR ERROR_CONFLICT_409: Invalid request format\\n2023-03-05T10:52:53 INFO Request rejected', stack_trace='', customer_sentiment='grateful', previous_tickets=4, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 3, 5, 12, 43, 52, tzinfo=datetime.timezone.utc), agent_id='AGENT-006', agent_actions=['consulted_kb', 'checked_config'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['error', 'performance', 'sync'], environment='development', business_impact='critical', affected_users=573, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000102', created_at=datetime.datetime(2023, 5, 15, 22, 46, 29, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 20, 7, 55, 29, tzinfo=datetime.timezone.utc), customer_id='CUST-02389', customer_tier='professional', organization_id='ORG-441', product='StreamProcessor', product_version='3.3.2', product_module='batch_processor', category='Security', subcategory='Encryption', priority='medium', severity='P4', channel='slack', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Getting ERROR_DISK_FULL errors. We need to ensure our system meets compliance requirements.', error_logs='2023-05-15T22:46:29 WARN Rate limit approaching threshold\\n2023-05-15T22:46:29 ERROR ERROR_DISK_FULL: Rate limit exceeded\\n2023-05-15T22:46:31 INFO Backing off for 60 seconds', stack_trace='at batch_processor.execute(batch_processor.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='confused', previous_tickets=5, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 5, 20, 7, 55, 29, tzinfo=datetime.timezone.utc), agent_id='AGENT-019', agent_actions=['consulted_kb', 'created_workaround'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['security', 'integration', 'data'], environment='production', business_impact='medium', affected_users=5, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000103', created_at=datetime.datetime(2023, 5, 22, 17, 49, 32, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 23, 4, 17, 44, tzinfo=datetime.timezone.utc), customer_id='CUST-00826', customer_tier='premium', organization_id='ORG-089', product='API Gateway', product_version='4.3.14', product_module='request_router', category='Feature Request', subcategory='Enhancement', priority='low', severity='P2', channel='api', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=7, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 5, 23, 4, 17, 44, tzinfo=datetime.timezone.utc), agent_id='AGENT-005', agent_actions=['viewed_logs', 'escalated_to_specialist', 'updated_documentation'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['bug', 'error', 'configuration'], environment='test', business_impact='high', affected_users=18, language='de', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000104', created_at=datetime.datetime(2024, 11, 3, 22, 13, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 3, 23, 13, 2, tzinfo=datetime.timezone.utc), customer_id='CUST-02194', customer_tier='starter', organization_id='ORG-213', product='StreamProcessor', product_version='4.6.9', product_module='batch_processor', category='Security', subcategory='Vulnerability', priority='critical', severity='P0', channel='slack', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=9, resolution='Root cause identified as Vulnerability issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 11, 3, 23, 13, 2, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['applied_fix', 'escalated_to_specialist', 'consulted_kb', 'ran_diagnostics'], escalated=True, transferred_count=3, satisfaction_score=1, resolution_helpful=True, tags=['database', 'security'], environment='test', business_impact='low', affected_users=339, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000105', created_at=datetime.datetime(2024, 10, 10, 7, 39, 19, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 10, 8, 31, 31, tzinfo=datetime.timezone.utc), customer_id='CUST-01768', customer_tier='starter', organization_id='ORG-187', product='API Gateway', product_version='4.4.0', product_module='auth_service', category='Feature Request', subcategory='Documentation', priority='critical', severity='P0', channel='api', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-10-10T07:39:19 WARN Rate limit approaching threshold\\n2024-10-10T07:39:19 ERROR ERROR_INVALID_400: Rate limit exceeded\\n2024-10-10T07:39:21 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'auth_service.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='angry', previous_tickets=7, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 10, 10, 8, 31, 31, tzinfo=datetime.timezone.utc), agent_id='AGENT-032', agent_actions=['checked_config', 'verified_resolution'], escalated=True, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['configuration', 'error', 'api', 'data', 'security'], environment='test', business_impact='low', affected_users=669, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000106', created_at=datetime.datetime(2023, 12, 18, 19, 14, 50, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 19, 4, 34, 2, tzinfo=datetime.timezone.utc), customer_id='CUST-04353', customer_tier='starter', organization_id='ORG-271', product='CloudBackup Enterprise', product_version='2.5.0', product_module='backup_service', category='Data Issue', subcategory='Sync Error', priority='low', severity='P2', channel='portal', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=5, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 12, 19, 4, 34, 2, tzinfo=datetime.timezone.utc), agent_id='AGENT-028', agent_actions=['viewed_logs', 'consulted_kb', 'ran_diagnostics', 'applied_fix'], escalated=True, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['configuration', 'database', 'authentication'], environment='sandbox', business_impact='critical', affected_users=22, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000107', created_at=datetime.datetime(2023, 6, 20, 16, 1, 32, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 20, 19, 44, 8, tzinfo=datetime.timezone.utc), customer_id='CUST-01805', customer_tier='premium', organization_id='ORG-056', product='DataSync Pro', product_version='4.7.8', product_module='scheduler', category='Feature Request', subcategory='UI/UX', priority='medium', severity='P0', channel='api', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-06-20T16:01:32 DEBUG Processing request ID-12345\\n2023-06-20T16:01:32 ERROR ERROR_CORRUPTION: Invalid request format\\n2023-06-20T16:01:33 INFO Request rejected', stack_trace='at scheduler.execute(scheduler.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='satisfied', previous_tickets=2, resolution='Applied hotfix version 3.2.2 to address the ERROR_CORRUPTION. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 6, 20, 19, 44, 8, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['escalated_to_specialist', 'checked_config'], escalated=False, transferred_count=1, satisfaction_score=1, resolution_helpful=False, tags=['data', 'error'], environment='test', business_impact='medium', affected_users=17, language='zh', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000108', created_at=datetime.datetime(2023, 9, 28, 11, 12, 32, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 29, 12, 42, 32, tzinfo=datetime.timezone.utc), customer_id='CUST-01776', customer_tier='free', organization_id='ORG-368', product='StreamProcessor', product_version='3.0.8', product_module='monitoring', category='Security', subcategory='Compliance', priority='critical', severity='P3', channel='slack', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Getting ERROR_DISK_FULL errors. We need to ensure our system meets compliance requirements.', error_logs='2023-09-28T11:12:32 WARN Rate limit approaching threshold\\n2023-09-28T11:12:32 ERROR ERROR_DISK_FULL: Rate limit exceeded\\n2023-09-28T11:12:34 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='grateful', previous_tickets=3, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 9, 29, 12, 42, 32, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['updated_documentation', 'verified_resolution', 'viewed_logs', 'escalated_to_specialist'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['error', 'configuration', 'integration', 'data', 'sync'], environment='development', business_impact='medium', affected_users=391, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000109', created_at=datetime.datetime(2023, 1, 21, 10, 53, 15, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 21, 14, 58, 3, tzinfo=datetime.timezone.utc), customer_id='CUST-04754', customer_tier='free', organization_id='ORG-279', product='Analytics Dashboard', product_version='4.0.10', product_module='export_module', category='Security', subcategory='Authentication', priority='high', severity='P1', channel='slack', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_CONNECTION_REFUSED errors. We need to ensure our system meets compliance requirements.', error_logs='2023-01-21T10:53:15 ERROR ERROR_CONNECTION_REFUSED: Database connection lost\\n2023-01-21T10:53:16 INFO Attempting to reconnect...\\n2023-01-21T10:53:18 ERROR Connection failed', stack_trace='at export_module.execute(export_module.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='confused', previous_tickets=2, resolution='Root cause identified as Authentication issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 1, 21, 14, 58, 3, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['escalated_to_specialist', 'created_workaround', 'checked_config'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['authentication', 'error', 'integration', 'bug'], environment='test', business_impact='medium', affected_users=61, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000110', created_at=datetime.datetime(2023, 10, 11, 21, 25, 3, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 11, 23, 47, 15, tzinfo=datetime.timezone.utc), customer_id='CUST-01617', customer_tier='premium', organization_id='ORG-287', product='DataSync Pro', product_version='3.4.5', product_module='api_connector', category='Technical Issue', subcategory='Bug', priority='high', severity='P0', channel='email', subject='DataSync Pro throwing ERROR_PERMISSION_403 during operation', description=\"We're experiencing issues with DataSync Pro. The system is throwing ERROR_PERMISSION_403 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-10-11T21:25:03 WARN Rate limit approaching threshold\\n2023-10-11T21:25:03 ERROR ERROR_PERMISSION_403: Rate limit exceeded\\n2023-10-11T21:25:05 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='confused', previous_tickets=10, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 10, 11, 23, 47, 15, tzinfo=datetime.timezone.utc), agent_id='AGENT-006', agent_actions=['updated_documentation', 'verified_resolution', 'ran_diagnostics'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['error', 'security', 'integration', 'api'], environment='development', business_impact='high', affected_users=378, language='fr', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000111', created_at=datetime.datetime(2024, 12, 4, 10, 45, 43, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 4, 12, 13, 19, tzinfo=datetime.timezone.utc), customer_id='CUST-02036', customer_tier='professional', organization_id='ORG-311', product='CloudBackup Enterprise', product_version='3.8.5', product_module='encryption_layer', category='Account Management', subcategory='Billing', priority='medium', severity='P0', channel='api', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-12-04T10:45:43 DEBUG Processing request ID-12345\\n2024-12-04T10:45:43 ERROR ERROR_SERVER_500: Invalid request format\\n2024-12-04T10:45:44 INFO Request rejected', stack_trace='at encryption_layer.execute(encryption_layer.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='neutral', previous_tickets=5, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 12, 4, 12, 13, 19, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['applied_fix', 'checked_config', 'ran_diagnostics'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['authentication', 'configuration', 'integration'], environment='production', business_impact='high', affected_users=23, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000112', created_at=datetime.datetime(2024, 10, 3, 21, 35, 5, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 4, 2, 45, 17, tzinfo=datetime.timezone.utc), customer_id='CUST-04412', customer_tier='starter', organization_id='ORG-112', product='CloudBackup Enterprise', product_version='3.6.4', product_module='encryption_layer', category='Feature Request', subcategory='New Feature', priority='low', severity='P1', channel='chat', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-10-03T21:35:05 WARN Rate limit approaching threshold\\n2024-10-03T21:35:05 ERROR ERROR_PARSING: Rate limit exceeded\\n2024-10-03T21:35:07 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='satisfied', previous_tickets=8, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 10, 4, 2, 45, 17, tzinfo=datetime.timezone.utc), agent_id='AGENT-009', agent_actions=['checked_config', 'consulted_kb', 'escalated_to_specialist'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['performance', 'error', 'bug', 'timeout', 'api'], environment='sandbox', business_impact='high', affected_users=22, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000113', created_at=datetime.datetime(2023, 10, 26, 12, 31, 17, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 29, 11, 31, 53, tzinfo=datetime.timezone.utc), customer_id='CUST-00609', customer_tier='starter', organization_id='ORG-121', product='StreamProcessor', product_version='3.8.0', product_module='batch_processor', category='Security', subcategory='Authorization', priority='medium', severity='P4', channel='api', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Getting ERROR_VALIDATION errors. We need to ensure our system meets compliance requirements.', error_logs='2023-10-26T12:31:17 ERROR ERROR_VALIDATION: Database connection lost\\n2023-10-26T12:31:18 INFO Attempting to reconnect...\\n2023-10-26T12:31:20 ERROR Connection failed', stack_trace='', customer_sentiment='confused', previous_tickets=10, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 10, 29, 11, 31, 53, tzinfo=datetime.timezone.utc), agent_id='AGENT-003', agent_actions=['contacted_customer', 'ran_diagnostics'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['configuration', 'integration', 'timeout', 'sync'], environment='staging', business_impact='medium', affected_users=50, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000114', created_at=datetime.datetime(2024, 4, 1, 4, 48, 23, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 1, 23, 37, 35, tzinfo=datetime.timezone.utc), customer_id='CUST-00596', customer_tier='professional', organization_id='ORG-114', product='DataSync Pro', product_version='2.2.15', product_module='sync_engine', category='Account Management', subcategory='Subscription', priority='high', severity='P3', channel='phone', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=8, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 4, 1, 23, 37, 35, tzinfo=datetime.timezone.utc), agent_id='AGENT-046', agent_actions=['created_workaround', 'viewed_logs'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['authentication', 'timeout', 'database', 'api'], environment='staging', business_impact='high', affected_users=231, language='ja', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000115', created_at=datetime.datetime(2023, 1, 15, 10, 46, 47, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 16, 21, 30, 35, tzinfo=datetime.timezone.utc), customer_id='CUST-00794', customer_tier='enterprise', organization_id='ORG-093', product='DataSync Pro', product_version='4.0.13', product_module='api_connector', category='Security', subcategory='Authorization', priority='high', severity='P4', channel='slack', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=10, resolution='Root cause identified as Authorization issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 1, 16, 21, 30, 35, tzinfo=datetime.timezone.utc), agent_id='AGENT-003', agent_actions=['updated_documentation', 'consulted_kb'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=False, tags=['security', 'database', 'sync'], environment='staging', business_impact='critical', affected_users=961, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000116', created_at=datetime.datetime(2023, 7, 9, 17, 12, 58, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 13, 10, 47, 46, tzinfo=datetime.timezone.utc), customer_id='CUST-00980', customer_tier='starter', organization_id='ORG-362', product='DataSync Pro', product_version='2.8.9', product_module='scheduler', category='Technical Issue', subcategory='Integration', priority='low', severity='P3', channel='email', subject='DataSync Pro throwing errors during operation', description=\"We're experiencing issues with DataSync Pro. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 7, 13, 10, 47, 46, tzinfo=datetime.timezone.utc), agent_id='AGENT-032', agent_actions=['viewed_logs', 'escalated_to_specialist', 'consulted_kb'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=True, tags=['database', 'sync', 'performance', 'api'], environment='development', business_impact='high', affected_users=50, language='it', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000117', created_at=datetime.datetime(2024, 2, 1, 19, 19, 48, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 6, 18, 36, 36, tzinfo=datetime.timezone.utc), customer_id='CUST-03033', customer_tier='enterprise', organization_id='ORG-364', product='Analytics Dashboard', product_version='2.4.15', product_module='export_module', category='Account Management', subcategory='Subscription', priority='low', severity='P4', channel='email', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-02-01T19:19:48 ERROR ERROR_TIMEOUT_429: Connection timeout after 30s\\n2024-02-01T19:19:49 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='neutral', previous_tickets=6, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 2, 6, 18, 36, 36, tzinfo=datetime.timezone.utc), agent_id='AGENT-024', agent_actions=['updated_documentation', 'checked_config'], escalated=False, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['performance', 'integration', 'api'], environment='development', business_impact='critical', affected_users=19, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000118', created_at=datetime.datetime(2023, 2, 20, 0, 59, 49, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 22, 3, 8, 13, tzinfo=datetime.timezone.utc), customer_id='CUST-02762', customer_tier='enterprise', organization_id='ORG-126', product='Analytics Dashboard', product_version='2.5.5', product_module='data_aggregator', category='Security', subcategory='Vulnerability', priority='high', severity='P4', channel='phone', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_AUTH_401 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-02-20T00:59:49 ERROR ERROR_AUTH_401: Database connection lost\\n2023-02-20T00:59:50 INFO Attempting to reconnect...\\n2023-02-20T00:59:52 ERROR Connection failed', stack_trace='', customer_sentiment='neutral', previous_tickets=10, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 2, 22, 3, 8, 13, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['contacted_customer', 'consulted_kb', 'applied_fix'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['bug', 'sync', 'integration', 'api'], environment='test', business_impact='critical', affected_users=254, language='ja', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000119', created_at=datetime.datetime(2023, 1, 29, 2, 17, 52, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 29, 10, 59, 52, tzinfo=datetime.timezone.utc), customer_id='CUST-03680', customer_tier='enterprise', organization_id='ORG-076', product='Analytics Dashboard', product_version='3.5.3', product_module='data_aggregator', category='Security', subcategory='Authorization', priority='low', severity='P1', channel='phone', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=8, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 1, 29, 10, 59, 52, tzinfo=datetime.timezone.utc), agent_id='AGENT-040', agent_actions=['contacted_customer', 'verified_resolution', 'updated_documentation', 'viewed_logs', 'checked_config', 'escalated_to_specialist'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['timeout', 'database', 'configuration', 'bug'], environment='test', business_impact='low', affected_users=50, language='de', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000120', created_at=datetime.datetime(2024, 2, 16, 17, 28, 13, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 16, 23, 1, 49, tzinfo=datetime.timezone.utc), customer_id='CUST-02859', customer_tier='starter', organization_id='ORG-268', product='CloudBackup Enterprise', product_version='3.7.13', product_module='backup_service', category='Account Management', subcategory='Subscription', priority='low', severity='P1', channel='api', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-02-16T17:28:13 ERROR ERROR_TIMEOUT_429: Database connection lost\\n2024-02-16T17:28:14 INFO Attempting to reconnect...\\n2024-02-16T17:28:16 ERROR Connection failed', stack_trace='ERROR: backup_service.service.ServiceException: Failed to process request\\n\\tat backup_service.handler.process(backup_service.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='confused', previous_tickets=7, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 2, 16, 23, 1, 49, tzinfo=datetime.timezone.utc), agent_id='AGENT-012', agent_actions=['applied_fix', 'checked_config', 'created_workaround', 'verified_resolution', 'viewed_logs', 'updated_documentation'], escalated=True, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['bug', 'api', 'configuration'], environment='sandbox', business_impact='critical', affected_users=26, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000121', created_at=datetime.datetime(2024, 9, 17, 20, 22, 34, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 19, 10, 50, 46, tzinfo=datetime.timezone.utc), customer_id='CUST-02631', customer_tier='enterprise', organization_id='ORG-470', product='DataSync Pro', product_version='2.4.14', product_module='scheduler', category='Technical Issue', subcategory='Performance', priority='high', severity='P3', channel='api', subject='Performance degradation in DataSync Pro', description=\"The DataSync Pro has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=3, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 9, 19, 10, 50, 46, tzinfo=datetime.timezone.utc), agent_id='AGENT-044', agent_actions=['viewed_logs', 'verified_resolution', 'checked_config', 'consulted_kb', 'updated_documentation'], escalated=False, transferred_count=2, satisfaction_score=1, resolution_helpful=True, tags=['performance', 'security'], environment='sandbox', business_impact='high', affected_users=607, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000122', created_at=datetime.datetime(2023, 11, 9, 13, 43, 5, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 10, 20, 59, 17, tzinfo=datetime.timezone.utc), customer_id='CUST-01443', customer_tier='starter', organization_id='ORG-269', product='CloudBackup Enterprise', product_version='3.5.0', product_module='encryption_layer', category='Technical Issue', subcategory='Configuration', priority='high', severity='P3', channel='slack', subject='CloudBackup Enterprise throwing ERROR_AUTH_401 during operation', description=\"We're experiencing issues with CloudBackup Enterprise. The system is throwing ERROR_AUTH_401 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-11-09T13:43:05 WARN Rate limit approaching threshold\\n2023-11-09T13:43:05 ERROR ERROR_AUTH_401: Rate limit exceeded\\n2023-11-09T13:43:07 INFO Backing off for 60 seconds', stack_trace='at encryption_layer.execute(encryption_layer.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='satisfied', previous_tickets=10, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 11, 10, 20, 59, 17, tzinfo=datetime.timezone.utc), agent_id='AGENT-026', agent_actions=['viewed_logs', 'consulted_kb', 'checked_config', 'created_workaround', 'verified_resolution', 'contacted_customer'], escalated=False, transferred_count=1, satisfaction_score=1, resolution_helpful=False, tags=['authentication', 'sync', 'error', 'api'], environment='sandbox', business_impact='critical', affected_users=665, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000123', created_at=datetime.datetime(2023, 5, 6, 8, 3, 49, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 6, 12, 4, 25, tzinfo=datetime.timezone.utc), customer_id='CUST-01078', customer_tier='enterprise', organization_id='ORG-091', product='API Gateway', product_version='4.3.10', product_module='rate_limiter', category='Security', subcategory='Authentication', priority='high', severity='P2', channel='slack', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_INVALID_400 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-05-06T08:03:49 WARN Rate limit approaching threshold\\n2023-05-06T08:03:49 ERROR ERROR_INVALID_400: Rate limit exceeded\\n2023-05-06T08:03:51 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='satisfied', previous_tickets=8, resolution='Applied hotfix version 3.2.2 to address the ERROR_INVALID_400. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 5, 6, 12, 4, 25, tzinfo=datetime.timezone.utc), agent_id='AGENT-045', agent_actions=['ran_diagnostics', 'created_workaround', 'consulted_kb'], escalated=False, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['performance', 'api'], environment='staging', business_impact='medium', affected_users=44, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000124', created_at=datetime.datetime(2024, 5, 6, 3, 39, 33, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 6, 9, 53, 21, tzinfo=datetime.timezone.utc), customer_id='CUST-03594', customer_tier='professional', organization_id='ORG-252', product='Analytics Dashboard', product_version='4.5.2', product_module='export_module', category='Technical Issue', subcategory='Configuration', priority='high', severity='P1', channel='slack', subject='Analytics Dashboard throwing ERROR_INVALID_400 during operation', description=\"We're experiencing issues with Analytics Dashboard. The system is throwing ERROR_INVALID_400 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-05-06T03:39:33 WARN Rate limit approaching threshold\\n2024-05-06T03:39:33 ERROR ERROR_INVALID_400: Rate limit exceeded\\n2024-05-06T03:39:35 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'export_module.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='angry', previous_tickets=8, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 5, 6, 9, 53, 21, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['checked_config', 'applied_fix', 'viewed_logs', 'created_workaround'], escalated=True, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['security', 'integration', 'performance', 'sync', 'api'], environment='production', business_impact='medium', affected_users=488, language='pt', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000125', created_at=datetime.datetime(2024, 8, 29, 15, 56, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 29, 19, 51, 14, tzinfo=datetime.timezone.utc), customer_id='CUST-03044', customer_tier='enterprise', organization_id='ORG-474', product='DataSync Pro', product_version='2.9.9', product_module='scheduler', category='Account Management', subcategory='Subscription', priority='high', severity='P1', channel='email', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-08-29T15:56:38 WARN Rate limit approaching threshold\\n2024-08-29T15:56:38 ERROR ERROR_CORRUPTION: Rate limit exceeded\\n2024-08-29T15:56:40 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='confused', previous_tickets=0, resolution='Root cause identified as Subscription issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 8, 29, 19, 51, 14, tzinfo=datetime.timezone.utc), agent_id='AGENT-027', agent_actions=['consulted_kb', 'updated_documentation', 'applied_fix', 'checked_config', 'created_workaround'], escalated=True, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'error', 'timeout', 'api'], environment='test', business_impact='critical', affected_users=796, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000126', created_at=datetime.datetime(2024, 10, 3, 4, 52, 30, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 3, 5, 49, 30, tzinfo=datetime.timezone.utc), customer_id='CUST-00833', customer_tier='starter', organization_id='ORG-061', product='StreamProcessor', product_version='2.7.12', product_module='monitoring', category='Technical Issue', subcategory='Bug', priority='medium', severity='P0', channel='portal', subject='StreamProcessor throwing ERROR_NOTFOUND_404 during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing ERROR_NOTFOUND_404 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-10-03T04:52:30 ERROR ERROR_NOTFOUND_404: Connection timeout after 30s\\n2024-10-03T04:52:31 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'monitoring.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='grateful', previous_tickets=2, resolution='Root cause identified as Bug issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 10, 3, 5, 49, 30, tzinfo=datetime.timezone.utc), agent_id='AGENT-040', agent_actions=['verified_resolution', 'escalated_to_specialist', 'updated_documentation', 'applied_fix', 'contacted_customer'], escalated=True, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['authentication', 'integration', 'bug', 'sync', 'data'], environment='sandbox', business_impact='critical', affected_users=2, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000127', created_at=datetime.datetime(2023, 5, 28, 23, 52, 59, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 30, 12, 49, 23, tzinfo=datetime.timezone.utc), customer_id='CUST-03150', customer_tier='enterprise', organization_id='ORG-323', product='Analytics Dashboard', product_version='4.4.9', product_module='report_builder', category='Data Issue', subcategory='Data Loss', priority='high', severity='P3', channel='chat', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=10, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 5, 30, 12, 49, 23, tzinfo=datetime.timezone.utc), agent_id='AGENT-036', agent_actions=['created_workaround', 'escalated_to_specialist'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['bug', 'security', 'error', 'integration'], environment='test', business_impact='critical', affected_users=135, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000128', created_at=datetime.datetime(2023, 10, 24, 9, 21, 13, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 24, 12, 45, 13, tzinfo=datetime.timezone.utc), customer_id='CUST-02045', customer_tier='starter', organization_id='ORG-047', product='CloudBackup Enterprise', product_version='2.6.12', product_module='encryption_layer', category='Account Management', subcategory='License', priority='medium', severity='P1', channel='portal', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-10-24T09:21:13 ERROR ERROR_PARSING: Database connection lost\\n2023-10-24T09:21:14 INFO Attempting to reconnect...\\n2023-10-24T09:21:16 ERROR Connection failed', stack_trace='at encryption_layer.execute(encryption_layer.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='confused', previous_tickets=8, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 10, 24, 12, 45, 13, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['applied_fix', 'updated_documentation', 'consulted_kb'], escalated=True, transferred_count=3, satisfaction_score=3, resolution_helpful=False, tags=['data', 'integration'], environment='staging', business_impact='medium', affected_users=21, language='pt', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000129', created_at=datetime.datetime(2024, 8, 2, 8, 18, 35, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 2, 12, 53, 59, tzinfo=datetime.timezone.utc), customer_id='CUST-04785', customer_tier='premium', organization_id='ORG-087', product='StreamProcessor', product_version='3.8.15', product_module='error_handler', category='Security', subcategory='Authentication', priority='high', severity='P2', channel='portal', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=0, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 8, 2, 12, 53, 59, tzinfo=datetime.timezone.utc), agent_id='AGENT-003', agent_actions=['updated_documentation', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['sync', 'configuration'], environment='test', business_impact='critical', affected_users=858, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000130', created_at=datetime.datetime(2024, 8, 22, 7, 2, 27, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 22, 8, 55, 15, tzinfo=datetime.timezone.utc), customer_id='CUST-03917', customer_tier='starter', organization_id='ORG-275', product='Analytics Dashboard', product_version='3.6.5', product_module='export_module', category='Feature Request', subcategory='Enhancement', priority='critical', severity='P1', channel='email', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=10, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 8, 22, 8, 55, 15, tzinfo=datetime.timezone.utc), agent_id='AGENT-045', agent_actions=['ran_diagnostics', 'created_workaround', 'checked_config'], escalated=True, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['performance', 'data', 'timeout'], environment='development', business_impact='low', affected_users=296, language='zh', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000131', created_at=datetime.datetime(2024, 2, 12, 11, 55, 56, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 20, 17, 19, 20, tzinfo=datetime.timezone.utc), customer_id='CUST-02908', customer_tier='premium', organization_id='ORG-185', product='API Gateway', product_version='2.1.9', product_module='cache_layer', category='Security', subcategory='Authentication', priority='low', severity='P4', channel='email', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_CONFLICT_409 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-02-12T11:55:56 DEBUG Processing request ID-12345\\n2024-02-12T11:55:56 ERROR ERROR_CONFLICT_409: Invalid request format\\n2024-02-12T11:55:57 INFO Request rejected', stack_trace='', customer_sentiment='neutral', previous_tickets=10, resolution='Applied hotfix version 3.2.2 to address the ERROR_CONFLICT_409. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 2, 20, 17, 19, 20, tzinfo=datetime.timezone.utc), agent_id='AGENT-026', agent_actions=['escalated_to_specialist', 'verified_resolution', 'consulted_kb'], escalated=False, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['timeout', 'configuration', 'performance', 'api'], environment='production', business_impact='high', affected_users=48, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000132', created_at=datetime.datetime(2024, 6, 8, 14, 41, 42, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 12, 18, 19, 30, tzinfo=datetime.timezone.utc), customer_id='CUST-03370', customer_tier='starter', organization_id='ORG-349', product='CloudBackup Enterprise', product_version='4.2.8', product_module='encryption_layer', category='Account Management', subcategory='Access Control', priority='low', severity='P4', channel='email', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-06-08T14:41:42 ERROR ERROR_INVALID_400: Database connection lost\\n2024-06-08T14:41:43 INFO Attempting to reconnect...\\n2024-06-08T14:41:45 ERROR Connection failed', stack_trace='', customer_sentiment='grateful', previous_tickets=5, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 6, 12, 18, 19, 30, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['verified_resolution', 'contacted_customer', 'applied_fix'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'timeout', 'database', 'api'], environment='sandbox', business_impact='medium', affected_users=41, language='en', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000133', created_at=datetime.datetime(2023, 9, 12, 22, 1, 2, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 12, 22, 53, 14, tzinfo=datetime.timezone.utc), customer_id='CUST-03602', customer_tier='enterprise', organization_id='ORG-489', product='CloudBackup Enterprise', product_version='3.2.0', product_module='backup_service', category='Feature Request', subcategory='Enhancement', priority='high', severity='P0', channel='phone', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=5, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 9, 12, 22, 53, 14, tzinfo=datetime.timezone.utc), agent_id='AGENT-010', agent_actions=['consulted_kb', 'viewed_logs', 'created_workaround'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['bug', 'api', 'timeout', 'data'], environment='sandbox', business_impact='medium', affected_users=617, language='zh', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000134', created_at=datetime.datetime(2023, 8, 13, 16, 40, 5, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 16, 0, 25, 5, tzinfo=datetime.timezone.utc), customer_id='CUST-04756', customer_tier='professional', organization_id='ORG-066', product='CloudBackup Enterprise', product_version='2.7.3', product_module='backup_service', category='Technical Issue', subcategory='Compatibility', priority='high', severity='P4', channel='api', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_PARSING in the logs. This is affecting our entire team's productivity.\", error_logs='2023-08-13T16:40:05 DEBUG Processing request ID-12345\\n2023-08-13T16:40:05 ERROR ERROR_PARSING: Invalid request format\\n2023-08-13T16:40:06 INFO Request rejected', stack_trace='', customer_sentiment='frustrated', previous_tickets=8, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 8, 16, 0, 25, 5, tzinfo=datetime.timezone.utc), agent_id='AGENT-050', agent_actions=['created_workaround', 'ran_diagnostics', 'escalated_to_specialist'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['error', 'timeout'], environment='sandbox', business_impact='critical', affected_users=846, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000135', created_at=datetime.datetime(2023, 7, 15, 6, 21, 20, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 18, 18, 11, 44, tzinfo=datetime.timezone.utc), customer_id='CUST-02128', customer_tier='starter', organization_id='ORG-280', product='API Gateway', product_version='4.3.11', product_module='cache_layer', category='Feature Request', subcategory='Documentation', priority='medium', severity='P4', channel='chat', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=5, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 7, 18, 18, 11, 44, tzinfo=datetime.timezone.utc), agent_id='AGENT-035', agent_actions=['checked_config', 'updated_documentation'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['data', 'configuration'], environment='development', business_impact='medium', affected_users=37, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000136', created_at=datetime.datetime(2024, 10, 13, 18, 22, 24, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 13, 22, 41, tzinfo=datetime.timezone.utc), customer_id='CUST-00383', customer_tier='enterprise', organization_id='ORG-301', product='API Gateway', product_version='4.1.3', product_module='request_router', category='Technical Issue', subcategory='Bug', priority='critical', severity='P2', channel='portal', subject='API Gateway throwing errors during operation', description=\"We're experiencing issues with API Gateway. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=5, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 10, 13, 22, 41, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['consulted_kb', 'contacted_customer', 'updated_documentation'], escalated=False, transferred_count=2, satisfaction_score=1, resolution_helpful=True, tags=['error', 'bug', 'api', 'security', 'data'], environment='production', business_impact='critical', affected_users=892, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000137', created_at=datetime.datetime(2024, 4, 2, 13, 4, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 2, 15, 59, 48, tzinfo=datetime.timezone.utc), customer_id='CUST-02624', customer_tier='premium', organization_id='ORG-357', product='Analytics Dashboard', product_version='2.6.7', product_module='export_module', category='Security', subcategory='Authentication', priority='low', severity='P0', channel='slack', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_CONFLICT_409 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-04-02T13:04:00 WARN Rate limit approaching threshold\\n2024-04-02T13:04:00 ERROR ERROR_CONFLICT_409: Rate limit exceeded\\n2024-04-02T13:04:02 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='satisfied', previous_tickets=8, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 4, 2, 15, 59, 48, tzinfo=datetime.timezone.utc), agent_id='AGENT-041', agent_actions=['verified_resolution', 'ran_diagnostics', 'created_workaround'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['data', 'bug'], environment='development', business_impact='medium', affected_users=4, language='en', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000138', created_at=datetime.datetime(2024, 6, 13, 6, 33, 33, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 16, 14, 4, 45, tzinfo=datetime.timezone.utc), customer_id='CUST-03259', customer_tier='starter', organization_id='ORG-225', product='API Gateway', product_version='4.7.7', product_module='cache_layer', category='Feature Request', subcategory='Enhancement', priority='low', severity='P3', channel='slack', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-06-13T06:33:33 ERROR ERROR_VALIDATION: Database connection lost\\n2024-06-13T06:33:34 INFO Attempting to reconnect...\\n2024-06-13T06:33:36 ERROR Connection failed', stack_trace='Stack trace:\\n  cache_layer::processData() at cache_layer.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='satisfied', previous_tickets=6, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 6, 16, 14, 4, 45, tzinfo=datetime.timezone.utc), agent_id='AGENT-021', agent_actions=['applied_fix', 'checked_config', 'verified_resolution', 'created_workaround'], escalated=True, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['bug', 'timeout', 'configuration'], environment='development', business_impact='critical', affected_users=42, language='zh', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000139', created_at=datetime.datetime(2024, 5, 15, 7, 31, 20, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 18, 9, 18, 44, tzinfo=datetime.timezone.utc), customer_id='CUST-00629', customer_tier='enterprise', organization_id='ORG-086', product='DataSync Pro', product_version='4.3.13', product_module='api_connector', category='Feature Request', subcategory='New Feature', priority='medium', severity='P4', channel='chat', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-05-15T07:31:20 ERROR ERROR_CORRUPTION: Database connection lost\\n2024-05-15T07:31:21 INFO Attempting to reconnect...\\n2024-05-15T07:31:23 ERROR Connection failed', stack_trace='ERROR: api_connector.service.ServiceException: Failed to process request\\n\\tat api_connector.handler.process(api_connector.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='angry', previous_tickets=8, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 5, 18, 9, 18, 44, tzinfo=datetime.timezone.utc), agent_id='AGENT-023', agent_actions=['ran_diagnostics', 'created_workaround', 'consulted_kb'], escalated=True, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['authentication', 'error', 'configuration', 'performance', 'integration'], environment='sandbox', business_impact='critical', affected_users=19, language='es', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000140', created_at=datetime.datetime(2023, 4, 12, 8, 22, 43, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 12, 18, 39, 31, tzinfo=datetime.timezone.utc), customer_id='CUST-04095', customer_tier='enterprise', organization_id='ORG-353', product='StreamProcessor', product_version='3.2.4', product_module='batch_processor', category='Feature Request', subcategory='API', priority='medium', severity='P2', channel='phone', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-04-12T08:22:43 DEBUG Processing request ID-12345\\n2023-04-12T08:22:43 ERROR ERROR_TIMEOUT_429: Invalid request format\\n2023-04-12T08:22:44 INFO Request rejected', stack_trace='', customer_sentiment='confused', previous_tickets=6, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 4, 12, 18, 39, 31, tzinfo=datetime.timezone.utc), agent_id='AGENT-020', agent_actions=['consulted_kb', 'created_workaround', 'applied_fix', 'ran_diagnostics'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['authentication', 'timeout', 'sync', 'integration', 'security'], environment='production', business_impact='critical', affected_users=2, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000141', created_at=datetime.datetime(2024, 4, 30, 22, 19, 47, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 30, 23, 46, 11, tzinfo=datetime.timezone.utc), customer_id='CUST-02680', customer_tier='free', organization_id='ORG-416', product='DataSync Pro', product_version='4.1.9', product_module='scheduler', category='Data Issue', subcategory='Sync Error', priority='high', severity='P0', channel='slack', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_CORRUPTION appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-04-30T22:19:47 DEBUG Processing request ID-12345\\n2024-04-30T22:19:47 ERROR ERROR_CORRUPTION: Invalid request format\\n2024-04-30T22:19:48 INFO Request rejected', stack_trace='at scheduler.execute(scheduler.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='neutral', previous_tickets=9, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 4, 30, 23, 46, 11, tzinfo=datetime.timezone.utc), agent_id='AGENT-001', agent_actions=['contacted_customer', 'viewed_logs', 'escalated_to_specialist'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['authentication', 'data', 'configuration'], environment='production', business_impact='critical', affected_users=487, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000142', created_at=datetime.datetime(2024, 11, 19, 16, 13, 9, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 19, 18, 42, 33, tzinfo=datetime.timezone.utc), customer_id='CUST-00602', customer_tier='enterprise', organization_id='ORG-477', product='API Gateway', product_version='2.6.1', product_module='cache_layer', category='Technical Issue', subcategory='Integration', priority='critical', severity='P0', channel='email', subject='API Gateway throwing ERROR_CONFLICT_409 during operation', description=\"We're experiencing issues with API Gateway. The system is throwing ERROR_CONFLICT_409 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-11-19T16:13:09 ERROR ERROR_CONFLICT_409: Connection timeout after 30s\\n2024-11-19T16:13:10 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='frustrated', previous_tickets=9, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 11, 19, 18, 42, 33, tzinfo=datetime.timezone.utc), agent_id='AGENT-009', agent_actions=['ran_diagnostics', 'viewed_logs'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['database', 'configuration'], environment='staging', business_impact='medium', affected_users=53, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000143', created_at=datetime.datetime(2023, 12, 19, 20, 49, 43, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 19, 22, 42, 31, tzinfo=datetime.timezone.utc), customer_id='CUST-01562', customer_tier='premium', organization_id='ORG-345', product='DataSync Pro', product_version='4.4.10', product_module='sync_engine', category='Security', subcategory='Authentication', priority='critical', severity='P0', channel='phone', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_INVALID_400 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-12-19T20:49:43 ERROR ERROR_INVALID_400: Connection timeout after 30s\\n2023-12-19T20:49:44 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='satisfied', previous_tickets=9, resolution='Applied hotfix version 3.2.2 to address the ERROR_INVALID_400. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 12, 19, 22, 42, 31, tzinfo=datetime.timezone.utc), agent_id='AGENT-001', agent_actions=['checked_config', 'created_workaround', 'viewed_logs'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['security', 'bug', 'data'], environment='sandbox', business_impact='low', affected_users=909, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000144', created_at=datetime.datetime(2024, 5, 29, 15, 58, 59, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 30, 5, 39, 11, tzinfo=datetime.timezone.utc), customer_id='CUST-03561', customer_tier='enterprise', organization_id='ORG-431', product='StreamProcessor', product_version='3.2.12', product_module='event_handler', category='Account Management', subcategory='Access Control', priority='critical', severity='P2', channel='phone', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=8, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 5, 30, 5, 39, 11, tzinfo=datetime.timezone.utc), agent_id='AGENT-006', agent_actions=['escalated_to_specialist', 'verified_resolution', 'applied_fix', 'created_workaround', 'viewed_logs'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=True, tags=['database', 'bug', 'data'], environment='development', business_impact='high', affected_users=458, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000145', created_at=datetime.datetime(2023, 4, 25, 1, 39, 26, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 25, 5, 51, 26, tzinfo=datetime.timezone.utc), customer_id='CUST-02634', customer_tier='premium', organization_id='ORG-398', product='StreamProcessor', product_version='3.7.12', product_module='batch_processor', category='Account Management', subcategory='Access Control', priority='high', severity='P1', channel='chat', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-04-25T01:39:26 ERROR ERROR_DISK_FULL: Connection timeout after 30s\\n2023-04-25T01:39:27 RETRY_FAILED: Max retries exceeded', stack_trace='Stack trace:\\n  batch_processor::processData() at batch_processor.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='grateful', previous_tickets=8, resolution='Applied hotfix version 3.2.2 to address the ERROR_DISK_FULL. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 4, 25, 5, 51, 26, tzinfo=datetime.timezone.utc), agent_id='AGENT-044', agent_actions=['applied_fix', 'consulted_kb', 'updated_documentation'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['error', 'data', 'authentication'], environment='production', business_impact='medium', affected_users=47, language='de', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000146', created_at=datetime.datetime(2023, 6, 1, 6, 30, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 1, 11, 49, 13, tzinfo=datetime.timezone.utc), customer_id='CUST-01262', customer_tier='professional', organization_id='ORG-468', product='DataSync Pro', product_version='4.8.11', product_module='scheduler', category='Security', subcategory='Compliance', priority='high', severity='P1', channel='chat', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=4, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 6, 1, 11, 49, 13, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['applied_fix', 'verified_resolution', 'contacted_customer', 'consulted_kb'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['integration', 'database', 'performance', 'sync'], environment='production', business_impact='low', affected_users=438, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000147', created_at=datetime.datetime(2024, 5, 18, 21, 45, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 19, 18, 9, 41, tzinfo=datetime.timezone.utc), customer_id='CUST-04943', customer_tier='free', organization_id='ORG-421', product='DataSync Pro', product_version='3.9.8', product_module='sync_engine', category='Security', subcategory='Authentication', priority='critical', severity='P4', channel='portal', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=9, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 5, 19, 18, 9, 41, tzinfo=datetime.timezone.utc), agent_id='AGENT-022', agent_actions=['applied_fix', 'consulted_kb', 'checked_config'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=False, tags=['api', 'data', 'error', 'configuration', 'bug'], environment='sandbox', business_impact='high', affected_users=194, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000148', created_at=datetime.datetime(2023, 11, 18, 18, 21, 31, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 21, 21, 22, 7, tzinfo=datetime.timezone.utc), customer_id='CUST-00666', customer_tier='free', organization_id='ORG-477', product='Analytics Dashboard', product_version='2.5.1', product_module='report_builder', category='Technical Issue', subcategory='Bug', priority='low', severity='P4', channel='slack', subject='Analytics Dashboard throwing ERROR_CONFLICT_409 during operation', description=\"We're experiencing issues with Analytics Dashboard. The system is throwing ERROR_CONFLICT_409 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-11-18T18:21:31 WARN Rate limit approaching threshold\\n2023-11-18T18:21:31 ERROR ERROR_CONFLICT_409: Rate limit exceeded\\n2023-11-18T18:21:33 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='frustrated', previous_tickets=5, resolution='Root cause identified as Bug issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 11, 21, 21, 22, 7, tzinfo=datetime.timezone.utc), agent_id='AGENT-040', agent_actions=['updated_documentation', 'verified_resolution', 'escalated_to_specialist', 'ran_diagnostics'], escalated=True, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['api', 'timeout'], environment='sandbox', business_impact='critical', affected_users=13, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000149', created_at=datetime.datetime(2024, 6, 28, 8, 29, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 28, 21, 44, 1, tzinfo=datetime.timezone.utc), customer_id='CUST-01097', customer_tier='enterprise', organization_id='ORG-265', product='DataSync Pro', product_version='4.4.11', product_module='data_validator', category='Feature Request', subcategory='Enhancement', priority='critical', severity='P2', channel='chat', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-06-28T08:29:37 DEBUG Processing request ID-12345\\n2024-06-28T08:29:37 ERROR ERROR_AUTH_401: Invalid request format\\n2024-06-28T08:29:38 INFO Request rejected', stack_trace='', customer_sentiment='satisfied', previous_tickets=10, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 6, 28, 21, 44, 1, tzinfo=datetime.timezone.utc), agent_id='AGENT-032', agent_actions=['ran_diagnostics', 'consulted_kb'], escalated=True, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['performance', 'error', 'integration', 'timeout'], environment='production', business_impact='low', affected_users=985, language='es', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000150', created_at=datetime.datetime(2024, 4, 20, 23, 33, 49, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 21, 6, 47, 1, tzinfo=datetime.timezone.utc), customer_id='CUST-00950', customer_tier='starter', organization_id='ORG-479', product='DataSync Pro', product_version='3.7.11', product_module='sync_engine', category='Account Management', subcategory='Access Control', priority='medium', severity='P1', channel='email', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-04-20T23:33:49 ERROR ERROR_INVALID_400: Connection timeout after 30s\\n2024-04-20T23:33:50 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='angry', previous_tickets=5, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 4, 21, 6, 47, 1, tzinfo=datetime.timezone.utc), agent_id='AGENT-015', agent_actions=['verified_resolution', 'updated_documentation'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['security', 'bug', 'data', 'database', 'api'], environment='sandbox', business_impact='medium', affected_users=19, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000151', created_at=datetime.datetime(2023, 7, 15, 18, 41, 30, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 18, 2, 14, 30, tzinfo=datetime.timezone.utc), customer_id='CUST-01489', customer_tier='premium', organization_id='ORG-013', product='CloudBackup Enterprise', product_version='3.3.5', product_module='backup_service', category='Technical Issue', subcategory='Bug', priority='medium', severity='P4', channel='api', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_AUTH_401 in the logs. This is affecting our entire team's productivity.\", error_logs='2023-07-15T18:41:30 ERROR ERROR_AUTH_401: Database connection lost\\n2023-07-15T18:41:31 INFO Attempting to reconnect...\\n2023-07-15T18:41:33 ERROR Connection failed', stack_trace=\"Traceback (most recent call last):\\n  File 'backup_service.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='angry', previous_tickets=1, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 7, 18, 2, 14, 30, tzinfo=datetime.timezone.utc), agent_id='AGENT-003', agent_actions=['checked_config', 'consulted_kb'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['authentication', 'performance', 'data'], environment='test', business_impact='low', affected_users=36, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000152', created_at=datetime.datetime(2024, 5, 13, 14, 36, 15, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 13, 23, 35, 3, tzinfo=datetime.timezone.utc), customer_id='CUST-01551', customer_tier='enterprise', organization_id='ORG-195', product='API Gateway', product_version='2.1.8', product_module='rate_limiter', category='Security', subcategory='Authentication', priority='critical', severity='P3', channel='phone', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_MEMORY_OOM errors. We need to ensure our system meets compliance requirements.', error_logs='2024-05-13T14:36:15 ERROR ERROR_MEMORY_OOM: Connection timeout after 30s\\n2024-05-13T14:36:16 RETRY_FAILED: Max retries exceeded', stack_trace='ERROR: rate_limiter.service.ServiceException: Failed to process request\\n\\tat rate_limiter.handler.process(rate_limiter.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='neutral', previous_tickets=4, resolution='Root cause identified as Authentication issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 5, 13, 23, 35, 3, tzinfo=datetime.timezone.utc), agent_id='AGENT-001', agent_actions=['ran_diagnostics', 'contacted_customer', 'applied_fix', 'consulted_kb'], escalated=True, transferred_count=1, satisfaction_score=2, resolution_helpful=True, tags=['performance', 'security', 'api'], environment='development', business_impact='high', affected_users=36, language='es', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000153', created_at=datetime.datetime(2024, 12, 6, 22, 42, 21, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 8, 8, 43, 33, tzinfo=datetime.timezone.utc), customer_id='CUST-02291', customer_tier='enterprise', organization_id='ORG-254', product='CloudBackup Enterprise', product_version='4.5.5', product_module='restore_module', category='Feature Request', subcategory='API', priority='high', severity='P4', channel='slack', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-12-06T22:42:21 ERROR ERROR_CONFLICT_409: Connection timeout after 30s\\n2024-12-06T22:42:22 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='frustrated', previous_tickets=8, resolution='Applied hotfix version 3.2.2 to address the ERROR_CONFLICT_409. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 12, 8, 8, 43, 33, tzinfo=datetime.timezone.utc), agent_id='AGENT-027', agent_actions=['updated_documentation', 'checked_config', 'viewed_logs', 'applied_fix'], escalated=True, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['security', 'database', 'data', 'api', 'timeout'], environment='staging', business_impact='medium', affected_users=694, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000154', created_at=datetime.datetime(2024, 6, 2, 20, 15, 28, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 3, 11, 9, 28, tzinfo=datetime.timezone.utc), customer_id='CUST-03023', customer_tier='professional', organization_id='ORG-395', product='Analytics Dashboard', product_version='3.2.8', product_module='visualization', category='Technical Issue', subcategory='Configuration', priority='high', severity='P2', channel='chat', subject='Performance degradation in Analytics Dashboard', description=\"The Analytics Dashboard has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_INVALID_400 in the logs. This is affecting our entire team's productivity.\", error_logs='2024-06-02T20:15:28 ERROR ERROR_INVALID_400: Connection timeout after 30s\\n2024-06-02T20:15:29 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='satisfied', previous_tickets=9, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 6, 3, 11, 9, 28, tzinfo=datetime.timezone.utc), agent_id='AGENT-041', agent_actions=['updated_documentation', 'contacted_customer', 'consulted_kb', 'ran_diagnostics'], escalated=True, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['error', 'database', 'authentication'], environment='production', business_impact='medium', affected_users=756, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000155', created_at=datetime.datetime(2024, 3, 31, 12, 27, 27, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 1, 8, 17, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-03292', customer_tier='premium', organization_id='ORG-124', product='API Gateway', product_version='4.2.0', product_module='request_router', category='Data Issue', subcategory='Validation', priority='critical', severity='P4', channel='phone', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_VALIDATION appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-03-31T12:27:27 WARN Rate limit approaching threshold\\n2024-03-31T12:27:27 ERROR ERROR_VALIDATION: Rate limit exceeded\\n2024-03-31T12:27:29 INFO Backing off for 60 seconds', stack_trace='ERROR: request_router.service.ServiceException: Failed to process request\\n\\tat request_router.handler.process(request_router.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='satisfied', previous_tickets=6, resolution='Root cause identified as Validation issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 4, 1, 8, 17, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-018', agent_actions=['created_workaround', 'checked_config', 'viewed_logs'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['timeout', 'sync'], environment='staging', business_impact='critical', affected_users=563, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000156', created_at=datetime.datetime(2023, 10, 28, 14, 54, 5, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 30, 9, 52, 53, tzinfo=datetime.timezone.utc), customer_id='CUST-02593', customer_tier='free', organization_id='ORG-356', product='API Gateway', product_version='3.3.3', product_module='rate_limiter', category='Data Issue', subcategory='Import/Export', priority='high', severity='P4', channel='slack', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=7, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 10, 30, 9, 52, 53, tzinfo=datetime.timezone.utc), agent_id='AGENT-003', agent_actions=['escalated_to_specialist', 'viewed_logs', 'applied_fix'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['timeout', 'database', 'integration'], environment='production', business_impact='critical', affected_users=737, language='es', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000157', created_at=datetime.datetime(2024, 4, 18, 13, 48, 47, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 18, 21, 24, 47, tzinfo=datetime.timezone.utc), customer_id='CUST-00283', customer_tier='professional', organization_id='ORG-193', product='API Gateway', product_version='3.5.1', product_module='auth_service', category='Account Management', subcategory='Subscription', priority='medium', severity='P1', channel='chat', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=6, resolution='Root cause identified as Subscription issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 4, 18, 21, 24, 47, tzinfo=datetime.timezone.utc), agent_id='AGENT-048', agent_actions=['viewed_logs', 'created_workaround'], escalated=True, transferred_count=1, satisfaction_score=1, resolution_helpful=True, tags=['configuration', 'data', 'api', 'authentication', 'error'], environment='test', business_impact='medium', affected_users=45, language='de', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000158', created_at=datetime.datetime(2024, 9, 28, 6, 52, 16, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 28, 9, 7, 52, tzinfo=datetime.timezone.utc), customer_id='CUST-03837', customer_tier='premium', organization_id='ORG-034', product='Analytics Dashboard', product_version='2.9.0', product_module='report_builder', category='Technical Issue', subcategory='Bug', priority='critical', severity='P1', channel='slack', subject='Performance degradation in Analytics Dashboard', description=\"The Analytics Dashboard has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_MEMORY_OOM in the logs. This is affecting our entire team's productivity.\", error_logs='2024-09-28T06:52:16 WARN Rate limit approaching threshold\\n2024-09-28T06:52:16 ERROR ERROR_MEMORY_OOM: Rate limit exceeded\\n2024-09-28T06:52:18 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='grateful', previous_tickets=10, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 9, 28, 9, 7, 52, tzinfo=datetime.timezone.utc), agent_id='AGENT-010', agent_actions=['verified_resolution', 'checked_config'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=False, tags=['configuration', 'api', 'database', 'data', 'error'], environment='test', business_impact='critical', affected_users=439, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000159', created_at=datetime.datetime(2023, 9, 22, 8, 55, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 23, 17, 2, 57, tzinfo=datetime.timezone.utc), customer_id='CUST-00071', customer_tier='professional', organization_id='ORG-371', product='Analytics Dashboard', product_version='2.3.4', product_module='visualization', category='Security', subcategory='Authentication', priority='low', severity='P2', channel='email', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_AUTH_401 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-09-22T08:55:45 DEBUG Processing request ID-12345\\n2023-09-22T08:55:45 ERROR ERROR_AUTH_401: Invalid request format\\n2023-09-22T08:55:46 INFO Request rejected', stack_trace='', customer_sentiment='angry', previous_tickets=4, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 9, 23, 17, 2, 57, tzinfo=datetime.timezone.utc), agent_id='AGENT-046', agent_actions=['contacted_customer', 'consulted_kb', 'created_workaround', 'updated_documentation'], escalated=True, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['integration', 'api'], environment='production', business_impact='high', affected_users=42, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000160', created_at=datetime.datetime(2024, 11, 10, 5, 41, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 12, 8, 15, 21, tzinfo=datetime.timezone.utc), customer_id='CUST-01631', customer_tier='enterprise', organization_id='ORG-042', product='DataSync Pro', product_version='3.0.0', product_module='scheduler', category='Data Issue', subcategory='Sync Error', priority='medium', severity='P3', channel='api', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_AUTH_401 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-11-10T05:41:45 DEBUG Processing request ID-12345\\n2024-11-10T05:41:45 ERROR ERROR_AUTH_401: Invalid request format\\n2024-11-10T05:41:46 INFO Request rejected', stack_trace='', customer_sentiment='frustrated', previous_tickets=7, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 11, 12, 8, 15, 21, tzinfo=datetime.timezone.utc), agent_id='AGENT-048', agent_actions=['escalated_to_specialist', 'verified_resolution', 'contacted_customer', 'ran_diagnostics', 'applied_fix'], escalated=False, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['api', 'bug'], environment='sandbox', business_impact='high', affected_users=48, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000161', created_at=datetime.datetime(2023, 2, 28, 4, 5, 32, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 28, 6, 27, 8, tzinfo=datetime.timezone.utc), customer_id='CUST-03266', customer_tier='free', organization_id='ORG-367', product='API Gateway', product_version='4.4.9', product_module='auth_service', category='Feature Request', subcategory='New Feature', priority='critical', severity='P1', channel='phone', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=3, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 2, 28, 6, 27, 8, tzinfo=datetime.timezone.utc), agent_id='AGENT-046', agent_actions=['created_workaround', 'consulted_kb'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['api', 'error', 'database'], environment='development', business_impact='critical', affected_users=402, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000162', created_at=datetime.datetime(2024, 2, 15, 14, 19, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 18, 4, 49, 45, tzinfo=datetime.timezone.utc), customer_id='CUST-01771', customer_tier='premium', organization_id='ORG-370', product='CloudBackup Enterprise', product_version='4.0.9', product_module='compression_engine', category='Feature Request', subcategory='Documentation', priority='low', severity='P4', channel='slack', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=10, resolution='Root cause identified as Documentation issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 2, 18, 4, 49, 45, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['checked_config', 'applied_fix', 'updated_documentation'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['configuration', 'data', 'bug', 'performance', 'api'], environment='sandbox', business_impact='critical', affected_users=3, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000163', created_at=datetime.datetime(2024, 7, 6, 8, 34, 18, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 10, 5, 31, 54, tzinfo=datetime.timezone.utc), customer_id='CUST-01126', customer_tier='professional', organization_id='ORG-129', product='API Gateway', product_version='3.0.1', product_module='request_router', category='Feature Request', subcategory='New Feature', priority='medium', severity='P4', channel='portal', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-07-06T08:34:18 DEBUG Processing request ID-12345\\n2024-07-06T08:34:18 ERROR ERROR_CONFLICT_409: Invalid request format\\n2024-07-06T08:34:19 INFO Request rejected', stack_trace='', customer_sentiment='angry', previous_tickets=7, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 7, 10, 5, 31, 54, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['viewed_logs', 'checked_config', 'verified_resolution', 'updated_documentation', 'consulted_kb'], escalated=True, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['database', 'security'], environment='development', business_impact='high', affected_users=12, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000164', created_at=datetime.datetime(2023, 8, 7, 3, 15, 8, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 8, 15, 21, 8, tzinfo=datetime.timezone.utc), customer_id='CUST-02075', customer_tier='enterprise', organization_id='ORG-492', product='DataSync Pro', product_version='4.5.13', product_module='scheduler', category='Technical Issue', subcategory='Bug', priority='medium', severity='P3', channel='chat', subject='Performance degradation in DataSync Pro', description=\"The DataSync Pro has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_PERMISSION_403 in the logs. This is affecting our entire team's productivity.\", error_logs='2023-08-07T03:15:08 DEBUG Processing request ID-12345\\n2023-08-07T03:15:08 ERROR ERROR_PERMISSION_403: Invalid request format\\n2023-08-07T03:15:09 INFO Request rejected', stack_trace=\"Traceback (most recent call last):\\n  File 'scheduler.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='confused', previous_tickets=3, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 8, 8, 15, 21, 8, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['contacted_customer', 'consulted_kb', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['integration', 'api', 'security', 'performance', 'database'], environment='production', business_impact='medium', affected_users=27, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000165', created_at=datetime.datetime(2024, 8, 22, 5, 58, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 22, 14, 49, 1, tzinfo=datetime.timezone.utc), customer_id='CUST-02917', customer_tier='starter', organization_id='ORG-048', product='API Gateway', product_version='4.2.14', product_module='request_router', category='Feature Request', subcategory='Documentation', priority='medium', severity='P1', channel='email', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-08-22T05:58:37 ERROR ERROR_VALIDATION: Database connection lost\\n2024-08-22T05:58:38 INFO Attempting to reconnect...\\n2024-08-22T05:58:40 ERROR Connection failed', stack_trace='', customer_sentiment='grateful', previous_tickets=8, resolution='Applied hotfix version 3.2.2 to address the ERROR_VALIDATION. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 8, 22, 14, 49, 1, tzinfo=datetime.timezone.utc), agent_id='AGENT-042', agent_actions=['ran_diagnostics', 'escalated_to_specialist', 'verified_resolution', 'consulted_kb', 'applied_fix', 'created_workaround'], escalated=True, transferred_count=2, satisfaction_score=4, resolution_helpful=False, tags=['database', 'timeout', 'authentication'], environment='sandbox', business_impact='medium', affected_users=40, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000166', created_at=datetime.datetime(2024, 8, 16, 22, 8, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 16, 23, 0, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-02127', customer_tier='premium', organization_id='ORG-339', product='DataSync Pro', product_version='3.2.2', product_module='scheduler', category='Data Issue', subcategory='Validation', priority='critical', severity='P0', channel='api', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_AUTH_401 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-08-16T22:08:39 WARN Rate limit approaching threshold\\n2024-08-16T22:08:39 ERROR ERROR_AUTH_401: Rate limit exceeded\\n2024-08-16T22:08:41 INFO Backing off for 60 seconds', stack_trace='Stack trace:\\n  scheduler::processData() at scheduler.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='neutral', previous_tickets=4, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 8, 16, 23, 0, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-035', agent_actions=['verified_resolution', 'escalated_to_specialist'], escalated=True, transferred_count=1, satisfaction_score=1, resolution_helpful=False, tags=['performance', 'integration', 'api'], environment='test', business_impact='high', affected_users=532, language='zh', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000167', created_at=datetime.datetime(2023, 12, 24, 11, 45, 22, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 25, 21, 15, 22, tzinfo=datetime.timezone.utc), customer_id='CUST-04676', customer_tier='free', organization_id='ORG-254', product='StreamProcessor', product_version='2.3.3', product_module='batch_processor', category='Account Management', subcategory='License', priority='high', severity='P3', channel='portal', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=5, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 12, 25, 21, 15, 22, tzinfo=datetime.timezone.utc), agent_id='AGENT-023', agent_actions=['escalated_to_specialist', 'ran_diagnostics'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['api', 'performance', 'timeout'], environment='development', business_impact='low', affected_users=34, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000168', created_at=datetime.datetime(2023, 9, 19, 23, 42, 26, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 21, 7, 28, 38, tzinfo=datetime.timezone.utc), customer_id='CUST-00822', customer_tier='enterprise', organization_id='ORG-465', product='Analytics Dashboard', product_version='4.4.9', product_module='export_module', category='Data Issue', subcategory='Sync Error', priority='low', severity='P2', channel='api', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_PARSING appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-09-19T23:42:26 ERROR ERROR_PARSING: Connection timeout after 30s\\n2023-09-19T23:42:27 RETRY_FAILED: Max retries exceeded', stack_trace='ERROR: export_module.service.ServiceException: Failed to process request\\n\\tat export_module.handler.process(export_module.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='satisfied', previous_tickets=10, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 9, 21, 7, 28, 38, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['created_workaround', 'ran_diagnostics', 'applied_fix'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['integration', 'configuration', 'authentication', 'timeout', 'database'], environment='development', business_impact='medium', affected_users=49, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000169', created_at=datetime.datetime(2024, 4, 22, 1, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 22, 15, 29, 12, tzinfo=datetime.timezone.utc), customer_id='CUST-00626', customer_tier='premium', organization_id='ORG-147', product='CloudBackup Enterprise', product_version='4.6.1', product_module='compression_engine', category='Data Issue', subcategory='Sync Error', priority='medium', severity='P2', channel='chat', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=4, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 4, 22, 15, 29, 12, tzinfo=datetime.timezone.utc), agent_id='AGENT-006', agent_actions=['applied_fix', 'viewed_logs'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=False, tags=['error', 'performance', 'api', 'data'], environment='staging', business_impact='low', affected_users=8, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000170', created_at=datetime.datetime(2024, 3, 22, 2, 2, 16, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 22, 3, 29, 52, tzinfo=datetime.timezone.utc), customer_id='CUST-02819', customer_tier='starter', organization_id='ORG-219', product='Analytics Dashboard', product_version='2.5.6', product_module='report_builder', category='Security', subcategory='Authentication', priority='critical', severity='P0', channel='phone', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_SERVER_500 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-03-22T02:02:16 WARN Rate limit approaching threshold\\n2024-03-22T02:02:16 ERROR ERROR_SERVER_500: Rate limit exceeded\\n2024-03-22T02:02:18 INFO Backing off for 60 seconds', stack_trace='at report_builder.execute(report_builder.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='grateful', previous_tickets=0, resolution='Root cause identified as Authentication issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 3, 22, 3, 29, 52, tzinfo=datetime.timezone.utc), agent_id='AGENT-018', agent_actions=['contacted_customer', 'verified_resolution', 'applied_fix', 'viewed_logs', 'escalated_to_specialist'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['api', 'timeout', 'performance', 'data'], environment='test', business_impact='low', affected_users=272, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000171', created_at=datetime.datetime(2024, 3, 4, 6, 14, 27, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 4, 6, 37, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-03374', customer_tier='professional', organization_id='ORG-014', product='Analytics Dashboard', product_version='3.8.10', product_module='data_aggregator', category='Account Management', subcategory='Billing', priority='critical', severity='P0', channel='portal', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-03-04T06:14:27 WARN Rate limit approaching threshold\\n2024-03-04T06:14:27 ERROR ERROR_INVALID_400: Rate limit exceeded\\n2024-03-04T06:14:29 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'data_aggregator.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='confused', previous_tickets=8, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 3, 4, 6, 37, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-018', agent_actions=['verified_resolution', 'ran_diagnostics', 'checked_config'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=False, tags=['configuration', 'integration'], environment='development', business_impact='high', affected_users=532, language='it', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000172', created_at=datetime.datetime(2024, 6, 21, 10, 2, 36, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 21, 10, 44, tzinfo=datetime.timezone.utc), customer_id='CUST-02907', customer_tier='free', organization_id='ORG-017', product='DataSync Pro', product_version='4.9.14', product_module='api_connector', category='Account Management', subcategory='Upgrade', priority='critical', severity='P0', channel='email', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=0, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 6, 21, 10, 44, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['created_workaround', 'checked_config'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['security', 'timeout'], environment='development', business_impact='medium', affected_users=162, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000173', created_at=datetime.datetime(2024, 6, 30, 8, 31, 12, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 1, 4, 7, 12, tzinfo=datetime.timezone.utc), customer_id='CUST-02053', customer_tier='starter', organization_id='ORG-367', product='DataSync Pro', product_version='2.4.9', product_module='api_connector', category='Account Management', subcategory='Subscription', priority='critical', severity='P4', channel='portal', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=2, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 7, 1, 4, 7, 12, tzinfo=datetime.timezone.utc), agent_id='AGENT-049', agent_actions=['checked_config', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['performance', 'error', 'authentication', 'database', 'security'], environment='test', business_impact='high', affected_users=8, language='fr', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000174', created_at=datetime.datetime(2024, 2, 12, 13, 16, 36, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 13, 2, 46, 36, tzinfo=datetime.timezone.utc), customer_id='CUST-02215', customer_tier='professional', organization_id='ORG-159', product='DataSync Pro', product_version='3.5.3', product_module='api_connector', category='Security', subcategory='Authorization', priority='critical', severity='P3', channel='slack', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_DEADLOCK errors. We need to ensure our system meets compliance requirements.', error_logs='2024-02-12T13:16:36 WARN Rate limit approaching threshold\\n2024-02-12T13:16:36 ERROR ERROR_DEADLOCK: Rate limit exceeded\\n2024-02-12T13:16:38 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'api_connector.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='grateful', previous_tickets=4, resolution='Applied hotfix version 3.2.2 to address the ERROR_DEADLOCK. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 2, 13, 2, 46, 36, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['updated_documentation', 'checked_config', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=True, tags=['integration', 'data', 'sync', 'configuration'], environment='staging', business_impact='low', affected_users=16, language='en', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000175', created_at=datetime.datetime(2023, 6, 13, 20, 5, 28, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 15, 1, 0, 4, tzinfo=datetime.timezone.utc), customer_id='CUST-00947', customer_tier='enterprise', organization_id='ORG-460', product='DataSync Pro', product_version='4.4.15', product_module='scheduler', category='Data Issue', subcategory='Sync Error', priority='high', severity='P3', channel='phone', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=10, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 6, 15, 1, 0, 4, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['escalated_to_specialist', 'updated_documentation', 'viewed_logs'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['database', 'sync', 'error'], environment='production', business_impact='low', affected_users=828, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000176', created_at=datetime.datetime(2023, 6, 14, 19, 36, 43, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 14, 20, 52, 19, tzinfo=datetime.timezone.utc), customer_id='CUST-02495', customer_tier='premium', organization_id='ORG-406', product='DataSync Pro', product_version='4.7.11', product_module='api_connector', category='Technical Issue', subcategory='Bug', priority='critical', severity='P0', channel='email', subject='Performance degradation in DataSync Pro', description=\"The DataSync Pro has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_CORRUPTION in the logs. This is affecting our entire team's productivity.\", error_logs='2023-06-14T19:36:43 ERROR ERROR_CORRUPTION: Connection timeout after 30s\\n2023-06-14T19:36:44 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='frustrated', previous_tickets=10, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 6, 14, 20, 52, 19, tzinfo=datetime.timezone.utc), agent_id='AGENT-015', agent_actions=['checked_config', 'updated_documentation', 'created_workaround', 'applied_fix'], escalated=True, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['integration', 'data'], environment='staging', business_impact='medium', affected_users=453, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000177', created_at=datetime.datetime(2023, 11, 12, 8, 38, 46, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 12, 9, 32, 46, tzinfo=datetime.timezone.utc), customer_id='CUST-04977', customer_tier='premium', organization_id='ORG-368', product='API Gateway', product_version='4.5.10', product_module='cache_layer', category='Technical Issue', subcategory='Integration', priority='high', severity='P0', channel='chat', subject='API Gateway throwing ERROR_DEADLOCK during operation', description=\"We're experiencing issues with API Gateway. The system is throwing ERROR_DEADLOCK when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-11-12T08:38:46 ERROR ERROR_DEADLOCK: Connection timeout after 30s\\n2023-11-12T08:38:47 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='satisfied', previous_tickets=1, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 11, 12, 9, 32, 46, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['escalated_to_specialist', 'updated_documentation', 'consulted_kb'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['sync', 'timeout', 'integration', 'error'], environment='test', business_impact='medium', affected_users=265, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000178', created_at=datetime.datetime(2023, 10, 12, 7, 14, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 12, 9, 19, 25, tzinfo=datetime.timezone.utc), customer_id='CUST-00429', customer_tier='professional', organization_id='ORG-376', product='Analytics Dashboard', product_version='2.7.5', product_module='report_builder', category='Account Management', subcategory='Billing', priority='critical', severity='P1', channel='phone', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=0, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 10, 12, 9, 19, 25, tzinfo=datetime.timezone.utc), agent_id='AGENT-024', agent_actions=['applied_fix', 'created_workaround', 'updated_documentation', 'contacted_customer'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['bug', 'authentication'], environment='test', business_impact='critical', affected_users=916, language='pt', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000179', created_at=datetime.datetime(2024, 12, 8, 3, 5, 43, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 8, 12, 34, 31, tzinfo=datetime.timezone.utc), customer_id='CUST-04656', customer_tier='premium', organization_id='ORG-022', product='DataSync Pro', product_version='2.2.4', product_module='scheduler', category='Security', subcategory='Encryption', priority='high', severity='P2', channel='api', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_RATELIMIT_429 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-12-08T03:05:43 DEBUG Processing request ID-12345\\n2024-12-08T03:05:43 ERROR ERROR_RATELIMIT_429: Invalid request format\\n2024-12-08T03:05:44 INFO Request rejected', stack_trace='', customer_sentiment='frustrated', previous_tickets=9, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 12, 8, 12, 34, 31, tzinfo=datetime.timezone.utc), agent_id='AGENT-025', agent_actions=['created_workaround', 'contacted_customer'], escalated=False, transferred_count=1, satisfaction_score=1, resolution_helpful=False, tags=['integration', 'performance', 'timeout', 'data', 'api'], environment='test', business_impact='low', affected_users=66, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000180', created_at=datetime.datetime(2024, 5, 22, 3, 13, 34, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 22, 4, 36, 58, tzinfo=datetime.timezone.utc), customer_id='CUST-01693', customer_tier='professional', organization_id='ORG-313', product='Analytics Dashboard', product_version='3.6.2', product_module='report_builder', category='Security', subcategory='Authorization', priority='medium', severity='P0', channel='email', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=9, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 5, 22, 4, 36, 58, tzinfo=datetime.timezone.utc), agent_id='AGENT-003', agent_actions=['consulted_kb', 'created_workaround', 'contacted_customer', 'updated_documentation'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['performance', 'sync', 'authentication', 'database'], environment='production', business_impact='low', affected_users=22, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000181', created_at=datetime.datetime(2023, 9, 7, 15, 4, 58, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 7, 19, 28, 58, tzinfo=datetime.timezone.utc), customer_id='CUST-00087', customer_tier='professional', organization_id='ORG-296', product='API Gateway', product_version='4.2.11', product_module='auth_service', category='Feature Request', subcategory='API', priority='medium', severity='P2', channel='chat', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-09-07T15:04:58 ERROR ERROR_DISK_FULL: Database connection lost\\n2023-09-07T15:04:59 INFO Attempting to reconnect...\\n2023-09-07T15:05:01 ERROR Connection failed', stack_trace=\"Traceback (most recent call last):\\n  File 'auth_service.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='satisfied', previous_tickets=8, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 9, 7, 19, 28, 58, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['updated_documentation', 'viewed_logs'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['sync', 'integration', 'api', 'security', 'error'], environment='sandbox', business_impact='medium', affected_users=47, language='de', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000182', created_at=datetime.datetime(2024, 2, 2, 2, 17, 27, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 2, 4, 30, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-01594', customer_tier='professional', organization_id='ORG-353', product='CloudBackup Enterprise', product_version='4.5.8', product_module='encryption_layer', category='Technical Issue', subcategory='Integration', priority='medium', severity='P1', channel='chat', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_VALIDATION in the logs. This is affecting our entire team's productivity.\", error_logs='2024-02-02T02:17:27 DEBUG Processing request ID-12345\\n2024-02-02T02:17:27 ERROR ERROR_VALIDATION: Invalid request format\\n2024-02-02T02:17:28 INFO Request rejected', stack_trace='', customer_sentiment='angry', previous_tickets=2, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 2, 2, 4, 30, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['viewed_logs', 'applied_fix'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=True, tags=['bug', 'authentication', 'data', 'configuration', 'timeout'], environment='development', business_impact='low', affected_users=41, language='it', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000183', created_at=datetime.datetime(2024, 5, 31, 8, 38, 53, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 31, 9, 29, 17, tzinfo=datetime.timezone.utc), customer_id='CUST-03412', customer_tier='free', organization_id='ORG-137', product='StreamProcessor', product_version='3.9.10', product_module='event_handler', category='Security', subcategory='Encryption', priority='low', severity='P0', channel='email', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Getting ERROR_AUTH_401 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-05-31T08:38:53 WARN Rate limit approaching threshold\\n2024-05-31T08:38:53 ERROR ERROR_AUTH_401: Rate limit exceeded\\n2024-05-31T08:38:55 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'event_handler.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='neutral', previous_tickets=9, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 5, 31, 9, 29, 17, tzinfo=datetime.timezone.utc), agent_id='AGENT-005', agent_actions=['escalated_to_specialist', 'verified_resolution', 'consulted_kb'], escalated=True, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['integration', 'security', 'timeout', 'api'], environment='production', business_impact='low', affected_users=30, language='zh', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000184', created_at=datetime.datetime(2024, 7, 26, 7, 17, 23, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 26, 13, 13, 47, tzinfo=datetime.timezone.utc), customer_id='CUST-01271', customer_tier='professional', organization_id='ORG-021', product='StreamProcessor', product_version='4.1.13', product_module='event_handler', category='Security', subcategory='Authentication', priority='high', severity='P1', channel='chat', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Getting ERROR_PARSING errors. We need to ensure our system meets compliance requirements.', error_logs='2024-07-26T07:17:23 DEBUG Processing request ID-12345\\n2024-07-26T07:17:23 ERROR ERROR_PARSING: Invalid request format\\n2024-07-26T07:17:24 INFO Request rejected', stack_trace='', customer_sentiment='neutral', previous_tickets=1, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 7, 26, 13, 13, 47, tzinfo=datetime.timezone.utc), agent_id='AGENT-013', agent_actions=['escalated_to_specialist', 'contacted_customer', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['bug', 'performance', 'timeout', 'authentication'], environment='staging', business_impact='low', affected_users=685, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000185', created_at=datetime.datetime(2024, 12, 13, 1, 38, 58, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 13, 9, 55, 10, tzinfo=datetime.timezone.utc), customer_id='CUST-04722', customer_tier='premium', organization_id='ORG-197', product='CloudBackup Enterprise', product_version='2.5.8', product_module='compression_engine', category='Data Issue', subcategory='Corruption', priority='low', severity='P1', channel='portal', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_AUTH_401 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-12-13T01:38:58 ERROR ERROR_AUTH_401: Connection timeout after 30s\\n2024-12-13T01:38:59 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'compression_engine.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='grateful', previous_tickets=5, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 12, 13, 9, 55, 10, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['escalated_to_specialist', 'checked_config'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['error', 'bug', 'data'], environment='staging', business_impact='medium', affected_users=3, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000186', created_at=datetime.datetime(2023, 4, 14, 6, 23, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 18, 2, 50, 3, tzinfo=datetime.timezone.utc), customer_id='CUST-03261', customer_tier='professional', organization_id='ORG-353', product='StreamProcessor', product_version='2.2.15', product_module='error_handler', category='Account Management', subcategory='Upgrade', priority='low', severity='P3', channel='slack', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-04-14T06:23:39 ERROR ERROR_CONNECTION_REFUSED: Database connection lost\\n2023-04-14T06:23:40 INFO Attempting to reconnect...\\n2023-04-14T06:23:42 ERROR Connection failed', stack_trace='', customer_sentiment='angry', previous_tickets=0, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 4, 18, 2, 50, 3, tzinfo=datetime.timezone.utc), agent_id='AGENT-035', agent_actions=['verified_resolution', 'consulted_kb', 'ran_diagnostics'], escalated=True, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'timeout', 'bug'], environment='test', business_impact='critical', affected_users=29, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000187', created_at=datetime.datetime(2023, 7, 31, 22, 20, 2, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 5, 15, 8, 38, tzinfo=datetime.timezone.utc), customer_id='CUST-01154', customer_tier='starter', organization_id='ORG-226', product='DataSync Pro', product_version='4.5.12', product_module='api_connector', category='Feature Request', subcategory='Documentation', priority='medium', severity='P4', channel='chat', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-07-31T22:20:02 DEBUG Processing request ID-12345\\n2023-07-31T22:20:02 ERROR ERROR_SERVER_500: Invalid request format\\n2023-07-31T22:20:03 INFO Request rejected', stack_trace='at api_connector.execute(api_connector.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='grateful', previous_tickets=0, resolution='Applied hotfix version 3.2.2 to address the ERROR_SERVER_500. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 8, 5, 15, 8, 38, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['viewed_logs', 'checked_config', 'applied_fix', 'verified_resolution'], escalated=True, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['timeout', 'data', 'error', 'bug'], environment='test', business_impact='high', affected_users=40, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000188', created_at=datetime.datetime(2024, 11, 7, 21, 0, 26, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 7, 22, 5, 14, tzinfo=datetime.timezone.utc), customer_id='CUST-04743', customer_tier='enterprise', organization_id='ORG-362', product='StreamProcessor', product_version='3.9.6', product_module='monitoring', category='Data Issue', subcategory='Import/Export', priority='medium', severity='P0', channel='slack', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_VALIDATION appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-11-07T21:00:26 ERROR ERROR_VALIDATION: Database connection lost\\n2024-11-07T21:00:27 INFO Attempting to reconnect...\\n2024-11-07T21:00:29 ERROR Connection failed', stack_trace='', customer_sentiment='neutral', previous_tickets=1, resolution='Root cause identified as Import/Export issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 11, 7, 22, 5, 14, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['checked_config', 'updated_documentation', 'escalated_to_specialist', 'contacted_customer', 'viewed_logs'], escalated=True, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['timeout', 'sync', 'security', 'performance'], environment='development', business_impact='high', affected_users=32, language='pt', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000189', created_at=datetime.datetime(2023, 8, 29, 4, 36, 27, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 30, 10, 36, 27, tzinfo=datetime.timezone.utc), customer_id='CUST-02144', customer_tier='professional', organization_id='ORG-275', product='DataSync Pro', product_version='2.2.11', product_module='scheduler', category='Feature Request', subcategory='API', priority='critical', severity='P4', channel='email', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=1, resolution='Root cause identified as API issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 8, 30, 10, 36, 27, tzinfo=datetime.timezone.utc), agent_id='AGENT-003', agent_actions=['verified_resolution', 'checked_config', 'viewed_logs', 'consulted_kb', 'escalated_to_specialist'], escalated=True, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['timeout', 'authentication', 'error', 'database', 'security'], environment='production', business_impact='critical', affected_users=354, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000190', created_at=datetime.datetime(2024, 8, 21, 1, 37, 7, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 21, 22, 2, 19, tzinfo=datetime.timezone.utc), customer_id='CUST-03933', customer_tier='free', organization_id='ORG-140', product='Analytics Dashboard', product_version='2.7.15', product_module='data_aggregator', category='Data Issue', subcategory='Validation', priority='high', severity='P2', channel='slack', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=3, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 8, 21, 22, 2, 19, tzinfo=datetime.timezone.utc), agent_id='AGENT-045', agent_actions=['verified_resolution', 'checked_config', 'viewed_logs', 'created_workaround', 'updated_documentation'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['bug', 'integration'], environment='test', business_impact='medium', affected_users=583, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000191', created_at=datetime.datetime(2023, 2, 22, 1, 30, 13, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 2, 6, 59, 37, tzinfo=datetime.timezone.utc), customer_id='CUST-01352', customer_tier='professional', organization_id='ORG-391', product='StreamProcessor', product_version='2.9.0', product_module='monitoring', category='Data Issue', subcategory='Validation', priority='low', severity='P4', channel='slack', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_TIMEOUT_429 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-02-22T01:30:13 WARN Rate limit approaching threshold\\n2023-02-22T01:30:13 ERROR ERROR_TIMEOUT_429: Rate limit exceeded\\n2023-02-22T01:30:15 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='confused', previous_tickets=10, resolution='Root cause identified as Validation issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 3, 2, 6, 59, 37, tzinfo=datetime.timezone.utc), agent_id='AGENT-015', agent_actions=['escalated_to_specialist', 'verified_resolution', 'ran_diagnostics', 'contacted_customer'], escalated=True, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['authentication', 'configuration', 'bug', 'security', 'error'], environment='development', business_impact='medium', affected_users=29, language='it', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000192', created_at=datetime.datetime(2024, 9, 28, 22, 35, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 29, 10, 50, 37, tzinfo=datetime.timezone.utc), customer_id='CUST-03146', customer_tier='enterprise', organization_id='ORG-242', product='CloudBackup Enterprise', product_version='2.2.0', product_module='compression_engine', category='Security', subcategory='Authentication', priority='medium', severity='P2', channel='slack', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Getting ERROR_VALIDATION errors. We need to ensure our system meets compliance requirements.', error_logs='2024-09-28T22:35:37 ERROR ERROR_VALIDATION: Database connection lost\\n2024-09-28T22:35:38 INFO Attempting to reconnect...\\n2024-09-28T22:35:40 ERROR Connection failed', stack_trace='', customer_sentiment='satisfied', previous_tickets=0, resolution='Applied hotfix version 3.2.2 to address the ERROR_VALIDATION. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 9, 29, 10, 50, 37, tzinfo=datetime.timezone.utc), agent_id='AGENT-021', agent_actions=['verified_resolution', 'consulted_kb'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=True, tags=['data', 'sync', 'database'], environment='test', business_impact='medium', affected_users=28, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000193', created_at=datetime.datetime(2023, 2, 13, 8, 54, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 14, 23, 42, 38, tzinfo=datetime.timezone.utc), customer_id='CUST-01759', customer_tier='starter', organization_id='ORG-195', product='DataSync Pro', product_version='3.1.9', product_module='api_connector', category='Security', subcategory='Compliance', priority='medium', severity='P3', channel='portal', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_INVALID_400 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-02-13T08:54:38 ERROR ERROR_INVALID_400: Database connection lost\\n2023-02-13T08:54:39 INFO Attempting to reconnect...\\n2023-02-13T08:54:41 ERROR Connection failed', stack_trace='ERROR: api_connector.service.ServiceException: Failed to process request\\n\\tat api_connector.handler.process(api_connector.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='neutral', previous_tickets=7, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 2, 14, 23, 42, 38, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['consulted_kb', 'contacted_customer', 'applied_fix'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['security', 'api', 'performance'], environment='production', business_impact='high', affected_users=44, language='pt', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000194', created_at=datetime.datetime(2024, 7, 15, 12, 4, 55, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 15, 18, 41, 31, tzinfo=datetime.timezone.utc), customer_id='CUST-04069', customer_tier='starter', organization_id='ORG-422', product='DataSync Pro', product_version='2.2.0', product_module='scheduler', category='Technical Issue', subcategory='Compatibility', priority='critical', severity='P2', channel='slack', subject='Performance degradation in DataSync Pro', description=\"The DataSync Pro has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_AUTH_401 in the logs. This is affecting our entire team's productivity.\", error_logs='2024-07-15T12:04:55 WARN Rate limit approaching threshold\\n2024-07-15T12:04:55 ERROR ERROR_AUTH_401: Rate limit exceeded\\n2024-07-15T12:04:57 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='neutral', previous_tickets=5, resolution='Applied hotfix version 3.2.2 to address the ERROR_AUTH_401. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 7, 15, 18, 41, 31, tzinfo=datetime.timezone.utc), agent_id='AGENT-032', agent_actions=['updated_documentation', 'applied_fix', 'verified_resolution', 'ran_diagnostics'], escalated=True, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['data', 'database', 'timeout'], environment='production', business_impact='medium', affected_users=332, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000195', created_at=datetime.datetime(2024, 2, 2, 6, 57, 23, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 3, 6, 12, 23, tzinfo=datetime.timezone.utc), customer_id='CUST-00786', customer_tier='enterprise', organization_id='ORG-265', product='API Gateway', product_version='2.9.3', product_module='request_router', category='Security', subcategory='Compliance', priority='low', severity='P2', channel='email', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_RATELIMIT_429 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-02-02T06:57:23 ERROR ERROR_RATELIMIT_429: Database connection lost\\n2024-02-02T06:57:24 INFO Attempting to reconnect...\\n2024-02-02T06:57:26 ERROR Connection failed', stack_trace='', customer_sentiment='grateful', previous_tickets=0, resolution='Root cause identified as Compliance issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 2, 3, 6, 12, 23, tzinfo=datetime.timezone.utc), agent_id='AGENT-019', agent_actions=['created_workaround', 'consulted_kb', 'checked_config'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=False, tags=['error', 'sync', 'authentication', 'integration', 'performance'], environment='test', business_impact='high', affected_users=11, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000196', created_at=datetime.datetime(2024, 7, 10, 4, 48, 4, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 11, 9, 1, 52, tzinfo=datetime.timezone.utc), customer_id='CUST-00730', customer_tier='free', organization_id='ORG-095', product='Analytics Dashboard', product_version='4.5.11', product_module='report_builder', category='Technical Issue', subcategory='Compatibility', priority='high', severity='P4', channel='api', subject='Performance degradation in Analytics Dashboard', description=\"The Analytics Dashboard has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_INVALID_400 in the logs. This is affecting our entire team's productivity.\", error_logs='2024-07-10T04:48:04 ERROR ERROR_INVALID_400: Database connection lost\\n2024-07-10T04:48:05 INFO Attempting to reconnect...\\n2024-07-10T04:48:07 ERROR Connection failed', stack_trace='Stack trace:\\n  report_builder::processData() at report_builder.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='confused', previous_tickets=2, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 7, 11, 9, 1, 52, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['checked_config', 'verified_resolution', 'updated_documentation', 'consulted_kb'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['authentication', 'bug', 'timeout', 'error', 'api'], environment='development', business_impact='low', affected_users=872, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000197', created_at=datetime.datetime(2023, 5, 19, 8, 2, 7, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 22, 14, 33, 19, tzinfo=datetime.timezone.utc), customer_id='CUST-04291', customer_tier='free', organization_id='ORG-172', product='API Gateway', product_version='3.2.6', product_module='cache_layer', category='Technical Issue', subcategory='Configuration', priority='low', severity='P3', channel='chat', subject='API Gateway throwing ERROR_PARSING during operation', description=\"We're experiencing issues with API Gateway. The system is throwing ERROR_PARSING when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-05-19T08:02:07 ERROR ERROR_PARSING: Connection timeout after 30s\\n2023-05-19T08:02:08 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='frustrated', previous_tickets=3, resolution='Applied hotfix version 3.2.2 to address the ERROR_PARSING. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 5, 22, 14, 33, 19, tzinfo=datetime.timezone.utc), agent_id='AGENT-042', agent_actions=['ran_diagnostics', 'consulted_kb', 'created_workaround', 'checked_config', 'escalated_to_specialist'], escalated=True, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['database', 'error', 'integration', 'sync', 'timeout'], environment='sandbox', business_impact='low', affected_users=33, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000198', created_at=datetime.datetime(2024, 6, 8, 8, 8, 28, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 10, 9, 19, 52, tzinfo=datetime.timezone.utc), customer_id='CUST-00562', customer_tier='professional', organization_id='ORG-440', product='CloudBackup Enterprise', product_version='3.0.7', product_module='restore_module', category='Technical Issue', subcategory='Compatibility', priority='medium', severity='P3', channel='email', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_CONNECTION_REFUSED in the logs. This is affecting our entire team's productivity.\", error_logs='2024-06-08T08:08:28 ERROR ERROR_CONNECTION_REFUSED: Database connection lost\\n2024-06-08T08:08:29 INFO Attempting to reconnect...\\n2024-06-08T08:08:31 ERROR Connection failed', stack_trace=\"Traceback (most recent call last):\\n  File 'restore_module.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='grateful', previous_tickets=10, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 6, 10, 9, 19, 52, tzinfo=datetime.timezone.utc), agent_id='AGENT-013', agent_actions=['updated_documentation', 'verified_resolution', 'escalated_to_specialist', 'viewed_logs'], escalated=False, transferred_count=1, satisfaction_score=1, resolution_helpful=False, tags=['bug', 'error', 'sync', 'integration'], environment='development', business_impact='high', affected_users=10, language='es', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000199', created_at=datetime.datetime(2023, 11, 22, 0, 35, 10, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 27, 7, 16, 34, tzinfo=datetime.timezone.utc), customer_id='CUST-03986', customer_tier='enterprise', organization_id='ORG-158', product='StreamProcessor', product_version='4.9.8', product_module='error_handler', category='Account Management', subcategory='License', priority='medium', severity='P4', channel='phone', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=10, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 11, 27, 7, 16, 34, tzinfo=datetime.timezone.utc), agent_id='AGENT-040', agent_actions=['escalated_to_specialist', 'contacted_customer'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['timeout', 'security', 'performance', 'integration', 'bug'], environment='development', business_impact='low', affected_users=29, language='zh', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000200', created_at=datetime.datetime(2023, 6, 29, 8, 53, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 29, 13, 30, 17, tzinfo=datetime.timezone.utc), customer_id='CUST-02956', customer_tier='premium', organization_id='ORG-010', product='StreamProcessor', product_version='2.2.8', product_module='error_handler', category='Security', subcategory='Authentication', priority='high', severity='P1', channel='email', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Getting ERROR_CONNECTION_REFUSED errors. We need to ensure our system meets compliance requirements.', error_logs='2023-06-29T08:53:41 WARN Rate limit approaching threshold\\n2023-06-29T08:53:41 ERROR ERROR_CONNECTION_REFUSED: Rate limit exceeded\\n2023-06-29T08:53:43 INFO Backing off for 60 seconds', stack_trace='ERROR: error_handler.service.ServiceException: Failed to process request\\n\\tat error_handler.handler.process(error_handler.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='frustrated', previous_tickets=0, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 6, 29, 13, 30, 17, tzinfo=datetime.timezone.utc), agent_id='AGENT-027', agent_actions=['created_workaround', 'updated_documentation', 'contacted_customer'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'timeout', 'performance', 'integration'], environment='development', business_impact='low', affected_users=877, language='it', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000201', created_at=datetime.datetime(2023, 5, 6, 4, 53, 30, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 6, 14, 50, 30, tzinfo=datetime.timezone.utc), customer_id='CUST-03520', customer_tier='free', organization_id='ORG-445', product='CloudBackup Enterprise', product_version='3.1.14', product_module='encryption_layer', category='Data Issue', subcategory='Corruption', priority='medium', severity='P2', channel='chat', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=0, resolution='Root cause identified as Corruption issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 5, 6, 14, 50, 30, tzinfo=datetime.timezone.utc), agent_id='AGENT-016', agent_actions=['ran_diagnostics', 'applied_fix', 'checked_config', 'consulted_kb', 'contacted_customer'], escalated=True, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['performance', 'timeout', 'bug'], environment='development', business_impact='low', affected_users=25, language='zh', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000202', created_at=datetime.datetime(2023, 4, 14, 21, 47, 30, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 15, 9, 29, 30, tzinfo=datetime.timezone.utc), customer_id='CUST-01579', customer_tier='professional', organization_id='ORG-275', product='Analytics Dashboard', product_version='4.5.3', product_module='report_builder', category='Technical Issue', subcategory='Compatibility', priority='critical', severity='P3', channel='portal', subject='Analytics Dashboard throwing ERROR_CORRUPTION during operation', description=\"We're experiencing issues with Analytics Dashboard. The system is throwing ERROR_CORRUPTION when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-04-14T21:47:30 DEBUG Processing request ID-12345\\n2023-04-14T21:47:30 ERROR ERROR_CORRUPTION: Invalid request format\\n2023-04-14T21:47:31 INFO Request rejected', stack_trace='', customer_sentiment='frustrated', previous_tickets=0, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 4, 15, 9, 29, 30, tzinfo=datetime.timezone.utc), agent_id='AGENT-015', agent_actions=['created_workaround', 'contacted_customer', 'checked_config', 'viewed_logs'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=False, tags=['security', 'performance'], environment='staging', business_impact='critical', affected_users=141, language='de', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000203', created_at=datetime.datetime(2023, 10, 13, 18, 0, 27, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 13, 21, 19, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-02782', customer_tier='starter', organization_id='ORG-139', product='DataSync Pro', product_version='2.9.5', product_module='sync_engine', category='Technical Issue', subcategory='Configuration', priority='medium', severity='P1', channel='phone', subject='Performance degradation in DataSync Pro', description=\"The DataSync Pro has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_PARSING in the logs. This is affecting our entire team's productivity.\", error_logs='2023-10-13T18:00:27 ERROR ERROR_PARSING: Database connection lost\\n2023-10-13T18:00:28 INFO Attempting to reconnect...\\n2023-10-13T18:00:30 ERROR Connection failed', stack_trace='', customer_sentiment='angry', previous_tickets=5, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 10, 13, 21, 19, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['created_workaround', 'consulted_kb'], escalated=True, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['api', 'configuration', 'sync', 'bug', 'authentication'], environment='sandbox', business_impact='critical', affected_users=11, language='de', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000204', created_at=datetime.datetime(2023, 11, 26, 10, 31, 30, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 26, 14, 33, 18, tzinfo=datetime.timezone.utc), customer_id='CUST-02095', customer_tier='starter', organization_id='ORG-320', product='API Gateway', product_version='3.3.11', product_module='cache_layer', category='Feature Request', subcategory='New Feature', priority='critical', severity='P1', channel='chat', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-11-26T10:31:30 ERROR ERROR_CORRUPTION: Connection timeout after 30s\\n2023-11-26T10:31:31 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='satisfied', previous_tickets=10, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 11, 26, 14, 33, 18, tzinfo=datetime.timezone.utc), agent_id='AGENT-028', agent_actions=['viewed_logs', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=False, tags=['timeout', 'performance', 'database', 'sync'], environment='production', business_impact='low', affected_users=544, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000205', created_at=datetime.datetime(2023, 9, 20, 20, 16, 49, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 21, 2, 31, 49, tzinfo=datetime.timezone.utc), customer_id='CUST-04193', customer_tier='starter', organization_id='ORG-187', product='StreamProcessor', product_version='2.8.12', product_module='error_handler', category='Account Management', subcategory='Upgrade', priority='medium', severity='P1', channel='portal', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=10, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 9, 21, 2, 31, 49, tzinfo=datetime.timezone.utc), agent_id='AGENT-016', agent_actions=['consulted_kb', 'applied_fix', 'viewed_logs', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['sync', 'bug', 'authentication', 'configuration'], environment='staging', business_impact='medium', affected_users=30, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000206', created_at=datetime.datetime(2023, 6, 18, 1, 16, 34, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 18, 2, 15, 22, tzinfo=datetime.timezone.utc), customer_id='CUST-02755', customer_tier='premium', organization_id='ORG-351', product='API Gateway', product_version='2.1.2', product_module='rate_limiter', category='Technical Issue', subcategory='Configuration', priority='medium', severity='P0', channel='portal', subject='Performance degradation in API Gateway', description=\"The API Gateway has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_PARSING in the logs. This is affecting our entire team's productivity.\", error_logs='2023-06-18T01:16:34 ERROR ERROR_PARSING: Connection timeout after 30s\\n2023-06-18T01:16:35 RETRY_FAILED: Max retries exceeded', stack_trace='ERROR: rate_limiter.service.ServiceException: Failed to process request\\n\\tat rate_limiter.handler.process(rate_limiter.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='neutral', previous_tickets=0, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 6, 18, 2, 15, 22, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['viewed_logs', 'ran_diagnostics'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['authentication', 'integration'], environment='development', business_impact='low', affected_users=27, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000207', created_at=datetime.datetime(2023, 12, 14, 12, 43, 28, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 15, 12, 55, 28, tzinfo=datetime.timezone.utc), customer_id='CUST-04679', customer_tier='free', organization_id='ORG-445', product='Analytics Dashboard', product_version='2.0.3', product_module='report_builder', category='Data Issue', subcategory='Sync Error', priority='critical', severity='P4', channel='email', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=1, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 12, 15, 12, 55, 28, tzinfo=datetime.timezone.utc), agent_id='AGENT-010', agent_actions=['created_workaround', 'ran_diagnostics'], escalated=True, transferred_count=1, satisfaction_score=1, resolution_helpful=False, tags=['bug', 'authentication', 'sync', 'database'], environment='sandbox', business_impact='high', affected_users=82, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000208', created_at=datetime.datetime(2023, 11, 27, 12, 45, 1, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 28, 17, 48, 37, tzinfo=datetime.timezone.utc), customer_id='CUST-00669', customer_tier='free', organization_id='ORG-372', product='CloudBackup Enterprise', product_version='3.8.1', product_module='restore_module', category='Security', subcategory='Authorization', priority='medium', severity='P2', channel='phone', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=7, resolution='Root cause identified as Authorization issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 11, 28, 17, 48, 37, tzinfo=datetime.timezone.utc), agent_id='AGENT-050', agent_actions=['escalated_to_specialist', 'applied_fix', 'checked_config'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['timeout', 'performance'], environment='sandbox', business_impact='high', affected_users=19, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000209', created_at=datetime.datetime(2024, 1, 22, 14, 29, 47, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 27, 7, 44, 47, tzinfo=datetime.timezone.utc), customer_id='CUST-04123', customer_tier='free', organization_id='ORG-113', product='DataSync Pro', product_version='3.5.8', product_module='data_validator', category='Feature Request', subcategory='Enhancement', priority='medium', severity='P4', channel='slack', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-01-22T14:29:47 ERROR ERROR_CONFLICT_409: Database connection lost\\n2024-01-22T14:29:48 INFO Attempting to reconnect...\\n2024-01-22T14:29:50 ERROR Connection failed', stack_trace='ERROR: data_validator.service.ServiceException: Failed to process request\\n\\tat data_validator.handler.process(data_validator.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='angry', previous_tickets=5, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 1, 27, 7, 44, 47, tzinfo=datetime.timezone.utc), agent_id='AGENT-029', agent_actions=['applied_fix', 'updated_documentation', 'escalated_to_specialist', 'consulted_kb', 'viewed_logs', 'ran_diagnostics'], escalated=False, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['bug', 'error', 'integration'], environment='sandbox', business_impact='medium', affected_users=50, language='es', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000210', created_at=datetime.datetime(2024, 8, 19, 3, 25, 55, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 20, 2, 49, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-01422', customer_tier='premium', organization_id='ORG-245', product='API Gateway', product_version='3.7.11', product_module='cache_layer', category='Account Management', subcategory='Access Control', priority='high', severity='P3', channel='phone', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-08-19T03:25:55 WARN Rate limit approaching threshold\\n2024-08-19T03:25:55 ERROR ERROR_CONNECTION_REFUSED: Rate limit exceeded\\n2024-08-19T03:25:57 INFO Backing off for 60 seconds', stack_trace='Stack trace:\\n  cache_layer::processData() at cache_layer.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='grateful', previous_tickets=0, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 8, 20, 2, 49, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['applied_fix', 'checked_config'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['configuration', 'bug'], environment='sandbox', business_impact='critical', affected_users=494, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000211', created_at=datetime.datetime(2024, 12, 11, 2, 23, 20, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 11, 4, 34, 44, tzinfo=datetime.timezone.utc), customer_id='CUST-00066', customer_tier='starter', organization_id='ORG-369', product='Analytics Dashboard', product_version='2.7.13', product_module='visualization', category='Technical Issue', subcategory='Configuration', priority='high', severity='P0', channel='slack', subject='Performance degradation in Analytics Dashboard', description=\"The Analytics Dashboard has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=8, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 12, 11, 4, 34, 44, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['viewed_logs', 'checked_config', 'contacted_customer', 'created_workaround'], escalated=True, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['configuration', 'timeout', 'api', 'integration', 'authentication'], environment='development', business_impact='critical', affected_users=81, language='it', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000212', created_at=datetime.datetime(2023, 7, 26, 17, 6, 51, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 31, 7, 8, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-02264', customer_tier='starter', organization_id='ORG-151', product='CloudBackup Enterprise', product_version='2.0.3', product_module='encryption_layer', category='Account Management', subcategory='Subscription', priority='medium', severity='P4', channel='phone', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-07-26T17:06:51 DEBUG Processing request ID-12345\\n2023-07-26T17:06:51 ERROR ERROR_DISK_FULL: Invalid request format\\n2023-07-26T17:06:52 INFO Request rejected', stack_trace='', customer_sentiment='satisfied', previous_tickets=1, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 7, 31, 7, 8, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['escalated_to_specialist', 'consulted_kb', 'applied_fix'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=False, tags=['performance', 'security', 'configuration', 'database'], environment='sandbox', business_impact='medium', affected_users=14, language='en', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000213', created_at=datetime.datetime(2023, 9, 20, 20, 18, 16, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 21, 13, 17, 4, tzinfo=datetime.timezone.utc), customer_id='CUST-01941', customer_tier='enterprise', organization_id='ORG-200', product='CloudBackup Enterprise', product_version='4.4.9', product_module='backup_service', category='Technical Issue', subcategory='Performance', priority='high', severity='P2', channel='chat', subject='CloudBackup Enterprise throwing ERROR_SSL_CERT during operation', description=\"We're experiencing issues with CloudBackup Enterprise. The system is throwing ERROR_SSL_CERT when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-09-20T20:18:16 DEBUG Processing request ID-12345\\n2023-09-20T20:18:16 ERROR ERROR_SSL_CERT: Invalid request format\\n2023-09-20T20:18:17 INFO Request rejected', stack_trace='', customer_sentiment='confused', previous_tickets=7, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 9, 21, 13, 17, 4, tzinfo=datetime.timezone.utc), agent_id='AGENT-037', agent_actions=['applied_fix', 'verified_resolution'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['security', 'error', 'authentication'], environment='production', business_impact='critical', affected_users=219, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000214', created_at=datetime.datetime(2023, 6, 4, 15, 37, 34, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 6, 12, 41, 10, tzinfo=datetime.timezone.utc), customer_id='CUST-03478', customer_tier='starter', organization_id='ORG-044', product='CloudBackup Enterprise', product_version='4.3.6', product_module='backup_service', category='Data Issue', subcategory='Data Loss', priority='medium', severity='P4', channel='email', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_RATELIMIT_429 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-06-04T15:37:34 ERROR ERROR_RATELIMIT_429: Connection timeout after 30s\\n2023-06-04T15:37:35 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='satisfied', previous_tickets=5, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 6, 6, 12, 41, 10, tzinfo=datetime.timezone.utc), agent_id='AGENT-018', agent_actions=['ran_diagnostics', 'contacted_customer', 'escalated_to_specialist', 'created_workaround'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['database', 'timeout', 'api', 'error'], environment='development', business_impact='low', affected_users=36, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000215', created_at=datetime.datetime(2023, 4, 23, 7, 48, 3, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 24, 23, 27, 3, tzinfo=datetime.timezone.utc), customer_id='CUST-02666', customer_tier='starter', organization_id='ORG-167', product='StreamProcessor', product_version='4.6.12', product_module='event_handler', category='Data Issue', subcategory='Sync Error', priority='critical', severity='P4', channel='email', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=0, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 4, 24, 23, 27, 3, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['consulted_kb', 'ran_diagnostics', 'viewed_logs', 'escalated_to_specialist'], escalated=True, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['bug', 'api', 'error', 'authentication', 'database'], environment='test', business_impact='low', affected_users=972, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000216', created_at=datetime.datetime(2024, 2, 3, 9, 5, 12, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 3, 20, 40, 36, tzinfo=datetime.timezone.utc), customer_id='CUST-00388', customer_tier='enterprise', organization_id='ORG-234', product='StreamProcessor', product_version='4.8.15', product_module='monitoring', category='Account Management', subcategory='Access Control', priority='medium', severity='P3', channel='api', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-02-03T09:05:12 WARN Rate limit approaching threshold\\n2024-02-03T09:05:12 ERROR ERROR_DISK_FULL: Rate limit exceeded\\n2024-02-03T09:05:14 INFO Backing off for 60 seconds', stack_trace='at monitoring.execute(monitoring.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='satisfied', previous_tickets=6, resolution='Root cause identified as Access Control issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 2, 3, 20, 40, 36, tzinfo=datetime.timezone.utc), agent_id='AGENT-027', agent_actions=['updated_documentation', 'contacted_customer', 'consulted_kb'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['integration', 'security'], environment='development', business_impact='medium', affected_users=9, language='zh', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000217', created_at=datetime.datetime(2023, 8, 26, 20, 13, 22, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 27, 21, 38, 34, tzinfo=datetime.timezone.utc), customer_id='CUST-03371', customer_tier='free', organization_id='ORG-461', product='StreamProcessor', product_version='2.8.2', product_module='event_handler', category='Account Management', subcategory='Subscription', priority='medium', severity='P3', channel='slack', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-08-26T20:13:22 WARN Rate limit approaching threshold\\n2023-08-26T20:13:22 ERROR ERROR_VALIDATION: Rate limit exceeded\\n2023-08-26T20:13:24 INFO Backing off for 60 seconds', stack_trace='Stack trace:\\n  event_handler::processData() at event_handler.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='frustrated', previous_tickets=1, resolution='Applied hotfix version 3.2.2 to address the ERROR_VALIDATION. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 8, 27, 21, 38, 34, tzinfo=datetime.timezone.utc), agent_id='AGENT-009', agent_actions=['updated_documentation', 'ran_diagnostics', 'checked_config', 'escalated_to_specialist'], escalated=True, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['configuration', 'performance', 'api'], environment='test', business_impact='high', affected_users=35, language='it', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000218', created_at=datetime.datetime(2024, 2, 5, 5, 33, 10, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 6, 17, 42, 46, tzinfo=datetime.timezone.utc), customer_id='CUST-01167', customer_tier='starter', organization_id='ORG-011', product='API Gateway', product_version='3.1.0', product_module='auth_service', category='Security', subcategory='Encryption', priority='medium', severity='P4', channel='portal', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_SSL_CERT errors. We need to ensure our system meets compliance requirements.', error_logs='2024-02-05T05:33:10 ERROR ERROR_SSL_CERT: Database connection lost\\n2024-02-05T05:33:11 INFO Attempting to reconnect...\\n2024-02-05T05:33:13 ERROR Connection failed', stack_trace=\"Traceback (most recent call last):\\n  File 'auth_service.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='angry', previous_tickets=2, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 2, 6, 17, 42, 46, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['checked_config', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['api', 'security', 'bug', 'timeout', 'database'], environment='sandbox', business_impact='critical', affected_users=30, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000219', created_at=datetime.datetime(2024, 10, 19, 19, 17, 3, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 19, 22, 37, 27, tzinfo=datetime.timezone.utc), customer_id='CUST-02097', customer_tier='starter', organization_id='ORG-250', product='DataSync Pro', product_version='4.5.14', product_module='sync_engine', category='Security', subcategory='Vulnerability', priority='medium', severity='P0', channel='slack', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_SERVER_500 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-10-19T19:17:03 DEBUG Processing request ID-12345\\n2024-10-19T19:17:03 ERROR ERROR_SERVER_500: Invalid request format\\n2024-10-19T19:17:04 INFO Request rejected', stack_trace='Stack trace:\\n  sync_engine::processData() at sync_engine.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='satisfied', previous_tickets=1, resolution='Root cause identified as Vulnerability issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 10, 19, 22, 37, 27, tzinfo=datetime.timezone.utc), agent_id='AGENT-020', agent_actions=['verified_resolution', 'created_workaround'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['authentication', 'performance', 'api', 'sync', 'database'], environment='test', business_impact='medium', affected_users=9, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000220', created_at=datetime.datetime(2024, 2, 6, 8, 49, 58, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 6, 17, 42, 46, tzinfo=datetime.timezone.utc), customer_id='CUST-04041', customer_tier='free', organization_id='ORG-308', product='API Gateway', product_version='3.9.5', product_module='cache_layer', category='Security', subcategory='Compliance', priority='high', severity='P3', channel='slack', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=7, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 2, 6, 17, 42, 46, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['consulted_kb', 'checked_config', 'created_workaround'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['data', 'api', 'bug'], environment='development', business_impact='medium', affected_users=344, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000221', created_at=datetime.datetime(2023, 9, 7, 5, 22, 24, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 8, 4, 0, 12, tzinfo=datetime.timezone.utc), customer_id='CUST-02458', customer_tier='premium', organization_id='ORG-278', product='API Gateway', product_version='4.7.3', product_module='rate_limiter', category='Account Management', subcategory='Subscription', priority='low', severity='P2', channel='api', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-09-07T05:22:24 DEBUG Processing request ID-12345\\n2023-09-07T05:22:24 ERROR ERROR_CONFLICT_409: Invalid request format\\n2023-09-07T05:22:25 INFO Request rejected', stack_trace='', customer_sentiment='angry', previous_tickets=2, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 9, 8, 4, 0, 12, tzinfo=datetime.timezone.utc), agent_id='AGENT-041', agent_actions=['viewed_logs', 'updated_documentation'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['authentication', 'error', 'performance', 'timeout', 'data'], environment='staging', business_impact='critical', affected_users=50, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000222', created_at=datetime.datetime(2024, 7, 22, 14, 13, 16, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 24, 3, 26, 28, tzinfo=datetime.timezone.utc), customer_id='CUST-02762', customer_tier='enterprise', organization_id='ORG-126', product='API Gateway', product_version='3.0.15', product_module='cache_layer', category='Feature Request', subcategory='Enhancement', priority='medium', severity='P3', channel='slack', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=0, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 7, 24, 3, 26, 28, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['updated_documentation', 'contacted_customer'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=False, tags=['timeout', 'performance', 'error', 'security', 'bug'], environment='production', business_impact='low', affected_users=27, language='ja', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000223', created_at=datetime.datetime(2024, 11, 28, 13, 31, 55, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 28, 15, 18, 7, tzinfo=datetime.timezone.utc), customer_id='CUST-02350', customer_tier='starter', organization_id='ORG-217', product='Analytics Dashboard', product_version='3.5.11', product_module='data_aggregator', category='Security', subcategory='Authentication', priority='critical', severity='P0', channel='slack', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_CONNECTION_REFUSED errors. We need to ensure our system meets compliance requirements.', error_logs='2024-11-28T13:31:55 DEBUG Processing request ID-12345\\n2024-11-28T13:31:55 ERROR ERROR_CONNECTION_REFUSED: Invalid request format\\n2024-11-28T13:31:56 INFO Request rejected', stack_trace='', customer_sentiment='neutral', previous_tickets=1, resolution='Root cause identified as Authentication issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 11, 28, 15, 18, 7, tzinfo=datetime.timezone.utc), agent_id='AGENT-028', agent_actions=['created_workaround', 'escalated_to_specialist', 'viewed_logs'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['api', 'timeout', 'error', 'performance', 'integration'], environment='development', business_impact='low', affected_users=63, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000224', created_at=datetime.datetime(2023, 7, 18, 2, 48, 24, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 18, 4, 4, tzinfo=datetime.timezone.utc), customer_id='CUST-00402', customer_tier='starter', organization_id='ORG-122', product='Analytics Dashboard', product_version='4.6.0', product_module='export_module', category='Account Management', subcategory='Billing', priority='critical', severity='P0', channel='slack', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=3, resolution='Root cause identified as Billing issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 7, 18, 4, 4, tzinfo=datetime.timezone.utc), agent_id='AGENT-010', agent_actions=['ran_diagnostics', 'updated_documentation', 'escalated_to_specialist', 'contacted_customer', 'created_workaround', 'consulted_kb'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=False, tags=['data', 'api'], environment='staging', business_impact='critical', affected_users=468, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000225', created_at=datetime.datetime(2024, 2, 23, 2, 34, 42, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 25, 10, 5, 18, tzinfo=datetime.timezone.utc), customer_id='CUST-03640', customer_tier='enterprise', organization_id='ORG-278', product='API Gateway', product_version='3.3.11', product_module='cache_layer', category='Feature Request', subcategory='Documentation', priority='critical', severity='P4', channel='portal', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-02-23T02:34:42 WARN Rate limit approaching threshold\\n2024-02-23T02:34:42 ERROR ERROR_NOTFOUND_404: Rate limit exceeded\\n2024-02-23T02:34:44 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='frustrated', previous_tickets=7, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 2, 25, 10, 5, 18, tzinfo=datetime.timezone.utc), agent_id='AGENT-050', agent_actions=['verified_resolution', 'ran_diagnostics'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['timeout', 'api', 'data', 'security', 'database'], environment='production', business_impact='critical', affected_users=445, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000226', created_at=datetime.datetime(2024, 9, 1, 1, 12, 54, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 2, 1, 27, 18, tzinfo=datetime.timezone.utc), customer_id='CUST-04657', customer_tier='free', organization_id='ORG-496', product='Analytics Dashboard', product_version='3.6.15', product_module='data_aggregator', category='Technical Issue', subcategory='Integration', priority='low', severity='P2', channel='slack', subject='Performance degradation in Analytics Dashboard', description=\"The Analytics Dashboard has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_CONNECTION_REFUSED in the logs. This is affecting our entire team's productivity.\", error_logs='2024-09-01T01:12:54 DEBUG Processing request ID-12345\\n2024-09-01T01:12:54 ERROR ERROR_CONNECTION_REFUSED: Invalid request format\\n2024-09-01T01:12:55 INFO Request rejected', stack_trace='', customer_sentiment='grateful', previous_tickets=9, resolution='Applied hotfix version 3.2.2 to address the ERROR_CONNECTION_REFUSED. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 9, 2, 1, 27, 18, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['contacted_customer', 'consulted_kb', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['sync', 'performance', 'security', 'configuration'], environment='sandbox', business_impact='low', affected_users=32, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000227', created_at=datetime.datetime(2023, 2, 12, 11, 0, 6, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 12, 21, 57, 6, tzinfo=datetime.timezone.utc), customer_id='CUST-02802', customer_tier='premium', organization_id='ORG-002', product='DataSync Pro', product_version='2.0.13', product_module='api_connector', category='Security', subcategory='Encryption', priority='low', severity='P2', channel='chat', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_PARSING errors. We need to ensure our system meets compliance requirements.', error_logs='2023-02-12T11:00:06 DEBUG Processing request ID-12345\\n2023-02-12T11:00:06 ERROR ERROR_PARSING: Invalid request format\\n2023-02-12T11:00:07 INFO Request rejected', stack_trace='', customer_sentiment='satisfied', previous_tickets=10, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 2, 12, 21, 57, 6, tzinfo=datetime.timezone.utc), agent_id='AGENT-001', agent_actions=['applied_fix', 'updated_documentation', 'checked_config'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['performance', 'database', 'data', 'sync', 'authentication'], environment='staging', business_impact='high', affected_users=21, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000228', created_at=datetime.datetime(2023, 12, 9, 9, 12, 25, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 11, 4, 22, 1, tzinfo=datetime.timezone.utc), customer_id='CUST-01085', customer_tier='premium', organization_id='ORG-453', product='StreamProcessor', product_version='4.7.9', product_module='monitoring', category='Feature Request', subcategory='Documentation', priority='medium', severity='P4', channel='api', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-12-09T09:12:25 DEBUG Processing request ID-12345\\n2023-12-09T09:12:25 ERROR ERROR_INVALID_400: Invalid request format\\n2023-12-09T09:12:26 INFO Request rejected', stack_trace='', customer_sentiment='satisfied', previous_tickets=5, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 12, 11, 4, 22, 1, tzinfo=datetime.timezone.utc), agent_id='AGENT-035', agent_actions=['checked_config', 'updated_documentation', 'applied_fix', 'verified_resolution'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['database', 'bug', 'security'], environment='development', business_impact='low', affected_users=9, language='pt', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000229', created_at=datetime.datetime(2023, 2, 10, 21, 11, 27, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 12, 18, 28, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-01812', customer_tier='premium', organization_id='ORG-276', product='API Gateway', product_version='3.2.7', product_module='cache_layer', category='Account Management', subcategory='License', priority='critical', severity='P4', channel='portal', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-02-10T21:11:27 DEBUG Processing request ID-12345\\n2023-02-10T21:11:27 ERROR ERROR_PARSING: Invalid request format\\n2023-02-10T21:11:28 INFO Request rejected', stack_trace='', customer_sentiment='neutral', previous_tickets=10, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 2, 12, 18, 28, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-022', agent_actions=['updated_documentation', 'ran_diagnostics', 'escalated_to_specialist', 'consulted_kb', 'verified_resolution', 'checked_config'], escalated=False, transferred_count=1, satisfaction_score=1, resolution_helpful=True, tags=['database', 'authentication', 'data'], environment='sandbox', business_impact='medium', affected_users=756, language='es', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000230', created_at=datetime.datetime(2023, 12, 11, 1, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 11, 3, 0, 36, tzinfo=datetime.timezone.utc), customer_id='CUST-01481', customer_tier='premium', organization_id='ORG-338', product='Analytics Dashboard', product_version='3.4.13', product_module='report_builder', category='Account Management', subcategory='License', priority='high', severity='P1', channel='portal', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-12-11T01:39:00 ERROR ERROR_VALIDATION: Connection timeout after 30s\\n2023-12-11T01:39:01 RETRY_FAILED: Max retries exceeded', stack_trace='at report_builder.execute(report_builder.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='confused', previous_tickets=10, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 12, 11, 3, 0, 36, tzinfo=datetime.timezone.utc), agent_id='AGENT-033', agent_actions=['ran_diagnostics', 'created_workaround', 'checked_config', 'applied_fix'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['integration', 'sync'], environment='sandbox', business_impact='high', affected_users=241, language='de', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000231', created_at=datetime.datetime(2024, 1, 22, 12, 24, 34, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 22, 13, 22, 10, tzinfo=datetime.timezone.utc), customer_id='CUST-03269', customer_tier='enterprise', organization_id='ORG-476', product='API Gateway', product_version='4.4.15', product_module='cache_layer', category='Data Issue', subcategory='Sync Error', priority='high', severity='P0', channel='chat', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_INVALID_400 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-01-22T12:24:34 ERROR ERROR_INVALID_400: Database connection lost\\n2024-01-22T12:24:35 INFO Attempting to reconnect...\\n2024-01-22T12:24:37 ERROR Connection failed', stack_trace='', customer_sentiment='frustrated', previous_tickets=7, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 1, 22, 13, 22, 10, tzinfo=datetime.timezone.utc), agent_id='AGENT-015', agent_actions=['contacted_customer', 'consulted_kb', 'created_workaround', 'escalated_to_specialist', 'verified_resolution'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['timeout', 'bug', 'configuration', 'sync', 'integration'], environment='development', business_impact='high', affected_users=683, language='fr', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000232', created_at=datetime.datetime(2024, 5, 28, 19, 46, 12, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 29, 8, 34, 48, tzinfo=datetime.timezone.utc), customer_id='CUST-04282', customer_tier='professional', organization_id='ORG-133', product='CloudBackup Enterprise', product_version='3.1.14', product_module='backup_service', category='Feature Request', subcategory='UI/UX', priority='critical', severity='P2', channel='email', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=10, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 5, 29, 8, 34, 48, tzinfo=datetime.timezone.utc), agent_id='AGENT-018', agent_actions=['verified_resolution', 'contacted_customer', 'updated_documentation', 'ran_diagnostics', 'created_workaround'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['performance', 'security', 'configuration', 'authentication'], environment='production', business_impact='critical', affected_users=964, language='de', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000233', created_at=datetime.datetime(2024, 6, 15, 23, 7, 13, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 17, 3, 13, 13, tzinfo=datetime.timezone.utc), customer_id='CUST-00895', customer_tier='starter', organization_id='ORG-053', product='Analytics Dashboard', product_version='3.2.6', product_module='visualization', category='Account Management', subcategory='License', priority='medium', severity='P3', channel='slack', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-06-15T23:07:13 ERROR ERROR_DISK_FULL: Connection timeout after 30s\\n2024-06-15T23:07:14 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'visualization.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='confused', previous_tickets=9, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 6, 17, 3, 13, 13, tzinfo=datetime.timezone.utc), agent_id='AGENT-025', agent_actions=['checked_config', 'verified_resolution', 'escalated_to_specialist'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['bug', 'api', 'performance', 'authentication'], environment='staging', business_impact='low', affected_users=44, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000234', created_at=datetime.datetime(2023, 2, 6, 22, 55, 11, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 9, 4, 27, 35, tzinfo=datetime.timezone.utc), customer_id='CUST-04999', customer_tier='premium', organization_id='ORG-174', product='StreamProcessor', product_version='2.3.11', product_module='event_handler', category='Security', subcategory='Compliance', priority='medium', severity='P3', channel='api', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=6, resolution='Root cause identified as Compliance issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 2, 9, 4, 27, 35, tzinfo=datetime.timezone.utc), agent_id='AGENT-040', agent_actions=['escalated_to_specialist', 'ran_diagnostics'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['error', 'api'], environment='development', business_impact='high', affected_users=6, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000235', created_at=datetime.datetime(2024, 6, 27, 2, 21, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 2, 11, 10, 21, tzinfo=datetime.timezone.utc), customer_id='CUST-02117', customer_tier='free', organization_id='ORG-395', product='CloudBackup Enterprise', product_version='2.9.8', product_module='backup_service', category='Data Issue', subcategory='Sync Error', priority='low', severity='P4', channel='api', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_NOTFOUND_404 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-06-27T02:21:45 DEBUG Processing request ID-12345\\n2024-06-27T02:21:45 ERROR ERROR_NOTFOUND_404: Invalid request format\\n2024-06-27T02:21:46 INFO Request rejected', stack_trace='', customer_sentiment='angry', previous_tickets=5, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 7, 2, 11, 10, 21, tzinfo=datetime.timezone.utc), agent_id='AGENT-042', agent_actions=['applied_fix', 'contacted_customer', 'viewed_logs', 'escalated_to_specialist'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=False, tags=['timeout', 'data'], environment='test', business_impact='critical', affected_users=32, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000236', created_at=datetime.datetime(2023, 9, 27, 13, 36, 6, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 2, 14, 6, 6, tzinfo=datetime.timezone.utc), customer_id='CUST-03342', customer_tier='professional', organization_id='ORG-354', product='API Gateway', product_version='2.5.2', product_module='rate_limiter', category='Feature Request', subcategory='Enhancement', priority='low', severity='P4', channel='portal', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=10, resolution='Root cause identified as Enhancement issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 10, 2, 14, 6, 6, tzinfo=datetime.timezone.utc), agent_id='AGENT-028', agent_actions=['checked_config', 'consulted_kb', 'created_workaround'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['api', 'data'], environment='test', business_impact='high', affected_users=27, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000237', created_at=datetime.datetime(2024, 2, 28, 17, 39, 19, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 1, 22, 24, 19, tzinfo=datetime.timezone.utc), customer_id='CUST-00864', customer_tier='starter', organization_id='ORG-033', product='DataSync Pro', product_version='4.5.3', product_module='sync_engine', category='Technical Issue', subcategory='Performance', priority='low', severity='P3', channel='chat', subject='DataSync Pro throwing errors during operation', description=\"We're experiencing issues with DataSync Pro. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=6, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 3, 1, 22, 24, 19, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['ran_diagnostics', 'applied_fix', 'verified_resolution'], escalated=True, transferred_count=1, satisfaction_score=2, resolution_helpful=True, tags=['timeout', 'error', 'api'], environment='test', business_impact='medium', affected_users=6, language='zh', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000238', created_at=datetime.datetime(2023, 12, 12, 4, 48, 24, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 12, 6, 40, 36, tzinfo=datetime.timezone.utc), customer_id='CUST-00288', customer_tier='starter', organization_id='ORG-446', product='DataSync Pro', product_version='4.1.9', product_module='api_connector', category='Feature Request', subcategory='New Feature', priority='medium', severity='P0', channel='api', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=7, resolution='Root cause identified as New Feature issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 12, 12, 6, 40, 36, tzinfo=datetime.timezone.utc), agent_id='AGENT-022', agent_actions=['contacted_customer', 'viewed_logs', 'applied_fix', 'checked_config'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['configuration', 'error', 'sync'], environment='development', business_impact='critical', affected_users=14, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000239', created_at=datetime.datetime(2023, 9, 16, 19, 58, 32, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 20, 4, 38, 8, tzinfo=datetime.timezone.utc), customer_id='CUST-03712', customer_tier='free', organization_id='ORG-155', product='CloudBackup Enterprise', product_version='3.5.13', product_module='restore_module', category='Feature Request', subcategory='API', priority='low', severity='P3', channel='email', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-09-16T19:58:32 ERROR ERROR_VALIDATION: Database connection lost\\n2023-09-16T19:58:33 INFO Attempting to reconnect...\\n2023-09-16T19:58:35 ERROR Connection failed', stack_trace=\"Traceback (most recent call last):\\n  File 'restore_module.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='confused', previous_tickets=6, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 9, 20, 4, 38, 8, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['checked_config', 'updated_documentation', 'contacted_customer'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['data', 'performance', 'configuration', 'error'], environment='staging', business_impact='high', affected_users=46, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000240', created_at=datetime.datetime(2023, 2, 5, 5, 49, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 5, 7, 2, 21, tzinfo=datetime.timezone.utc), customer_id='CUST-04491', customer_tier='professional', organization_id='ORG-238', product='API Gateway', product_version='4.2.9', product_module='auth_service', category='Technical Issue', subcategory='Compatibility', priority='low', severity='P0', channel='phone', subject='Performance degradation in API Gateway', description=\"The API Gateway has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=9, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 2, 5, 7, 2, 21, tzinfo=datetime.timezone.utc), agent_id='AGENT-028', agent_actions=['checked_config', 'consulted_kb', 'viewed_logs', 'applied_fix'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['timeout', 'performance', 'database', 'data'], environment='sandbox', business_impact='critical', affected_users=34, language='es', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000241', created_at=datetime.datetime(2024, 5, 1, 0, 40, 54, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 6, 10, 18, 6, tzinfo=datetime.timezone.utc), customer_id='CUST-02765', customer_tier='free', organization_id='ORG-140', product='CloudBackup Enterprise', product_version='2.5.6', product_module='encryption_layer', category='Data Issue', subcategory='Validation', priority='medium', severity='P4', channel='portal', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_SERVER_500 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-05-01T00:40:54 ERROR ERROR_SERVER_500: Connection timeout after 30s\\n2024-05-01T00:40:55 RETRY_FAILED: Max retries exceeded', stack_trace='Stack trace:\\n  encryption_layer::processData() at encryption_layer.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='angry', previous_tickets=2, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 5, 6, 10, 18, 6, tzinfo=datetime.timezone.utc), agent_id='AGENT-049', agent_actions=['viewed_logs', 'applied_fix', 'updated_documentation', 'consulted_kb', 'ran_diagnostics'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['configuration', 'bug', 'error', 'database'], environment='test', business_impact='low', affected_users=7, language='es', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000242', created_at=datetime.datetime(2024, 4, 7, 0, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 7, 12, 24, 36, tzinfo=datetime.timezone.utc), customer_id='CUST-02923', customer_tier='free', organization_id='ORG-196', product='API Gateway', product_version='4.7.6', product_module='auth_service', category='Security', subcategory='Vulnerability', priority='high', severity='P3', channel='slack', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=9, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 4, 7, 12, 24, 36, tzinfo=datetime.timezone.utc), agent_id='AGENT-006', agent_actions=['consulted_kb', 'checked_config', 'ran_diagnostics', 'viewed_logs'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=False, tags=['integration', 'security', 'data', 'configuration', 'authentication'], environment='development', business_impact='high', affected_users=91, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000243', created_at=datetime.datetime(2024, 12, 23, 1, 35, 22, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 24, 2, 20, 58, tzinfo=datetime.timezone.utc), customer_id='CUST-01177', customer_tier='enterprise', organization_id='ORG-226', product='DataSync Pro', product_version='4.4.12', product_module='scheduler', category='Account Management', subcategory='Billing', priority='medium', severity='P2', channel='portal', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=2, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 12, 24, 2, 20, 58, tzinfo=datetime.timezone.utc), agent_id='AGENT-013', agent_actions=['viewed_logs', 'ran_diagnostics', 'consulted_kb'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['database', 'sync', 'configuration'], environment='test', business_impact='critical', affected_users=43, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000244', created_at=datetime.datetime(2024, 4, 13, 9, 14, 22, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 13, 10, 8, 58, tzinfo=datetime.timezone.utc), customer_id='CUST-03965', customer_tier='professional', organization_id='ORG-488', product='StreamProcessor', product_version='2.8.10', product_module='monitoring', category='Technical Issue', subcategory='Integration', priority='high', severity='P0', channel='email', subject='Performance degradation in StreamProcessor', description=\"The StreamProcessor has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=9, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 4, 13, 10, 8, 58, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['consulted_kb', 'verified_resolution', 'applied_fix', 'ran_diagnostics'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['performance', 'integration', 'sync'], environment='sandbox', business_impact='high', affected_users=654, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000245', created_at=datetime.datetime(2024, 6, 29, 10, 32, 3, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 29, 16, 21, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-04697', customer_tier='starter', organization_id='ORG-446', product='DataSync Pro', product_version='3.8.2', product_module='data_validator', category='Security', subcategory='Authorization', priority='low', severity='P1', channel='phone', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=10, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 6, 29, 16, 21, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-022', agent_actions=['checked_config', 'ran_diagnostics'], escalated=True, transferred_count=2, satisfaction_score=2, resolution_helpful=True, tags=['authentication', 'data'], environment='staging', business_impact='low', affected_users=34, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000246', created_at=datetime.datetime(2024, 12, 17, 5, 1, 24, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 25, 3, 56, 36, tzinfo=datetime.timezone.utc), customer_id='CUST-02226', customer_tier='starter', organization_id='ORG-370', product='CloudBackup Enterprise', product_version='2.2.7', product_module='backup_service', category='Account Management', subcategory='Billing', priority='low', severity='P4', channel='api', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-12-17T05:01:24 ERROR ERROR_DEADLOCK: Connection timeout after 30s\\n2024-12-17T05:01:25 RETRY_FAILED: Max retries exceeded', stack_trace='Stack trace:\\n  backup_service::processData() at backup_service.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='neutral', previous_tickets=7, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 12, 25, 3, 56, 36, tzinfo=datetime.timezone.utc), agent_id='AGENT-016', agent_actions=['viewed_logs', 'consulted_kb', 'created_workaround', 'checked_config'], escalated=False, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['bug', 'error', 'performance', 'sync', 'database'], environment='production', business_impact='high', affected_users=6, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000247', created_at=datetime.datetime(2023, 9, 2, 12, 41, 16, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 2, 20, 37, 4, tzinfo=datetime.timezone.utc), customer_id='CUST-03536', customer_tier='enterprise', organization_id='ORG-092', product='API Gateway', product_version='2.5.13', product_module='rate_limiter', category='Technical Issue', subcategory='Bug', priority='high', severity='P2', channel='chat', subject='Performance degradation in API Gateway', description=\"The API Gateway has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_PERMISSION_403 in the logs. This is affecting our entire team's productivity.\", error_logs='2023-09-02T12:41:16 ERROR ERROR_PERMISSION_403: Connection timeout after 30s\\n2023-09-02T12:41:17 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='angry', previous_tickets=7, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 9, 2, 20, 37, 4, tzinfo=datetime.timezone.utc), agent_id='AGENT-015', agent_actions=['applied_fix', 'checked_config'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['timeout', 'integration'], environment='test', business_impact='low', affected_users=875, language='it', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000248', created_at=datetime.datetime(2023, 6, 28, 7, 4, 47, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 29, 15, 35, 23, tzinfo=datetime.timezone.utc), customer_id='CUST-01629', customer_tier='premium', organization_id='ORG-477', product='Analytics Dashboard', product_version='3.5.0', product_module='export_module', category='Data Issue', subcategory='Data Loss', priority='high', severity='P4', channel='email', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=1, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 6, 29, 15, 35, 23, tzinfo=datetime.timezone.utc), agent_id='AGENT-035', agent_actions=['checked_config', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['configuration', 'error'], environment='sandbox', business_impact='critical', affected_users=570, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000249', created_at=datetime.datetime(2023, 8, 30, 9, 52, 19, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 31, 0, 15, 7, tzinfo=datetime.timezone.utc), customer_id='CUST-02193', customer_tier='free', organization_id='ORG-273', product='StreamProcessor', product_version='4.6.13', product_module='batch_processor', category='Technical Issue', subcategory='Compatibility', priority='critical', severity='P3', channel='api', subject='StreamProcessor throwing ERROR_NOTFOUND_404 during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing ERROR_NOTFOUND_404 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-08-30T09:52:19 DEBUG Processing request ID-12345\\n2023-08-30T09:52:19 ERROR ERROR_NOTFOUND_404: Invalid request format\\n2023-08-30T09:52:20 INFO Request rejected', stack_trace='', customer_sentiment='neutral', previous_tickets=7, resolution='Applied hotfix version 3.2.2 to address the ERROR_NOTFOUND_404. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 8, 31, 0, 15, 7, tzinfo=datetime.timezone.utc), agent_id='AGENT-027', agent_actions=['verified_resolution', 'escalated_to_specialist', 'applied_fix'], escalated=False, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['security', 'data', 'performance'], environment='development', business_impact='medium', affected_users=852, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000250', created_at=datetime.datetime(2023, 10, 29, 13, 58, 6, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 29, 22, 44, 18, tzinfo=datetime.timezone.utc), customer_id='CUST-03413', customer_tier='starter', organization_id='ORG-148', product='Analytics Dashboard', product_version='2.4.6', product_module='export_module', category='Account Management', subcategory='Billing', priority='critical', severity='P2', channel='phone', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-10-29T13:58:06 WARN Rate limit approaching threshold\\n2023-10-29T13:58:06 ERROR ERROR_PERMISSION_403: Rate limit exceeded\\n2023-10-29T13:58:08 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'export_module.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='neutral', previous_tickets=9, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 10, 29, 22, 44, 18, tzinfo=datetime.timezone.utc), agent_id='AGENT-021', agent_actions=['viewed_logs', 'checked_config', 'updated_documentation'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=False, tags=['configuration', 'timeout', 'sync', 'database'], environment='test', business_impact='medium', affected_users=502, language='zh', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000251', created_at=datetime.datetime(2024, 3, 6, 10, 0, 31, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 7, 11, 10, 7, tzinfo=datetime.timezone.utc), customer_id='CUST-03444', customer_tier='enterprise', organization_id='ORG-429', product='Analytics Dashboard', product_version='3.7.10', product_module='visualization', category='Technical Issue', subcategory='Integration', priority='low', severity='P2', channel='chat', subject='Analytics Dashboard throwing ERROR_TIMEOUT_429 during operation', description=\"We're experiencing issues with Analytics Dashboard. The system is throwing ERROR_TIMEOUT_429 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-03-06T10:00:31 DEBUG Processing request ID-12345\\n2024-03-06T10:00:31 ERROR ERROR_TIMEOUT_429: Invalid request format\\n2024-03-06T10:00:32 INFO Request rejected', stack_trace='at visualization.execute(visualization.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='grateful', previous_tickets=10, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 3, 7, 11, 10, 7, tzinfo=datetime.timezone.utc), agent_id='AGENT-023', agent_actions=['applied_fix', 'escalated_to_specialist'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['bug', 'api', 'authentication'], environment='test', business_impact='medium', affected_users=17, language='es', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000252', created_at=datetime.datetime(2024, 9, 9, 10, 27, 57, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 9, 17, 5, 9, tzinfo=datetime.timezone.utc), customer_id='CUST-02687', customer_tier='professional', organization_id='ORG-122', product='API Gateway', product_version='3.6.5', product_module='cache_layer', category='Technical Issue', subcategory='Integration', priority='low', severity='P0', channel='phone', subject='Performance degradation in API Gateway', description=\"The API Gateway has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_CORRUPTION in the logs. This is affecting our entire team's productivity.\", error_logs='2024-09-09T10:27:57 DEBUG Processing request ID-12345\\n2024-09-09T10:27:57 ERROR ERROR_CORRUPTION: Invalid request format\\n2024-09-09T10:27:58 INFO Request rejected', stack_trace='', customer_sentiment='confused', previous_tickets=6, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 9, 9, 17, 5, 9, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['contacted_customer', 'escalated_to_specialist', 'verified_resolution', 'updated_documentation', 'viewed_logs', 'created_workaround'], escalated=True, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['integration', 'timeout', 'configuration', 'api'], environment='sandbox', business_impact='high', affected_users=20, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000253', created_at=datetime.datetime(2024, 1, 24, 8, 52, 36, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 24, 10, 19, 36, tzinfo=datetime.timezone.utc), customer_id='CUST-03251', customer_tier='professional', organization_id='ORG-199', product='Analytics Dashboard', product_version='3.0.0', product_module='report_builder', category='Feature Request', subcategory='Enhancement', priority='low', severity='P0', channel='email', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-01-24T08:52:36 ERROR ERROR_VALIDATION: Database connection lost\\n2024-01-24T08:52:37 INFO Attempting to reconnect...\\n2024-01-24T08:52:39 ERROR Connection failed', stack_trace='ERROR: report_builder.service.ServiceException: Failed to process request\\n\\tat report_builder.handler.process(report_builder.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='frustrated', previous_tickets=4, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 1, 24, 10, 19, 36, tzinfo=datetime.timezone.utc), agent_id='AGENT-042', agent_actions=['updated_documentation', 'created_workaround'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['error', 'configuration', 'database', 'security', 'integration'], environment='sandbox', business_impact='low', affected_users=29, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000254', created_at=datetime.datetime(2024, 3, 17, 8, 49, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 17, 19, 46, tzinfo=datetime.timezone.utc), customer_id='CUST-02616', customer_tier='starter', organization_id='ORG-291', product='CloudBackup Enterprise', product_version='3.7.11', product_module='restore_module', category='Security', subcategory='Authentication', priority='high', severity='P3', channel='portal', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Getting ERROR_SERVER_500 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-03-17T08:49:00 ERROR ERROR_SERVER_500: Database connection lost\\n2024-03-17T08:49:01 INFO Attempting to reconnect...\\n2024-03-17T08:49:03 ERROR Connection failed', stack_trace='', customer_sentiment='angry', previous_tickets=5, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 3, 17, 19, 46, tzinfo=datetime.timezone.utc), agent_id='AGENT-035', agent_actions=['applied_fix', 'consulted_kb'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['api', 'performance', 'security', 'sync'], environment='test', business_impact='medium', affected_users=868, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000255', created_at=datetime.datetime(2023, 3, 12, 20, 6, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 13, 16, 42, 37, tzinfo=datetime.timezone.utc), customer_id='CUST-04584', customer_tier='free', organization_id='ORG-388', product='API Gateway', product_version='4.4.12', product_module='request_router', category='Feature Request', subcategory='New Feature', priority='critical', severity='P3', channel='chat', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-03-12T20:06:37 WARN Rate limit approaching threshold\\n2023-03-12T20:06:37 ERROR ERROR_NOTFOUND_404: Rate limit exceeded\\n2023-03-12T20:06:39 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='satisfied', previous_tickets=6, resolution='Applied hotfix version 3.2.2 to address the ERROR_NOTFOUND_404. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 3, 13, 16, 42, 37, tzinfo=datetime.timezone.utc), agent_id='AGENT-024', agent_actions=['escalated_to_specialist', 'contacted_customer', 'ran_diagnostics', 'consulted_kb'], escalated=True, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'data', 'api', 'security'], environment='production', business_impact='medium', affected_users=644, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000256', created_at=datetime.datetime(2024, 10, 15, 19, 25, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 16, 8, 34, 2, tzinfo=datetime.timezone.utc), customer_id='CUST-04111', customer_tier='enterprise', organization_id='ORG-207', product='API Gateway', product_version='2.2.5', product_module='rate_limiter', category='Security', subcategory='Compliance', priority='critical', severity='P2', channel='portal', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_DISK_FULL errors. We need to ensure our system meets compliance requirements.', error_logs='2024-10-15T19:25:38 ERROR ERROR_DISK_FULL: Connection timeout after 30s\\n2024-10-15T19:25:39 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'rate_limiter.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='satisfied', previous_tickets=3, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 10, 16, 8, 34, 2, tzinfo=datetime.timezone.utc), agent_id='AGENT-042', agent_actions=['escalated_to_specialist', 'viewed_logs', 'checked_config', 'contacted_customer', 'verified_resolution'], escalated=True, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['timeout', 'sync'], environment='test', business_impact='high', affected_users=836, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000257', created_at=datetime.datetime(2023, 12, 13, 22, 8, 16, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 13, 23, 34, 40, tzinfo=datetime.timezone.utc), customer_id='CUST-02727', customer_tier='enterprise', organization_id='ORG-201', product='API Gateway', product_version='3.8.6', product_module='auth_service', category='Account Management', subcategory='Subscription', priority='medium', severity='P0', channel='email', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=2, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 12, 13, 23, 34, 40, tzinfo=datetime.timezone.utc), agent_id='AGENT-024', agent_actions=['created_workaround', 'ran_diagnostics', 'verified_resolution', 'consulted_kb', 'contacted_customer', 'viewed_logs'], escalated=True, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['bug', 'security', 'data', 'authentication', 'integration'], environment='staging', business_impact='low', affected_users=38, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000258', created_at=datetime.datetime(2023, 8, 26, 10, 56, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 29, 4, 8, 5, tzinfo=datetime.timezone.utc), customer_id='CUST-01416', customer_tier='enterprise', organization_id='ORG-153', product='StreamProcessor', product_version='4.4.7', product_module='batch_processor', category='Security', subcategory='Authentication', priority='low', severity='P4', channel='chat', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=7, resolution='Root cause identified as Authentication issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 8, 29, 4, 8, 5, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['ran_diagnostics', 'contacted_customer'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['performance', 'error', 'configuration', 'sync', 'database'], environment='staging', business_impact='critical', affected_users=46, language='es', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000259', created_at=datetime.datetime(2023, 7, 3, 9, 36, 2, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 5, 17, 27, 2, tzinfo=datetime.timezone.utc), customer_id='CUST-03561', customer_tier='enterprise', organization_id='ORG-431', product='DataSync Pro', product_version='2.1.7', product_module='scheduler', category='Security', subcategory='Vulnerability', priority='medium', severity='P4', channel='email', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_DISK_FULL errors. We need to ensure our system meets compliance requirements.', error_logs='2023-07-03T09:36:02 ERROR ERROR_DISK_FULL: Database connection lost\\n2023-07-03T09:36:03 INFO Attempting to reconnect...\\n2023-07-03T09:36:05 ERROR Connection failed', stack_trace='Stack trace:\\n  scheduler::processData() at scheduler.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='grateful', previous_tickets=6, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 7, 5, 17, 27, 2, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['verified_resolution', 'updated_documentation'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=False, tags=['sync', 'error', 'database'], environment='production', business_impact='high', affected_users=24, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000260', created_at=datetime.datetime(2024, 7, 4, 11, 58, 30, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 4, 22, 43, 30, tzinfo=datetime.timezone.utc), customer_id='CUST-04207', customer_tier='starter', organization_id='ORG-295', product='DataSync Pro', product_version='3.6.4', product_module='sync_engine', category='Security', subcategory='Authentication', priority='medium', severity='P2', channel='chat', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_PARSING errors. We need to ensure our system meets compliance requirements.', error_logs='2024-07-04T11:58:30 ERROR ERROR_PARSING: Database connection lost\\n2024-07-04T11:58:31 INFO Attempting to reconnect...\\n2024-07-04T11:58:33 ERROR Connection failed', stack_trace=\"Traceback (most recent call last):\\n  File 'sync_engine.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='satisfied', previous_tickets=2, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 7, 4, 22, 43, 30, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['contacted_customer', 'consulted_kb', 'applied_fix'], escalated=True, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['database', 'error', 'bug', 'authentication', 'data'], environment='staging', business_impact='medium', affected_users=37, language='es', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000261', created_at=datetime.datetime(2024, 8, 18, 5, 34, 24, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 20, 14, 11, 36, tzinfo=datetime.timezone.utc), customer_id='CUST-02944', customer_tier='free', organization_id='ORG-268', product='DataSync Pro', product_version='3.1.13', product_module='sync_engine', category='Account Management', subcategory='License', priority='critical', severity='P4', channel='api', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-08-18T05:34:24 ERROR ERROR_SERVER_500: Database connection lost\\n2024-08-18T05:34:25 INFO Attempting to reconnect...\\n2024-08-18T05:34:27 ERROR Connection failed', stack_trace='', customer_sentiment='grateful', previous_tickets=5, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 8, 20, 14, 11, 36, tzinfo=datetime.timezone.utc), agent_id='AGENT-025', agent_actions=['escalated_to_specialist', 'ran_diagnostics'], escalated=True, transferred_count=3, satisfaction_score=1, resolution_helpful=True, tags=['api', 'integration', 'bug', 'performance', 'authentication'], environment='development', business_impact='low', affected_users=217, language='zh', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000262', created_at=datetime.datetime(2023, 5, 29, 15, 18, 1, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 29, 20, 45, 1, tzinfo=datetime.timezone.utc), customer_id='CUST-03634', customer_tier='starter', organization_id='ORG-093', product='API Gateway', product_version='2.9.6', product_module='request_router', category='Data Issue', subcategory='Data Loss', priority='low', severity='P1', channel='slack', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=4, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 5, 29, 20, 45, 1, tzinfo=datetime.timezone.utc), agent_id='AGENT-017', agent_actions=['escalated_to_specialist', 'contacted_customer'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['database', 'timeout', 'api', 'authentication'], environment='staging', business_impact='low', affected_users=42, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000263', created_at=datetime.datetime(2024, 1, 9, 12, 57, 24, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 12, 19, 28, tzinfo=datetime.timezone.utc), customer_id='CUST-00155', customer_tier='professional', organization_id='ORG-168', product='Analytics Dashboard', product_version='3.5.6', product_module='export_module', category='Account Management', subcategory='License', priority='high', severity='P4', channel='portal', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-01-09T12:57:24 ERROR ERROR_CONFLICT_409: Connection timeout after 30s\\n2024-01-09T12:57:25 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='frustrated', previous_tickets=4, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 1, 12, 19, 28, tzinfo=datetime.timezone.utc), agent_id='AGENT-033', agent_actions=['contacted_customer', 'created_workaround', 'verified_resolution', 'viewed_logs'], escalated=False, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['timeout', 'integration'], environment='development', business_impact='high', affected_users=429, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000264', created_at=datetime.datetime(2024, 6, 30, 12, 28, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 1, 18, 11, 12, tzinfo=datetime.timezone.utc), customer_id='CUST-04898', customer_tier='professional', organization_id='ORG-281', product='StreamProcessor', product_version='3.2.5', product_module='event_handler', category='Data Issue', subcategory='Data Loss', priority='high', severity='P4', channel='email', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_VALIDATION appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-06-30T12:28:00 DEBUG Processing request ID-12345\\n2024-06-30T12:28:00 ERROR ERROR_VALIDATION: Invalid request format\\n2024-06-30T12:28:01 INFO Request rejected', stack_trace='Stack trace:\\n  event_handler::processData() at event_handler.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='confused', previous_tickets=9, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 7, 1, 18, 11, 12, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['applied_fix', 'checked_config', 'viewed_logs', 'ran_diagnostics', 'updated_documentation', 'consulted_kb'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['data', 'configuration', 'database', 'authentication'], environment='sandbox', business_impact='low', affected_users=520, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000265', created_at=datetime.datetime(2024, 10, 16, 15, 10, 11, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 20, 22, 20, 23, tzinfo=datetime.timezone.utc), customer_id='CUST-04242', customer_tier='enterprise', organization_id='ORG-298', product='CloudBackup Enterprise', product_version='2.1.7', product_module='compression_engine', category='Security', subcategory='Encryption', priority='medium', severity='P4', channel='chat', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Getting ERROR_INVALID_400 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-10-16T15:10:11 ERROR ERROR_INVALID_400: Connection timeout after 30s\\n2024-10-16T15:10:12 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='grateful', previous_tickets=10, resolution='Applied hotfix version 3.2.2 to address the ERROR_INVALID_400. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 10, 20, 22, 20, 23, tzinfo=datetime.timezone.utc), agent_id='AGENT-023', agent_actions=['viewed_logs', 'escalated_to_specialist', 'ran_diagnostics'], escalated=False, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['data', 'authentication', 'database', 'performance'], environment='development', business_impact='low', affected_users=23, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000266', created_at=datetime.datetime(2024, 11, 14, 9, 29, 7, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 14, 23, 15, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-04576', customer_tier='free', organization_id='ORG-267', product='DataSync Pro', product_version='4.6.2', product_module='data_validator', category='Data Issue', subcategory='Import/Export', priority='medium', severity='P2', channel='chat', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=6, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 11, 14, 23, 15, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-047', agent_actions=['created_workaround', 'checked_config', 'verified_resolution', 'escalated_to_specialist', 'contacted_customer'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['bug', 'authentication', 'error', 'timeout', 'integration'], environment='development', business_impact='high', affected_users=35, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000267', created_at=datetime.datetime(2024, 10, 14, 8, 22, 54, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 14, 10, 36, 42, tzinfo=datetime.timezone.utc), customer_id='CUST-03476', customer_tier='professional', organization_id='ORG-040', product='StreamProcessor', product_version='2.5.14', product_module='monitoring', category='Data Issue', subcategory='Sync Error', priority='critical', severity='P1', channel='slack', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_CONFLICT_409 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-10-14T08:22:54 WARN Rate limit approaching threshold\\n2024-10-14T08:22:54 ERROR ERROR_CONFLICT_409: Rate limit exceeded\\n2024-10-14T08:22:56 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='grateful', previous_tickets=8, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 10, 14, 10, 36, 42, tzinfo=datetime.timezone.utc), agent_id='AGENT-024', agent_actions=['updated_documentation', 'ran_diagnostics'], escalated=True, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['authentication', 'error', 'security'], environment='sandbox', business_impact='low', affected_users=450, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000268', created_at=datetime.datetime(2024, 3, 28, 3, 20, 36, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 30, 19, 59, 36, tzinfo=datetime.timezone.utc), customer_id='CUST-04903', customer_tier='professional', organization_id='ORG-110', product='DataSync Pro', product_version='4.9.12', product_module='sync_engine', category='Data Issue', subcategory='Corruption', priority='medium', severity='P4', channel='chat', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_CONNECTION_REFUSED appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-03-28T03:20:36 DEBUG Processing request ID-12345\\n2024-03-28T03:20:36 ERROR ERROR_CONNECTION_REFUSED: Invalid request format\\n2024-03-28T03:20:37 INFO Request rejected', stack_trace='', customer_sentiment='satisfied', previous_tickets=1, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 3, 30, 19, 59, 36, tzinfo=datetime.timezone.utc), agent_id='AGENT-047', agent_actions=['created_workaround', 'contacted_customer', 'escalated_to_specialist'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['security', 'api'], environment='development', business_impact='low', affected_users=18, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000269', created_at=datetime.datetime(2024, 4, 18, 21, 27, 18, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 18, 23, 8, 42, tzinfo=datetime.timezone.utc), customer_id='CUST-02733', customer_tier='professional', organization_id='ORG-108', product='StreamProcessor', product_version='3.8.12', product_module='batch_processor', category='Technical Issue', subcategory='Bug', priority='low', severity='P0', channel='phone', subject='StreamProcessor throwing ERROR_TIMEOUT_429 during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing ERROR_TIMEOUT_429 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-04-18T21:27:18 ERROR ERROR_TIMEOUT_429: Connection timeout after 30s\\n2024-04-18T21:27:19 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='satisfied', previous_tickets=7, resolution='Root cause identified as Bug issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 4, 18, 23, 8, 42, tzinfo=datetime.timezone.utc), agent_id='AGENT-046', agent_actions=['contacted_customer', 'checked_config', 'created_workaround'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['timeout', 'security', 'database', 'sync'], environment='development', business_impact='critical', affected_users=41, language='ja', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000270', created_at=datetime.datetime(2024, 1, 30, 0, 17, 2, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 30, 14, 8, 2, tzinfo=datetime.timezone.utc), customer_id='CUST-03932', customer_tier='free', organization_id='ORG-496', product='DataSync Pro', product_version='4.1.5', product_module='data_validator', category='Account Management', subcategory='Billing', priority='high', severity='P2', channel='portal', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=3, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 1, 30, 14, 8, 2, tzinfo=datetime.timezone.utc), agent_id='AGENT-032', agent_actions=['consulted_kb', 'ran_diagnostics'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=False, tags=['bug', 'authentication'], environment='test', business_impact='medium', affected_users=581, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000271', created_at=datetime.datetime(2023, 7, 9, 10, 9, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 10, 20, 7, 57, tzinfo=datetime.timezone.utc), customer_id='CUST-01241', customer_tier='starter', organization_id='ORG-491', product='API Gateway', product_version='2.3.10', product_module='auth_service', category='Account Management', subcategory='Upgrade', priority='medium', severity='P3', channel='api', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-07-09T10:09:45 ERROR ERROR_PERMISSION_403: Connection timeout after 30s\\n2023-07-09T10:09:46 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'auth_service.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='neutral', previous_tickets=3, resolution='Root cause identified as Upgrade issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 7, 10, 20, 7, 57, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['applied_fix', 'created_workaround'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['configuration', 'security', 'api', 'timeout'], environment='test', business_impact='low', affected_users=37, language='de', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000272', created_at=datetime.datetime(2023, 7, 26, 23, 9, 1, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 27, 1, 12, 37, tzinfo=datetime.timezone.utc), customer_id='CUST-02079', customer_tier='free', organization_id='ORG-013', product='API Gateway', product_version='3.4.6', product_module='cache_layer', category='Technical Issue', subcategory='Bug', priority='medium', severity='P0', channel='phone', subject='API Gateway throwing ERROR_INVALID_400 during operation', description=\"We're experiencing issues with API Gateway. The system is throwing ERROR_INVALID_400 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-07-26T23:09:01 ERROR ERROR_INVALID_400: Database connection lost\\n2023-07-26T23:09:02 INFO Attempting to reconnect...\\n2023-07-26T23:09:04 ERROR Connection failed', stack_trace='Stack trace:\\n  cache_layer::processData() at cache_layer.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='satisfied', previous_tickets=0, resolution='Root cause identified as Bug issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 7, 27, 1, 12, 37, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['applied_fix', 'escalated_to_specialist', 'viewed_logs'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=False, tags=['api', 'security'], environment='staging', business_impact='high', affected_users=8, language='it', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000273', created_at=datetime.datetime(2023, 10, 14, 15, 29, 23, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 14, 19, 16, 11, tzinfo=datetime.timezone.utc), customer_id='CUST-04725', customer_tier='professional', organization_id='ORG-431', product='Analytics Dashboard', product_version='3.8.4', product_module='visualization', category='Security', subcategory='Encryption', priority='critical', severity='P1', channel='slack', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_DISK_FULL errors. We need to ensure our system meets compliance requirements.', error_logs='2023-10-14T15:29:23 ERROR ERROR_DISK_FULL: Connection timeout after 30s\\n2023-10-14T15:29:24 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='confused', previous_tickets=0, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 10, 14, 19, 16, 11, tzinfo=datetime.timezone.utc), agent_id='AGENT-038', agent_actions=['checked_config', 'contacted_customer'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['error', 'data', 'database', 'bug', 'timeout'], environment='production', business_impact='medium', affected_users=651, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000274', created_at=datetime.datetime(2023, 7, 21, 8, 18, 29, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 21, 11, 10, 5, tzinfo=datetime.timezone.utc), customer_id='CUST-02831', customer_tier='premium', organization_id='ORG-165', product='API Gateway', product_version='4.5.3', product_module='rate_limiter', category='Feature Request', subcategory='Enhancement', priority='medium', severity='P1', channel='phone', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-07-21T08:18:29 ERROR ERROR_RATELIMIT_429: Connection timeout after 30s\\n2023-07-21T08:18:30 RETRY_FAILED: Max retries exceeded', stack_trace='at rate_limiter.execute(rate_limiter.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='neutral', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 7, 21, 11, 10, 5, tzinfo=datetime.timezone.utc), agent_id='AGENT-044', agent_actions=['escalated_to_specialist', 'created_workaround', 'ran_diagnostics', 'applied_fix'], escalated=True, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['database', 'bug', 'authentication', 'integration', 'performance'], environment='development', business_impact='high', affected_users=33, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000275', created_at=datetime.datetime(2024, 1, 2, 0, 25, 19, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 5, 9, 19, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-04001', customer_tier='free', organization_id='ORG-070', product='CloudBackup Enterprise', product_version='3.1.11', product_module='compression_engine', category='Security', subcategory='Authentication', priority='low', severity='P3', channel='phone', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Getting ERROR_PERMISSION_403 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-01-02T00:25:19 DEBUG Processing request ID-12345\\n2024-01-02T00:25:19 ERROR ERROR_PERMISSION_403: Invalid request format\\n2024-01-02T00:25:20 INFO Request rejected', stack_trace='', customer_sentiment='angry', previous_tickets=3, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 1, 5, 9, 19, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-016', agent_actions=['checked_config', 'verified_resolution', 'consulted_kb', 'created_workaround', 'updated_documentation'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=False, tags=['data', 'integration', 'database'], environment='development', business_impact='high', affected_users=40, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000276', created_at=datetime.datetime(2024, 7, 5, 1, 29, 11, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 6, 8, 15, 59, tzinfo=datetime.timezone.utc), customer_id='CUST-02104', customer_tier='professional', organization_id='ORG-304', product='DataSync Pro', product_version='4.5.10', product_module='data_validator', category='Data Issue', subcategory='Sync Error', priority='high', severity='P4', channel='email', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_MEMORY_OOM appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-07-05T01:29:11 DEBUG Processing request ID-12345\\n2024-07-05T01:29:11 ERROR ERROR_MEMORY_OOM: Invalid request format\\n2024-07-05T01:29:12 INFO Request rejected', stack_trace='Stack trace:\\n  data_validator::processData() at data_validator.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='confused', previous_tickets=1, resolution='Root cause identified as Sync Error issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 7, 6, 8, 15, 59, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['viewed_logs', 'checked_config'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['authentication', 'data', 'database', 'configuration', 'performance'], environment='production', business_impact='low', affected_users=538, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000277', created_at=datetime.datetime(2024, 11, 13, 7, 11, 47, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 13, 15, 50, 11, tzinfo=datetime.timezone.utc), customer_id='CUST-00383', customer_tier='enterprise', organization_id='ORG-301', product='DataSync Pro', product_version='4.6.10', product_module='sync_engine', category='Technical Issue', subcategory='Bug', priority='high', severity='P1', channel='chat', subject='DataSync Pro throwing ERROR_NOTFOUND_404 during operation', description=\"We're experiencing issues with DataSync Pro. The system is throwing ERROR_NOTFOUND_404 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-11-13T07:11:47 DEBUG Processing request ID-12345\\n2024-11-13T07:11:47 ERROR ERROR_NOTFOUND_404: Invalid request format\\n2024-11-13T07:11:48 INFO Request rejected', stack_trace='at sync_engine.execute(sync_engine.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='frustrated', previous_tickets=9, resolution='Root cause identified as Bug issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 11, 13, 15, 50, 11, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['contacted_customer', 'consulted_kb', 'viewed_logs'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['authentication', 'configuration', 'sync'], environment='sandbox', business_impact='low', affected_users=813, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000278', created_at=datetime.datetime(2023, 11, 15, 16, 59, 43, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 16, 0, 29, 7, tzinfo=datetime.timezone.utc), customer_id='CUST-01211', customer_tier='professional', organization_id='ORG-194', product='StreamProcessor', product_version='4.4.14', product_module='event_handler', category='Technical Issue', subcategory='Bug', priority='critical', severity='P3', channel='api', subject='StreamProcessor throwing errors during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=5, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 11, 16, 0, 29, 7, tzinfo=datetime.timezone.utc), agent_id='AGENT-050', agent_actions=['applied_fix', 'verified_resolution', 'created_workaround'], escalated=True, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['performance', 'authentication'], environment='test', business_impact='low', affected_users=343, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000279', created_at=datetime.datetime(2023, 8, 22, 13, 26, 46, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 27, 21, 15, 22, tzinfo=datetime.timezone.utc), customer_id='CUST-02487', customer_tier='premium', organization_id='ORG-167', product='Analytics Dashboard', product_version='4.9.13', product_module='export_module', category='Feature Request', subcategory='UI/UX', priority='medium', severity='P4', channel='slack', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-08-22T13:26:46 ERROR ERROR_MEMORY_OOM: Connection timeout after 30s\\n2023-08-22T13:26:47 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='satisfied', previous_tickets=9, resolution='Applied hotfix version 3.2.2 to address the ERROR_MEMORY_OOM. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 8, 27, 21, 15, 22, tzinfo=datetime.timezone.utc), agent_id='AGENT-042', agent_actions=['contacted_customer', 'updated_documentation', 'created_workaround'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['api', 'bug'], environment='development', business_impact='high', affected_users=33, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000280', created_at=datetime.datetime(2023, 4, 9, 18, 41, 22, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 10, 11, 24, 34, tzinfo=datetime.timezone.utc), customer_id='CUST-00552', customer_tier='free', organization_id='ORG-284', product='API Gateway', product_version='2.1.11', product_module='rate_limiter', category='Feature Request', subcategory='UI/UX', priority='high', severity='P3', channel='chat', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-04-09T18:41:22 DEBUG Processing request ID-12345\\n2023-04-09T18:41:22 ERROR ERROR_TIMEOUT_429: Invalid request format\\n2023-04-09T18:41:23 INFO Request rejected', stack_trace='', customer_sentiment='frustrated', previous_tickets=5, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 4, 10, 11, 24, 34, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['viewed_logs', 'updated_documentation', 'applied_fix', 'escalated_to_specialist'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['api', 'configuration', 'authentication', 'error', 'database'], environment='sandbox', business_impact='low', affected_users=852, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000281', created_at=datetime.datetime(2024, 1, 16, 2, 17, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 19, 7, 27, 14, tzinfo=datetime.timezone.utc), customer_id='CUST-02740', customer_tier='premium', organization_id='ORG-447', product='Analytics Dashboard', product_version='2.2.7', product_module='visualization', category='Feature Request', subcategory='UI/UX', priority='low', severity='P3', channel='portal', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=6, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 1, 19, 7, 27, 14, tzinfo=datetime.timezone.utc), agent_id='AGENT-022', agent_actions=['consulted_kb', 'verified_resolution', 'created_workaround'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=False, tags=['error', 'configuration', 'security'], environment='test', business_impact='low', affected_users=21, language='zh', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000282', created_at=datetime.datetime(2023, 5, 6, 14, 9, 10, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 10, 23, 56, 34, tzinfo=datetime.timezone.utc), customer_id='CUST-01094', customer_tier='premium', organization_id='ORG-321', product='API Gateway', product_version='4.2.4', product_module='rate_limiter', category='Security', subcategory='Encryption', priority='medium', severity='P4', channel='portal', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_CORRUPTION errors. We need to ensure our system meets compliance requirements.', error_logs='2023-05-06T14:09:10 WARN Rate limit approaching threshold\\n2023-05-06T14:09:10 ERROR ERROR_CORRUPTION: Rate limit exceeded\\n2023-05-06T14:09:12 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='confused', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 5, 10, 23, 56, 34, tzinfo=datetime.timezone.utc), agent_id='AGENT-040', agent_actions=['ran_diagnostics', 'checked_config', 'viewed_logs'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['security', 'configuration', 'timeout'], environment='test', business_impact='critical', affected_users=23, language='en', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000283', created_at=datetime.datetime(2024, 9, 8, 23, 47, 26, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 9, 1, 41, 26, tzinfo=datetime.timezone.utc), customer_id='CUST-03791', customer_tier='enterprise', organization_id='ORG-390', product='API Gateway', product_version='2.5.14', product_module='request_router', category='Account Management', subcategory='Subscription', priority='high', severity='P0', channel='chat', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-09-08T23:47:26 ERROR ERROR_SERVER_500: Connection timeout after 30s\\n2024-09-08T23:47:27 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'request_router.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='frustrated', previous_tickets=2, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 9, 9, 1, 41, 26, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['checked_config', 'contacted_customer'], escalated=True, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'configuration', 'error', 'bug', 'performance'], environment='development', business_impact='medium', affected_users=918, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000284', created_at=datetime.datetime(2024, 3, 19, 14, 2, 50, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 20, 0, 35, 14, tzinfo=datetime.timezone.utc), customer_id='CUST-02745', customer_tier='free', organization_id='ORG-062', product='DataSync Pro', product_version='3.0.11', product_module='data_validator', category='Data Issue', subcategory='Corruption', priority='low', severity='P1', channel='email', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_DEADLOCK appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-03-19T14:02:50 DEBUG Processing request ID-12345\\n2024-03-19T14:02:50 ERROR ERROR_DEADLOCK: Invalid request format\\n2024-03-19T14:02:51 INFO Request rejected', stack_trace='ERROR: data_validator.service.ServiceException: Failed to process request\\n\\tat data_validator.handler.process(data_validator.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='confused', previous_tickets=1, resolution='Root cause identified as Corruption issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 3, 20, 0, 35, 14, tzinfo=datetime.timezone.utc), agent_id='AGENT-047', agent_actions=['contacted_customer', 'created_workaround', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['api', 'timeout', 'integration', 'data'], environment='sandbox', business_impact='critical', affected_users=46, language='pt', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000285', created_at=datetime.datetime(2023, 6, 28, 16, 19, 22, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 28, 20, 44, 34, tzinfo=datetime.timezone.utc), customer_id='CUST-01452', customer_tier='starter', organization_id='ORG-239', product='StreamProcessor', product_version='4.0.5', product_module='event_handler', category='Account Management', subcategory='Access Control', priority='high', severity='P1', channel='slack', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-06-28T16:19:22 ERROR ERROR_PARSING: Database connection lost\\n2023-06-28T16:19:23 INFO Attempting to reconnect...\\n2023-06-28T16:19:25 ERROR Connection failed', stack_trace='', customer_sentiment='satisfied', previous_tickets=7, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 6, 28, 20, 44, 34, tzinfo=datetime.timezone.utc), agent_id='AGENT-020', agent_actions=['ran_diagnostics', 'created_workaround', 'consulted_kb'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['error', 'api'], environment='staging', business_impact='high', affected_users=62, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000286', created_at=datetime.datetime(2023, 1, 6, 13, 13, 32, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 6, 20, 20, 44, tzinfo=datetime.timezone.utc), customer_id='CUST-00151', customer_tier='starter', organization_id='ORG-387', product='StreamProcessor', product_version='3.5.10', product_module='monitoring', category='Data Issue', subcategory='Corruption', priority='high', severity='P2', channel='chat', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_PERMISSION_403 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-01-06T13:13:32 WARN Rate limit approaching threshold\\n2023-01-06T13:13:32 ERROR ERROR_PERMISSION_403: Rate limit exceeded\\n2023-01-06T13:13:34 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='satisfied', previous_tickets=6, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 1, 6, 20, 20, 44, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['ran_diagnostics', 'viewed_logs', 'checked_config', 'escalated_to_specialist'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['security', 'database', 'timeout', 'api'], environment='test', business_impact='critical', affected_users=163, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000287', created_at=datetime.datetime(2024, 1, 26, 14, 36, 36, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 26, 17, 17, 24, tzinfo=datetime.timezone.utc), customer_id='CUST-01219', customer_tier='enterprise', organization_id='ORG-031', product='Analytics Dashboard', product_version='4.8.2', product_module='report_builder', category='Security', subcategory='Authorization', priority='critical', severity='P1', channel='email', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_TIMEOUT_429 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-01-26T14:36:36 ERROR ERROR_TIMEOUT_429: Database connection lost\\n2024-01-26T14:36:37 INFO Attempting to reconnect...\\n2024-01-26T14:36:39 ERROR Connection failed', stack_trace='', customer_sentiment='confused', previous_tickets=5, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 1, 26, 17, 17, 24, tzinfo=datetime.timezone.utc), agent_id='AGENT-036', agent_actions=['ran_diagnostics', 'viewed_logs', 'verified_resolution', 'checked_config'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['bug', 'security'], environment='staging', business_impact='low', affected_users=787, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000288', created_at=datetime.datetime(2023, 3, 23, 3, 10, 6, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 23, 6, 32, 18, tzinfo=datetime.timezone.utc), customer_id='CUST-02518', customer_tier='professional', organization_id='ORG-419', product='Analytics Dashboard', product_version='3.4.13', product_module='visualization', category='Security', subcategory='Encryption', priority='critical', severity='P1', channel='slack', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_PARSING errors. We need to ensure our system meets compliance requirements.', error_logs='2023-03-23T03:10:06 DEBUG Processing request ID-12345\\n2023-03-23T03:10:06 ERROR ERROR_PARSING: Invalid request format\\n2023-03-23T03:10:07 INFO Request rejected', stack_trace='', customer_sentiment='angry', previous_tickets=8, resolution='Root cause identified as Encryption issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 3, 23, 6, 32, 18, tzinfo=datetime.timezone.utc), agent_id='AGENT-032', agent_actions=['checked_config', 'contacted_customer'], escalated=True, transferred_count=1, satisfaction_score=1, resolution_helpful=True, tags=['sync', 'api', 'performance', 'configuration', 'error'], environment='sandbox', business_impact='critical', affected_users=121, language='it', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000289', created_at=datetime.datetime(2024, 1, 19, 15, 27, 28, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 19, 18, 11, 52, tzinfo=datetime.timezone.utc), customer_id='CUST-03525', customer_tier='premium', organization_id='ORG-366', product='Analytics Dashboard', product_version='4.1.5', product_module='export_module', category='Security', subcategory='Authorization', priority='high', severity='P1', channel='phone', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_DISK_FULL errors. We need to ensure our system meets compliance requirements.', error_logs='2024-01-19T15:27:28 ERROR ERROR_DISK_FULL: Database connection lost\\n2024-01-19T15:27:29 INFO Attempting to reconnect...\\n2024-01-19T15:27:31 ERROR Connection failed', stack_trace=\"Traceback (most recent call last):\\n  File 'export_module.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='grateful', previous_tickets=8, resolution='Applied hotfix version 3.2.2 to address the ERROR_DISK_FULL. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 1, 19, 18, 11, 52, tzinfo=datetime.timezone.utc), agent_id='AGENT-034', agent_actions=['updated_documentation', 'checked_config', 'consulted_kb', 'viewed_logs'], escalated=True, transferred_count=3, satisfaction_score=3, resolution_helpful=False, tags=['data', 'database'], environment='development', business_impact='medium', affected_users=420, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000290', created_at=datetime.datetime(2023, 9, 14, 8, 58, 28, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 16, 21, 2, 40, tzinfo=datetime.timezone.utc), customer_id='CUST-02361', customer_tier='free', organization_id='ORG-235', product='Analytics Dashboard', product_version='4.9.1', product_module='report_builder', category='Account Management', subcategory='License', priority='low', severity='P3', channel='chat', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-09-14T08:58:28 ERROR ERROR_SERVER_500: Database connection lost\\n2023-09-14T08:58:29 INFO Attempting to reconnect...\\n2023-09-14T08:58:31 ERROR Connection failed', stack_trace='Stack trace:\\n  report_builder::processData() at report_builder.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='frustrated', previous_tickets=0, resolution='Applied hotfix version 3.2.2 to address the ERROR_SERVER_500. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 9, 16, 21, 2, 40, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['applied_fix', 'escalated_to_specialist', 'updated_documentation'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['bug', 'timeout', 'api', 'data', 'performance'], environment='production', business_impact='low', affected_users=17, language='de', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000291', created_at=datetime.datetime(2023, 9, 11, 10, 7, 32, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 11, 14, 51, 20, tzinfo=datetime.timezone.utc), customer_id='CUST-02346', customer_tier='starter', organization_id='ORG-301', product='DataSync Pro', product_version='3.8.8', product_module='scheduler', category='Feature Request', subcategory='API', priority='medium', severity='P1', channel='api', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-09-11T10:07:32 WARN Rate limit approaching threshold\\n2023-09-11T10:07:32 ERROR ERROR_TIMEOUT_429: Rate limit exceeded\\n2023-09-11T10:07:34 INFO Backing off for 60 seconds', stack_trace='at scheduler.execute(scheduler.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='grateful', previous_tickets=2, resolution='Applied hotfix version 3.2.2 to address the ERROR_TIMEOUT_429. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 9, 11, 14, 51, 20, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['applied_fix', 'escalated_to_specialist'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['timeout', 'data', 'performance'], environment='sandbox', business_impact='low', affected_users=50, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000292', created_at=datetime.datetime(2023, 6, 2, 20, 44, 57, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 3, 1, 48, 33, tzinfo=datetime.timezone.utc), customer_id='CUST-04170', customer_tier='professional', organization_id='ORG-497', product='CloudBackup Enterprise', product_version='3.0.7', product_module='backup_service', category='Feature Request', subcategory='New Feature', priority='critical', severity='P2', channel='email', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-06-02T20:44:57 DEBUG Processing request ID-12345\\n2023-06-02T20:44:57 ERROR ERROR_INVALID_400: Invalid request format\\n2023-06-02T20:44:58 INFO Request rejected', stack_trace='at backup_service.execute(backup_service.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='angry', previous_tickets=3, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 6, 3, 1, 48, 33, tzinfo=datetime.timezone.utc), agent_id='AGENT-026', agent_actions=['consulted_kb', 'created_workaround'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['security', 'data', 'bug', 'error', 'integration'], environment='development', business_impact='medium', affected_users=511, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000293', created_at=datetime.datetime(2023, 5, 24, 4, 29, 1, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 24, 5, 53, 1, tzinfo=datetime.timezone.utc), customer_id='CUST-04832', customer_tier='professional', organization_id='ORG-319', product='CloudBackup Enterprise', product_version='4.6.14', product_module='compression_engine', category='Technical Issue', subcategory='Integration', priority='critical', severity='P0', channel='portal', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_DEADLOCK in the logs. This is affecting our entire team's productivity.\", error_logs='2023-05-24T04:29:01 ERROR ERROR_DEADLOCK: Database connection lost\\n2023-05-24T04:29:02 INFO Attempting to reconnect...\\n2023-05-24T04:29:04 ERROR Connection failed', stack_trace='', customer_sentiment='angry', previous_tickets=3, resolution='Root cause identified as Integration issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 5, 24, 5, 53, 1, tzinfo=datetime.timezone.utc), agent_id='AGENT-003', agent_actions=['updated_documentation', 'contacted_customer', 'applied_fix'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=False, tags=['integration', 'performance', 'error', 'authentication', 'database'], environment='sandbox', business_impact='medium', affected_users=19, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000294', created_at=datetime.datetime(2024, 8, 6, 12, 20, 53, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 6, 13, 45, 29, tzinfo=datetime.timezone.utc), customer_id='CUST-01358', customer_tier='premium', organization_id='ORG-461', product='StreamProcessor', product_version='4.8.3', product_module='batch_processor', category='Feature Request', subcategory='Enhancement', priority='low', severity='P0', channel='api', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=7, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 8, 6, 13, 45, 29, tzinfo=datetime.timezone.utc), agent_id='AGENT-019', agent_actions=['updated_documentation', 'ran_diagnostics'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['timeout', 'bug', 'authentication'], environment='staging', business_impact='low', affected_users=27, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000295', created_at=datetime.datetime(2023, 8, 3, 17, 5, 56, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 6, 11, 5, 20, tzinfo=datetime.timezone.utc), customer_id='CUST-01463', customer_tier='enterprise', organization_id='ORG-237', product='API Gateway', product_version='2.7.11', product_module='cache_layer', category='Security', subcategory='Compliance', priority='medium', severity='P4', channel='chat', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_NOTFOUND_404 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-08-03T17:05:56 ERROR ERROR_NOTFOUND_404: Connection timeout after 30s\\n2023-08-03T17:05:57 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='grateful', previous_tickets=5, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 8, 6, 11, 5, 20, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['consulted_kb', 'updated_documentation', 'created_workaround', 'escalated_to_specialist', 'viewed_logs'], escalated=True, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['configuration', 'sync', 'error'], environment='staging', business_impact='critical', affected_users=30, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000296', created_at=datetime.datetime(2023, 10, 11, 19, 24, 55, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 11, 22, 6, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-03598', customer_tier='professional', organization_id='ORG-202', product='StreamProcessor', product_version='2.1.5', product_module='monitoring', category='Feature Request', subcategory='API', priority='critical', severity='P1', channel='slack', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=3, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 10, 11, 22, 6, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-049', agent_actions=['updated_documentation', 'contacted_customer'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['authentication', 'data'], environment='development', business_impact='medium', affected_users=237, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000297', created_at=datetime.datetime(2024, 1, 4, 17, 48, 11, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 5, 12, 19, 23, tzinfo=datetime.timezone.utc), customer_id='CUST-01230', customer_tier='free', organization_id='ORG-060', product='Analytics Dashboard', product_version='4.8.3', product_module='data_aggregator', category='Account Management', subcategory='Access Control', priority='high', severity='P2', channel='phone', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-01-04T17:48:11 DEBUG Processing request ID-12345\\n2024-01-04T17:48:11 ERROR ERROR_CORRUPTION: Invalid request format\\n2024-01-04T17:48:12 INFO Request rejected', stack_trace='', customer_sentiment='angry', previous_tickets=1, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 1, 5, 12, 19, 23, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['consulted_kb', 'viewed_logs', 'contacted_customer', 'ran_diagnostics', 'updated_documentation'], escalated=True, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['timeout', 'security', 'sync'], environment='staging', business_impact='critical', affected_users=689, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000298', created_at=datetime.datetime(2023, 5, 23, 14, 30, 15, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 23, 20, 10, 27, tzinfo=datetime.timezone.utc), customer_id='CUST-01502', customer_tier='professional', organization_id='ORG-401', product='StreamProcessor', product_version='4.6.15', product_module='error_handler', category='Technical Issue', subcategory='Configuration', priority='medium', severity='P2', channel='api', subject='StreamProcessor throwing ERROR_RATELIMIT_429 during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing ERROR_RATELIMIT_429 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-05-23T14:30:15 ERROR ERROR_RATELIMIT_429: Connection timeout after 30s\\n2023-05-23T14:30:16 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='confused', previous_tickets=4, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 5, 23, 20, 10, 27, tzinfo=datetime.timezone.utc), agent_id='AGENT-035', agent_actions=['consulted_kb', 'escalated_to_specialist'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['database', 'data', 'performance'], environment='sandbox', business_impact='low', affected_users=24, language='pt', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000299', created_at=datetime.datetime(2023, 8, 14, 6, 33, 7, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 17, 10, 4, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-03303', customer_tier='free', organization_id='ORG-452', product='Analytics Dashboard', product_version='3.2.7', product_module='report_builder', category='Account Management', subcategory='Billing', priority='low', severity='P4', channel='api', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-08-14T06:33:07 DEBUG Processing request ID-12345\\n2023-08-14T06:33:07 ERROR ERROR_PARSING: Invalid request format\\n2023-08-14T06:33:08 INFO Request rejected', stack_trace='Stack trace:\\n  report_builder::processData() at report_builder.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='angry', previous_tickets=10, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 8, 17, 10, 4, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-035', agent_actions=['verified_resolution', 'viewed_logs', 'applied_fix', 'checked_config', 'escalated_to_specialist'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['integration', 'security'], environment='sandbox', business_impact='high', affected_users=1, language='pt', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000300', created_at=datetime.datetime(2024, 3, 25, 5, 11, 13, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 26, 0, 34, 37, tzinfo=datetime.timezone.utc), customer_id='CUST-04988', customer_tier='premium', organization_id='ORG-244', product='DataSync Pro', product_version='2.6.7', product_module='api_connector', category='Feature Request', subcategory='API', priority='medium', severity='P3', channel='api', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-03-25T05:11:13 ERROR ERROR_SERVER_500: Connection timeout after 30s\\n2024-03-25T05:11:14 RETRY_FAILED: Max retries exceeded', stack_trace='Stack trace:\\n  api_connector::processData() at api_connector.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='frustrated', previous_tickets=8, resolution='Root cause identified as API issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 3, 26, 0, 34, 37, tzinfo=datetime.timezone.utc), agent_id='AGENT-045', agent_actions=['viewed_logs', 'applied_fix', 'checked_config', 'consulted_kb'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=False, tags=['database', 'error', 'performance', 'configuration', 'security'], environment='development', business_impact='high', affected_users=21, language='zh', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000301', created_at=datetime.datetime(2024, 12, 18, 21, 57, 10, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 21, 5, 12, 46, tzinfo=datetime.timezone.utc), customer_id='CUST-03253', customer_tier='enterprise', organization_id='ORG-026', product='DataSync Pro', product_version='3.8.11', product_module='scheduler', category='Data Issue', subcategory='Validation', priority='critical', severity='P4', channel='portal', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_PERMISSION_403 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-12-18T21:57:10 ERROR ERROR_PERMISSION_403: Database connection lost\\n2024-12-18T21:57:11 INFO Attempting to reconnect...\\n2024-12-18T21:57:13 ERROR Connection failed', stack_trace=\"Traceback (most recent call last):\\n  File 'scheduler.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='grateful', previous_tickets=3, resolution='Applied hotfix version 3.2.2 to address the ERROR_PERMISSION_403. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 12, 21, 5, 12, 46, tzinfo=datetime.timezone.utc), agent_id='AGENT-013', agent_actions=['updated_documentation', 'escalated_to_specialist', 'checked_config', 'ran_diagnostics', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['sync', 'bug', 'security', 'api'], environment='sandbox', business_impact='critical', affected_users=910, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000302', created_at=datetime.datetime(2023, 3, 5, 3, 1, 44, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 5, 4, 40, 8, tzinfo=datetime.timezone.utc), customer_id='CUST-04625', customer_tier='enterprise', organization_id='ORG-100', product='StreamProcessor', product_version='2.9.0', product_module='event_handler', category='Account Management', subcategory='Subscription', priority='critical', severity='P0', channel='email', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=8, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 3, 5, 4, 40, 8, tzinfo=datetime.timezone.utc), agent_id='AGENT-035', agent_actions=['consulted_kb', 'ran_diagnostics', 'applied_fix', 'checked_config', 'created_workaround'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['configuration', 'timeout'], environment='sandbox', business_impact='high', affected_users=316, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000303', created_at=datetime.datetime(2023, 11, 1, 1, 42, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 2, 13, 19, 17, tzinfo=datetime.timezone.utc), customer_id='CUST-04755', customer_tier='enterprise', organization_id='ORG-211', product='CloudBackup Enterprise', product_version='3.9.3', product_module='encryption_layer', category='Data Issue', subcategory='Import/Export', priority='high', severity='P4', channel='portal', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=5, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 11, 2, 13, 19, 17, tzinfo=datetime.timezone.utc), agent_id='AGENT-005', agent_actions=['ran_diagnostics', 'verified_resolution', 'updated_documentation'], escalated=False, transferred_count=1, satisfaction_score=1, resolution_helpful=False, tags=['timeout', 'configuration'], environment='sandbox', business_impact='medium', affected_users=464, language='en', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000304', created_at=datetime.datetime(2023, 8, 20, 14, 17, 2, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 20, 16, 54, 50, tzinfo=datetime.timezone.utc), customer_id='CUST-02855', customer_tier='premium', organization_id='ORG-380', product='DataSync Pro', product_version='4.7.0', product_module='api_connector', category='Account Management', subcategory='Upgrade', priority='critical', severity='P1', channel='slack', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-08-20T14:17:02 DEBUG Processing request ID-12345\\n2023-08-20T14:17:02 ERROR ERROR_INVALID_400: Invalid request format\\n2023-08-20T14:17:03 INFO Request rejected', stack_trace='', customer_sentiment='satisfied', previous_tickets=3, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 8, 20, 16, 54, 50, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['consulted_kb', 'contacted_customer', 'ran_diagnostics', 'applied_fix', 'created_workaround', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['performance', 'timeout'], environment='development', business_impact='low', affected_users=539, language='it', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000305', created_at=datetime.datetime(2023, 12, 2, 5, 49, 54, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 2, 10, 6, 6, tzinfo=datetime.timezone.utc), customer_id='CUST-02330', customer_tier='starter', organization_id='ORG-157', product='Analytics Dashboard', product_version='3.2.1', product_module='data_aggregator', category='Feature Request', subcategory='UI/UX', priority='high', severity='P1', channel='phone', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-12-02T05:49:54 DEBUG Processing request ID-12345\\n2023-12-02T05:49:54 ERROR ERROR_VALIDATION: Invalid request format\\n2023-12-02T05:49:55 INFO Request rejected', stack_trace='', customer_sentiment='angry', previous_tickets=0, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 12, 2, 10, 6, 6, tzinfo=datetime.timezone.utc), agent_id='AGENT-036', agent_actions=['checked_config', 'viewed_logs', 'verified_resolution'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['error', 'integration'], environment='sandbox', business_impact='high', affected_users=222, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000306', created_at=datetime.datetime(2023, 5, 2, 3, 47, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 2, 14, 11, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-04576', customer_tier='free', organization_id='ORG-267', product='API Gateway', product_version='3.0.13', product_module='auth_service', category='Feature Request', subcategory='UI/UX', priority='low', severity='P1', channel='slack', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-05-02T03:47:39 ERROR ERROR_CONFLICT_409: Connection timeout after 30s\\n2023-05-02T03:47:40 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'auth_service.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='satisfied', previous_tickets=8, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 5, 2, 14, 11, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-015', agent_actions=['consulted_kb', 'contacted_customer'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['security', 'bug', 'data', 'performance', 'timeout'], environment='sandbox', business_impact='medium', affected_users=38, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000307', created_at=datetime.datetime(2024, 1, 19, 11, 11, 5, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 21, 2, 41, 41, tzinfo=datetime.timezone.utc), customer_id='CUST-01437', customer_tier='enterprise', organization_id='ORG-106', product='Analytics Dashboard', product_version='4.4.15', product_module='visualization', category='Technical Issue', subcategory='Compatibility', priority='medium', severity='P3', channel='portal', subject='Performance degradation in Analytics Dashboard', description=\"The Analytics Dashboard has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_RATELIMIT_429 in the logs. This is affecting our entire team's productivity.\", error_logs='2024-01-19T11:11:05 DEBUG Processing request ID-12345\\n2024-01-19T11:11:05 ERROR ERROR_RATELIMIT_429: Invalid request format\\n2024-01-19T11:11:06 INFO Request rejected', stack_trace='', customer_sentiment='neutral', previous_tickets=0, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 1, 21, 2, 41, 41, tzinfo=datetime.timezone.utc), agent_id='AGENT-032', agent_actions=['verified_resolution', 'applied_fix', 'ran_diagnostics', 'consulted_kb', 'viewed_logs', 'created_workaround'], escalated=False, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['data', 'security', 'bug', 'timeout'], environment='sandbox', business_impact='high', affected_users=44, language='ja', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000308', created_at=datetime.datetime(2024, 1, 16, 1, 48, 2, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 16, 4, 12, 2, tzinfo=datetime.timezone.utc), customer_id='CUST-04541', customer_tier='premium', organization_id='ORG-049', product='CloudBackup Enterprise', product_version='4.2.13', product_module='backup_service', category='Feature Request', subcategory='API', priority='high', severity='P0', channel='api', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-01-16T01:48:02 WARN Rate limit approaching threshold\\n2024-01-16T01:48:02 ERROR ERROR_DISK_FULL: Rate limit exceeded\\n2024-01-16T01:48:04 INFO Backing off for 60 seconds', stack_trace='at backup_service.execute(backup_service.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='grateful', previous_tickets=1, resolution='Root cause identified as API issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 1, 16, 4, 12, 2, tzinfo=datetime.timezone.utc), agent_id='AGENT-037', agent_actions=['escalated_to_specialist', 'verified_resolution'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['timeout', 'database', 'api', 'error'], environment='development', business_impact='high', affected_users=253, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000309', created_at=datetime.datetime(2023, 4, 29, 4, 42, 10, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 29, 10, 52, 22, tzinfo=datetime.timezone.utc), customer_id='CUST-02734', customer_tier='enterprise', organization_id='ORG-088', product='API Gateway', product_version='2.1.12', product_module='auth_service', category='Technical Issue', subcategory='Compatibility', priority='high', severity='P1', channel='slack', subject='API Gateway throwing errors during operation', description=\"We're experiencing issues with API Gateway. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=0, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 4, 29, 10, 52, 22, tzinfo=datetime.timezone.utc), agent_id='AGENT-049', agent_actions=['escalated_to_specialist', 'verified_resolution', 'applied_fix', 'viewed_logs'], escalated=True, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['security', 'database', 'bug'], environment='production', business_impact='high', affected_users=300, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000310', created_at=datetime.datetime(2024, 12, 23, 22, 18, 46, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 25, 20, 6, 10, tzinfo=datetime.timezone.utc), customer_id='CUST-03632', customer_tier='free', organization_id='ORG-064', product='StreamProcessor', product_version='2.2.5', product_module='monitoring', category='Feature Request', subcategory='UI/UX', priority='low', severity='P3', channel='portal', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-12-23T22:18:46 DEBUG Processing request ID-12345\\n2024-12-23T22:18:46 ERROR ERROR_TIMEOUT_429: Invalid request format\\n2024-12-23T22:18:47 INFO Request rejected', stack_trace='at monitoring.execute(monitoring.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='angry', previous_tickets=10, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 12, 25, 20, 6, 10, tzinfo=datetime.timezone.utc), agent_id='AGENT-001', agent_actions=['updated_documentation', 'consulted_kb', 'ran_diagnostics'], escalated=True, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['api', 'bug'], environment='staging', business_impact='high', affected_users=23, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000311', created_at=datetime.datetime(2024, 9, 16, 21, 19, 15, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 17, 1, 16, 15, tzinfo=datetime.timezone.utc), customer_id='CUST-01007', customer_tier='free', organization_id='ORG-155', product='StreamProcessor', product_version='4.0.6', product_module='event_handler', category='Data Issue', subcategory='Import/Export', priority='critical', severity='P2', channel='chat', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_NOTFOUND_404 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-09-16T21:19:15 ERROR ERROR_NOTFOUND_404: Database connection lost\\n2024-09-16T21:19:16 INFO Attempting to reconnect...\\n2024-09-16T21:19:18 ERROR Connection failed', stack_trace='', customer_sentiment='angry', previous_tickets=1, resolution='Applied hotfix version 3.2.2 to address the ERROR_NOTFOUND_404. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 9, 17, 1, 16, 15, tzinfo=datetime.timezone.utc), agent_id='AGENT-046', agent_actions=['consulted_kb', 'applied_fix', 'verified_resolution', 'ran_diagnostics', 'escalated_to_specialist', 'created_workaround'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['data', 'integration', 'error', 'security'], environment='development', business_impact='low', affected_users=193, language='es', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000312', created_at=datetime.datetime(2024, 10, 4, 18, 24, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 4, 23, 7, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-01853', customer_tier='professional', organization_id='ORG-288', product='StreamProcessor', product_version='2.6.13', product_module='monitoring', category='Feature Request', subcategory='Documentation', priority='high', severity='P2', channel='portal', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-10-04T18:24:39 WARN Rate limit approaching threshold\\n2024-10-04T18:24:39 ERROR ERROR_CONFLICT_409: Rate limit exceeded\\n2024-10-04T18:24:41 INFO Backing off for 60 seconds', stack_trace='Stack trace:\\n  monitoring::processData() at monitoring.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='neutral', previous_tickets=4, resolution='Applied hotfix version 3.2.2 to address the ERROR_CONFLICT_409. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 10, 4, 23, 7, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-044', agent_actions=['contacted_customer', 'updated_documentation', 'consulted_kb'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['sync', 'security'], environment='test', business_impact='high', affected_users=683, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000313', created_at=datetime.datetime(2023, 2, 24, 21, 7, 25, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 25, 2, 11, 1, tzinfo=datetime.timezone.utc), customer_id='CUST-04702', customer_tier='professional', organization_id='ORG-209', product='Analytics Dashboard', product_version='4.6.2', product_module='visualization', category='Data Issue', subcategory='Sync Error', priority='high', severity='P1', channel='chat', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_SERVER_500 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-02-24T21:07:25 ERROR ERROR_SERVER_500: Database connection lost\\n2023-02-24T21:07:26 INFO Attempting to reconnect...\\n2023-02-24T21:07:28 ERROR Connection failed', stack_trace='ERROR: visualization.service.ServiceException: Failed to process request\\n\\tat visualization.handler.process(visualization.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='confused', previous_tickets=8, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 2, 25, 2, 11, 1, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['verified_resolution', 'ran_diagnostics', 'updated_documentation'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['performance', 'sync', 'bug', 'api'], environment='test', business_impact='high', affected_users=689, language='it', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000314', created_at=datetime.datetime(2023, 3, 20, 9, 19, 4, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 21, 19, 41, 52, tzinfo=datetime.timezone.utc), customer_id='CUST-01352', customer_tier='professional', organization_id='ORG-391', product='Analytics Dashboard', product_version='4.8.14', product_module='report_builder', category='Data Issue', subcategory='Corruption', priority='high', severity='P3', channel='phone', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_MEMORY_OOM appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-03-20T09:19:04 ERROR ERROR_MEMORY_OOM: Connection timeout after 30s\\n2023-03-20T09:19:05 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='frustrated', previous_tickets=4, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 3, 21, 19, 41, 52, tzinfo=datetime.timezone.utc), agent_id='AGENT-040', agent_actions=['created_workaround', 'contacted_customer', 'escalated_to_specialist', 'checked_config', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['bug', 'authentication', 'data', 'security'], environment='development', business_impact='medium', affected_users=916, language='it', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000315', created_at=datetime.datetime(2023, 1, 23, 2, 20, 31, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 23, 2, 55, 19, tzinfo=datetime.timezone.utc), customer_id='CUST-03637', customer_tier='premium', organization_id='ORG-232', product='Analytics Dashboard', product_version='4.7.0', product_module='data_aggregator', category='Technical Issue', subcategory='Performance', priority='medium', severity='P0', channel='chat', subject='Performance degradation in Analytics Dashboard', description=\"The Analytics Dashboard has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_CONFLICT_409 in the logs. This is affecting our entire team's productivity.\", error_logs='2023-01-23T02:20:31 ERROR ERROR_CONFLICT_409: Database connection lost\\n2023-01-23T02:20:32 INFO Attempting to reconnect...\\n2023-01-23T02:20:34 ERROR Connection failed', stack_trace='ERROR: data_aggregator.service.ServiceException: Failed to process request\\n\\tat data_aggregator.handler.process(data_aggregator.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='frustrated', previous_tickets=10, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 1, 23, 2, 55, 19, tzinfo=datetime.timezone.utc), agent_id='AGENT-020', agent_actions=['viewed_logs', 'updated_documentation'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['bug', 'error', 'data'], environment='test', business_impact='critical', affected_users=19, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000316', created_at=datetime.datetime(2024, 12, 25, 1, 3, 1, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 26, 19, 13, 49, tzinfo=datetime.timezone.utc), customer_id='CUST-04247', customer_tier='enterprise', organization_id='ORG-341', product='Analytics Dashboard', product_version='4.6.8', product_module='visualization', category='Feature Request', subcategory='Enhancement', priority='medium', severity='P3', channel='portal', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=4, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 12, 26, 19, 13, 49, tzinfo=datetime.timezone.utc), agent_id='AGENT-045', agent_actions=['applied_fix', 'contacted_customer', 'consulted_kb', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=1, resolution_helpful=True, tags=['data', 'error', 'security'], environment='development', business_impact='critical', affected_users=34, language='ja', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000317', created_at=datetime.datetime(2023, 6, 29, 6, 43, 28, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 30, 8, 42, 52, tzinfo=datetime.timezone.utc), customer_id='CUST-04943', customer_tier='free', organization_id='ORG-421', product='CloudBackup Enterprise', product_version='3.6.10', product_module='compression_engine', category='Security', subcategory='Compliance', priority='high', severity='P3', channel='phone', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Getting ERROR_AUTH_401 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-06-29T06:43:28 ERROR ERROR_AUTH_401: Database connection lost\\n2023-06-29T06:43:29 INFO Attempting to reconnect...\\n2023-06-29T06:43:31 ERROR Connection failed', stack_trace='at compression_engine.execute(compression_engine.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='angry', previous_tickets=5, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 6, 30, 8, 42, 52, tzinfo=datetime.timezone.utc), agent_id='AGENT-022', agent_actions=['created_workaround', 'contacted_customer'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['bug', 'configuration', 'api', 'error', 'sync'], environment='production', business_impact='low', affected_users=310, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000318', created_at=datetime.datetime(2024, 3, 13, 3, 37, 15, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 14, 2, 1, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-04401', customer_tier='enterprise', organization_id='ORG-251', product='CloudBackup Enterprise', product_version='3.9.13', product_module='encryption_layer', category='Technical Issue', subcategory='Configuration', priority='medium', severity='P3', channel='slack', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=9, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 3, 14, 2, 1, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-029', agent_actions=['checked_config', 'applied_fix'], escalated=False, transferred_count=1, satisfaction_score=1, resolution_helpful=False, tags=['data', 'configuration', 'sync', 'error', 'database'], environment='staging', business_impact='medium', affected_users=45, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000319', created_at=datetime.datetime(2023, 8, 21, 9, 2, 22, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 21, 15, 17, 22, tzinfo=datetime.timezone.utc), customer_id='CUST-03315', customer_tier='enterprise', organization_id='ORG-186', product='DataSync Pro', product_version='3.4.14', product_module='scheduler', category='Data Issue', subcategory='Import/Export', priority='low', severity='P0', channel='api', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=0, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 8, 21, 15, 17, 22, tzinfo=datetime.timezone.utc), agent_id='AGENT-005', agent_actions=['contacted_customer', 'consulted_kb'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['sync', 'database', 'data', 'authentication'], environment='staging', business_impact='high', affected_users=36, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000320', created_at=datetime.datetime(2024, 8, 4, 13, 40, 35, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 4, 14, 14, 11, tzinfo=datetime.timezone.utc), customer_id='CUST-02154', customer_tier='premium', organization_id='ORG-482', product='API Gateway', product_version='3.2.0', product_module='rate_limiter', category='Feature Request', subcategory='New Feature', priority='medium', severity='P0', channel='phone', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-08-04T13:40:35 WARN Rate limit approaching threshold\\n2024-08-04T13:40:35 ERROR ERROR_CONFLICT_409: Rate limit exceeded\\n2024-08-04T13:40:37 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='confused', previous_tickets=7, resolution='Root cause identified as New Feature issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 8, 4, 14, 14, 11, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['updated_documentation', 'escalated_to_specialist', 'applied_fix', 'checked_config'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['sync', 'performance'], environment='staging', business_impact='low', affected_users=8, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000321', created_at=datetime.datetime(2024, 3, 9, 1, 17, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 9, 3, 26, 41, tzinfo=datetime.timezone.utc), customer_id='CUST-03922', customer_tier='premium', organization_id='ORG-251', product='CloudBackup Enterprise', product_version='2.3.10', product_module='compression_engine', category='Technical Issue', subcategory='Integration', priority='medium', severity='P0', channel='api', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_AUTH_401 in the logs. This is affecting our entire team's productivity.\", error_logs='2024-03-09T01:17:41 WARN Rate limit approaching threshold\\n2024-03-09T01:17:41 ERROR ERROR_AUTH_401: Rate limit exceeded\\n2024-03-09T01:17:43 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='neutral', previous_tickets=5, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 3, 9, 3, 26, 41, tzinfo=datetime.timezone.utc), agent_id='AGENT-027', agent_actions=['updated_documentation', 'verified_resolution', 'checked_config'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['integration', 'performance', 'sync'], environment='production', business_impact='critical', affected_users=3, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000322', created_at=datetime.datetime(2023, 10, 23, 13, 46, 26, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 24, 3, 24, 50, tzinfo=datetime.timezone.utc), customer_id='CUST-02162', customer_tier='starter', organization_id='ORG-495', product='DataSync Pro', product_version='3.3.7', product_module='scheduler', category='Feature Request', subcategory='UI/UX', priority='high', severity='P3', channel='chat', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-10-23T13:46:26 ERROR ERROR_CONNECTION_REFUSED: Connection timeout after 30s\\n2023-10-23T13:46:27 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'scheduler.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='neutral', previous_tickets=9, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 10, 24, 3, 24, 50, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['consulted_kb', 'contacted_customer', 'updated_documentation', 'verified_resolution', 'checked_config'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['security', 'api', 'data', 'bug'], environment='development', business_impact='high', affected_users=774, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000323', created_at=datetime.datetime(2024, 6, 8, 12, 33, 32, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 9, 18, 25, 8, tzinfo=datetime.timezone.utc), customer_id='CUST-04063', customer_tier='starter', organization_id='ORG-118', product='StreamProcessor', product_version='2.9.14', product_module='batch_processor', category='Data Issue', subcategory='Validation', priority='high', severity='P4', channel='phone', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=1, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 6, 9, 18, 25, 8, tzinfo=datetime.timezone.utc), agent_id='AGENT-044', agent_actions=['checked_config', 'applied_fix', 'viewed_logs', 'escalated_to_specialist', 'verified_resolution'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['sync', 'timeout', 'error', 'performance', 'database'], environment='development', business_impact='low', affected_users=546, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000324', created_at=datetime.datetime(2023, 1, 30, 18, 1, 33, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 31, 4, 36, 57, tzinfo=datetime.timezone.utc), customer_id='CUST-01868', customer_tier='enterprise', organization_id='ORG-056', product='DataSync Pro', product_version='3.1.11', product_module='data_validator', category='Feature Request', subcategory='Documentation', priority='critical', severity='P2', channel='slack', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=7, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 1, 31, 4, 36, 57, tzinfo=datetime.timezone.utc), agent_id='AGENT-022', agent_actions=['created_workaround', 'viewed_logs', 'applied_fix', 'contacted_customer'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['bug', 'configuration', 'database'], environment='development', business_impact='critical', affected_users=300, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000325', created_at=datetime.datetime(2023, 7, 5, 16, 7, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 6, 7, 45, 29, tzinfo=datetime.timezone.utc), customer_id='CUST-02385', customer_tier='professional', organization_id='ORG-339', product='API Gateway', product_version='2.7.2', product_module='auth_service', category='Technical Issue', subcategory='Integration', priority='low', severity='P3', channel='api', subject='API Gateway throwing ERROR_MEMORY_OOM during operation', description=\"We're experiencing issues with API Gateway. The system is throwing ERROR_MEMORY_OOM when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-07-05T16:07:41 ERROR ERROR_MEMORY_OOM: Database connection lost\\n2023-07-05T16:07:42 INFO Attempting to reconnect...\\n2023-07-05T16:07:44 ERROR Connection failed', stack_trace='at auth_service.execute(auth_service.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='grateful', previous_tickets=8, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 7, 6, 7, 45, 29, tzinfo=datetime.timezone.utc), agent_id='AGENT-015', agent_actions=['escalated_to_specialist', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['timeout', 'integration', 'sync'], environment='staging', business_impact='medium', affected_users=49, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000326', created_at=datetime.datetime(2023, 5, 18, 15, 29, 55, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 19, 8, 38, 19, tzinfo=datetime.timezone.utc), customer_id='CUST-04449', customer_tier='free', organization_id='ORG-228', product='DataSync Pro', product_version='3.9.1', product_module='data_validator', category='Feature Request', subcategory='New Feature', priority='medium', severity='P3', channel='api', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-05-18T15:29:55 ERROR ERROR_CORRUPTION: Database connection lost\\n2023-05-18T15:29:56 INFO Attempting to reconnect...\\n2023-05-18T15:29:58 ERROR Connection failed', stack_trace='', customer_sentiment='grateful', previous_tickets=4, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 5, 19, 8, 38, 19, tzinfo=datetime.timezone.utc), agent_id='AGENT-029', agent_actions=['verified_resolution', 'updated_documentation', 'created_workaround'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['timeout', 'performance', 'database'], environment='development', business_impact='medium', affected_users=47, language='ja', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000327', created_at=datetime.datetime(2023, 2, 15, 16, 23, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 16, 8, 2, 3, tzinfo=datetime.timezone.utc), customer_id='CUST-02026', customer_tier='professional', organization_id='ORG-202', product='CloudBackup Enterprise', product_version='3.4.6', product_module='compression_engine', category='Account Management', subcategory='Access Control', priority='critical', severity='P3', channel='phone', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=7, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 2, 16, 8, 2, 3, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['consulted_kb', 'applied_fix', 'created_workaround', 'contacted_customer', 'verified_resolution'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['api', 'configuration', 'database', 'integration'], environment='production', business_impact='medium', affected_users=153, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000328', created_at=datetime.datetime(2023, 2, 8, 14, 24, 54, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 8, 20, 32, 6, tzinfo=datetime.timezone.utc), customer_id='CUST-01964', customer_tier='starter', organization_id='ORG-428', product='CloudBackup Enterprise', product_version='3.1.2', product_module='encryption_layer', category='Account Management', subcategory='Access Control', priority='critical', severity='P2', channel='portal', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-02-08T14:24:54 DEBUG Processing request ID-12345\\n2023-02-08T14:24:54 ERROR ERROR_CONNECTION_REFUSED: Invalid request format\\n2023-02-08T14:24:55 INFO Request rejected', stack_trace='', customer_sentiment='angry', previous_tickets=3, resolution='Applied hotfix version 3.2.2 to address the ERROR_CONNECTION_REFUSED. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 2, 8, 20, 32, 6, tzinfo=datetime.timezone.utc), agent_id='AGENT-005', agent_actions=['consulted_kb', 'viewed_logs', 'ran_diagnostics', 'contacted_customer', 'verified_resolution'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=True, tags=['error', 'integration', 'security', 'performance', 'sync'], environment='production', business_impact='low', affected_users=713, language='pt', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000329', created_at=datetime.datetime(2023, 12, 24, 10, 36, 57, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 25, 5, 8, 45, tzinfo=datetime.timezone.utc), customer_id='CUST-03566', customer_tier='enterprise', organization_id='ORG-034', product='API Gateway', product_version='2.9.9', product_module='auth_service', category='Account Management', subcategory='Subscription', priority='critical', severity='P4', channel='portal', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-12-24T10:36:57 ERROR ERROR_MEMORY_OOM: Database connection lost\\n2023-12-24T10:36:58 INFO Attempting to reconnect...\\n2023-12-24T10:37:00 ERROR Connection failed', stack_trace='at auth_service.execute(auth_service.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='angry', previous_tickets=10, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 12, 25, 5, 8, 45, tzinfo=datetime.timezone.utc), agent_id='AGENT-009', agent_actions=['created_workaround', 'escalated_to_specialist', 'ran_diagnostics', 'verified_resolution', 'contacted_customer'], escalated=True, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['error', 'api', 'sync'], environment='sandbox', business_impact='medium', affected_users=584, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000330', created_at=datetime.datetime(2024, 11, 15, 22, 31, 54, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 16, 3, 23, 30, tzinfo=datetime.timezone.utc), customer_id='CUST-03226', customer_tier='professional', organization_id='ORG-119', product='API Gateway', product_version='2.2.0', product_module='auth_service', category='Data Issue', subcategory='Import/Export', priority='critical', severity='P1', channel='chat', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 11, 16, 3, 23, 30, tzinfo=datetime.timezone.utc), agent_id='AGENT-035', agent_actions=['viewed_logs', 'created_workaround', 'consulted_kb', 'updated_documentation'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=False, tags=['api', 'sync', 'bug', 'security', 'error'], environment='production', business_impact='critical', affected_users=834, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000331', created_at=datetime.datetime(2024, 12, 5, 10, 24, 4, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 6, 15, 45, 4, tzinfo=datetime.timezone.utc), customer_id='CUST-00430', customer_tier='premium', organization_id='ORG-017', product='CloudBackup Enterprise', product_version='2.7.15', product_module='restore_module', category='Feature Request', subcategory='Documentation', priority='medium', severity='P3', channel='portal', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-12-05T10:24:04 DEBUG Processing request ID-12345\\n2024-12-05T10:24:04 ERROR ERROR_DISK_FULL: Invalid request format\\n2024-12-05T10:24:05 INFO Request rejected', stack_trace='at restore_module.execute(restore_module.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='angry', previous_tickets=10, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 12, 6, 15, 45, 4, tzinfo=datetime.timezone.utc), agent_id='AGENT-020', agent_actions=['escalated_to_specialist', 'updated_documentation', 'consulted_kb', 'checked_config'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['database', 'bug', 'configuration'], environment='sandbox', business_impact='high', affected_users=12, language='it', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000332', created_at=datetime.datetime(2024, 4, 12, 21, 57, 10, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 13, 4, 48, 10, tzinfo=datetime.timezone.utc), customer_id='CUST-01156', customer_tier='enterprise', organization_id='ORG-027', product='Analytics Dashboard', product_version='4.3.3', product_module='visualization', category='Feature Request', subcategory='UI/UX', priority='high', severity='P1', channel='phone', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=3, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 4, 13, 4, 48, 10, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['checked_config', 'updated_documentation', 'ran_diagnostics'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['performance', 'configuration'], environment='test', business_impact='low', affected_users=425, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000333', created_at=datetime.datetime(2024, 7, 20, 7, 51, 25, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 21, 3, 22, 1, tzinfo=datetime.timezone.utc), customer_id='CUST-04897', customer_tier='free', organization_id='ORG-014', product='StreamProcessor', product_version='2.3.0', product_module='event_handler', category='Security', subcategory='Encryption', priority='medium', severity='P3', channel='email', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Getting ERROR_CORRUPTION errors. We need to ensure our system meets compliance requirements.', error_logs='2024-07-20T07:51:25 ERROR ERROR_CORRUPTION: Database connection lost\\n2024-07-20T07:51:26 INFO Attempting to reconnect...\\n2024-07-20T07:51:28 ERROR Connection failed', stack_trace='Stack trace:\\n  event_handler::processData() at event_handler.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='satisfied', previous_tickets=4, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 7, 21, 3, 22, 1, tzinfo=datetime.timezone.utc), agent_id='AGENT-037', agent_actions=['created_workaround', 'viewed_logs', 'contacted_customer', 'verified_resolution', 'consulted_kb'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['bug', 'error', 'authentication', 'performance', 'data'], environment='staging', business_impact='high', affected_users=35, language='pt', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000334', created_at=datetime.datetime(2024, 6, 24, 20, 11, 34, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 24, 20, 57, 46, tzinfo=datetime.timezone.utc), customer_id='CUST-03074', customer_tier='starter', organization_id='ORG-014', product='CloudBackup Enterprise', product_version='2.4.1', product_module='restore_module', category='Account Management', subcategory='Upgrade', priority='critical', severity='P0', channel='portal', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=7, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 6, 24, 20, 57, 46, tzinfo=datetime.timezone.utc), agent_id='AGENT-012', agent_actions=['applied_fix', 'verified_resolution', 'checked_config'], escalated=True, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['configuration', 'timeout'], environment='development', business_impact='medium', affected_users=135, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000335', created_at=datetime.datetime(2023, 2, 4, 19, 36, 52, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 6, 23, 55, 28, tzinfo=datetime.timezone.utc), customer_id='CUST-04132', customer_tier='starter', organization_id='ORG-312', product='StreamProcessor', product_version='3.6.3', product_module='batch_processor', category='Feature Request', subcategory='Enhancement', priority='medium', severity='P3', channel='chat', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-02-04T19:36:52 ERROR ERROR_TIMEOUT_429: Connection timeout after 30s\\n2023-02-04T19:36:53 RETRY_FAILED: Max retries exceeded', stack_trace='Stack trace:\\n  batch_processor::processData() at batch_processor.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='angry', previous_tickets=9, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 2, 6, 23, 55, 28, tzinfo=datetime.timezone.utc), agent_id='AGENT-013', agent_actions=['ran_diagnostics', 'viewed_logs', 'contacted_customer', 'checked_config'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['sync', 'bug', 'database'], environment='test', business_impact='critical', affected_users=46, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000336', created_at=datetime.datetime(2023, 9, 20, 2, 15, 59, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 20, 19, 12, 59, tzinfo=datetime.timezone.utc), customer_id='CUST-04535', customer_tier='starter', organization_id='ORG-111', product='StreamProcessor', product_version='4.8.9', product_module='monitoring', category='Technical Issue', subcategory='Performance', priority='high', severity='P4', channel='phone', subject='StreamProcessor throwing errors during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=6, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 9, 20, 19, 12, 59, tzinfo=datetime.timezone.utc), agent_id='AGENT-044', agent_actions=['verified_resolution', 'applied_fix', 'consulted_kb', 'ran_diagnostics'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['authentication', 'error'], environment='production', business_impact='low', affected_users=192, language='es', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000337', created_at=datetime.datetime(2024, 1, 22, 1, 35, 52, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 22, 15, 3, 28, tzinfo=datetime.timezone.utc), customer_id='CUST-00008', customer_tier='professional', organization_id='ORG-475', product='API Gateway', product_version='2.1.10', product_module='cache_layer', category='Feature Request', subcategory='Enhancement', priority='low', severity='P2', channel='phone', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=4, resolution='Root cause identified as Enhancement issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 1, 22, 15, 3, 28, tzinfo=datetime.timezone.utc), agent_id='AGENT-050', agent_actions=['updated_documentation', 'escalated_to_specialist', 'applied_fix'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['timeout', 'error'], environment='test', business_impact='critical', affected_users=15, language='de', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000338', created_at=datetime.datetime(2024, 5, 7, 13, 39, 58, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 7, 19, 29, 10, tzinfo=datetime.timezone.utc), customer_id='CUST-00122', customer_tier='premium', organization_id='ORG-453', product='Analytics Dashboard', product_version='3.3.6', product_module='visualization', category='Account Management', subcategory='License', priority='low', severity='P1', channel='chat', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=9, resolution='Root cause identified as License issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 5, 7, 19, 29, 10, tzinfo=datetime.timezone.utc), agent_id='AGENT-040', agent_actions=['applied_fix', 'checked_config'], escalated=True, transferred_count=0, satisfaction_score=2, resolution_helpful=True, tags=['data', 'security', 'configuration', 'sync', 'database'], environment='sandbox', business_impact='low', affected_users=41, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000339', created_at=datetime.datetime(2024, 6, 25, 17, 23, 35, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 25, 20, 3, 11, tzinfo=datetime.timezone.utc), customer_id='CUST-01341', customer_tier='starter', organization_id='ORG-138', product='CloudBackup Enterprise', product_version='3.1.13', product_module='restore_module', category='Account Management', subcategory='License', priority='critical', severity='P0', channel='slack', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-06-25T17:23:35 ERROR ERROR_NOTFOUND_404: Connection timeout after 30s\\n2024-06-25T17:23:36 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'restore_module.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='neutral', previous_tickets=4, resolution='Applied hotfix version 3.2.2 to address the ERROR_NOTFOUND_404. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 6, 25, 20, 3, 11, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['ran_diagnostics', 'contacted_customer', 'created_workaround'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['security', 'data', 'database'], environment='production', business_impact='high', affected_users=112, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000340', created_at=datetime.datetime(2024, 6, 22, 5, 5, 8, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 23, 1, 3, 20, tzinfo=datetime.timezone.utc), customer_id='CUST-02365', customer_tier='starter', organization_id='ORG-405', product='API Gateway', product_version='3.9.14', product_module='request_router', category='Data Issue', subcategory='Corruption', priority='critical', severity='P4', channel='portal', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_AUTH_401 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-06-22T05:05:08 ERROR ERROR_AUTH_401: Database connection lost\\n2024-06-22T05:05:09 INFO Attempting to reconnect...\\n2024-06-22T05:05:11 ERROR Connection failed', stack_trace='', customer_sentiment='grateful', previous_tickets=8, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 6, 23, 1, 3, 20, tzinfo=datetime.timezone.utc), agent_id='AGENT-010', agent_actions=['ran_diagnostics', 'checked_config', 'updated_documentation', 'consulted_kb'], escalated=True, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['api', 'data'], environment='production', business_impact='critical', affected_users=516, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000341', created_at=datetime.datetime(2023, 2, 25, 17, 1, 26, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 27, 16, 18, 50, tzinfo=datetime.timezone.utc), customer_id='CUST-02181', customer_tier='enterprise', organization_id='ORG-274', product='DataSync Pro', product_version='2.7.10', product_module='api_connector', category='Feature Request', subcategory='UI/UX', priority='critical', severity='P4', channel='portal', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-02-25T17:01:26 WARN Rate limit approaching threshold\\n2023-02-25T17:01:26 ERROR ERROR_VALIDATION: Rate limit exceeded\\n2023-02-25T17:01:28 INFO Backing off for 60 seconds', stack_trace='at api_connector.execute(api_connector.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='neutral', previous_tickets=5, resolution='Root cause identified as UI/UX issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 2, 27, 16, 18, 50, tzinfo=datetime.timezone.utc), agent_id='AGENT-034', agent_actions=['viewed_logs', 'verified_resolution', 'consulted_kb'], escalated=True, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['timeout', 'authentication'], environment='production', business_impact='high', affected_users=142, language='de', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000342', created_at=datetime.datetime(2023, 9, 21, 17, 31, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 23, 21, 30, 25, tzinfo=datetime.timezone.utc), customer_id='CUST-02377', customer_tier='free', organization_id='ORG-236', product='DataSync Pro', product_version='3.6.3', product_module='sync_engine', category='Account Management', subcategory='Access Control', priority='low', severity='P4', channel='slack', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-09-21T17:31:37 DEBUG Processing request ID-12345\\n2023-09-21T17:31:37 ERROR ERROR_VALIDATION: Invalid request format\\n2023-09-21T17:31:38 INFO Request rejected', stack_trace='', customer_sentiment='confused', previous_tickets=1, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 9, 23, 21, 30, 25, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['verified_resolution', 'created_workaround'], escalated=True, transferred_count=2, satisfaction_score=4, resolution_helpful=False, tags=['api', 'sync', 'error'], environment='test', business_impact='medium', affected_users=19, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000343', created_at=datetime.datetime(2023, 8, 8, 0, 27, 2, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 8, 9, 33, 2, tzinfo=datetime.timezone.utc), customer_id='CUST-03821', customer_tier='free', organization_id='ORG-270', product='CloudBackup Enterprise', product_version='2.0.3', product_module='backup_service', category='Feature Request', subcategory='UI/UX', priority='medium', severity='P1', channel='api', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-08-08T00:27:02 DEBUG Processing request ID-12345\\n2023-08-08T00:27:02 ERROR ERROR_DEADLOCK: Invalid request format\\n2023-08-08T00:27:03 INFO Request rejected', stack_trace='Stack trace:\\n  backup_service::processData() at backup_service.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='confused', previous_tickets=9, resolution='Root cause identified as UI/UX issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 8, 8, 9, 33, 2, tzinfo=datetime.timezone.utc), agent_id='AGENT-045', agent_actions=['viewed_logs', 'contacted_customer', 'consulted_kb', 'verified_resolution', 'updated_documentation'], escalated=True, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'integration', 'performance'], environment='sandbox', business_impact='critical', affected_users=36, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000344', created_at=datetime.datetime(2024, 10, 16, 10, 40, 3, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 20, 2, 19, 3, tzinfo=datetime.timezone.utc), customer_id='CUST-02424', customer_tier='enterprise', organization_id='ORG-309', product='CloudBackup Enterprise', product_version='3.9.13', product_module='backup_service', category='Data Issue', subcategory='Validation', priority='high', severity='P4', channel='phone', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_PARSING appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-10-16T10:40:03 DEBUG Processing request ID-12345\\n2024-10-16T10:40:03 ERROR ERROR_PARSING: Invalid request format\\n2024-10-16T10:40:04 INFO Request rejected', stack_trace='Stack trace:\\n  backup_service::processData() at backup_service.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='satisfied', previous_tickets=8, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 10, 20, 2, 19, 3, tzinfo=datetime.timezone.utc), agent_id='AGENT-020', agent_actions=['verified_resolution', 'contacted_customer'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['configuration', 'performance', 'database', 'api'], environment='development', business_impact='critical', affected_users=52, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000345', created_at=datetime.datetime(2023, 1, 28, 1, 26, 18, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 28, 2, 13, 42, tzinfo=datetime.timezone.utc), customer_id='CUST-01249', customer_tier='premium', organization_id='ORG-373', product='StreamProcessor', product_version='2.9.6', product_module='event_handler', category='Data Issue', subcategory='Corruption', priority='critical', severity='P0', channel='slack', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_PERMISSION_403 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-01-28T01:26:18 ERROR ERROR_PERMISSION_403: Database connection lost\\n2023-01-28T01:26:19 INFO Attempting to reconnect...\\n2023-01-28T01:26:21 ERROR Connection failed', stack_trace='at event_handler.execute(event_handler.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='grateful', previous_tickets=5, resolution='Root cause identified as Corruption issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 1, 28, 2, 13, 42, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['contacted_customer', 'ran_diagnostics'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['api', 'database', 'integration', 'sync'], environment='development', business_impact='high', affected_users=927, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000346', created_at=datetime.datetime(2023, 1, 25, 12, 16, 52, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 25, 12, 49, 52, tzinfo=datetime.timezone.utc), customer_id='CUST-01641', customer_tier='free', organization_id='ORG-096', product='Analytics Dashboard', product_version='3.6.10', product_module='data_aggregator', category='Account Management', subcategory='License', priority='critical', severity='P0', channel='api', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-01-25T12:16:52 WARN Rate limit approaching threshold\\n2023-01-25T12:16:52 ERROR ERROR_SSL_CERT: Rate limit exceeded\\n2023-01-25T12:16:54 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='angry', previous_tickets=5, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 1, 25, 12, 49, 52, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['escalated_to_specialist', 'consulted_kb', 'checked_config', 'applied_fix', 'contacted_customer'], escalated=True, transferred_count=0, satisfaction_score=1, resolution_helpful=True, tags=['api', 'error'], environment='test', business_impact='medium', affected_users=983, language='de', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000347', created_at=datetime.datetime(2023, 10, 20, 4, 0, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 22, 6, 40, 14, tzinfo=datetime.timezone.utc), customer_id='CUST-00316', customer_tier='free', organization_id='ORG-068', product='DataSync Pro', product_version='3.0.3', product_module='sync_engine', category='Feature Request', subcategory='Enhancement', priority='medium', severity='P4', channel='slack', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-10-20T04:00:38 DEBUG Processing request ID-12345\\n2023-10-20T04:00:38 ERROR ERROR_PARSING: Invalid request format\\n2023-10-20T04:00:39 INFO Request rejected', stack_trace='', customer_sentiment='angry', previous_tickets=1, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 10, 22, 6, 40, 14, tzinfo=datetime.timezone.utc), agent_id='AGENT-035', agent_actions=['consulted_kb', 'contacted_customer'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['api', 'security'], environment='test', business_impact='low', affected_users=45, language='pt', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000348', created_at=datetime.datetime(2023, 2, 28, 19, 2, 58, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 2, 23, 31, 46, tzinfo=datetime.timezone.utc), customer_id='CUST-02720', customer_tier='free', organization_id='ORG-440', product='DataSync Pro', product_version='2.4.5', product_module='data_validator', category='Security', subcategory='Encryption', priority='medium', severity='P4', channel='slack', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_DISK_FULL errors. We need to ensure our system meets compliance requirements.', error_logs='2023-02-28T19:02:58 ERROR ERROR_DISK_FULL: Database connection lost\\n2023-02-28T19:02:59 INFO Attempting to reconnect...\\n2023-02-28T19:03:01 ERROR Connection failed', stack_trace=\"Traceback (most recent call last):\\n  File 'data_validator.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='frustrated', previous_tickets=4, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 3, 2, 23, 31, 46, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['applied_fix', 'viewed_logs', 'checked_config', 'consulted_kb'], escalated=True, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['sync', 'security', 'authentication', 'timeout', 'data'], environment='sandbox', business_impact='low', affected_users=19, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000349', created_at=datetime.datetime(2024, 9, 17, 8, 9, 36, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 17, 23, 3, tzinfo=datetime.timezone.utc), customer_id='CUST-01798', customer_tier='starter', organization_id='ORG-037', product='DataSync Pro', product_version='4.7.4', product_module='sync_engine', category='Data Issue', subcategory='Corruption', priority='high', severity='P2', channel='email', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_AUTH_401 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-09-17T08:09:36 WARN Rate limit approaching threshold\\n2024-09-17T08:09:36 ERROR ERROR_AUTH_401: Rate limit exceeded\\n2024-09-17T08:09:38 INFO Backing off for 60 seconds', stack_trace='at sync_engine.execute(sync_engine.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='angry', previous_tickets=0, resolution='Applied hotfix version 3.2.2 to address the ERROR_AUTH_401. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 9, 17, 23, 3, tzinfo=datetime.timezone.utc), agent_id='AGENT-012', agent_actions=['escalated_to_specialist', 'checked_config', 'ran_diagnostics', 'applied_fix', 'created_workaround', 'consulted_kb'], escalated=True, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['api', 'integration'], environment='staging', business_impact='medium', affected_users=14, language='es', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000350', created_at=datetime.datetime(2024, 10, 10, 2, 12, 23, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 10, 15, 30, 59, tzinfo=datetime.timezone.utc), customer_id='CUST-04503', customer_tier='premium', organization_id='ORG-299', product='CloudBackup Enterprise', product_version='3.7.13', product_module='backup_service', category='Security', subcategory='Authentication', priority='high', severity='P3', channel='phone', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Getting ERROR_MEMORY_OOM errors. We need to ensure our system meets compliance requirements.', error_logs='2024-10-10T02:12:23 WARN Rate limit approaching threshold\\n2024-10-10T02:12:23 ERROR ERROR_MEMORY_OOM: Rate limit exceeded\\n2024-10-10T02:12:25 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='grateful', previous_tickets=7, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 10, 10, 15, 30, 59, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['escalated_to_specialist', 'ran_diagnostics'], escalated=True, transferred_count=0, satisfaction_score=1, resolution_helpful=True, tags=['data', 'security', 'timeout', 'error', 'configuration'], environment='test', business_impact='low', affected_users=883, language='zh', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000351', created_at=datetime.datetime(2024, 5, 18, 20, 15, 42, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 19, 1, 37, 54, tzinfo=datetime.timezone.utc), customer_id='CUST-03773', customer_tier='starter', organization_id='ORG-499', product='Analytics Dashboard', product_version='4.7.13', product_module='data_aggregator', category='Security', subcategory='Vulnerability', priority='low', severity='P0', channel='api', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_DISK_FULL errors. We need to ensure our system meets compliance requirements.', error_logs='2024-05-18T20:15:42 WARN Rate limit approaching threshold\\n2024-05-18T20:15:42 ERROR ERROR_DISK_FULL: Rate limit exceeded\\n2024-05-18T20:15:44 INFO Backing off for 60 seconds', stack_trace='at data_aggregator.execute(data_aggregator.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='frustrated', previous_tickets=3, resolution='Applied hotfix version 3.2.2 to address the ERROR_DISK_FULL. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 5, 19, 1, 37, 54, tzinfo=datetime.timezone.utc), agent_id='AGENT-041', agent_actions=['created_workaround', 'updated_documentation'], escalated=True, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['bug', 'sync'], environment='staging', business_impact='critical', affected_users=38, language='zh', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000352', created_at=datetime.datetime(2023, 11, 22, 11, 12, 25, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 22, 15, 59, 49, tzinfo=datetime.timezone.utc), customer_id='CUST-01651', customer_tier='enterprise', organization_id='ORG-426', product='StreamProcessor', product_version='2.9.0', product_module='event_handler', category='Account Management', subcategory='Billing', priority='critical', severity='P2', channel='api', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-11-22T11:12:25 DEBUG Processing request ID-12345\\n2023-11-22T11:12:25 ERROR ERROR_TIMEOUT_429: Invalid request format\\n2023-11-22T11:12:26 INFO Request rejected', stack_trace='Stack trace:\\n  event_handler::processData() at event_handler.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='frustrated', previous_tickets=3, resolution='Root cause identified as Billing issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 11, 22, 15, 59, 49, tzinfo=datetime.timezone.utc), agent_id='AGENT-006', agent_actions=['contacted_customer', 'updated_documentation'], escalated=True, transferred_count=1, satisfaction_score=2, resolution_helpful=True, tags=['bug', 'performance', 'configuration'], environment='test', business_impact='low', affected_users=925, language='de', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000353', created_at=datetime.datetime(2024, 4, 9, 4, 10, 29, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 10, 20, 18, 53, tzinfo=datetime.timezone.utc), customer_id='CUST-03347', customer_tier='professional', organization_id='ORG-436', product='Analytics Dashboard', product_version='3.8.9', product_module='data_aggregator', category='Feature Request', subcategory='New Feature', priority='medium', severity='P3', channel='chat', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=3, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 4, 10, 20, 18, 53, tzinfo=datetime.timezone.utc), agent_id='AGENT-048', agent_actions=['applied_fix', 'viewed_logs', 'consulted_kb', 'checked_config', 'escalated_to_specialist'], escalated=True, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['authentication', 'configuration', 'database', 'data', 'bug'], environment='test', business_impact='critical', affected_users=41, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000354', created_at=datetime.datetime(2024, 11, 19, 7, 33, 25, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 19, 13, 18, 25, tzinfo=datetime.timezone.utc), customer_id='CUST-02798', customer_tier='premium', organization_id='ORG-425', product='CloudBackup Enterprise', product_version='3.0.5', product_module='restore_module', category='Security', subcategory='Compliance', priority='low', severity='P1', channel='chat', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Getting ERROR_NOTFOUND_404 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-11-19T07:33:25 ERROR ERROR_NOTFOUND_404: Database connection lost\\n2024-11-19T07:33:26 INFO Attempting to reconnect...\\n2024-11-19T07:33:28 ERROR Connection failed', stack_trace='', customer_sentiment='neutral', previous_tickets=1, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 11, 19, 13, 18, 25, tzinfo=datetime.timezone.utc), agent_id='AGENT-029', agent_actions=['updated_documentation', 'verified_resolution', 'viewed_logs', 'contacted_customer', 'applied_fix'], escalated=True, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['sync', 'data'], environment='development', business_impact='high', affected_users=30, language='de', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000355', created_at=datetime.datetime(2024, 6, 2, 15, 32, 47, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 4, 0, 30, 59, tzinfo=datetime.timezone.utc), customer_id='CUST-04710', customer_tier='free', organization_id='ORG-224', product='DataSync Pro', product_version='2.8.2', product_module='scheduler', category='Data Issue', subcategory='Corruption', priority='medium', severity='P3', channel='api', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=0, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 6, 4, 0, 30, 59, tzinfo=datetime.timezone.utc), agent_id='AGENT-027', agent_actions=['consulted_kb', 'contacted_customer', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['timeout', 'authentication'], environment='development', business_impact='high', affected_users=25, language='pt', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000356', created_at=datetime.datetime(2024, 10, 3, 17, 19, 44, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 4, 23, 30, 32, tzinfo=datetime.timezone.utc), customer_id='CUST-02851', customer_tier='premium', organization_id='ORG-464', product='API Gateway', product_version='3.6.11', product_module='auth_service', category='Data Issue', subcategory='Data Loss', priority='critical', severity='P4', channel='phone', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_MEMORY_OOM appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-10-03T17:19:44 ERROR ERROR_MEMORY_OOM: Database connection lost\\n2024-10-03T17:19:45 INFO Attempting to reconnect...\\n2024-10-03T17:19:47 ERROR Connection failed', stack_trace='', customer_sentiment='confused', previous_tickets=5, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 10, 4, 23, 30, 32, tzinfo=datetime.timezone.utc), agent_id='AGENT-027', agent_actions=['contacted_customer', 'applied_fix', 'created_workaround', 'checked_config'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=True, tags=['security', 'bug', 'api', 'sync', 'timeout'], environment='development', business_impact='low', affected_users=366, language='pt', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000357', created_at=datetime.datetime(2023, 12, 1, 8, 13, 26, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 2, 21, 12, 14, tzinfo=datetime.timezone.utc), customer_id='CUST-00210', customer_tier='professional', organization_id='ORG-397', product='CloudBackup Enterprise', product_version='2.5.10', product_module='compression_engine', category='Feature Request', subcategory='Enhancement', priority='low', severity='P3', channel='slack', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-12-01T08:13:26 ERROR ERROR_DEADLOCK: Database connection lost\\n2023-12-01T08:13:27 INFO Attempting to reconnect...\\n2023-12-01T08:13:29 ERROR Connection failed', stack_trace='', customer_sentiment='satisfied', previous_tickets=5, resolution='Root cause identified as Enhancement issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 12, 2, 21, 12, 14, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['checked_config', 'created_workaround', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['api', 'database', 'performance'], environment='test', business_impact='low', affected_users=20, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000358', created_at=datetime.datetime(2023, 4, 30, 18, 38, 49, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 1, 23, 57, 25, tzinfo=datetime.timezone.utc), customer_id='CUST-02460', customer_tier='premium', organization_id='ORG-095', product='Analytics Dashboard', product_version='2.4.5', product_module='visualization', category='Security', subcategory='Compliance', priority='medium', severity='P3', channel='api', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_SSL_CERT errors. We need to ensure our system meets compliance requirements.', error_logs='2023-04-30T18:38:49 ERROR ERROR_SSL_CERT: Database connection lost\\n2023-04-30T18:38:50 INFO Attempting to reconnect...\\n2023-04-30T18:38:52 ERROR Connection failed', stack_trace='at visualization.execute(visualization.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='satisfied', previous_tickets=3, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 5, 1, 23, 57, 25, tzinfo=datetime.timezone.utc), agent_id='AGENT-048', agent_actions=['created_workaround', 'consulted_kb', 'verified_resolution', 'applied_fix'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=False, tags=['api', 'data', 'configuration'], environment='development', business_impact='low', affected_users=26, language='pt', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000359', created_at=datetime.datetime(2024, 12, 5, 7, 31, 20, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 5, 10, 1, 20, tzinfo=datetime.timezone.utc), customer_id='CUST-02945', customer_tier='professional', organization_id='ORG-169', product='Analytics Dashboard', product_version='4.6.14', product_module='report_builder', category='Technical Issue', subcategory='Compatibility', priority='critical', severity='P1', channel='email', subject='Performance degradation in Analytics Dashboard', description=\"The Analytics Dashboard has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_CONFLICT_409 in the logs. This is affecting our entire team's productivity.\", error_logs='2024-12-05T07:31:20 DEBUG Processing request ID-12345\\n2024-12-05T07:31:20 ERROR ERROR_CONFLICT_409: Invalid request format\\n2024-12-05T07:31:21 INFO Request rejected', stack_trace='at report_builder.execute(report_builder.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='angry', previous_tickets=6, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 12, 5, 10, 1, 20, tzinfo=datetime.timezone.utc), agent_id='AGENT-013', agent_actions=['consulted_kb', 'verified_resolution'], escalated=True, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['configuration', 'sync', 'api'], environment='test', business_impact='medium', affected_users=808, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000360', created_at=datetime.datetime(2024, 8, 2, 12, 54, 6, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 2, 23, 21, 6, tzinfo=datetime.timezone.utc), customer_id='CUST-02404', customer_tier='free', organization_id='ORG-057', product='DataSync Pro', product_version='3.5.11', product_module='sync_engine', category='Account Management', subcategory='Billing', priority='high', severity='P2', channel='phone', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=0, resolution='Root cause identified as Billing issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 8, 2, 23, 21, 6, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['updated_documentation', 'verified_resolution', 'ran_diagnostics'], escalated=False, transferred_count=0, satisfaction_score=1, resolution_helpful=True, tags=['error', 'api', 'sync', 'performance', 'timeout'], environment='sandbox', business_impact='low', affected_users=89, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000361', created_at=datetime.datetime(2023, 2, 1, 6, 40, 57, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 4, 7, 48, 45, tzinfo=datetime.timezone.utc), customer_id='CUST-00131', customer_tier='starter', organization_id='ORG-404', product='DataSync Pro', product_version='4.5.15', product_module='data_validator', category='Data Issue', subcategory='Sync Error', priority='low', severity='P3', channel='api', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_CORRUPTION appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-02-01T06:40:57 DEBUG Processing request ID-12345\\n2023-02-01T06:40:57 ERROR ERROR_CORRUPTION: Invalid request format\\n2023-02-01T06:40:58 INFO Request rejected', stack_trace='', customer_sentiment='frustrated', previous_tickets=4, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 2, 4, 7, 48, 45, tzinfo=datetime.timezone.utc), agent_id='AGENT-033', agent_actions=['checked_config', 'escalated_to_specialist', 'created_workaround'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=False, tags=['data', 'performance', 'timeout', 'sync'], environment='staging', business_impact='low', affected_users=43, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000362', created_at=datetime.datetime(2024, 3, 8, 15, 41, 56, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 10, 8, 12, 32, tzinfo=datetime.timezone.utc), customer_id='CUST-02354', customer_tier='free', organization_id='ORG-194', product='StreamProcessor', product_version='3.4.9', product_module='event_handler', category='Feature Request', subcategory='API', priority='critical', severity='P4', channel='portal', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-03-08T15:41:56 WARN Rate limit approaching threshold\\n2024-03-08T15:41:56 ERROR ERROR_PERMISSION_403: Rate limit exceeded\\n2024-03-08T15:41:58 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'event_handler.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='grateful', previous_tickets=4, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 3, 10, 8, 12, 32, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['created_workaround', 'applied_fix'], escalated=False, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['authentication', 'api', 'security', 'sync'], environment='development', business_impact='high', affected_users=905, language='ja', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000363', created_at=datetime.datetime(2024, 12, 29, 7, 22, 11, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 29, 8, 21, 35, tzinfo=datetime.timezone.utc), customer_id='CUST-04792', customer_tier='professional', organization_id='ORG-476', product='StreamProcessor', product_version='3.3.6', product_module='event_handler', category='Feature Request', subcategory='New Feature', priority='critical', severity='P0', channel='email', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-12-29T07:22:11 ERROR ERROR_VALIDATION: Connection timeout after 30s\\n2024-12-29T07:22:12 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='angry', previous_tickets=5, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 12, 29, 8, 21, 35, tzinfo=datetime.timezone.utc), agent_id='AGENT-023', agent_actions=['applied_fix', 'updated_documentation', 'verified_resolution', 'escalated_to_specialist'], escalated=True, transferred_count=3, satisfaction_score=2, resolution_helpful=True, tags=['security', 'integration', 'data', 'sync', 'bug'], environment='development', business_impact='low', affected_users=810, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000364', created_at=datetime.datetime(2024, 8, 31, 6, 42, 33, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 2, 17, 8, 21, tzinfo=datetime.timezone.utc), customer_id='CUST-03593', customer_tier='professional', organization_id='ORG-307', product='StreamProcessor', product_version='4.9.14', product_module='monitoring', category='Account Management', subcategory='Subscription', priority='low', severity='P3', channel='api', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-08-31T06:42:33 DEBUG Processing request ID-12345\\n2024-08-31T06:42:33 ERROR ERROR_SERVER_500: Invalid request format\\n2024-08-31T06:42:34 INFO Request rejected', stack_trace='', customer_sentiment='frustrated', previous_tickets=9, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 9, 2, 17, 8, 21, tzinfo=datetime.timezone.utc), agent_id='AGENT-010', agent_actions=['consulted_kb', 'verified_resolution', 'ran_diagnostics', 'viewed_logs'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['sync', 'data'], environment='development', business_impact='low', affected_users=28, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000365', created_at=datetime.datetime(2023, 11, 26, 0, 35, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 26, 4, 15, 17, tzinfo=datetime.timezone.utc), customer_id='CUST-03982', customer_tier='professional', organization_id='ORG-278', product='Analytics Dashboard', product_version='4.4.12', product_module='export_module', category='Data Issue', subcategory='Data Loss', priority='critical', severity='P1', channel='portal', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_SSL_CERT appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-11-26T00:35:41 DEBUG Processing request ID-12345\\n2023-11-26T00:35:41 ERROR ERROR_SSL_CERT: Invalid request format\\n2023-11-26T00:35:42 INFO Request rejected', stack_trace='', customer_sentiment='frustrated', previous_tickets=7, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 11, 26, 4, 15, 17, tzinfo=datetime.timezone.utc), agent_id='AGENT-005', agent_actions=['updated_documentation', 'consulted_kb', 'viewed_logs'], escalated=True, transferred_count=3, satisfaction_score=3, resolution_helpful=False, tags=['performance', 'database', 'timeout', 'configuration'], environment='sandbox', business_impact='critical', affected_users=98, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000366', created_at=datetime.datetime(2024, 5, 7, 15, 21, 7, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 12, 22, 19, 19, tzinfo=datetime.timezone.utc), customer_id='CUST-01802', customer_tier='enterprise', organization_id='ORG-342', product='StreamProcessor', product_version='3.2.1', product_module='error_handler', category='Data Issue', subcategory='Data Loss', priority='low', severity='P4', channel='portal', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_CONNECTION_REFUSED appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-05-07T15:21:07 DEBUG Processing request ID-12345\\n2024-05-07T15:21:07 ERROR ERROR_CONNECTION_REFUSED: Invalid request format\\n2024-05-07T15:21:08 INFO Request rejected', stack_trace=\"Traceback (most recent call last):\\n  File 'error_handler.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='angry', previous_tickets=5, resolution='Root cause identified as Data Loss issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 5, 12, 22, 19, 19, tzinfo=datetime.timezone.utc), agent_id='AGENT-041', agent_actions=['ran_diagnostics', 'viewed_logs', 'updated_documentation', 'consulted_kb', 'created_workaround', 'applied_fix'], escalated=True, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['authentication', 'integration', 'configuration', 'database'], environment='production', business_impact='low', affected_users=46, language='it', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000367', created_at=datetime.datetime(2024, 9, 29, 6, 48, 46, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 1, 15, 37, 22, tzinfo=datetime.timezone.utc), customer_id='CUST-03283', customer_tier='free', organization_id='ORG-169', product='CloudBackup Enterprise', product_version='4.4.5', product_module='compression_engine', category='Security', subcategory='Authentication', priority='critical', severity='P4', channel='phone', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=3, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 10, 1, 15, 37, 22, tzinfo=datetime.timezone.utc), agent_id='AGENT-036', agent_actions=['ran_diagnostics', 'escalated_to_specialist', 'viewed_logs'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['timeout', 'sync', 'database'], environment='sandbox', business_impact='high', affected_users=843, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000368', created_at=datetime.datetime(2024, 1, 21, 23, 4, 43, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 22, 1, 14, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-02159', customer_tier='enterprise', organization_id='ORG-131', product='DataSync Pro', product_version='4.7.9', product_module='data_validator', category='Technical Issue', subcategory='Compatibility', priority='low', severity='P0', channel='chat', subject='Performance degradation in DataSync Pro', description=\"The DataSync Pro has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=5, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 1, 22, 1, 14, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-010', agent_actions=['consulted_kb', 'verified_resolution', 'viewed_logs'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['api', 'bug'], environment='staging', business_impact='high', affected_users=46, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000369', created_at=datetime.datetime(2023, 3, 23, 15, 0, 22, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 24, 13, 54, 58, tzinfo=datetime.timezone.utc), customer_id='CUST-00940', customer_tier='premium', organization_id='ORG-373', product='DataSync Pro', product_version='3.2.15', product_module='api_connector', category='Technical Issue', subcategory='Bug', priority='critical', severity='P3', channel='slack', subject='Performance degradation in DataSync Pro', description=\"The DataSync Pro has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_TIMEOUT_429 in the logs. This is affecting our entire team's productivity.\", error_logs='2023-03-23T15:00:22 WARN Rate limit approaching threshold\\n2023-03-23T15:00:22 ERROR ERROR_TIMEOUT_429: Rate limit exceeded\\n2023-03-23T15:00:24 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='satisfied', previous_tickets=8, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 3, 24, 13, 54, 58, tzinfo=datetime.timezone.utc), agent_id='AGENT-036', agent_actions=['applied_fix', 'viewed_logs'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['api', 'database'], environment='sandbox', business_impact='low', affected_users=591, language='de', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000370', created_at=datetime.datetime(2023, 12, 5, 21, 59, 31, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 7, 11, 54, 7, tzinfo=datetime.timezone.utc), customer_id='CUST-00625', customer_tier='professional', organization_id='ORG-167', product='API Gateway', product_version='3.0.0', product_module='auth_service', category='Account Management', subcategory='Subscription', priority='low', severity='P2', channel='phone', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=9, resolution='Root cause identified as Subscription issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 12, 7, 11, 54, 7, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['updated_documentation', 'viewed_logs', 'escalated_to_specialist'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['performance', 'configuration'], environment='production', business_impact='low', affected_users=6, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000371', created_at=datetime.datetime(2024, 12, 15, 21, 2, 58, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 16, 0, 43, 46, tzinfo=datetime.timezone.utc), customer_id='CUST-01143', customer_tier='enterprise', organization_id='ORG-295', product='DataSync Pro', product_version='4.1.6', product_module='api_connector', category='Feature Request', subcategory='New Feature', priority='high', severity='P1', channel='portal', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-12-15T21:02:58 ERROR ERROR_CORRUPTION: Database connection lost\\n2024-12-15T21:02:59 INFO Attempting to reconnect...\\n2024-12-15T21:03:01 ERROR Connection failed', stack_trace='', customer_sentiment='satisfied', previous_tickets=4, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 12, 16, 0, 43, 46, tzinfo=datetime.timezone.utc), agent_id='AGENT-047', agent_actions=['updated_documentation', 'checked_config', 'ran_diagnostics', 'applied_fix'], escalated=True, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['authentication', 'error', 'sync', 'data'], environment='sandbox', business_impact='critical', affected_users=552, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000372', created_at=datetime.datetime(2023, 7, 18, 11, 32, 19, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 18, 15, 54, 31, tzinfo=datetime.timezone.utc), customer_id='CUST-01775', customer_tier='premium', organization_id='ORG-101', product='DataSync Pro', product_version='4.7.3', product_module='sync_engine', category='Security', subcategory='Authentication', priority='critical', severity='P2', channel='portal', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=5, resolution='Root cause identified as Authentication issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 7, 18, 15, 54, 31, tzinfo=datetime.timezone.utc), agent_id='AGENT-049', agent_actions=['applied_fix', 'consulted_kb'], escalated=True, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['sync', 'data'], environment='development', business_impact='low', affected_users=898, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000373', created_at=datetime.datetime(2024, 10, 3, 23, 20, 1, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 5, 20, 57, 13, tzinfo=datetime.timezone.utc), customer_id='CUST-02351', customer_tier='starter', organization_id='ORG-188', product='StreamProcessor', product_version='3.2.3', product_module='event_handler', category='Data Issue', subcategory='Validation', priority='medium', severity='P4', channel='chat', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_SSL_CERT appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-10-03T23:20:01 DEBUG Processing request ID-12345\\n2024-10-03T23:20:01 ERROR ERROR_SSL_CERT: Invalid request format\\n2024-10-03T23:20:02 INFO Request rejected', stack_trace='', customer_sentiment='neutral', previous_tickets=1, resolution='Root cause identified as Validation issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 10, 5, 20, 57, 13, tzinfo=datetime.timezone.utc), agent_id='AGENT-018', agent_actions=['created_workaround', 'escalated_to_specialist', 'applied_fix', 'ran_diagnostics', 'viewed_logs'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['database', 'api', 'bug', 'sync'], environment='production', business_impact='high', affected_users=17, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000374', created_at=datetime.datetime(2023, 6, 20, 18, 34, 34, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 21, 4, 55, 34, tzinfo=datetime.timezone.utc), customer_id='CUST-03701', customer_tier='free', organization_id='ORG-132', product='StreamProcessor', product_version='2.5.15', product_module='batch_processor', category='Data Issue', subcategory='Data Loss', priority='low', severity='P1', channel='api', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=5, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 6, 21, 4, 55, 34, tzinfo=datetime.timezone.utc), agent_id='AGENT-024', agent_actions=['escalated_to_specialist', 'verified_resolution'], escalated=True, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['bug', 'authentication'], environment='test', business_impact='medium', affected_users=7, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000375', created_at=datetime.datetime(2024, 4, 12, 11, 17, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 13, 13, 7, 33, tzinfo=datetime.timezone.utc), customer_id='CUST-01751', customer_tier='free', organization_id='ORG-094', product='API Gateway', product_version='3.7.5', product_module='auth_service', category='Security', subcategory='Compliance', priority='medium', severity='P3', channel='api', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_DEADLOCK errors. We need to ensure our system meets compliance requirements.', error_logs='2024-04-12T11:17:45 WARN Rate limit approaching threshold\\n2024-04-12T11:17:45 ERROR ERROR_DEADLOCK: Rate limit exceeded\\n2024-04-12T11:17:47 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='frustrated', previous_tickets=4, resolution='Applied hotfix version 3.2.2 to address the ERROR_DEADLOCK. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 4, 13, 13, 7, 33, tzinfo=datetime.timezone.utc), agent_id='AGENT-049', agent_actions=['updated_documentation', 'ran_diagnostics', 'consulted_kb'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=False, tags=['api', 'data'], environment='staging', business_impact='critical', affected_users=45, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000376', created_at=datetime.datetime(2023, 6, 2, 11, 55, 56, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 2, 16, 17, 32, tzinfo=datetime.timezone.utc), customer_id='CUST-01188', customer_tier='premium', organization_id='ORG-466', product='StreamProcessor', product_version='3.4.14', product_module='batch_processor', category='Feature Request', subcategory='Documentation', priority='low', severity='P0', channel='portal', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=9, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 6, 2, 16, 17, 32, tzinfo=datetime.timezone.utc), agent_id='AGENT-028', agent_actions=['checked_config', 'created_workaround', 'contacted_customer'], escalated=True, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['database', 'sync', 'performance', 'integration'], environment='development', business_impact='medium', affected_users=23, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000377', created_at=datetime.datetime(2023, 4, 14, 17, 24, 30, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 16, 15, 5, 54, tzinfo=datetime.timezone.utc), customer_id='CUST-04195', customer_tier='premium', organization_id='ORG-359', product='StreamProcessor', product_version='4.5.2', product_module='error_handler', category='Account Management', subcategory='Subscription', priority='critical', severity='P4', channel='api', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-04-14T17:24:30 DEBUG Processing request ID-12345\\n2023-04-14T17:24:30 ERROR ERROR_TIMEOUT_429: Invalid request format\\n2023-04-14T17:24:31 INFO Request rejected', stack_trace='Stack trace:\\n  error_handler::processData() at error_handler.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='grateful', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 4, 16, 15, 5, 54, tzinfo=datetime.timezone.utc), agent_id='AGENT-035', agent_actions=['checked_config', 'escalated_to_specialist', 'consulted_kb'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['performance', 'database', 'security'], environment='test', business_impact='high', affected_users=795, language='de', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000378', created_at=datetime.datetime(2024, 10, 21, 11, 17, 54, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 22, 10, 46, 6, tzinfo=datetime.timezone.utc), customer_id='CUST-02934', customer_tier='starter', organization_id='ORG-103', product='CloudBackup Enterprise', product_version='4.1.12', product_module='restore_module', category='Security', subcategory='Compliance', priority='critical', severity='P4', channel='portal', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=1, resolution='Root cause identified as Compliance issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 10, 22, 10, 46, 6, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['applied_fix', 'checked_config', 'updated_documentation', 'consulted_kb', 'contacted_customer'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['performance', 'data', 'api', 'configuration', 'integration'], environment='staging', business_impact='critical', affected_users=642, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000379', created_at=datetime.datetime(2024, 10, 4, 23, 27, 34, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 7, 8, 22, 46, tzinfo=datetime.timezone.utc), customer_id='CUST-04190', customer_tier='free', organization_id='ORG-289', product='DataSync Pro', product_version='4.5.7', product_module='api_connector', category='Account Management', subcategory='Upgrade', priority='high', severity='P4', channel='phone', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-10-04T23:27:34 DEBUG Processing request ID-12345\\n2024-10-04T23:27:34 ERROR ERROR_NOTFOUND_404: Invalid request format\\n2024-10-04T23:27:35 INFO Request rejected', stack_trace=\"Traceback (most recent call last):\\n  File 'api_connector.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='satisfied', previous_tickets=1, resolution='Root cause identified as Upgrade issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 10, 7, 8, 22, 46, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['contacted_customer', 'viewed_logs', 'created_workaround', 'checked_config'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['performance', 'error', 'database'], environment='sandbox', business_impact='low', affected_users=118, language='es', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000380', created_at=datetime.datetime(2024, 11, 25, 5, 34, 53, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 27, 1, 28, 53, tzinfo=datetime.timezone.utc), customer_id='CUST-01877', customer_tier='free', organization_id='ORG-289', product='StreamProcessor', product_version='2.4.6', product_module='batch_processor', category='Security', subcategory='Vulnerability', priority='medium', severity='P4', channel='api', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=3, resolution='Root cause identified as Vulnerability issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 11, 27, 1, 28, 53, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['verified_resolution', 'viewed_logs', 'contacted_customer'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['configuration', 'timeout', 'performance', 'api', 'sync'], environment='production', business_impact='low', affected_users=19, language='es', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000381', created_at=datetime.datetime(2023, 4, 18, 10, 39, 42, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 19, 18, 6, 6, tzinfo=datetime.timezone.utc), customer_id='CUST-04524', customer_tier='premium', organization_id='ORG-110', product='API Gateway', product_version='3.8.9', product_module='auth_service', category='Data Issue', subcategory='Sync Error', priority='medium', severity='P2', channel='phone', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_INVALID_400 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-04-18T10:39:42 DEBUG Processing request ID-12345\\n2023-04-18T10:39:42 ERROR ERROR_INVALID_400: Invalid request format\\n2023-04-18T10:39:43 INFO Request rejected', stack_trace='', customer_sentiment='confused', previous_tickets=4, resolution='Root cause identified as Sync Error issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 4, 19, 18, 6, 6, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['contacted_customer', 'consulted_kb'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['configuration', 'database', 'integration'], environment='sandbox', business_impact='medium', affected_users=36, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000382', created_at=datetime.datetime(2024, 10, 14, 2, 0, 21, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 14, 6, 19, 33, tzinfo=datetime.timezone.utc), customer_id='CUST-03457', customer_tier='free', organization_id='ORG-479', product='DataSync Pro', product_version='3.5.4', product_module='sync_engine', category='Security', subcategory='Authorization', priority='critical', severity='P1', channel='email', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_NOTFOUND_404 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-10-14T02:00:21 DEBUG Processing request ID-12345\\n2024-10-14T02:00:21 ERROR ERROR_NOTFOUND_404: Invalid request format\\n2024-10-14T02:00:22 INFO Request rejected', stack_trace=\"Traceback (most recent call last):\\n  File 'sync_engine.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='frustrated', previous_tickets=5, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 10, 14, 6, 19, 33, tzinfo=datetime.timezone.utc), agent_id='AGENT-001', agent_actions=['checked_config', 'viewed_logs'], escalated=True, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['error', 'database', 'bug'], environment='sandbox', business_impact='medium', affected_users=184, language='ja', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000383', created_at=datetime.datetime(2023, 9, 11, 3, 49, 52, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 11, 23, 52, 16, tzinfo=datetime.timezone.utc), customer_id='CUST-04154', customer_tier='free', organization_id='ORG-134', product='API Gateway', product_version='3.6.15', product_module='auth_service', category='Technical Issue', subcategory='Integration', priority='medium', severity='P2', channel='chat', subject='API Gateway throwing errors during operation', description=\"We're experiencing issues with API Gateway. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=9, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 9, 11, 23, 52, 16, tzinfo=datetime.timezone.utc), agent_id='AGENT-024', agent_actions=['ran_diagnostics', 'escalated_to_specialist'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['data', 'bug'], environment='sandbox', business_impact='critical', affected_users=50, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000384', created_at=datetime.datetime(2023, 4, 22, 22, 9, 51, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 22, 23, 23, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-00370', customer_tier='free', organization_id='ORG-357', product='Analytics Dashboard', product_version='4.8.10', product_module='report_builder', category='Data Issue', subcategory='Import/Export', priority='critical', severity='P0', channel='api', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_PERMISSION_403 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-04-22T22:09:51 WARN Rate limit approaching threshold\\n2023-04-22T22:09:51 ERROR ERROR_PERMISSION_403: Rate limit exceeded\\n2023-04-22T22:09:53 INFO Backing off for 60 seconds', stack_trace='Stack trace:\\n  report_builder::processData() at report_builder.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='neutral', previous_tickets=1, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 4, 22, 23, 23, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-017', agent_actions=['escalated_to_specialist', 'ran_diagnostics', 'updated_documentation', 'contacted_customer', 'checked_config', 'verified_resolution'], escalated=True, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['bug', 'database', 'performance'], environment='test', business_impact='high', affected_users=891, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000385', created_at=datetime.datetime(2023, 1, 11, 23, 37, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 15, 1, 59, 14, tzinfo=datetime.timezone.utc), customer_id='CUST-02868', customer_tier='starter', organization_id='ORG-331', product='Analytics Dashboard', product_version='2.2.3', product_module='data_aggregator', category='Data Issue', subcategory='Corruption', priority='high', severity='P4', channel='slack', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_CONNECTION_REFUSED appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-01-11T23:37:38 DEBUG Processing request ID-12345\\n2023-01-11T23:37:38 ERROR ERROR_CONNECTION_REFUSED: Invalid request format\\n2023-01-11T23:37:39 INFO Request rejected', stack_trace='', customer_sentiment='satisfied', previous_tickets=8, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 1, 15, 1, 59, 14, tzinfo=datetime.timezone.utc), agent_id='AGENT-048', agent_actions=['escalated_to_specialist', 'viewed_logs'], escalated=True, transferred_count=0, satisfaction_score=5, resolution_helpful=False, tags=['timeout', 'performance', 'bug', 'database', 'integration'], environment='development', business_impact='critical', affected_users=794, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000386', created_at=datetime.datetime(2023, 6, 25, 7, 16, 33, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 27, 2, 43, 33, tzinfo=datetime.timezone.utc), customer_id='CUST-03208', customer_tier='professional', organization_id='ORG-061', product='Analytics Dashboard', product_version='4.5.2', product_module='data_aggregator', category='Security', subcategory='Compliance', priority='low', severity='P4', channel='slack', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_AUTH_401 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-06-25T07:16:33 DEBUG Processing request ID-12345\\n2023-06-25T07:16:33 ERROR ERROR_AUTH_401: Invalid request format\\n2023-06-25T07:16:34 INFO Request rejected', stack_trace='', customer_sentiment='neutral', previous_tickets=4, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 6, 27, 2, 43, 33, tzinfo=datetime.timezone.utc), agent_id='AGENT-029', agent_actions=['escalated_to_specialist', 'applied_fix', 'checked_config', 'updated_documentation', 'ran_diagnostics'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['database', 'performance'], environment='staging', business_impact='high', affected_users=16, language='de', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000387', created_at=datetime.datetime(2023, 7, 6, 1, 54, 19, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 6, 6, 3, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-04935', customer_tier='enterprise', organization_id='ORG-227', product='DataSync Pro', product_version='3.4.6', product_module='scheduler', category='Security', subcategory='Authentication', priority='critical', severity='P1', channel='portal', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=1, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 7, 6, 6, 3, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-044', agent_actions=['created_workaround', 'checked_config', 'contacted_customer'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['timeout', 'error', 'api', 'sync'], environment='test', business_impact='medium', affected_users=83, language='pt', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000388', created_at=datetime.datetime(2024, 2, 29, 8, 3, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 2, 2, 43, 17, tzinfo=datetime.timezone.utc), customer_id='CUST-01968', customer_tier='professional', organization_id='ORG-238', product='API Gateway', product_version='2.2.10', product_module='auth_service', category='Technical Issue', subcategory='Configuration', priority='critical', severity='P4', channel='email', subject='Performance degradation in API Gateway', description=\"The API Gateway has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_INVALID_400 in the logs. This is affecting our entire team's productivity.\", error_logs='2024-02-29T08:03:41 ERROR ERROR_INVALID_400: Database connection lost\\n2024-02-29T08:03:42 INFO Attempting to reconnect...\\n2024-02-29T08:03:44 ERROR Connection failed', stack_trace='ERROR: auth_service.service.ServiceException: Failed to process request\\n\\tat auth_service.handler.process(auth_service.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='satisfied', previous_tickets=3, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 3, 2, 2, 43, 17, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['viewed_logs', 'created_workaround'], escalated=True, transferred_count=1, satisfaction_score=1, resolution_helpful=True, tags=['security', 'bug', 'data'], environment='development', business_impact='low', affected_users=827, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000389', created_at=datetime.datetime(2023, 3, 2, 12, 11, 40, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 2, 14, 44, 4, tzinfo=datetime.timezone.utc), customer_id='CUST-01862', customer_tier='professional', organization_id='ORG-210', product='DataSync Pro', product_version='2.2.0', product_module='data_validator', category='Data Issue', subcategory='Corruption', priority='medium', severity='P1', channel='api', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_AUTH_401 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-03-02T12:11:40 WARN Rate limit approaching threshold\\n2023-03-02T12:11:40 ERROR ERROR_AUTH_401: Rate limit exceeded\\n2023-03-02T12:11:42 INFO Backing off for 60 seconds', stack_trace='Stack trace:\\n  data_validator::processData() at data_validator.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='confused', previous_tickets=9, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 3, 2, 14, 44, 4, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['checked_config', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['performance', 'configuration'], environment='staging', business_impact='critical', affected_users=32, language='ja', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000390', created_at=datetime.datetime(2024, 1, 24, 13, 14, 57, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 24, 14, 8, 57, tzinfo=datetime.timezone.utc), customer_id='CUST-04858', customer_tier='enterprise', organization_id='ORG-187', product='DataSync Pro', product_version='4.6.11', product_module='api_connector', category='Data Issue', subcategory='Validation', priority='critical', severity='P0', channel='api', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=6, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 1, 24, 14, 8, 57, tzinfo=datetime.timezone.utc), agent_id='AGENT-028', agent_actions=['viewed_logs', 'applied_fix', 'escalated_to_specialist', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['database', 'configuration', 'performance', 'data'], environment='production', business_impact='medium', affected_users=224, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000391', created_at=datetime.datetime(2024, 6, 14, 0, 21, 22, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 14, 13, 48, 58, tzinfo=datetime.timezone.utc), customer_id='CUST-02135', customer_tier='free', organization_id='ORG-467', product='API Gateway', product_version='3.0.8', product_module='rate_limiter', category='Security', subcategory='Authentication', priority='low', severity='P1', channel='api', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_VALIDATION errors. We need to ensure our system meets compliance requirements.', error_logs='2024-06-14T00:21:22 ERROR ERROR_VALIDATION: Database connection lost\\n2024-06-14T00:21:23 INFO Attempting to reconnect...\\n2024-06-14T00:21:25 ERROR Connection failed', stack_trace='', customer_sentiment='confused', previous_tickets=10, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 6, 14, 13, 48, 58, tzinfo=datetime.timezone.utc), agent_id='AGENT-023', agent_actions=['escalated_to_specialist', 'checked_config', 'viewed_logs', 'ran_diagnostics'], escalated=True, transferred_count=3, satisfaction_score=3, resolution_helpful=False, tags=['data', 'sync'], environment='production', business_impact='medium', affected_users=28, language='de', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000392', created_at=datetime.datetime(2024, 6, 11, 14, 15, 53, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 12, 9, 51, 17, tzinfo=datetime.timezone.utc), customer_id='CUST-04903', customer_tier='professional', organization_id='ORG-110', product='DataSync Pro', product_version='4.4.0', product_module='sync_engine', category='Security', subcategory='Encryption', priority='critical', severity='P3', channel='chat', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_AUTH_401 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-06-11T14:15:53 DEBUG Processing request ID-12345\\n2024-06-11T14:15:53 ERROR ERROR_AUTH_401: Invalid request format\\n2024-06-11T14:15:54 INFO Request rejected', stack_trace=\"Traceback (most recent call last):\\n  File 'sync_engine.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='satisfied', previous_tickets=10, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 6, 12, 9, 51, 17, tzinfo=datetime.timezone.utc), agent_id='AGENT-045', agent_actions=['ran_diagnostics', 'consulted_kb', 'viewed_logs'], escalated=True, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['timeout', 'api', 'configuration', 'bug'], environment='sandbox', business_impact='high', affected_users=429, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000393', created_at=datetime.datetime(2023, 10, 16, 18, 28, 40, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 16, 19, 52, 40, tzinfo=datetime.timezone.utc), customer_id='CUST-01156', customer_tier='enterprise', organization_id='ORG-027', product='Analytics Dashboard', product_version='4.8.6', product_module='report_builder', category='Technical Issue', subcategory='Configuration', priority='low', severity='P0', channel='phone', subject='Performance degradation in Analytics Dashboard', description=\"The Analytics Dashboard has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_INVALID_400 in the logs. This is affecting our entire team's productivity.\", error_logs='2023-10-16T18:28:40 ERROR ERROR_INVALID_400: Database connection lost\\n2023-10-16T18:28:41 INFO Attempting to reconnect...\\n2023-10-16T18:28:43 ERROR Connection failed', stack_trace='Stack trace:\\n  report_builder::processData() at report_builder.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='angry', previous_tickets=3, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 10, 16, 19, 52, 40, tzinfo=datetime.timezone.utc), agent_id='AGENT-003', agent_actions=['checked_config', 'created_workaround', 'updated_documentation', 'contacted_customer'], escalated=True, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['integration', 'sync', 'performance', 'bug'], environment='test', business_impact='low', affected_users=9, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000394', created_at=datetime.datetime(2023, 11, 26, 7, 8, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 26, 22, 25, 25, tzinfo=datetime.timezone.utc), customer_id='CUST-02030', customer_tier='professional', organization_id='ORG-465', product='API Gateway', product_version='4.8.10', product_module='rate_limiter', category='Feature Request', subcategory='Enhancement', priority='high', severity='P2', channel='portal', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=0, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 11, 26, 22, 25, 25, tzinfo=datetime.timezone.utc), agent_id='AGENT-013', agent_actions=['checked_config', 'consulted_kb', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['error', 'api', 'integration', 'configuration', 'timeout'], environment='test', business_impact='low', affected_users=732, language='zh', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000395', created_at=datetime.datetime(2024, 7, 25, 15, 40, 57, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 26, 12, 18, 45, tzinfo=datetime.timezone.utc), customer_id='CUST-04645', customer_tier='professional', organization_id='ORG-257', product='StreamProcessor', product_version='2.0.4', product_module='batch_processor', category='Technical Issue', subcategory='Bug', priority='medium', severity='P3', channel='api', subject='StreamProcessor throwing ERROR_TIMEOUT_429 during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing ERROR_TIMEOUT_429 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-07-25T15:40:57 WARN Rate limit approaching threshold\\n2024-07-25T15:40:57 ERROR ERROR_TIMEOUT_429: Rate limit exceeded\\n2024-07-25T15:40:59 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='neutral', previous_tickets=4, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 7, 26, 12, 18, 45, tzinfo=datetime.timezone.utc), agent_id='AGENT-032', agent_actions=['contacted_customer', 'consulted_kb', 'updated_documentation'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=False, tags=['performance', 'timeout'], environment='production', business_impact='critical', affected_users=12, language='pt', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000396', created_at=datetime.datetime(2023, 5, 2, 21, 3, 29, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 2, 21, 59, 17, tzinfo=datetime.timezone.utc), customer_id='CUST-02233', customer_tier='free', organization_id='ORG-047', product='StreamProcessor', product_version='4.3.11', product_module='error_handler', category='Technical Issue', subcategory='Compatibility', priority='critical', severity='P0', channel='phone', subject='Performance degradation in StreamProcessor', description=\"The StreamProcessor has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_SSL_CERT in the logs. This is affecting our entire team's productivity.\", error_logs='2023-05-02T21:03:29 ERROR ERROR_SSL_CERT: Database connection lost\\n2023-05-02T21:03:30 INFO Attempting to reconnect...\\n2023-05-02T21:03:32 ERROR Connection failed', stack_trace=\"Traceback (most recent call last):\\n  File 'error_handler.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='satisfied', previous_tickets=7, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 5, 2, 21, 59, 17, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['applied_fix', 'checked_config', 'verified_resolution'], escalated=True, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['database', 'bug', 'data'], environment='test', business_impact='high', affected_users=673, language='en', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000397', created_at=datetime.datetime(2023, 8, 6, 0, 23, 53, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 6, 4, 23, 17, tzinfo=datetime.timezone.utc), customer_id='CUST-03981', customer_tier='professional', organization_id='ORG-468', product='DataSync Pro', product_version='4.5.7', product_module='data_validator', category='Data Issue', subcategory='Sync Error', priority='low', severity='P1', channel='slack', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=1, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 8, 6, 4, 23, 17, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['applied_fix', 'verified_resolution', 'viewed_logs', 'escalated_to_specialist'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=False, tags=['error', 'timeout', 'data', 'sync'], environment='staging', business_impact='low', affected_users=40, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000398', created_at=datetime.datetime(2024, 4, 15, 23, 58, 57, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 18, 13, 30, 9, tzinfo=datetime.timezone.utc), customer_id='CUST-04678', customer_tier='premium', organization_id='ORG-431', product='StreamProcessor', product_version='4.9.6', product_module='event_handler', category='Data Issue', subcategory='Import/Export', priority='medium', severity='P4', channel='api', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_SERVER_500 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-04-15T23:58:57 DEBUG Processing request ID-12345\\n2024-04-15T23:58:57 ERROR ERROR_SERVER_500: Invalid request format\\n2024-04-15T23:58:58 INFO Request rejected', stack_trace='', customer_sentiment='neutral', previous_tickets=5, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 4, 18, 13, 30, 9, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['consulted_kb', 'checked_config'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['bug', 'error'], environment='production', business_impact='low', affected_users=10, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000399', created_at=datetime.datetime(2023, 8, 30, 8, 2, 35, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 31, 14, 48, 11, tzinfo=datetime.timezone.utc), customer_id='CUST-03801', customer_tier='professional', organization_id='ORG-237', product='Analytics Dashboard', product_version='2.9.0', product_module='visualization', category='Technical Issue', subcategory='Performance', priority='low', severity='P2', channel='portal', subject='Analytics Dashboard throwing ERROR_DEADLOCK during operation', description=\"We're experiencing issues with Analytics Dashboard. The system is throwing ERROR_DEADLOCK when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-08-30T08:02:35 ERROR ERROR_DEADLOCK: Connection timeout after 30s\\n2023-08-30T08:02:36 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='frustrated', previous_tickets=5, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 8, 31, 14, 48, 11, tzinfo=datetime.timezone.utc), agent_id='AGENT-040', agent_actions=['ran_diagnostics', 'viewed_logs', 'contacted_customer'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['data', 'sync', 'performance', 'integration', 'database'], environment='sandbox', business_impact='low', affected_users=11, language='pt', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000400', created_at=datetime.datetime(2024, 2, 3, 15, 15, 46, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 4, 5, 46, 58, tzinfo=datetime.timezone.utc), customer_id='CUST-03279', customer_tier='premium', organization_id='ORG-405', product='DataSync Pro', product_version='2.4.9', product_module='scheduler', category='Feature Request', subcategory='New Feature', priority='high', severity='P2', channel='slack', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=10, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 2, 4, 5, 46, 58, tzinfo=datetime.timezone.utc), agent_id='AGENT-037', agent_actions=['checked_config', 'viewed_logs'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['authentication', 'security'], environment='staging', business_impact='high', affected_users=926, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000401', created_at=datetime.datetime(2023, 5, 23, 17, 14, 9, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 23, 19, 14, 45, tzinfo=datetime.timezone.utc), customer_id='CUST-02211', customer_tier='professional', organization_id='ORG-195', product='StreamProcessor', product_version='2.1.13', product_module='batch_processor', category='Feature Request', subcategory='Documentation', priority='high', severity='P0', channel='portal', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-05-23T17:14:09 ERROR ERROR_CONNECTION_REFUSED: Database connection lost\\n2023-05-23T17:14:10 INFO Attempting to reconnect...\\n2023-05-23T17:14:12 ERROR Connection failed', stack_trace='', customer_sentiment='frustrated', previous_tickets=6, resolution='Applied hotfix version 3.2.2 to address the ERROR_CONNECTION_REFUSED. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 5, 23, 19, 14, 45, tzinfo=datetime.timezone.utc), agent_id='AGENT-009', agent_actions=['updated_documentation', 'verified_resolution', 'created_workaround'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['database', 'bug', 'performance'], environment='staging', business_impact='high', affected_users=14, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000402', created_at=datetime.datetime(2024, 11, 26, 14, 57, 15, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 29, 5, 41, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-03756', customer_tier='starter', organization_id='ORG-414', product='Analytics Dashboard', product_version='2.3.9', product_module='data_aggregator', category='Data Issue', subcategory='Validation', priority='high', severity='P4', channel='phone', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=6, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 11, 29, 5, 41, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['contacted_customer', 'applied_fix', 'verified_resolution', 'updated_documentation', 'ran_diagnostics', 'escalated_to_specialist'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=True, tags=['security', 'api'], environment='sandbox', business_impact='low', affected_users=119, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000403', created_at=datetime.datetime(2024, 2, 22, 16, 50, 56, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 23, 23, 15, 32, tzinfo=datetime.timezone.utc), customer_id='CUST-00436', customer_tier='free', organization_id='ORG-176', product='API Gateway', product_version='4.2.2', product_module='cache_layer', category='Data Issue', subcategory='Data Loss', priority='high', severity='P3', channel='portal', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=6, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 2, 23, 23, 15, 32, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['updated_documentation', 'created_workaround', 'viewed_logs', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['api', 'integration', 'configuration', 'database', 'bug'], environment='development', business_impact='high', affected_users=730, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000404', created_at=datetime.datetime(2023, 2, 28, 9, 27, 1, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 28, 12, 42, 1, tzinfo=datetime.timezone.utc), customer_id='CUST-03656', customer_tier='enterprise', organization_id='ORG-318', product='Analytics Dashboard', product_version='3.7.0', product_module='export_module', category='Data Issue', subcategory='Import/Export', priority='high', severity='P1', channel='phone', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_PERMISSION_403 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-02-28T09:27:01 WARN Rate limit approaching threshold\\n2023-02-28T09:27:01 ERROR ERROR_PERMISSION_403: Rate limit exceeded\\n2023-02-28T09:27:03 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='neutral', previous_tickets=10, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 2, 28, 12, 42, 1, tzinfo=datetime.timezone.utc), agent_id='AGENT-027', agent_actions=['updated_documentation', 'consulted_kb', 'verified_resolution'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['sync', 'authentication', 'data', 'configuration'], environment='sandbox', business_impact='high', affected_users=427, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000405', created_at=datetime.datetime(2023, 2, 19, 8, 2, 52, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 19, 12, 16, 40, tzinfo=datetime.timezone.utc), customer_id='CUST-04686', customer_tier='starter', organization_id='ORG-184', product='DataSync Pro', product_version='3.1.6', product_module='data_validator', category='Technical Issue', subcategory='Compatibility', priority='critical', severity='P2', channel='api', subject='DataSync Pro throwing ERROR_CONFLICT_409 during operation', description=\"We're experiencing issues with DataSync Pro. The system is throwing ERROR_CONFLICT_409 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-02-19T08:02:52 WARN Rate limit approaching threshold\\n2023-02-19T08:02:52 ERROR ERROR_CONFLICT_409: Rate limit exceeded\\n2023-02-19T08:02:54 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='angry', previous_tickets=9, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 2, 19, 12, 16, 40, tzinfo=datetime.timezone.utc), agent_id='AGENT-006', agent_actions=['viewed_logs', 'contacted_customer', 'ran_diagnostics'], escalated=True, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['performance', 'error', 'bug', 'security'], environment='test', business_impact='high', affected_users=136, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000406', created_at=datetime.datetime(2024, 8, 18, 6, 25, 2, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 18, 18, 34, 38, tzinfo=datetime.timezone.utc), customer_id='CUST-03243', customer_tier='enterprise', organization_id='ORG-009', product='Analytics Dashboard', product_version='4.5.12', product_module='data_aggregator', category='Data Issue', subcategory='Validation', priority='medium', severity='P2', channel='chat', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_VALIDATION appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-08-18T06:25:02 ERROR ERROR_VALIDATION: Connection timeout after 30s\\n2024-08-18T06:25:03 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='neutral', previous_tickets=4, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 8, 18, 18, 34, 38, tzinfo=datetime.timezone.utc), agent_id='AGENT-005', agent_actions=['checked_config', 'escalated_to_specialist', 'ran_diagnostics'], escalated=True, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['integration', 'sync', 'timeout', 'database'], environment='production', business_impact='low', affected_users=25, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000407', created_at=datetime.datetime(2024, 2, 17, 6, 3, 2, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 18, 0, 4, 14, tzinfo=datetime.timezone.utc), customer_id='CUST-04131', customer_tier='professional', organization_id='ORG-317', product='StreamProcessor', product_version='2.5.13', product_module='monitoring', category='Feature Request', subcategory='Documentation', priority='critical', severity='P4', channel='chat', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=6, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 2, 18, 0, 4, 14, tzinfo=datetime.timezone.utc), agent_id='AGENT-012', agent_actions=['contacted_customer', 'viewed_logs', 'escalated_to_specialist'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['bug', 'error'], environment='staging', business_impact='high', affected_users=452, language='fr', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000408', created_at=datetime.datetime(2024, 2, 26, 8, 41, 21, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 26, 16, 46, 45, tzinfo=datetime.timezone.utc), customer_id='CUST-01875', customer_tier='free', organization_id='ORG-351', product='DataSync Pro', product_version='3.8.4', product_module='api_connector', category='Security', subcategory='Authentication', priority='medium', severity='P2', channel='api', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=0, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 2, 26, 16, 46, 45, tzinfo=datetime.timezone.utc), agent_id='AGENT-003', agent_actions=['applied_fix', 'consulted_kb', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['integration', 'database', 'configuration'], environment='sandbox', business_impact='high', affected_users=2, language='de', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000409', created_at=datetime.datetime(2024, 10, 24, 0, 54, 18, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 24, 11, 27, 18, tzinfo=datetime.timezone.utc), customer_id='CUST-04300', customer_tier='free', organization_id='ORG-168', product='CloudBackup Enterprise', product_version='4.9.11', product_module='compression_engine', category='Data Issue', subcategory='Data Loss', priority='high', severity='P2', channel='portal', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_SSL_CERT appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-10-24T00:54:18 DEBUG Processing request ID-12345\\n2024-10-24T00:54:18 ERROR ERROR_SSL_CERT: Invalid request format\\n2024-10-24T00:54:19 INFO Request rejected', stack_trace=\"Traceback (most recent call last):\\n  File 'compression_engine.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='angry', previous_tickets=0, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 10, 24, 11, 27, 18, tzinfo=datetime.timezone.utc), agent_id='AGENT-034', agent_actions=['viewed_logs', 'consulted_kb'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['integration', 'database', 'authentication'], environment='test', business_impact='medium', affected_users=699, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000410', created_at=datetime.datetime(2024, 2, 4, 4, 4, 15, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 5, 4, 42, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-01772', customer_tier='free', organization_id='ORG-215', product='DataSync Pro', product_version='4.4.2', product_module='scheduler', category='Feature Request', subcategory='API', priority='medium', severity='P2', channel='portal', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-02-04T04:04:15 ERROR ERROR_NOTFOUND_404: Database connection lost\\n2024-02-04T04:04:16 INFO Attempting to reconnect...\\n2024-02-04T04:04:18 ERROR Connection failed', stack_trace='at scheduler.execute(scheduler.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='grateful', previous_tickets=7, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 2, 5, 4, 42, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-049', agent_actions=['consulted_kb', 'verified_resolution', 'applied_fix', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['data', 'error', 'integration', 'performance', 'sync'], environment='production', business_impact='critical', affected_users=35, language='it', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000411', created_at=datetime.datetime(2024, 10, 20, 5, 7, 51, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 20, 6, 30, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-03396', customer_tier='professional', organization_id='ORG-380', product='CloudBackup Enterprise', product_version='3.3.4', product_module='compression_engine', category='Data Issue', subcategory='Validation', priority='critical', severity='P1', channel='portal', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_CONFLICT_409 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-10-20T05:07:51 WARN Rate limit approaching threshold\\n2024-10-20T05:07:51 ERROR ERROR_CONFLICT_409: Rate limit exceeded\\n2024-10-20T05:07:53 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='neutral', previous_tickets=4, resolution='Applied hotfix version 3.2.2 to address the ERROR_CONFLICT_409. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 10, 20, 6, 30, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-022', agent_actions=['contacted_customer', 'checked_config', 'verified_resolution', 'applied_fix'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['data', 'sync', 'error', 'api'], environment='test', business_impact='low', affected_users=394, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000412', created_at=datetime.datetime(2024, 6, 18, 7, 3, 55, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 19, 2, 30, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-01660', customer_tier='professional', organization_id='ORG-066', product='Analytics Dashboard', product_version='3.5.6', product_module='report_builder', category='Security', subcategory='Authentication', priority='critical', severity='P3', channel='api', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_DEADLOCK errors. We need to ensure our system meets compliance requirements.', error_logs='2024-06-18T07:03:55 WARN Rate limit approaching threshold\\n2024-06-18T07:03:55 ERROR ERROR_DEADLOCK: Rate limit exceeded\\n2024-06-18T07:03:57 INFO Backing off for 60 seconds', stack_trace='at report_builder.execute(report_builder.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='grateful', previous_tickets=4, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 6, 19, 2, 30, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['applied_fix', 'contacted_customer'], escalated=True, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['integration', 'configuration', 'error'], environment='sandbox', business_impact='high', affected_users=576, language='it', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000413', created_at=datetime.datetime(2024, 8, 19, 11, 17, 42, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 19, 15, 5, 42, tzinfo=datetime.timezone.utc), customer_id='CUST-04675', customer_tier='enterprise', organization_id='ORG-433', product='CloudBackup Enterprise', product_version='3.6.11', product_module='backup_service', category='Security', subcategory='Vulnerability', priority='medium', severity='P1', channel='phone', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=6, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 8, 19, 15, 5, 42, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['updated_documentation', 'contacted_customer', 'checked_config'], escalated=True, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['database', 'configuration', 'integration', 'bug', 'authentication'], environment='production', business_impact='medium', affected_users=22, language='ja', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000414', created_at=datetime.datetime(2023, 7, 17, 23, 48, 9, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 19, 11, 22, 57, tzinfo=datetime.timezone.utc), customer_id='CUST-03712', customer_tier='free', organization_id='ORG-155', product='CloudBackup Enterprise', product_version='2.8.13', product_module='encryption_layer', category='Technical Issue', subcategory='Configuration', priority='critical', severity='P4', channel='email', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_PARSING in the logs. This is affecting our entire team's productivity.\", error_logs='2023-07-17T23:48:09 ERROR ERROR_PARSING: Database connection lost\\n2023-07-17T23:48:10 INFO Attempting to reconnect...\\n2023-07-17T23:48:12 ERROR Connection failed', stack_trace='', customer_sentiment='angry', previous_tickets=3, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 7, 19, 11, 22, 57, tzinfo=datetime.timezone.utc), agent_id='AGENT-036', agent_actions=['checked_config', 'verified_resolution', 'updated_documentation', 'consulted_kb', 'created_workaround', 'ran_diagnostics'], escalated=True, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['integration', 'error', 'performance'], environment='sandbox', business_impact='low', affected_users=995, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000415', created_at=datetime.datetime(2024, 6, 16, 8, 57, 24, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 16, 12, 13, tzinfo=datetime.timezone.utc), customer_id='CUST-01193', customer_tier='enterprise', organization_id='ORG-094', product='DataSync Pro', product_version='4.8.15', product_module='scheduler', category='Data Issue', subcategory='Corruption', priority='medium', severity='P1', channel='api', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_INVALID_400 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-06-16T08:57:24 ERROR ERROR_INVALID_400: Connection timeout after 30s\\n2024-06-16T08:57:25 RETRY_FAILED: Max retries exceeded', stack_trace='at scheduler.execute(scheduler.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='grateful', previous_tickets=3, resolution='Applied hotfix version 3.2.2 to address the ERROR_INVALID_400. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 6, 16, 12, 13, tzinfo=datetime.timezone.utc), agent_id='AGENT-026', agent_actions=['ran_diagnostics', 'viewed_logs', 'applied_fix', 'verified_resolution', 'consulted_kb'], escalated=True, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['timeout', 'configuration', 'bug', 'data', 'authentication'], environment='staging', business_impact='critical', affected_users=4, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000416', created_at=datetime.datetime(2023, 8, 10, 20, 13, 48, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 11, 3, 16, 12, tzinfo=datetime.timezone.utc), customer_id='CUST-03052', customer_tier='starter', organization_id='ORG-426', product='Analytics Dashboard', product_version='2.7.6', product_module='visualization', category='Account Management', subcategory='Access Control', priority='critical', severity='P2', channel='chat', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-08-10T20:13:48 DEBUG Processing request ID-12345\\n2023-08-10T20:13:48 ERROR ERROR_INVALID_400: Invalid request format\\n2023-08-10T20:13:49 INFO Request rejected', stack_trace='', customer_sentiment='grateful', previous_tickets=9, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 8, 11, 3, 16, 12, tzinfo=datetime.timezone.utc), agent_id='AGENT-021', agent_actions=['updated_documentation', 'checked_config', 'consulted_kb', 'verified_resolution'], escalated=True, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['timeout', 'performance', 'error', 'authentication', 'integration'], environment='development', business_impact='medium', affected_users=427, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000417', created_at=datetime.datetime(2024, 12, 19, 2, 25, 11, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 19, 8, 13, 11, tzinfo=datetime.timezone.utc), customer_id='CUST-04895', customer_tier='free', organization_id='ORG-157', product='DataSync Pro', product_version='2.5.1', product_module='sync_engine', category='Security', subcategory='Authentication', priority='medium', severity='P2', channel='slack', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_PARSING errors. We need to ensure our system meets compliance requirements.', error_logs='2024-12-19T02:25:11 ERROR ERROR_PARSING: Database connection lost\\n2024-12-19T02:25:12 INFO Attempting to reconnect...\\n2024-12-19T02:25:14 ERROR Connection failed', stack_trace='', customer_sentiment='satisfied', previous_tickets=5, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 12, 19, 8, 13, 11, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['updated_documentation', 'escalated_to_specialist', 'viewed_logs', 'ran_diagnostics', 'verified_resolution', 'applied_fix'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['database', 'configuration', 'security', 'api', 'timeout'], environment='development', business_impact='critical', affected_users=7, language='pt', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000418', created_at=datetime.datetime(2023, 12, 9, 9, 45, 17, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 11, 21, 39, 17, tzinfo=datetime.timezone.utc), customer_id='CUST-02977', customer_tier='enterprise', organization_id='ORG-128', product='CloudBackup Enterprise', product_version='4.8.14', product_module='backup_service', category='Data Issue', subcategory='Import/Export', priority='high', severity='P4', channel='chat', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_CONNECTION_REFUSED appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-12-09T09:45:17 WARN Rate limit approaching threshold\\n2023-12-09T09:45:17 ERROR ERROR_CONNECTION_REFUSED: Rate limit exceeded\\n2023-12-09T09:45:19 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='satisfied', previous_tickets=10, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 12, 11, 21, 39, 17, tzinfo=datetime.timezone.utc), agent_id='AGENT-016', agent_actions=['checked_config', 'contacted_customer', 'consulted_kb', 'updated_documentation'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['data', 'api', 'sync', 'error', 'security'], environment='production', business_impact='medium', affected_users=169, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000419', created_at=datetime.datetime(2023, 8, 16, 0, 57, 15, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 16, 1, 59, 3, tzinfo=datetime.timezone.utc), customer_id='CUST-00179', customer_tier='premium', organization_id='ORG-415', product='API Gateway', product_version='2.3.0', product_module='auth_service', category='Technical Issue', subcategory='Bug', priority='critical', severity='P1', channel='phone', subject='API Gateway throwing errors during operation', description=\"We're experiencing issues with API Gateway. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=3, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 8, 16, 1, 59, 3, tzinfo=datetime.timezone.utc), agent_id='AGENT-027', agent_actions=['contacted_customer', 'ran_diagnostics', 'viewed_logs', 'checked_config', 'created_workaround', 'applied_fix'], escalated=True, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['database', 'bug', 'sync', 'authentication', 'data'], environment='staging', business_impact='medium', affected_users=171, language='zh', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000420', created_at=datetime.datetime(2023, 7, 24, 23, 41, 59, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 31, 3, 30, 35, tzinfo=datetime.timezone.utc), customer_id='CUST-00716', customer_tier='premium', organization_id='ORG-481', product='CloudBackup Enterprise', product_version='3.0.5', product_module='encryption_layer', category='Account Management', subcategory='Subscription', priority='low', severity='P4', channel='portal', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=0, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 7, 31, 3, 30, 35, tzinfo=datetime.timezone.utc), agent_id='AGENT-009', agent_actions=['checked_config', 'escalated_to_specialist'], escalated=False, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['configuration', 'data', 'database', 'integration', 'sync'], environment='test', business_impact='low', affected_users=32, language='es', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000421', created_at=datetime.datetime(2023, 11, 15, 2, 24, 25, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 15, 10, 14, 49, tzinfo=datetime.timezone.utc), customer_id='CUST-02606', customer_tier='premium', organization_id='ORG-383', product='DataSync Pro', product_version='4.8.2', product_module='sync_engine', category='Security', subcategory='Vulnerability', priority='medium', severity='P2', channel='email', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_MEMORY_OOM errors. We need to ensure our system meets compliance requirements.', error_logs='2023-11-15T02:24:25 ERROR ERROR_MEMORY_OOM: Database connection lost\\n2023-11-15T02:24:26 INFO Attempting to reconnect...\\n2023-11-15T02:24:28 ERROR Connection failed', stack_trace='ERROR: sync_engine.service.ServiceException: Failed to process request\\n\\tat sync_engine.handler.process(sync_engine.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='frustrated', previous_tickets=7, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 11, 15, 10, 14, 49, tzinfo=datetime.timezone.utc), agent_id='AGENT-049', agent_actions=['escalated_to_specialist', 'viewed_logs', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=False, tags=['integration', 'bug'], environment='sandbox', business_impact='low', affected_users=19, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000422', created_at=datetime.datetime(2024, 8, 14, 7, 52, 43, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 14, 14, 7, 7, tzinfo=datetime.timezone.utc), customer_id='CUST-01414', customer_tier='professional', organization_id='ORG-331', product='DataSync Pro', product_version='4.8.3', product_module='data_validator', category='Technical Issue', subcategory='Bug', priority='medium', severity='P2', channel='slack', subject='Performance degradation in DataSync Pro', description=\"The DataSync Pro has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=8, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 8, 14, 14, 7, 7, tzinfo=datetime.timezone.utc), agent_id='AGENT-050', agent_actions=['created_workaround', 'contacted_customer', 'checked_config'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['sync', 'security', 'error', 'timeout'], environment='test', business_impact='critical', affected_users=8, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000423', created_at=datetime.datetime(2023, 2, 15, 9, 28, 20, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 15, 15, 37, 20, tzinfo=datetime.timezone.utc), customer_id='CUST-03214', customer_tier='starter', organization_id='ORG-103', product='DataSync Pro', product_version='3.5.5', product_module='data_validator', category='Technical Issue', subcategory='Configuration', priority='medium', severity='P1', channel='api', subject='Performance degradation in DataSync Pro', description=\"The DataSync Pro has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_NOTFOUND_404 in the logs. This is affecting our entire team's productivity.\", error_logs='2023-02-15T09:28:20 DEBUG Processing request ID-12345\\n2023-02-15T09:28:20 ERROR ERROR_NOTFOUND_404: Invalid request format\\n2023-02-15T09:28:21 INFO Request rejected', stack_trace=\"Traceback (most recent call last):\\n  File 'data_validator.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='neutral', previous_tickets=7, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 2, 15, 15, 37, 20, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['updated_documentation', 'viewed_logs'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['integration', 'error'], environment='development', business_impact='critical', affected_users=9, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000424', created_at=datetime.datetime(2024, 3, 18, 19, 8, 33, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 19, 12, 36, 45, tzinfo=datetime.timezone.utc), customer_id='CUST-01564', customer_tier='starter', organization_id='ORG-071', product='API Gateway', product_version='4.1.10', product_module='auth_service', category='Technical Issue', subcategory='Compatibility', priority='low', severity='P2', channel='chat', subject='API Gateway throwing ERROR_CONFLICT_409 during operation', description=\"We're experiencing issues with API Gateway. The system is throwing ERROR_CONFLICT_409 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-03-18T19:08:33 DEBUG Processing request ID-12345\\n2024-03-18T19:08:33 ERROR ERROR_CONFLICT_409: Invalid request format\\n2024-03-18T19:08:34 INFO Request rejected', stack_trace='', customer_sentiment='neutral', previous_tickets=0, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 3, 19, 12, 36, 45, tzinfo=datetime.timezone.utc), agent_id='AGENT-032', agent_actions=['verified_resolution', 'updated_documentation', 'viewed_logs', 'checked_config', 'contacted_customer', 'escalated_to_specialist'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['authentication', 'security', 'integration', 'error', 'bug'], environment='production', business_impact='critical', affected_users=46, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000425', created_at=datetime.datetime(2024, 4, 2, 19, 57, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 7, 8, 9, 45, tzinfo=datetime.timezone.utc), customer_id='CUST-04775', customer_tier='professional', organization_id='ORG-243', product='CloudBackup Enterprise', product_version='4.4.9', product_module='restore_module', category='Technical Issue', subcategory='Integration', priority='low', severity='P4', channel='chat', subject='CloudBackup Enterprise throwing errors during operation', description=\"We're experiencing issues with CloudBackup Enterprise. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=0, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 4, 7, 8, 9, 45, tzinfo=datetime.timezone.utc), agent_id='AGENT-017', agent_actions=['contacted_customer', 'updated_documentation', 'checked_config'], escalated=False, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['authentication', 'bug', 'sync', 'database'], environment='sandbox', business_impact='critical', affected_users=38, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000426', created_at=datetime.datetime(2024, 10, 5, 5, 38, 40, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 6, 6, 49, 28, tzinfo=datetime.timezone.utc), customer_id='CUST-00009', customer_tier='starter', organization_id='ORG-152', product='StreamProcessor', product_version='3.1.4', product_module='event_handler', category='Security', subcategory='Compliance', priority='medium', severity='P3', channel='portal', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=2, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 10, 6, 6, 49, 28, tzinfo=datetime.timezone.utc), agent_id='AGENT-013', agent_actions=['checked_config', 'applied_fix'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['api', 'data'], environment='test', business_impact='low', affected_users=14, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000427', created_at=datetime.datetime(2024, 3, 28, 21, 46, 14, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 29, 2, 54, 38, tzinfo=datetime.timezone.utc), customer_id='CUST-03626', customer_tier='free', organization_id='ORG-457', product='API Gateway', product_version='4.1.6', product_module='auth_service', category='Data Issue', subcategory='Sync Error', priority='high', severity='P1', channel='phone', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_NOTFOUND_404 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-03-28T21:46:14 ERROR ERROR_NOTFOUND_404: Connection timeout after 30s\\n2024-03-28T21:46:15 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='grateful', previous_tickets=3, resolution='Applied hotfix version 3.2.2 to address the ERROR_NOTFOUND_404. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 3, 29, 2, 54, 38, tzinfo=datetime.timezone.utc), agent_id='AGENT-018', agent_actions=['escalated_to_specialist', 'applied_fix', 'checked_config', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['authentication', 'performance', 'bug', 'timeout'], environment='staging', business_impact='critical', affected_users=118, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000428', created_at=datetime.datetime(2024, 10, 29, 6, 9, 25, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 29, 7, 37, 1, tzinfo=datetime.timezone.utc), customer_id='CUST-04689', customer_tier='free', organization_id='ORG-286', product='Analytics Dashboard', product_version='2.4.4', product_module='data_aggregator', category='Security', subcategory='Compliance', priority='high', severity='P1', channel='chat', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=10, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 10, 29, 7, 37, 1, tzinfo=datetime.timezone.utc), agent_id='AGENT-022', agent_actions=['contacted_customer', 'consulted_kb'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['bug', 'integration', 'security', 'configuration', 'timeout'], environment='test', business_impact='low', affected_users=372, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000429', created_at=datetime.datetime(2023, 8, 22, 12, 1, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 22, 15, 13, tzinfo=datetime.timezone.utc), customer_id='CUST-04114', customer_tier='enterprise', organization_id='ORG-314', product='DataSync Pro', product_version='2.7.11', product_module='scheduler', category='Security', subcategory='Authorization', priority='high', severity='P1', channel='chat', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_SERVER_500 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-08-22T12:01:00 ERROR ERROR_SERVER_500: Database connection lost\\n2023-08-22T12:01:01 INFO Attempting to reconnect...\\n2023-08-22T12:01:03 ERROR Connection failed', stack_trace='', customer_sentiment='satisfied', previous_tickets=0, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 8, 22, 15, 13, tzinfo=datetime.timezone.utc), agent_id='AGENT-034', agent_actions=['checked_config', 'contacted_customer', 'ran_diagnostics'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['database', 'performance', 'authentication', 'configuration'], environment='test', business_impact='high', affected_users=246, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000430', created_at=datetime.datetime(2024, 1, 20, 9, 31, 6, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 20, 14, 29, 18, tzinfo=datetime.timezone.utc), customer_id='CUST-01586', customer_tier='enterprise', organization_id='ORG-263', product='StreamProcessor', product_version='3.2.4', product_module='batch_processor', category='Security', subcategory='Authorization', priority='medium', severity='P0', channel='chat', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=4, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 1, 20, 14, 29, 18, tzinfo=datetime.timezone.utc), agent_id='AGENT-034', agent_actions=['escalated_to_specialist', 'consulted_kb'], escalated=True, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['configuration', 'performance', 'bug'], environment='staging', business_impact='high', affected_users=34, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000431', created_at=datetime.datetime(2024, 6, 13, 13, 21, 26, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 13, 19, 42, 26, tzinfo=datetime.timezone.utc), customer_id='CUST-01755', customer_tier='starter', organization_id='ORG-106', product='Analytics Dashboard', product_version='3.4.4', product_module='visualization', category='Data Issue', subcategory='Corruption', priority='low', severity='P0', channel='api', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_NOTFOUND_404 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-06-13T13:21:26 DEBUG Processing request ID-12345\\n2024-06-13T13:21:26 ERROR ERROR_NOTFOUND_404: Invalid request format\\n2024-06-13T13:21:27 INFO Request rejected', stack_trace='ERROR: visualization.service.ServiceException: Failed to process request\\n\\tat visualization.handler.process(visualization.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='neutral', previous_tickets=7, resolution='Applied hotfix version 3.2.2 to address the ERROR_NOTFOUND_404. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 6, 13, 19, 42, 26, tzinfo=datetime.timezone.utc), agent_id='AGENT-020', agent_actions=['checked_config', 'applied_fix', 'contacted_customer'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['configuration', 'bug', 'performance'], environment='staging', business_impact='high', affected_users=6, language='en', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000432', created_at=datetime.datetime(2023, 6, 2, 3, 47, 16, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 4, 14, 25, 4, tzinfo=datetime.timezone.utc), customer_id='CUST-01900', customer_tier='enterprise', organization_id='ORG-458', product='DataSync Pro', product_version='4.2.4', product_module='sync_engine', category='Data Issue', subcategory='Sync Error', priority='medium', severity='P4', channel='slack', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=0, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 6, 4, 14, 25, 4, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['checked_config', 'escalated_to_specialist', 'updated_documentation', 'applied_fix', 'consulted_kb'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['api', 'configuration', 'database', 'integration', 'authentication'], environment='sandbox', business_impact='critical', affected_users=21, language='es', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000433', created_at=datetime.datetime(2023, 3, 18, 14, 18, 2, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 18, 17, 42, 38, tzinfo=datetime.timezone.utc), customer_id='CUST-03517', customer_tier='starter', organization_id='ORG-036', product='StreamProcessor', product_version='3.1.2', product_module='batch_processor', category='Security', subcategory='Encryption', priority='high', severity='P0', channel='phone', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Getting ERROR_NOTFOUND_404 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-03-18T14:18:02 ERROR ERROR_NOTFOUND_404: Connection timeout after 30s\\n2023-03-18T14:18:03 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='grateful', previous_tickets=6, resolution='Root cause identified as Encryption issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 3, 18, 17, 42, 38, tzinfo=datetime.timezone.utc), agent_id='AGENT-036', agent_actions=['viewed_logs', 'ran_diagnostics', 'applied_fix'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['security', 'authentication', 'timeout', 'configuration', 'api'], environment='test', business_impact='low', affected_users=289, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000434', created_at=datetime.datetime(2023, 6, 4, 15, 39, 51, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 4, 20, 33, 15, tzinfo=datetime.timezone.utc), customer_id='CUST-03731', customer_tier='starter', organization_id='ORG-250', product='CloudBackup Enterprise', product_version='4.8.5', product_module='restore_module', category='Data Issue', subcategory='Data Loss', priority='low', severity='P0', channel='email', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_CONNECTION_REFUSED appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-06-04T15:39:51 WARN Rate limit approaching threshold\\n2023-06-04T15:39:51 ERROR ERROR_CONNECTION_REFUSED: Rate limit exceeded\\n2023-06-04T15:39:53 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'restore_module.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='grateful', previous_tickets=10, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 6, 4, 20, 33, 15, tzinfo=datetime.timezone.utc), agent_id='AGENT-001', agent_actions=['ran_diagnostics', 'created_workaround', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['sync', 'database', 'api', 'error'], environment='test', business_impact='medium', affected_users=45, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000435', created_at=datetime.datetime(2023, 12, 6, 21, 27, 15, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 11, 13, 26, 3, tzinfo=datetime.timezone.utc), customer_id='CUST-00276', customer_tier='enterprise', organization_id='ORG-178', product='API Gateway', product_version='4.4.6', product_module='cache_layer', category='Data Issue', subcategory='Corruption', priority='low', severity='P4', channel='portal', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=1, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 12, 11, 13, 26, 3, tzinfo=datetime.timezone.utc), agent_id='AGENT-038', agent_actions=['contacted_customer', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=False, tags=['bug', 'api', 'configuration', 'database', 'integration'], environment='production', business_impact='low', affected_users=29, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000436', created_at=datetime.datetime(2024, 9, 30, 18, 10, 4, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 30, 21, 34, 40, tzinfo=datetime.timezone.utc), customer_id='CUST-00268', customer_tier='starter', organization_id='ORG-368', product='CloudBackup Enterprise', product_version='4.4.7', product_module='backup_service', category='Technical Issue', subcategory='Performance', priority='high', severity='P1', channel='api', subject='CloudBackup Enterprise throwing ERROR_RATELIMIT_429 during operation', description=\"We're experiencing issues with CloudBackup Enterprise. The system is throwing ERROR_RATELIMIT_429 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-09-30T18:10:04 WARN Rate limit approaching threshold\\n2024-09-30T18:10:04 ERROR ERROR_RATELIMIT_429: Rate limit exceeded\\n2024-09-30T18:10:06 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='grateful', previous_tickets=9, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 9, 30, 21, 34, 40, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['consulted_kb', 'applied_fix', 'created_workaround'], escalated=True, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['authentication', 'api', 'performance', 'error', 'data'], environment='development', business_impact='high', affected_users=114, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000437', created_at=datetime.datetime(2024, 10, 4, 6, 21, 56, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 4, 10, 7, 32, tzinfo=datetime.timezone.utc), customer_id='CUST-00842', customer_tier='starter', organization_id='ORG-324', product='API Gateway', product_version='2.7.4', product_module='cache_layer', category='Technical Issue', subcategory='Performance', priority='high', severity='P1', channel='slack', subject='Performance degradation in API Gateway', description=\"The API Gateway has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_VALIDATION in the logs. This is affecting our entire team's productivity.\", error_logs='2024-10-04T06:21:56 ERROR ERROR_VALIDATION: Database connection lost\\n2024-10-04T06:21:57 INFO Attempting to reconnect...\\n2024-10-04T06:21:59 ERROR Connection failed', stack_trace='at cache_layer.execute(cache_layer.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='neutral', previous_tickets=0, resolution='Root cause identified as Performance issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 10, 4, 10, 7, 32, tzinfo=datetime.timezone.utc), agent_id='AGENT-029', agent_actions=['created_workaround', 'applied_fix', 'escalated_to_specialist'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=False, tags=['security', 'timeout', 'sync'], environment='development', business_impact='medium', affected_users=909, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000438', created_at=datetime.datetime(2023, 4, 23, 15, 25, 11, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 24, 21, 31, 47, tzinfo=datetime.timezone.utc), customer_id='CUST-00358', customer_tier='professional', organization_id='ORG-149', product='DataSync Pro', product_version='3.2.1', product_module='data_validator', category='Technical Issue', subcategory='Integration', priority='medium', severity='P3', channel='slack', subject='Performance degradation in DataSync Pro', description=\"The DataSync Pro has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=6, resolution='Root cause identified as Integration issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 4, 24, 21, 31, 47, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['applied_fix', 'ran_diagnostics', 'consulted_kb'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'timeout', 'api', 'security'], environment='production', business_impact='low', affected_users=24, language='pt', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000439', created_at=datetime.datetime(2024, 3, 7, 0, 28, 8, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 13, 8, 44, 20, tzinfo=datetime.timezone.utc), customer_id='CUST-01184', customer_tier='professional', organization_id='ORG-395', product='API Gateway', product_version='3.0.14', product_module='cache_layer', category='Security', subcategory='Compliance', priority='low', severity='P4', channel='slack', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=0, resolution='Root cause identified as Compliance issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 3, 13, 8, 44, 20, tzinfo=datetime.timezone.utc), agent_id='AGENT-016', agent_actions=['created_workaround', 'checked_config', 'applied_fix'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=False, tags=['database', 'security'], environment='staging', business_impact='low', affected_users=42, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000440', created_at=datetime.datetime(2023, 10, 10, 17, 16, 43, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 10, 18, 41, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-03185', customer_tier='starter', organization_id='ORG-381', product='StreamProcessor', product_version='3.9.8', product_module='event_handler', category='Feature Request', subcategory='Documentation', priority='critical', severity='P0', channel='portal', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-10-10T17:16:43 ERROR ERROR_RATELIMIT_429: Connection timeout after 30s\\n2023-10-10T17:16:44 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='frustrated', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 10, 10, 18, 41, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-006', agent_actions=['verified_resolution', 'viewed_logs', 'created_workaround'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['security', 'authentication'], environment='development', business_impact='low', affected_users=434, language='de', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000441', created_at=datetime.datetime(2024, 7, 23, 22, 35, 21, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 25, 2, 52, 9, tzinfo=datetime.timezone.utc), customer_id='CUST-00135', customer_tier='premium', organization_id='ORG-023', product='StreamProcessor', product_version='4.5.2', product_module='event_handler', category='Feature Request', subcategory='UI/UX', priority='critical', severity='P4', channel='chat', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-07-23T22:35:21 ERROR ERROR_RATELIMIT_429: Database connection lost\\n2024-07-23T22:35:22 INFO Attempting to reconnect...\\n2024-07-23T22:35:24 ERROR Connection failed', stack_trace='', customer_sentiment='satisfied', previous_tickets=6, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 7, 25, 2, 52, 9, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['escalated_to_specialist', 'verified_resolution', 'contacted_customer'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['api', 'sync', 'performance'], environment='production', business_impact='low', affected_users=622, language='it', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000442', created_at=datetime.datetime(2024, 2, 24, 3, 17, 6, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 25, 7, 5, 6, tzinfo=datetime.timezone.utc), customer_id='CUST-02246', customer_tier='professional', organization_id='ORG-479', product='DataSync Pro', product_version='4.5.4', product_module='scheduler', category='Account Management', subcategory='License', priority='medium', severity='P2', channel='email', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-02-24T03:17:06 WARN Rate limit approaching threshold\\n2024-02-24T03:17:06 ERROR ERROR_AUTH_401: Rate limit exceeded\\n2024-02-24T03:17:08 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'scheduler.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='confused', previous_tickets=5, resolution='Applied hotfix version 3.2.2 to address the ERROR_AUTH_401. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 2, 25, 7, 5, 6, tzinfo=datetime.timezone.utc), agent_id='AGENT-050', agent_actions=['checked_config', 'applied_fix'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['sync', 'bug', 'performance'], environment='staging', business_impact='critical', affected_users=41, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000443', created_at=datetime.datetime(2024, 11, 7, 18, 29, 56, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 8, 7, 4, 44, tzinfo=datetime.timezone.utc), customer_id='CUST-00070', customer_tier='professional', organization_id='ORG-062', product='StreamProcessor', product_version='2.9.4', product_module='batch_processor', category='Technical Issue', subcategory='Performance', priority='low', severity='P1', channel='phone', subject='StreamProcessor throwing ERROR_SSL_CERT during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing ERROR_SSL_CERT when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-11-07T18:29:56 ERROR ERROR_SSL_CERT: Connection timeout after 30s\\n2024-11-07T18:29:57 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'batch_processor.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='satisfied', previous_tickets=1, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 11, 8, 7, 4, 44, tzinfo=datetime.timezone.utc), agent_id='AGENT-017', agent_actions=['updated_documentation', 'ran_diagnostics', 'escalated_to_specialist'], escalated=True, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['api', 'data'], environment='sandbox', business_impact='high', affected_users=41, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000444', created_at=datetime.datetime(2024, 1, 17, 4, 41, 7, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 17, 14, 35, 7, tzinfo=datetime.timezone.utc), customer_id='CUST-00263', customer_tier='enterprise', organization_id='ORG-352', product='CloudBackup Enterprise', product_version='2.8.11', product_module='backup_service', category='Security', subcategory='Encryption', priority='low', severity='P1', channel='api', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Getting ERROR_PARSING errors. We need to ensure our system meets compliance requirements.', error_logs='2024-01-17T04:41:07 WARN Rate limit approaching threshold\\n2024-01-17T04:41:07 ERROR ERROR_PARSING: Rate limit exceeded\\n2024-01-17T04:41:09 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='confused', previous_tickets=3, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 1, 17, 14, 35, 7, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['contacted_customer', 'escalated_to_specialist'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=True, tags=['authentication', 'timeout', 'error', 'performance'], environment='test', business_impact='high', affected_users=30, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000445', created_at=datetime.datetime(2023, 2, 8, 9, 51, 22, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 8, 16, 18, 22, tzinfo=datetime.timezone.utc), customer_id='CUST-00298', customer_tier='starter', organization_id='ORG-005', product='DataSync Pro', product_version='3.9.7', product_module='sync_engine', category='Security', subcategory='Authorization', priority='low', severity='P1', channel='email', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=1, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 2, 8, 16, 18, 22, tzinfo=datetime.timezone.utc), agent_id='AGENT-048', agent_actions=['ran_diagnostics', 'consulted_kb'], escalated=True, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['database', 'authentication'], environment='test', business_impact='critical', affected_users=7, language='it', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000446', created_at=datetime.datetime(2023, 3, 6, 17, 31, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 6, 22, 50, 50, tzinfo=datetime.timezone.utc), customer_id='CUST-01786', customer_tier='premium', organization_id='ORG-094', product='DataSync Pro', product_version='3.8.7', product_module='sync_engine', category='Feature Request', subcategory='UI/UX', priority='low', severity='P1', channel='chat', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-03-06T17:31:38 DEBUG Processing request ID-12345\\n2023-03-06T17:31:38 ERROR ERROR_NOTFOUND_404: Invalid request format\\n2023-03-06T17:31:39 INFO Request rejected', stack_trace='Stack trace:\\n  sync_engine::processData() at sync_engine.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='confused', previous_tickets=2, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 3, 6, 22, 50, 50, tzinfo=datetime.timezone.utc), agent_id='AGENT-044', agent_actions=['updated_documentation', 'verified_resolution', 'contacted_customer', 'checked_config', 'consulted_kb'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['api', 'performance', 'security', 'authentication'], environment='staging', business_impact='critical', affected_users=20, language='fr', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000447', created_at=datetime.datetime(2023, 9, 5, 20, 28, 16, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 8, 20, 34, 16, tzinfo=datetime.timezone.utc), customer_id='CUST-01497', customer_tier='professional', organization_id='ORG-335', product='API Gateway', product_version='2.9.9', product_module='rate_limiter', category='Account Management', subcategory='Upgrade', priority='low', severity='P3', channel='chat', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-09-05T20:28:16 DEBUG Processing request ID-12345\\n2023-09-05T20:28:16 ERROR ERROR_PARSING: Invalid request format\\n2023-09-05T20:28:17 INFO Request rejected', stack_trace=\"Traceback (most recent call last):\\n  File 'rate_limiter.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='satisfied', previous_tickets=5, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 9, 8, 20, 34, 16, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['consulted_kb', 'viewed_logs', 'checked_config', 'verified_resolution', 'contacted_customer'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['error', 'configuration', 'authentication'], environment='test', business_impact='high', affected_users=40, language='zh', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000448', created_at=datetime.datetime(2023, 5, 16, 20, 58, 14, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 18, 0, 44, 26, tzinfo=datetime.timezone.utc), customer_id='CUST-00800', customer_tier='enterprise', organization_id='ORG-313', product='StreamProcessor', product_version='3.6.9', product_module='batch_processor', category='Feature Request', subcategory='UI/UX', priority='high', severity='P4', channel='chat', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=7, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 5, 18, 0, 44, 26, tzinfo=datetime.timezone.utc), agent_id='AGENT-037', agent_actions=['contacted_customer', 'ran_diagnostics'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['api', 'configuration', 'security', 'data', 'integration'], environment='staging', business_impact='high', affected_users=328, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000449', created_at=datetime.datetime(2023, 8, 31, 13, 36, 4, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 2, 5, 34, 52, tzinfo=datetime.timezone.utc), customer_id='CUST-03341', customer_tier='premium', organization_id='ORG-315', product='CloudBackup Enterprise', product_version='3.2.15', product_module='backup_service', category='Feature Request', subcategory='New Feature', priority='low', severity='P2', channel='phone', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-08-31T13:36:04 ERROR ERROR_NOTFOUND_404: Connection timeout after 30s\\n2023-08-31T13:36:05 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='angry', previous_tickets=10, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 9, 2, 5, 34, 52, tzinfo=datetime.timezone.utc), agent_id='AGENT-019', agent_actions=['contacted_customer', 'viewed_logs', 'consulted_kb'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=True, tags=['configuration', 'timeout'], environment='sandbox', business_impact='low', affected_users=42, language='zh', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000450', created_at=datetime.datetime(2024, 3, 13, 7, 0, 29, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 17, 17, 48, 29, tzinfo=datetime.timezone.utc), customer_id='CUST-04764', customer_tier='enterprise', organization_id='ORG-057', product='StreamProcessor', product_version='4.0.12', product_module='event_handler', category='Technical Issue', subcategory='Configuration', priority='medium', severity='P4', channel='chat', subject='Performance degradation in StreamProcessor', description=\"The StreamProcessor has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_PERMISSION_403 in the logs. This is affecting our entire team's productivity.\", error_logs='2024-03-13T07:00:29 DEBUG Processing request ID-12345\\n2024-03-13T07:00:29 ERROR ERROR_PERMISSION_403: Invalid request format\\n2024-03-13T07:00:30 INFO Request rejected', stack_trace='Stack trace:\\n  event_handler::processData() at event_handler.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='neutral', previous_tickets=1, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 3, 17, 17, 48, 29, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['escalated_to_specialist', 'created_workaround', 'checked_config', 'ran_diagnostics', 'updated_documentation', 'contacted_customer'], escalated=True, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['performance', 'authentication', 'error'], environment='test', business_impact='high', affected_users=35, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000451', created_at=datetime.datetime(2023, 3, 29, 17, 19, 6, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 29, 20, 21, 30, tzinfo=datetime.timezone.utc), customer_id='CUST-02856', customer_tier='premium', organization_id='ORG-312', product='CloudBackup Enterprise', product_version='4.1.4', product_module='backup_service', category='Data Issue', subcategory='Data Loss', priority='medium', severity='P1', channel='api', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_CORRUPTION appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-03-29T17:19:06 WARN Rate limit approaching threshold\\n2023-03-29T17:19:06 ERROR ERROR_CORRUPTION: Rate limit exceeded\\n2023-03-29T17:19:08 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='angry', previous_tickets=7, resolution='Root cause identified as Data Loss issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 3, 29, 20, 21, 30, tzinfo=datetime.timezone.utc), agent_id='AGENT-042', agent_actions=['created_workaround', 'applied_fix', 'escalated_to_specialist', 'consulted_kb'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['authentication', 'bug', 'data'], environment='sandbox', business_impact='high', affected_users=11, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000452', created_at=datetime.datetime(2023, 11, 19, 10, 10, 23, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 20, 22, 44, 35, tzinfo=datetime.timezone.utc), customer_id='CUST-03569', customer_tier='starter', organization_id='ORG-297', product='API Gateway', product_version='4.4.0', product_module='cache_layer', category='Feature Request', subcategory='Enhancement', priority='low', severity='P2', channel='portal', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-11-19T10:10:23 ERROR ERROR_CONFLICT_409: Connection timeout after 30s\\n2023-11-19T10:10:24 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='satisfied', previous_tickets=6, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 11, 20, 22, 44, 35, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['applied_fix', 'escalated_to_specialist', 'contacted_customer', 'ran_diagnostics', 'updated_documentation'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=True, tags=['configuration', 'error'], environment='staging', business_impact='high', affected_users=48, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000453', created_at=datetime.datetime(2023, 4, 30, 15, 20, 6, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 30, 17, 32, 42, tzinfo=datetime.timezone.utc), customer_id='CUST-02408', customer_tier='starter', organization_id='ORG-304', product='CloudBackup Enterprise', product_version='3.6.8', product_module='encryption_layer', category='Technical Issue', subcategory='Performance', priority='critical', severity='P0', channel='phone', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=6, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 4, 30, 17, 32, 42, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['verified_resolution', 'created_workaround', 'escalated_to_specialist', 'contacted_customer'], escalated=True, transferred_count=1, satisfaction_score=1, resolution_helpful=True, tags=['performance', 'data'], environment='test', business_impact='critical', affected_users=375, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000454', created_at=datetime.datetime(2023, 9, 9, 3, 7, 49, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 11, 5, 25, 13, tzinfo=datetime.timezone.utc), customer_id='CUST-02383', customer_tier='starter', organization_id='ORG-028', product='DataSync Pro', product_version='3.1.12', product_module='sync_engine', category='Data Issue', subcategory='Data Loss', priority='low', severity='P3', channel='api', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_RATELIMIT_429 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-09-09T03:07:49 ERROR ERROR_RATELIMIT_429: Database connection lost\\n2023-09-09T03:07:50 INFO Attempting to reconnect...\\n2023-09-09T03:07:52 ERROR Connection failed', stack_trace='', customer_sentiment='grateful', previous_tickets=1, resolution='Applied hotfix version 3.2.2 to address the ERROR_RATELIMIT_429. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 9, 11, 5, 25, 13, tzinfo=datetime.timezone.utc), agent_id='AGENT-048', agent_actions=['ran_diagnostics', 'consulted_kb', 'checked_config', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['database', 'data', 'bug', 'error'], environment='staging', business_impact='critical', affected_users=7, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000455', created_at=datetime.datetime(2023, 12, 29, 15, 26, 13, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 31, 5, 6, 25, tzinfo=datetime.timezone.utc), customer_id='CUST-02308', customer_tier='enterprise', organization_id='ORG-320', product='DataSync Pro', product_version='3.7.2', product_module='data_validator', category='Technical Issue', subcategory='Compatibility', priority='low', severity='P3', channel='slack', subject='DataSync Pro throwing ERROR_NOTFOUND_404 during operation', description=\"We're experiencing issues with DataSync Pro. The system is throwing ERROR_NOTFOUND_404 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-12-29T15:26:13 ERROR ERROR_NOTFOUND_404: Database connection lost\\n2023-12-29T15:26:14 INFO Attempting to reconnect...\\n2023-12-29T15:26:16 ERROR Connection failed', stack_trace=\"Traceback (most recent call last):\\n  File 'data_validator.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='satisfied', previous_tickets=0, resolution='Root cause identified as Compatibility issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 12, 31, 5, 6, 25, tzinfo=datetime.timezone.utc), agent_id='AGENT-012', agent_actions=['applied_fix', 'contacted_customer'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=False, tags=['api', 'performance', 'bug', 'data', 'database'], environment='test', business_impact='low', affected_users=22, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000456', created_at=datetime.datetime(2024, 7, 29, 16, 52, 26, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 30, 14, 42, 14, tzinfo=datetime.timezone.utc), customer_id='CUST-00896', customer_tier='enterprise', organization_id='ORG-236', product='StreamProcessor', product_version='2.9.1', product_module='error_handler', category='Account Management', subcategory='License', priority='high', severity='P4', channel='slack', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-07-29T16:52:26 ERROR ERROR_CORRUPTION: Connection timeout after 30s\\n2024-07-29T16:52:27 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='grateful', previous_tickets=1, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 7, 30, 14, 42, 14, tzinfo=datetime.timezone.utc), agent_id='AGENT-048', agent_actions=['contacted_customer', 'updated_documentation', 'viewed_logs'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['authentication', 'error', 'configuration'], environment='production', business_impact='low', affected_users=209, language='it', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000457', created_at=datetime.datetime(2024, 5, 2, 11, 33, 12, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 2, 12, 25, 24, tzinfo=datetime.timezone.utc), customer_id='CUST-04061', customer_tier='starter', organization_id='ORG-217', product='StreamProcessor', product_version='2.0.7', product_module='batch_processor', category='Technical Issue', subcategory='Performance', priority='low', severity='P0', channel='email', subject='StreamProcessor throwing ERROR_VALIDATION during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing ERROR_VALIDATION when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-05-02T11:33:12 ERROR ERROR_VALIDATION: Database connection lost\\n2024-05-02T11:33:13 INFO Attempting to reconnect...\\n2024-05-02T11:33:15 ERROR Connection failed', stack_trace='', customer_sentiment='neutral', previous_tickets=0, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 5, 2, 12, 25, 24, tzinfo=datetime.timezone.utc), agent_id='AGENT-017', agent_actions=['applied_fix', 'ran_diagnostics', 'consulted_kb', 'created_workaround', 'contacted_customer'], escalated=True, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['configuration', 'database', 'timeout'], environment='sandbox', business_impact='low', affected_users=4, language='ja', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000458', created_at=datetime.datetime(2024, 4, 28, 17, 48, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 28, 19, 56, 29, tzinfo=datetime.timezone.utc), customer_id='CUST-04162', customer_tier='enterprise', organization_id='ORG-489', product='DataSync Pro', product_version='4.9.5', product_module='sync_engine', category='Data Issue', subcategory='Corruption', priority='critical', severity='P1', channel='api', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=3, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 4, 28, 19, 56, 29, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['updated_documentation', 'checked_config', 'escalated_to_specialist'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['error', 'sync', 'bug', 'security'], environment='sandbox', business_impact='high', affected_users=303, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000459', created_at=datetime.datetime(2024, 7, 16, 13, 7, 23, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 16, 15, 4, 23, tzinfo=datetime.timezone.utc), customer_id='CUST-00500', customer_tier='professional', organization_id='ORG-411', product='API Gateway', product_version='2.6.7', product_module='cache_layer', category='Account Management', subcategory='Billing', priority='high', severity='P0', channel='portal', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=9, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 7, 16, 15, 4, 23, tzinfo=datetime.timezone.utc), agent_id='AGENT-049', agent_actions=['updated_documentation', 'applied_fix'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['configuration', 'authentication', 'error', 'security', 'data'], environment='staging', business_impact='high', affected_users=610, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000460', created_at=datetime.datetime(2023, 4, 20, 6, 57, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 20, 9, 34, 21, tzinfo=datetime.timezone.utc), customer_id='CUST-02417', customer_tier='free', organization_id='ORG-137', product='CloudBackup Enterprise', product_version='2.2.11', product_module='backup_service', category='Data Issue', subcategory='Sync Error', priority='critical', severity='P1', channel='phone', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_MEMORY_OOM appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-04-20T06:57:45 WARN Rate limit approaching threshold\\n2023-04-20T06:57:45 ERROR ERROR_MEMORY_OOM: Rate limit exceeded\\n2023-04-20T06:57:47 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='neutral', previous_tickets=7, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 4, 20, 9, 34, 21, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['contacted_customer', 'viewed_logs'], escalated=True, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['integration', 'performance'], environment='test', business_impact='high', affected_users=331, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000461', created_at=datetime.datetime(2023, 3, 31, 15, 30, 36, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 1, 20, 3, tzinfo=datetime.timezone.utc), customer_id='CUST-01577', customer_tier='starter', organization_id='ORG-310', product='CloudBackup Enterprise', product_version='2.8.6', product_module='backup_service', category='Data Issue', subcategory='Import/Export', priority='low', severity='P2', channel='phone', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_TIMEOUT_429 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-03-31T15:30:36 DEBUG Processing request ID-12345\\n2023-03-31T15:30:36 ERROR ERROR_TIMEOUT_429: Invalid request format\\n2023-03-31T15:30:37 INFO Request rejected', stack_trace='', customer_sentiment='angry', previous_tickets=10, resolution='Root cause identified as Import/Export issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 4, 1, 20, 3, tzinfo=datetime.timezone.utc), agent_id='AGENT-034', agent_actions=['escalated_to_specialist', 'consulted_kb', 'created_workaround'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['bug', 'configuration', 'timeout'], environment='staging', business_impact='low', affected_users=25, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000462', created_at=datetime.datetime(2023, 7, 18, 11, 21, 49, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 18, 18, 5, 1, tzinfo=datetime.timezone.utc), customer_id='CUST-02359', customer_tier='premium', organization_id='ORG-419', product='CloudBackup Enterprise', product_version='3.2.11', product_module='compression_engine', category='Technical Issue', subcategory='Integration', priority='high', severity='P2', channel='email', subject='CloudBackup Enterprise throwing ERROR_VALIDATION during operation', description=\"We're experiencing issues with CloudBackup Enterprise. The system is throwing ERROR_VALIDATION when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-07-18T11:21:49 DEBUG Processing request ID-12345\\n2023-07-18T11:21:49 ERROR ERROR_VALIDATION: Invalid request format\\n2023-07-18T11:21:50 INFO Request rejected', stack_trace='Stack trace:\\n  compression_engine::processData() at compression_engine.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='neutral', previous_tickets=10, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 7, 18, 18, 5, 1, tzinfo=datetime.timezone.utc), agent_id='AGENT-036', agent_actions=['updated_documentation', 'checked_config', 'viewed_logs', 'created_workaround', 'applied_fix', 'ran_diagnostics'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['error', 'bug', 'authentication'], environment='staging', business_impact='low', affected_users=2, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000463', created_at=datetime.datetime(2023, 8, 9, 3, 34, 3, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 10, 1, 32, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-00453', customer_tier='premium', organization_id='ORG-400', product='StreamProcessor', product_version='3.3.4', product_module='monitoring', category='Technical Issue', subcategory='Configuration', priority='high', severity='P2', channel='phone', subject='Performance degradation in StreamProcessor', description=\"The StreamProcessor has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_AUTH_401 in the logs. This is affecting our entire team's productivity.\", error_logs='2023-08-09T03:34:03 DEBUG Processing request ID-12345\\n2023-08-09T03:34:03 ERROR ERROR_AUTH_401: Invalid request format\\n2023-08-09T03:34:04 INFO Request rejected', stack_trace='at monitoring.execute(monitoring.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='confused', previous_tickets=1, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 8, 10, 1, 32, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-029', agent_actions=['checked_config', 'verified_resolution', 'ran_diagnostics', 'consulted_kb', 'updated_documentation', 'escalated_to_specialist'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['integration', 'timeout', 'api', 'error', 'security'], environment='test', business_impact='critical', affected_users=12, language='ja', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000464', created_at=datetime.datetime(2024, 8, 23, 6, 7, 55, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 23, 12, 0, 7, tzinfo=datetime.timezone.utc), customer_id='CUST-00569', customer_tier='free', organization_id='ORG-343', product='DataSync Pro', product_version='2.1.5', product_module='sync_engine', category='Security', subcategory='Vulnerability', priority='low', severity='P1', channel='chat', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_INVALID_400 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-08-23T06:07:55 ERROR ERROR_INVALID_400: Database connection lost\\n2024-08-23T06:07:56 INFO Attempting to reconnect...\\n2024-08-23T06:07:58 ERROR Connection failed', stack_trace='ERROR: sync_engine.service.ServiceException: Failed to process request\\n\\tat sync_engine.handler.process(sync_engine.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='angry', previous_tickets=8, resolution='Applied hotfix version 3.2.2 to address the ERROR_INVALID_400. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 8, 23, 12, 0, 7, tzinfo=datetime.timezone.utc), agent_id='AGENT-009', agent_actions=['escalated_to_specialist', 'created_workaround', 'updated_documentation', 'checked_config', 'applied_fix', 'viewed_logs'], escalated=True, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['authentication', 'integration', 'database', 'data'], environment='staging', business_impact='low', affected_users=18, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000465', created_at=datetime.datetime(2024, 9, 9, 4, 49, 14, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 12, 11, 52, 50, tzinfo=datetime.timezone.utc), customer_id='CUST-04414', customer_tier='premium', organization_id='ORG-216', product='API Gateway', product_version='3.0.5', product_module='cache_layer', category='Account Management', subcategory='Access Control', priority='high', severity='P4', channel='portal', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-09-09T04:49:14 DEBUG Processing request ID-12345\\n2024-09-09T04:49:14 ERROR ERROR_MEMORY_OOM: Invalid request format\\n2024-09-09T04:49:15 INFO Request rejected', stack_trace='Stack trace:\\n  cache_layer::processData() at cache_layer.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='satisfied', previous_tickets=3, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 9, 12, 11, 52, 50, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['applied_fix', 'viewed_logs'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['error', 'security'], environment='test', business_impact='high', affected_users=538, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000466', created_at=datetime.datetime(2023, 7, 30, 18, 41, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 1, 13, 42, 21, tzinfo=datetime.timezone.utc), customer_id='CUST-03516', customer_tier='enterprise', organization_id='ORG-281', product='CloudBackup Enterprise', product_version='4.4.3', product_module='encryption_layer', category='Technical Issue', subcategory='Integration', priority='medium', severity='P3', channel='portal', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_SERVER_500 in the logs. This is affecting our entire team's productivity.\", error_logs='2023-07-30T18:41:45 DEBUG Processing request ID-12345\\n2023-07-30T18:41:45 ERROR ERROR_SERVER_500: Invalid request format\\n2023-07-30T18:41:46 INFO Request rejected', stack_trace='', customer_sentiment='frustrated', previous_tickets=5, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 8, 1, 13, 42, 21, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['created_workaround', 'updated_documentation', 'viewed_logs', 'verified_resolution', 'contacted_customer', 'ran_diagnostics'], escalated=True, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['authentication', 'sync', 'api'], environment='sandbox', business_impact='critical', affected_users=9, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000467', created_at=datetime.datetime(2024, 12, 2, 4, 23, 57, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 3, 3, 31, 9, tzinfo=datetime.timezone.utc), customer_id='CUST-01947', customer_tier='enterprise', organization_id='ORG-398', product='CloudBackup Enterprise', product_version='4.7.2', product_module='restore_module', category='Technical Issue', subcategory='Bug', priority='critical', severity='P3', channel='slack', subject='CloudBackup Enterprise throwing ERROR_AUTH_401 during operation', description=\"We're experiencing issues with CloudBackup Enterprise. The system is throwing ERROR_AUTH_401 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-12-02T04:23:57 DEBUG Processing request ID-12345\\n2024-12-02T04:23:57 ERROR ERROR_AUTH_401: Invalid request format\\n2024-12-02T04:23:58 INFO Request rejected', stack_trace=\"Traceback (most recent call last):\\n  File 'restore_module.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='frustrated', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 12, 3, 3, 31, 9, tzinfo=datetime.timezone.utc), agent_id='AGENT-016', agent_actions=['verified_resolution', 'checked_config', 'ran_diagnostics', 'viewed_logs', 'escalated_to_specialist', 'applied_fix'], escalated=True, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'timeout', 'security', 'integration', 'bug'], environment='staging', business_impact='medium', affected_users=696, language='de', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000468', created_at=datetime.datetime(2023, 7, 6, 20, 13, 35, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 9, 14, 1, 35, tzinfo=datetime.timezone.utc), customer_id='CUST-03046', customer_tier='professional', organization_id='ORG-193', product='DataSync Pro', product_version='3.0.4', product_module='sync_engine', category='Account Management', subcategory='Billing', priority='medium', severity='P4', channel='email', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-07-06T20:13:35 ERROR ERROR_AUTH_401: Database connection lost\\n2023-07-06T20:13:36 INFO Attempting to reconnect...\\n2023-07-06T20:13:38 ERROR Connection failed', stack_trace='', customer_sentiment='neutral', previous_tickets=1, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 7, 9, 14, 1, 35, tzinfo=datetime.timezone.utc), agent_id='AGENT-026', agent_actions=['created_workaround', 'ran_diagnostics'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['performance', 'sync'], environment='sandbox', business_impact='high', affected_users=49, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000469', created_at=datetime.datetime(2023, 4, 9, 17, 13, 10, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 11, 18, 27, 34, tzinfo=datetime.timezone.utc), customer_id='CUST-00527', customer_tier='enterprise', organization_id='ORG-414', product='Analytics Dashboard', product_version='2.3.0', product_module='data_aggregator', category='Account Management', subcategory='Billing', priority='critical', severity='P4', channel='email', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-04-09T17:13:10 DEBUG Processing request ID-12345\\n2023-04-09T17:13:10 ERROR ERROR_CONNECTION_REFUSED: Invalid request format\\n2023-04-09T17:13:11 INFO Request rejected', stack_trace='Stack trace:\\n  data_aggregator::processData() at data_aggregator.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='satisfied', previous_tickets=8, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 4, 11, 18, 27, 34, tzinfo=datetime.timezone.utc), agent_id='AGENT-045', agent_actions=['ran_diagnostics', 'applied_fix', 'updated_documentation'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['sync', 'timeout'], environment='development', business_impact='low', affected_users=50, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000470', created_at=datetime.datetime(2024, 3, 19, 21, 56, 44, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 19, 23, 26, 44, tzinfo=datetime.timezone.utc), customer_id='CUST-01121', customer_tier='professional', organization_id='ORG-228', product='API Gateway', product_version='3.3.1', product_module='cache_layer', category='Account Management', subcategory='License', priority='critical', severity='P1', channel='api', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-03-19T21:56:44 WARN Rate limit approaching threshold\\n2024-03-19T21:56:44 ERROR ERROR_CONFLICT_409: Rate limit exceeded\\n2024-03-19T21:56:46 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='angry', previous_tickets=2, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 3, 19, 23, 26, 44, tzinfo=datetime.timezone.utc), agent_id='AGENT-047', agent_actions=['escalated_to_specialist', 'consulted_kb', 'viewed_logs', 'created_workaround'], escalated=True, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['database', 'sync', 'security', 'timeout'], environment='development', business_impact='medium', affected_users=292, language='zh', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000471', created_at=datetime.datetime(2023, 9, 23, 20, 34, 31, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 23, 23, 25, 31, tzinfo=datetime.timezone.utc), customer_id='CUST-03910', customer_tier='starter', organization_id='ORG-372', product='CloudBackup Enterprise', product_version='2.2.15', product_module='compression_engine', category='Security', subcategory='Encryption', priority='critical', severity='P1', channel='email', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Getting ERROR_MEMORY_OOM errors. We need to ensure our system meets compliance requirements.', error_logs='2023-09-23T20:34:31 ERROR ERROR_MEMORY_OOM: Database connection lost\\n2023-09-23T20:34:32 INFO Attempting to reconnect...\\n2023-09-23T20:34:34 ERROR Connection failed', stack_trace='ERROR: compression_engine.service.ServiceException: Failed to process request\\n\\tat compression_engine.handler.process(compression_engine.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='frustrated', previous_tickets=7, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 9, 23, 23, 25, 31, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['created_workaround', 'consulted_kb', 'viewed_logs', 'ran_diagnostics'], escalated=True, transferred_count=1, satisfaction_score=2, resolution_helpful=True, tags=['database', 'security'], environment='sandbox', business_impact='high', affected_users=226, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000472', created_at=datetime.datetime(2024, 8, 7, 4, 47, 27, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 7, 8, 39, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-02568', customer_tier='starter', organization_id='ORG-465', product='CloudBackup Enterprise', product_version='3.5.14', product_module='restore_module', category='Technical Issue', subcategory='Configuration', priority='critical', severity='P1', channel='phone', subject='CloudBackup Enterprise throwing ERROR_NOTFOUND_404 during operation', description=\"We're experiencing issues with CloudBackup Enterprise. The system is throwing ERROR_NOTFOUND_404 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-08-07T04:47:27 DEBUG Processing request ID-12345\\n2024-08-07T04:47:27 ERROR ERROR_NOTFOUND_404: Invalid request format\\n2024-08-07T04:47:28 INFO Request rejected', stack_trace='', customer_sentiment='angry', previous_tickets=10, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 8, 7, 8, 39, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-046', agent_actions=['updated_documentation', 'checked_config'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['database', 'bug', 'security'], environment='production', business_impact='critical', affected_users=818, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000473', created_at=datetime.datetime(2024, 5, 2, 2, 57, 20, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 2, 5, 57, 56, tzinfo=datetime.timezone.utc), customer_id='CUST-02279', customer_tier='premium', organization_id='ORG-332', product='StreamProcessor', product_version='2.8.8', product_module='batch_processor', category='Security', subcategory='Compliance', priority='medium', severity='P1', channel='email', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Getting ERROR_CORRUPTION errors. We need to ensure our system meets compliance requirements.', error_logs='2024-05-02T02:57:20 ERROR ERROR_CORRUPTION: Database connection lost\\n2024-05-02T02:57:21 INFO Attempting to reconnect...\\n2024-05-02T02:57:23 ERROR Connection failed', stack_trace='', customer_sentiment='confused', previous_tickets=8, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 5, 2, 5, 57, 56, tzinfo=datetime.timezone.utc), agent_id='AGENT-013', agent_actions=['applied_fix', 'ran_diagnostics', 'updated_documentation', 'consulted_kb', 'contacted_customer', 'viewed_logs'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['authentication', 'configuration'], environment='test', business_impact='high', affected_users=4, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000474', created_at=datetime.datetime(2023, 5, 27, 19, 17, 55, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 27, 20, 34, 43, tzinfo=datetime.timezone.utc), customer_id='CUST-03394', customer_tier='enterprise', organization_id='ORG-018', product='CloudBackup Enterprise', product_version='3.4.14', product_module='compression_engine', category='Account Management', subcategory='Billing', priority='high', severity='P0', channel='portal', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-05-27T19:17:55 WARN Rate limit approaching threshold\\n2023-05-27T19:17:55 ERROR ERROR_MEMORY_OOM: Rate limit exceeded\\n2023-05-27T19:17:57 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='neutral', previous_tickets=10, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 5, 27, 20, 34, 43, tzinfo=datetime.timezone.utc), agent_id='AGENT-009', agent_actions=['created_workaround', 'applied_fix', 'verified_resolution', 'consulted_kb'], escalated=True, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['data', 'database', 'performance'], environment='development', business_impact='low', affected_users=601, language='pt', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000475', created_at=datetime.datetime(2024, 1, 19, 0, 48, 52, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 19, 1, 13, 28, tzinfo=datetime.timezone.utc), customer_id='CUST-00804', customer_tier='free', organization_id='ORG-013', product='StreamProcessor', product_version='4.8.8', product_module='monitoring', category='Technical Issue', subcategory='Integration', priority='critical', severity='P0', channel='phone', subject='StreamProcessor throwing ERROR_DEADLOCK during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing ERROR_DEADLOCK when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-01-19T00:48:52 WARN Rate limit approaching threshold\\n2024-01-19T00:48:52 ERROR ERROR_DEADLOCK: Rate limit exceeded\\n2024-01-19T00:48:54 INFO Backing off for 60 seconds', stack_trace='ERROR: monitoring.service.ServiceException: Failed to process request\\n\\tat monitoring.handler.process(monitoring.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='grateful', previous_tickets=6, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 1, 19, 1, 13, 28, tzinfo=datetime.timezone.utc), agent_id='AGENT-048', agent_actions=['verified_resolution', 'updated_documentation', 'escalated_to_specialist'], escalated=False, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['security', 'configuration'], environment='production', business_impact='medium', affected_users=43, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000476', created_at=datetime.datetime(2024, 8, 20, 5, 31, 51, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 20, 10, 22, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-04422', customer_tier='starter', organization_id='ORG-273', product='DataSync Pro', product_version='3.8.3', product_module='api_connector', category='Security', subcategory='Encryption', priority='medium', severity='P2', channel='email', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_PARSING errors. We need to ensure our system meets compliance requirements.', error_logs='2024-08-20T05:31:51 ERROR ERROR_PARSING: Database connection lost\\n2024-08-20T05:31:52 INFO Attempting to reconnect...\\n2024-08-20T05:31:54 ERROR Connection failed', stack_trace='', customer_sentiment='neutral', previous_tickets=4, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 8, 20, 10, 22, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-005', agent_actions=['ran_diagnostics', 'updated_documentation', 'contacted_customer', 'checked_config'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['security', 'integration', 'data'], environment='development', business_impact='low', affected_users=20, language='ja', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000477', created_at=datetime.datetime(2023, 1, 18, 22, 56, 51, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 19, 0, 23, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-02145', customer_tier='starter', organization_id='ORG-357', product='DataSync Pro', product_version='2.3.12', product_module='scheduler', category='Data Issue', subcategory='Validation', priority='critical', severity='P0', channel='portal', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_MEMORY_OOM appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-01-18T22:56:51 WARN Rate limit approaching threshold\\n2023-01-18T22:56:51 ERROR ERROR_MEMORY_OOM: Rate limit exceeded\\n2023-01-18T22:56:53 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='frustrated', previous_tickets=5, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 1, 19, 0, 23, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-019', agent_actions=['viewed_logs', 'contacted_customer', 'verified_resolution', 'created_workaround'], escalated=True, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['bug', 'database', 'error'], environment='test', business_impact='medium', affected_users=393, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000478', created_at=datetime.datetime(2023, 8, 3, 22, 41, 16, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 6, 3, 25, 40, tzinfo=datetime.timezone.utc), customer_id='CUST-04965', customer_tier='enterprise', organization_id='ORG-152', product='API Gateway', product_version='3.3.13', product_module='request_router', category='Feature Request', subcategory='Enhancement', priority='low', severity='P3', channel='portal', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-08-03T22:41:16 ERROR ERROR_RATELIMIT_429: Database connection lost\\n2023-08-03T22:41:17 INFO Attempting to reconnect...\\n2023-08-03T22:41:19 ERROR Connection failed', stack_trace='ERROR: request_router.service.ServiceException: Failed to process request\\n\\tat request_router.handler.process(request_router.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='grateful', previous_tickets=0, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 8, 6, 3, 25, 40, tzinfo=datetime.timezone.utc), agent_id='AGENT-020', agent_actions=['viewed_logs', 'created_workaround', 'applied_fix'], escalated=True, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['sync', 'timeout'], environment='test', business_impact='critical', affected_users=22, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000479', created_at=datetime.datetime(2024, 11, 9, 22, 9, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 13, 2, 57, 9, tzinfo=datetime.timezone.utc), customer_id='CUST-02722', customer_tier='premium', organization_id='ORG-380', product='Analytics Dashboard', product_version='3.4.15', product_module='visualization', category='Security', subcategory='Encryption', priority='high', severity='P4', channel='phone', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=2, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 11, 13, 2, 57, 9, tzinfo=datetime.timezone.utc), agent_id='AGENT-019', agent_actions=['created_workaround', 'applied_fix', 'contacted_customer'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['integration', 'security', 'error', 'configuration'], environment='test', business_impact='medium', affected_users=812, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000480', created_at=datetime.datetime(2024, 11, 28, 5, 53, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 28, 7, 0, 17, tzinfo=datetime.timezone.utc), customer_id='CUST-04709', customer_tier='premium', organization_id='ORG-146', product='API Gateway', product_version='4.6.6', product_module='request_router', category='Account Management', subcategory='Subscription', priority='medium', severity='P0', channel='slack', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-11-28T05:53:41 DEBUG Processing request ID-12345\\n2024-11-28T05:53:41 ERROR ERROR_RATELIMIT_429: Invalid request format\\n2024-11-28T05:53:42 INFO Request rejected', stack_trace=\"Traceback (most recent call last):\\n  File 'request_router.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='angry', previous_tickets=3, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 11, 28, 7, 0, 17, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['applied_fix', 'updated_documentation', 'escalated_to_specialist'], escalated=True, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['sync', 'integration', 'data'], environment='sandbox', business_impact='medium', affected_users=26, language='ja', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000481', created_at=datetime.datetime(2023, 12, 7, 23, 39, 24, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 8, 3, 15, 24, tzinfo=datetime.timezone.utc), customer_id='CUST-04932', customer_tier='starter', organization_id='ORG-403', product='Analytics Dashboard', product_version='4.3.13', product_module='report_builder', category='Feature Request', subcategory='Documentation', priority='low', severity='P0', channel='slack', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-12-07T23:39:24 ERROR ERROR_NOTFOUND_404: Database connection lost\\n2023-12-07T23:39:25 INFO Attempting to reconnect...\\n2023-12-07T23:39:27 ERROR Connection failed', stack_trace='at report_builder.execute(report_builder.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='confused', previous_tickets=0, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 12, 8, 3, 15, 24, tzinfo=datetime.timezone.utc), agent_id='AGENT-006', agent_actions=['escalated_to_specialist', 'verified_resolution', 'ran_diagnostics', 'updated_documentation'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['integration', 'sync', 'api', 'data'], environment='sandbox', business_impact='high', affected_users=23, language='pt', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000482', created_at=datetime.datetime(2023, 10, 19, 4, 9, 30, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 21, 16, 52, 6, tzinfo=datetime.timezone.utc), customer_id='CUST-02225', customer_tier='enterprise', organization_id='ORG-081', product='API Gateway', product_version='4.4.15', product_module='request_router', category='Account Management', subcategory='Upgrade', priority='critical', severity='P4', channel='phone', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-10-19T04:09:30 WARN Rate limit approaching threshold\\n2023-10-19T04:09:30 ERROR ERROR_NOTFOUND_404: Rate limit exceeded\\n2023-10-19T04:09:32 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'request_router.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='neutral', previous_tickets=4, resolution='Applied hotfix version 3.2.2 to address the ERROR_NOTFOUND_404. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 10, 21, 16, 52, 6, tzinfo=datetime.timezone.utc), agent_id='AGENT-001', agent_actions=['created_workaround', 'verified_resolution', 'ran_diagnostics'], escalated=True, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['authentication', 'configuration'], environment='staging', business_impact='high', affected_users=307, language='pt', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000483', created_at=datetime.datetime(2023, 1, 5, 23, 19, 46, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 6, 9, 50, 22, tzinfo=datetime.timezone.utc), customer_id='CUST-04596', customer_tier='free', organization_id='ORG-351', product='Analytics Dashboard', product_version='3.7.11', product_module='visualization', category='Technical Issue', subcategory='Integration', priority='high', severity='P2', channel='api', subject='Analytics Dashboard throwing ERROR_VALIDATION during operation', description=\"We're experiencing issues with Analytics Dashboard. The system is throwing ERROR_VALIDATION when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-01-05T23:19:46 ERROR ERROR_VALIDATION: Connection timeout after 30s\\n2023-01-05T23:19:47 RETRY_FAILED: Max retries exceeded', stack_trace='Stack trace:\\n  visualization::processData() at visualization.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='grateful', previous_tickets=3, resolution='Root cause identified as Integration issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 1, 6, 9, 50, 22, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['contacted_customer', 'created_workaround', 'viewed_logs', 'updated_documentation', 'ran_diagnostics'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=False, tags=['integration', 'bug', 'api', 'timeout'], environment='test', business_impact='critical', affected_users=509, language='zh', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000484', created_at=datetime.datetime(2024, 10, 20, 20, 14, 32, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 21, 22, 0, 44, tzinfo=datetime.timezone.utc), customer_id='CUST-03360', customer_tier='premium', organization_id='ORG-146', product='Analytics Dashboard', product_version='3.0.6', product_module='visualization', category='Account Management', subcategory='Upgrade', priority='high', severity='P4', channel='slack', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-10-20T20:14:32 DEBUG Processing request ID-12345\\n2024-10-20T20:14:32 ERROR ERROR_INVALID_400: Invalid request format\\n2024-10-20T20:14:33 INFO Request rejected', stack_trace='', customer_sentiment='confused', previous_tickets=5, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 10, 21, 22, 0, 44, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['verified_resolution', 'applied_fix', 'created_workaround', 'ran_diagnostics', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['database', 'sync', 'error'], environment='development', business_impact='medium', affected_users=466, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000485', created_at=datetime.datetime(2023, 11, 19, 20, 17, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 19, 22, 5, 3, tzinfo=datetime.timezone.utc), customer_id='CUST-02541', customer_tier='professional', organization_id='ORG-368', product='DataSync Pro', product_version='3.3.7', product_module='sync_engine', category='Account Management', subcategory='Access Control', priority='high', severity='P0', channel='api', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-11-19T20:17:39 DEBUG Processing request ID-12345\\n2023-11-19T20:17:39 ERROR ERROR_CORRUPTION: Invalid request format\\n2023-11-19T20:17:40 INFO Request rejected', stack_trace='', customer_sentiment='frustrated', previous_tickets=1, resolution='Root cause identified as Access Control issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 11, 19, 22, 5, 3, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['applied_fix', 'consulted_kb'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=False, tags=['integration', 'security', 'bug'], environment='test', business_impact='medium', affected_users=340, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000486', created_at=datetime.datetime(2023, 2, 25, 19, 8, 27, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 25, 23, 10, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-01344', customer_tier='premium', organization_id='ORG-052', product='CloudBackup Enterprise', product_version='2.9.12', product_module='backup_service', category='Security', subcategory='Encryption', priority='critical', severity='P2', channel='chat', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Getting ERROR_VALIDATION errors. We need to ensure our system meets compliance requirements.', error_logs='2023-02-25T19:08:27 ERROR ERROR_VALIDATION: Database connection lost\\n2023-02-25T19:08:28 INFO Attempting to reconnect...\\n2023-02-25T19:08:30 ERROR Connection failed', stack_trace='ERROR: backup_service.service.ServiceException: Failed to process request\\n\\tat backup_service.handler.process(backup_service.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='satisfied', previous_tickets=9, resolution='Root cause identified as Encryption issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 2, 25, 23, 10, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-024', agent_actions=['created_workaround', 'viewed_logs'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=False, tags=['api', 'authentication', 'database', 'security'], environment='staging', business_impact='critical', affected_users=426, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000487', created_at=datetime.datetime(2023, 6, 2, 13, 8, 46, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 3, 1, 29, 46, tzinfo=datetime.timezone.utc), customer_id='CUST-04417', customer_tier='premium', organization_id='ORG-253', product='StreamProcessor', product_version='3.4.0', product_module='batch_processor', category='Feature Request', subcategory='UI/UX', priority='critical', severity='P3', channel='email', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-06-02T13:08:46 ERROR ERROR_SERVER_500: Connection timeout after 30s\\n2023-06-02T13:08:47 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='frustrated', previous_tickets=1, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 6, 3, 1, 29, 46, tzinfo=datetime.timezone.utc), agent_id='AGENT-023', agent_actions=['created_workaround', 'verified_resolution', 'contacted_customer', 'consulted_kb'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['error', 'api', 'performance'], environment='staging', business_impact='low', affected_users=713, language='de', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000488', created_at=datetime.datetime(2023, 9, 27, 1, 41, 5, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 27, 5, 48, 17, tzinfo=datetime.timezone.utc), customer_id='CUST-04366', customer_tier='starter', organization_id='ORG-365', product='CloudBackup Enterprise', product_version='2.1.5', product_module='encryption_layer', category='Feature Request', subcategory='API', priority='medium', severity='P0', channel='email', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=2, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 9, 27, 5, 48, 17, tzinfo=datetime.timezone.utc), agent_id='AGENT-015', agent_actions=['escalated_to_specialist', 'applied_fix'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['sync', 'api', 'configuration'], environment='sandbox', business_impact='medium', affected_users=43, language='zh', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000489', created_at=datetime.datetime(2023, 6, 23, 22, 21, 7, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 24, 18, 2, 31, tzinfo=datetime.timezone.utc), customer_id='CUST-03689', customer_tier='starter', organization_id='ORG-382', product='Analytics Dashboard', product_version='4.4.10', product_module='visualization', category='Security', subcategory='Vulnerability', priority='critical', severity='P3', channel='slack', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_PERMISSION_403 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-06-23T22:21:07 ERROR ERROR_PERMISSION_403: Database connection lost\\n2023-06-23T22:21:08 INFO Attempting to reconnect...\\n2023-06-23T22:21:10 ERROR Connection failed', stack_trace='', customer_sentiment='grateful', previous_tickets=10, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 6, 24, 18, 2, 31, tzinfo=datetime.timezone.utc), agent_id='AGENT-016', agent_actions=['ran_diagnostics', 'viewed_logs', 'escalated_to_specialist', 'applied_fix', 'checked_config'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=False, tags=['bug', 'error'], environment='staging', business_impact='low', affected_users=985, language='zh', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000490', created_at=datetime.datetime(2024, 7, 6, 14, 38, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 6, 17, 9, 57, tzinfo=datetime.timezone.utc), customer_id='CUST-03134', customer_tier='free', organization_id='ORG-135', product='DataSync Pro', product_version='2.4.13', product_module='data_validator', category='Feature Request', subcategory='New Feature', priority='medium', severity='P1', channel='api', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-07-06T14:38:45 ERROR ERROR_TIMEOUT_429: Connection timeout after 30s\\n2024-07-06T14:38:46 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='angry', previous_tickets=10, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 7, 6, 17, 9, 57, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['verified_resolution', 'ran_diagnostics'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['api', 'sync', 'timeout', 'error'], environment='sandbox', business_impact='critical', affected_users=35, language='pt', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000491', created_at=datetime.datetime(2023, 12, 8, 14, 18, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 8, 18, 57, 41, tzinfo=datetime.timezone.utc), customer_id='CUST-04477', customer_tier='starter', organization_id='ORG-433', product='API Gateway', product_version='3.3.1', product_module='auth_service', category='Data Issue', subcategory='Sync Error', priority='medium', severity='P0', channel='chat', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_CORRUPTION appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-12-08T14:18:41 DEBUG Processing request ID-12345\\n2023-12-08T14:18:41 ERROR ERROR_CORRUPTION: Invalid request format\\n2023-12-08T14:18:42 INFO Request rejected', stack_trace='at auth_service.execute(auth_service.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='satisfied', previous_tickets=0, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 12, 8, 18, 57, 41, tzinfo=datetime.timezone.utc), agent_id='AGENT-046', agent_actions=['checked_config', 'contacted_customer'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['error', 'database', 'security', 'sync', 'bug'], environment='development', business_impact='critical', affected_users=11, language='de', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000492', created_at=datetime.datetime(2024, 11, 8, 6, 15, 1, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 8, 8, 39, 1, tzinfo=datetime.timezone.utc), customer_id='CUST-03239', customer_tier='enterprise', organization_id='ORG-081', product='API Gateway', product_version='4.8.15', product_module='auth_service', category='Data Issue', subcategory='Data Loss', priority='critical', severity='P1', channel='api', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_RATELIMIT_429 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-11-08T06:15:01 ERROR ERROR_RATELIMIT_429: Database connection lost\\n2024-11-08T06:15:02 INFO Attempting to reconnect...\\n2024-11-08T06:15:04 ERROR Connection failed', stack_trace='ERROR: auth_service.service.ServiceException: Failed to process request\\n\\tat auth_service.handler.process(auth_service.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='satisfied', previous_tickets=7, resolution='Applied hotfix version 3.2.2 to address the ERROR_RATELIMIT_429. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 11, 8, 8, 39, 1, tzinfo=datetime.timezone.utc), agent_id='AGENT-018', agent_actions=['escalated_to_specialist', 'applied_fix', 'ran_diagnostics'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['timeout', 'data', 'error', 'bug'], environment='test', business_impact='low', affected_users=679, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000493', created_at=datetime.datetime(2023, 4, 26, 17, 41, 56, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 27, 15, 11, 56, tzinfo=datetime.timezone.utc), customer_id='CUST-01246', customer_tier='free', organization_id='ORG-139', product='DataSync Pro', product_version='3.9.10', product_module='sync_engine', category='Feature Request', subcategory='Documentation', priority='low', severity='P2', channel='phone', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=5, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 4, 27, 15, 11, 56, tzinfo=datetime.timezone.utc), agent_id='AGENT-023', agent_actions=['updated_documentation', 'escalated_to_specialist'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=True, tags=['integration', 'database'], environment='development', business_impact='medium', affected_users=5, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000494', created_at=datetime.datetime(2023, 3, 15, 13, 13, 34, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 16, 19, 18, 58, tzinfo=datetime.timezone.utc), customer_id='CUST-01878', customer_tier='free', organization_id='ORG-333', product='StreamProcessor', product_version='4.7.5', product_module='event_handler', category='Data Issue', subcategory='Import/Export', priority='low', severity='P2', channel='slack', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_SERVER_500 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-03-15T13:13:34 ERROR ERROR_SERVER_500: Database connection lost\\n2023-03-15T13:13:35 INFO Attempting to reconnect...\\n2023-03-15T13:13:37 ERROR Connection failed', stack_trace='', customer_sentiment='confused', previous_tickets=3, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 3, 16, 19, 18, 58, tzinfo=datetime.timezone.utc), agent_id='AGENT-010', agent_actions=['contacted_customer', 'consulted_kb'], escalated=True, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['integration', 'performance', 'data', 'security'], environment='staging', business_impact='high', affected_users=36, language='pt', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000495', created_at=datetime.datetime(2023, 6, 10, 21, 52, 7, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 11, 6, 59, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-01533', customer_tier='starter', organization_id='ORG-013', product='StreamProcessor', product_version='4.9.15', product_module='event_handler', category='Security', subcategory='Compliance', priority='low', severity='P1', channel='phone', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Getting ERROR_VALIDATION errors. We need to ensure our system meets compliance requirements.', error_logs='2023-06-10T21:52:07 ERROR ERROR_VALIDATION: Connection timeout after 30s\\n2023-06-10T21:52:08 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='satisfied', previous_tickets=9, resolution='Root cause identified as Compliance issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 6, 11, 6, 59, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-050', agent_actions=['escalated_to_specialist', 'contacted_customer', 'viewed_logs'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['bug', 'configuration', 'api'], environment='staging', business_impact='critical', affected_users=8, language='ja', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000496', created_at=datetime.datetime(2024, 7, 28, 21, 10, 54, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 29, 9, 34, 54, tzinfo=datetime.timezone.utc), customer_id='CUST-02986', customer_tier='starter', organization_id='ORG-153', product='StreamProcessor', product_version='3.9.2', product_module='monitoring', category='Data Issue', subcategory='Data Loss', priority='high', severity='P2', channel='portal', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_PARSING appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-07-28T21:10:54 ERROR ERROR_PARSING: Database connection lost\\n2024-07-28T21:10:55 INFO Attempting to reconnect...\\n2024-07-28T21:10:57 ERROR Connection failed', stack_trace='', customer_sentiment='confused', previous_tickets=9, resolution='Applied hotfix version 3.2.2 to address the ERROR_PARSING. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 7, 29, 9, 34, 54, tzinfo=datetime.timezone.utc), agent_id='AGENT-044', agent_actions=['contacted_customer', 'consulted_kb', 'viewed_logs'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['error', 'timeout', 'bug', 'integration'], environment='test', business_impact='low', affected_users=57, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000497', created_at=datetime.datetime(2024, 3, 9, 23, 40, 25, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 10, 2, 57, 49, tzinfo=datetime.timezone.utc), customer_id='CUST-03408', customer_tier='professional', organization_id='ORG-339', product='StreamProcessor', product_version='3.7.9', product_module='monitoring', category='Feature Request', subcategory='Enhancement', priority='medium', severity='P0', channel='slack', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-03-09T23:40:25 WARN Rate limit approaching threshold\\n2024-03-09T23:40:25 ERROR ERROR_RATELIMIT_429: Rate limit exceeded\\n2024-03-09T23:40:27 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='grateful', previous_tickets=7, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 3, 10, 2, 57, 49, tzinfo=datetime.timezone.utc), agent_id='AGENT-049', agent_actions=['applied_fix', 'escalated_to_specialist', 'checked_config', 'verified_resolution', 'created_workaround', 'consulted_kb'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['integration', 'data', 'error'], environment='production', business_impact='critical', affected_users=21, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000498', created_at=datetime.datetime(2023, 9, 15, 12, 3, 28, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 19, 7, 53, 16, tzinfo=datetime.timezone.utc), customer_id='CUST-00470', customer_tier='professional', organization_id='ORG-351', product='StreamProcessor', product_version='2.6.14', product_module='event_handler', category='Security', subcategory='Vulnerability', priority='medium', severity='P4', channel='api', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Getting ERROR_CONNECTION_REFUSED errors. We need to ensure our system meets compliance requirements.', error_logs='2023-09-15T12:03:28 WARN Rate limit approaching threshold\\n2023-09-15T12:03:28 ERROR ERROR_CONNECTION_REFUSED: Rate limit exceeded\\n2023-09-15T12:03:30 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'event_handler.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='frustrated', previous_tickets=8, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 9, 19, 7, 53, 16, tzinfo=datetime.timezone.utc), agent_id='AGENT-047', agent_actions=['consulted_kb', 'viewed_logs', 'escalated_to_specialist'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['authentication', 'database', 'data', 'api'], environment='test', business_impact='low', affected_users=46, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000499', created_at=datetime.datetime(2023, 11, 13, 10, 47, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 13, 11, 59, tzinfo=datetime.timezone.utc), customer_id='CUST-00812', customer_tier='free', organization_id='ORG-341', product='API Gateway', product_version='4.1.5', product_module='cache_layer', category='Account Management', subcategory='License', priority='high', severity='P0', channel='slack', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-11-13T10:47:00 WARN Rate limit approaching threshold\\n2023-11-13T10:47:00 ERROR ERROR_MEMORY_OOM: Rate limit exceeded\\n2023-11-13T10:47:02 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='confused', previous_tickets=10, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 11, 13, 11, 59, tzinfo=datetime.timezone.utc), agent_id='AGENT-040', agent_actions=['viewed_logs', 'contacted_customer', 'escalated_to_specialist', 'ran_diagnostics', 'created_workaround'], escalated=False, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['sync', 'error', 'authentication'], environment='test', business_impact='low', affected_users=121, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000500', created_at=datetime.datetime(2024, 6, 27, 7, 54, 24, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 27, 18, 29, 48, tzinfo=datetime.timezone.utc), customer_id='CUST-04355', customer_tier='free', organization_id='ORG-209', product='StreamProcessor', product_version='4.8.11', product_module='event_handler', category='Feature Request', subcategory='Enhancement', priority='medium', severity='P3', channel='slack', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=1, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 6, 27, 18, 29, 48, tzinfo=datetime.timezone.utc), agent_id='AGENT-022', agent_actions=['viewed_logs', 'checked_config', 'consulted_kb'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['error', 'authentication', 'api'], environment='staging', business_impact='critical', affected_users=5, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000501', created_at=datetime.datetime(2023, 4, 19, 23, 49, 12, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 20, 2, 6, 36, tzinfo=datetime.timezone.utc), customer_id='CUST-03606', customer_tier='starter', organization_id='ORG-270', product='API Gateway', product_version='4.3.14', product_module='request_router', category='Feature Request', subcategory='Enhancement', priority='critical', severity='P1', channel='email', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-04-19T23:49:12 ERROR ERROR_VALIDATION: Connection timeout after 30s\\n2023-04-19T23:49:13 RETRY_FAILED: Max retries exceeded', stack_trace='ERROR: request_router.service.ServiceException: Failed to process request\\n\\tat request_router.handler.process(request_router.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='frustrated', previous_tickets=5, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 4, 20, 2, 6, 36, tzinfo=datetime.timezone.utc), agent_id='AGENT-013', agent_actions=['updated_documentation', 'verified_resolution', 'ran_diagnostics', 'applied_fix', 'consulted_kb'], escalated=True, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['database', 'authentication', 'api', 'bug', 'data'], environment='production', business_impact='low', affected_users=467, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000502', created_at=datetime.datetime(2023, 11, 17, 13, 51, 5, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 17, 20, 6, 5, tzinfo=datetime.timezone.utc), customer_id='CUST-04149', customer_tier='premium', organization_id='ORG-356', product='API Gateway', product_version='2.8.13', product_module='cache_layer', category='Data Issue', subcategory='Sync Error', priority='low', severity='P0', channel='portal', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_CONFLICT_409 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-11-17T13:51:05 DEBUG Processing request ID-12345\\n2023-11-17T13:51:05 ERROR ERROR_CONFLICT_409: Invalid request format\\n2023-11-17T13:51:06 INFO Request rejected', stack_trace='', customer_sentiment='satisfied', previous_tickets=6, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 11, 17, 20, 6, 5, tzinfo=datetime.timezone.utc), agent_id='AGENT-001', agent_actions=['contacted_customer', 'ran_diagnostics', 'created_workaround'], escalated=True, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['performance', 'api'], environment='staging', business_impact='medium', affected_users=39, language='zh', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000503', created_at=datetime.datetime(2024, 9, 18, 3, 11, 29, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 18, 6, 53, 29, tzinfo=datetime.timezone.utc), customer_id='CUST-03670', customer_tier='professional', organization_id='ORG-017', product='StreamProcessor', product_version='3.1.11', product_module='event_handler', category='Technical Issue', subcategory='Performance', priority='high', severity='P1', channel='email', subject='StreamProcessor throwing errors during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=10, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 9, 18, 6, 53, 29, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['verified_resolution', 'ran_diagnostics', 'escalated_to_specialist', 'contacted_customer', 'created_workaround'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=False, tags=['database', 'configuration', 'timeout', 'authentication', 'performance'], environment='test', business_impact='high', affected_users=460, language='de', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000504', created_at=datetime.datetime(2024, 8, 26, 8, 36, 40, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 26, 15, 11, 28, tzinfo=datetime.timezone.utc), customer_id='CUST-03237', customer_tier='premium', organization_id='ORG-047', product='CloudBackup Enterprise', product_version='4.4.10', product_module='compression_engine', category='Technical Issue', subcategory='Compatibility', priority='low', severity='P0', channel='chat', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_CORRUPTION in the logs. This is affecting our entire team's productivity.\", error_logs='2024-08-26T08:36:40 ERROR ERROR_CORRUPTION: Database connection lost\\n2024-08-26T08:36:41 INFO Attempting to reconnect...\\n2024-08-26T08:36:43 ERROR Connection failed', stack_trace='Stack trace:\\n  compression_engine::processData() at compression_engine.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='frustrated', previous_tickets=5, resolution='Root cause identified as Compatibility issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 8, 26, 15, 11, 28, tzinfo=datetime.timezone.utc), agent_id='AGENT-028', agent_actions=['applied_fix', 'updated_documentation', 'escalated_to_specialist', 'verified_resolution', 'viewed_logs', 'contacted_customer'], escalated=True, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['performance', 'bug', 'integration'], environment='staging', business_impact='low', affected_users=6, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000505', created_at=datetime.datetime(2023, 4, 26, 1, 54, 27, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 26, 11, 52, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-02314', customer_tier='premium', organization_id='ORG-394', product='StreamProcessor', product_version='4.1.6', product_module='batch_processor', category='Feature Request', subcategory='API', priority='medium', severity='P2', channel='portal', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-04-26T01:54:27 ERROR ERROR_VALIDATION: Connection timeout after 30s\\n2023-04-26T01:54:28 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'batch_processor.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='satisfied', previous_tickets=8, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 4, 26, 11, 52, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-034', agent_actions=['created_workaround', 'contacted_customer', 'verified_resolution', 'viewed_logs'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['database', 'api'], environment='test', business_impact='low', affected_users=1, language='pt', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000506', created_at=datetime.datetime(2024, 4, 26, 17, 7, 51, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 27, 4, 44, 27, tzinfo=datetime.timezone.utc), customer_id='CUST-04943', customer_tier='free', organization_id='ORG-421', product='API Gateway', product_version='2.9.8', product_module='cache_layer', category='Feature Request', subcategory='Enhancement', priority='low', severity='P1', channel='chat', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=2, resolution='Root cause identified as Enhancement issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 4, 27, 4, 44, 27, tzinfo=datetime.timezone.utc), agent_id='AGENT-044', agent_actions=['escalated_to_specialist', 'applied_fix', 'checked_config'], escalated=False, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['error', 'configuration', 'performance'], environment='staging', business_impact='low', affected_users=10, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000507', created_at=datetime.datetime(2024, 5, 25, 18, 36, 35, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 26, 21, 11, 23, tzinfo=datetime.timezone.utc), customer_id='CUST-02712', customer_tier='free', organization_id='ORG-022', product='CloudBackup Enterprise', product_version='2.1.2', product_module='restore_module', category='Technical Issue', subcategory='Performance', priority='critical', severity='P4', channel='api', subject='CloudBackup Enterprise throwing errors during operation', description=\"We're experiencing issues with CloudBackup Enterprise. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=0, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 5, 26, 21, 11, 23, tzinfo=datetime.timezone.utc), agent_id='AGENT-033', agent_actions=['escalated_to_specialist', 'ran_diagnostics', 'viewed_logs', 'consulted_kb'], escalated=True, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['configuration', 'api'], environment='production', business_impact='medium', affected_users=819, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000508', created_at=datetime.datetime(2024, 8, 9, 3, 21, 21, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 9, 16, 0, 57, tzinfo=datetime.timezone.utc), customer_id='CUST-03921', customer_tier='free', organization_id='ORG-129', product='Analytics Dashboard', product_version='3.4.11', product_module='data_aggregator', category='Data Issue', subcategory='Corruption', priority='critical', severity='P3', channel='api', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_MEMORY_OOM appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-08-09T03:21:21 ERROR ERROR_MEMORY_OOM: Connection timeout after 30s\\n2024-08-09T03:21:22 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='angry', previous_tickets=1, resolution='Applied hotfix version 3.2.2 to address the ERROR_MEMORY_OOM. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 8, 9, 16, 0, 57, tzinfo=datetime.timezone.utc), agent_id='AGENT-036', agent_actions=['contacted_customer', 'applied_fix'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['authentication', 'timeout', 'data'], environment='development', business_impact='medium', affected_users=784, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000509', created_at=datetime.datetime(2024, 5, 17, 3, 56, 51, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 17, 8, 43, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-00306', customer_tier='starter', organization_id='ORG-109', product='DataSync Pro', product_version='2.5.13', product_module='scheduler', category='Feature Request', subcategory='Documentation', priority='high', severity='P1', channel='chat', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=6, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 5, 17, 8, 43, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['applied_fix', 'viewed_logs'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['api', 'configuration', 'timeout', 'security', 'authentication'], environment='staging', business_impact='low', affected_users=238, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000510', created_at=datetime.datetime(2023, 8, 2, 0, 40, 17, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 2, 3, 43, 53, tzinfo=datetime.timezone.utc), customer_id='CUST-04737', customer_tier='starter', organization_id='ORG-048', product='CloudBackup Enterprise', product_version='4.6.8', product_module='backup_service', category='Feature Request', subcategory='API', priority='high', severity='P1', channel='api', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-08-02T00:40:17 DEBUG Processing request ID-12345\\n2023-08-02T00:40:17 ERROR ERROR_CONNECTION_REFUSED: Invalid request format\\n2023-08-02T00:40:18 INFO Request rejected', stack_trace='', customer_sentiment='satisfied', previous_tickets=3, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 8, 2, 3, 43, 53, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['updated_documentation', 'verified_resolution', 'ran_diagnostics'], escalated=True, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['database', 'configuration', 'authentication', 'security', 'bug'], environment='test', business_impact='high', affected_users=9, language='ja', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000511', created_at=datetime.datetime(2024, 9, 13, 22, 25, 40, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 14, 3, 12, 28, tzinfo=datetime.timezone.utc), customer_id='CUST-01108', customer_tier='enterprise', organization_id='ORG-100', product='DataSync Pro', product_version='3.0.13', product_module='api_connector', category='Security', subcategory='Encryption', priority='low', severity='P1', channel='slack', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_MEMORY_OOM errors. We need to ensure our system meets compliance requirements.', error_logs='2024-09-13T22:25:40 DEBUG Processing request ID-12345\\n2024-09-13T22:25:40 ERROR ERROR_MEMORY_OOM: Invalid request format\\n2024-09-13T22:25:41 INFO Request rejected', stack_trace='ERROR: api_connector.service.ServiceException: Failed to process request\\n\\tat api_connector.handler.process(api_connector.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='frustrated', previous_tickets=0, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 9, 14, 3, 12, 28, tzinfo=datetime.timezone.utc), agent_id='AGENT-047', agent_actions=['verified_resolution', 'updated_documentation', 'contacted_customer', 'viewed_logs', 'applied_fix'], escalated=True, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['api', 'database', 'timeout'], environment='sandbox', business_impact='low', affected_users=28, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000512', created_at=datetime.datetime(2023, 2, 11, 4, 0, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 11, 5, 54, 1, tzinfo=datetime.timezone.utc), customer_id='CUST-02428', customer_tier='starter', organization_id='ORG-453', product='CloudBackup Enterprise', product_version='2.7.15', product_module='restore_module', category='Feature Request', subcategory='UI/UX', priority='critical', severity='P0', channel='slack', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-02-11T04:00:37 ERROR ERROR_TIMEOUT_429: Database connection lost\\n2023-02-11T04:00:38 INFO Attempting to reconnect...\\n2023-02-11T04:00:40 ERROR Connection failed', stack_trace='Stack trace:\\n  restore_module::processData() at restore_module.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='frustrated', previous_tickets=9, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 2, 11, 5, 54, 1, tzinfo=datetime.timezone.utc), agent_id='AGENT-033', agent_actions=['checked_config', 'updated_documentation', 'applied_fix', 'escalated_to_specialist'], escalated=True, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['data', 'authentication'], environment='staging', business_impact='medium', affected_users=223, language='it', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000513', created_at=datetime.datetime(2024, 2, 22, 7, 19, 30, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 22, 8, 57, 54, tzinfo=datetime.timezone.utc), customer_id='CUST-03919', customer_tier='enterprise', organization_id='ORG-023', product='API Gateway', product_version='3.3.9', product_module='request_router', category='Data Issue', subcategory='Corruption', priority='critical', severity='P1', channel='chat', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_INVALID_400 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-02-22T07:19:30 WARN Rate limit approaching threshold\\n2024-02-22T07:19:30 ERROR ERROR_INVALID_400: Rate limit exceeded\\n2024-02-22T07:19:32 INFO Backing off for 60 seconds', stack_trace='at request_router.execute(request_router.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='frustrated', previous_tickets=0, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 2, 22, 8, 57, 54, tzinfo=datetime.timezone.utc), agent_id='AGENT-041', agent_actions=['applied_fix', 'viewed_logs', 'updated_documentation', 'verified_resolution', 'consulted_kb'], escalated=True, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['database', 'security', 'sync'], environment='test', business_impact='medium', affected_users=530, language='pt', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000514', created_at=datetime.datetime(2024, 10, 7, 23, 0, 42, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 8, 5, 24, 6, tzinfo=datetime.timezone.utc), customer_id='CUST-02023', customer_tier='professional', organization_id='ORG-201', product='CloudBackup Enterprise', product_version='3.0.8', product_module='encryption_layer', category='Technical Issue', subcategory='Bug', priority='low', severity='P1', channel='chat', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_NOTFOUND_404 in the logs. This is affecting our entire team's productivity.\", error_logs='2024-10-07T23:00:42 ERROR ERROR_NOTFOUND_404: Connection timeout after 30s\\n2024-10-07T23:00:43 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='frustrated', previous_tickets=2, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 10, 8, 5, 24, 6, tzinfo=datetime.timezone.utc), agent_id='AGENT-023', agent_actions=['applied_fix', 'consulted_kb'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['integration', 'data'], environment='staging', business_impact='medium', affected_users=28, language='de', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000515', created_at=datetime.datetime(2023, 11, 6, 14, 31, 16, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 7, 16, 21, 40, tzinfo=datetime.timezone.utc), customer_id='CUST-04550', customer_tier='free', organization_id='ORG-199', product='Analytics Dashboard', product_version='3.7.6', product_module='export_module', category='Account Management', subcategory='Billing', priority='high', severity='P2', channel='api', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-11-06T14:31:16 ERROR ERROR_VALIDATION: Connection timeout after 30s\\n2023-11-06T14:31:17 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='frustrated', previous_tickets=9, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 11, 7, 16, 21, 40, tzinfo=datetime.timezone.utc), agent_id='AGENT-035', agent_actions=['created_workaround', 'checked_config', 'escalated_to_specialist'], escalated=True, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['configuration', 'database'], environment='staging', business_impact='low', affected_users=165, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000516', created_at=datetime.datetime(2023, 12, 8, 1, 9, 36, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 8, 5, 36, 36, tzinfo=datetime.timezone.utc), customer_id='CUST-03792', customer_tier='enterprise', organization_id='ORG-441', product='DataSync Pro', product_version='4.2.7', product_module='api_connector', category='Account Management', subcategory='Access Control', priority='low', severity='P0', channel='slack', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=5, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 12, 8, 5, 36, 36, tzinfo=datetime.timezone.utc), agent_id='AGENT-026', agent_actions=['updated_documentation', 'applied_fix', 'contacted_customer'], escalated=False, transferred_count=1, satisfaction_score=1, resolution_helpful=True, tags=['configuration', 'bug', 'data', 'database', 'api'], environment='sandbox', business_impact='low', affected_users=4, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000517', created_at=datetime.datetime(2023, 6, 17, 13, 24, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 18, 19, 48, 45, tzinfo=datetime.timezone.utc), customer_id='CUST-00085', customer_tier='enterprise', organization_id='ORG-483', product='DataSync Pro', product_version='3.9.0', product_module='sync_engine', category='Account Management', subcategory='Upgrade', priority='high', severity='P4', channel='slack', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-06-17T13:24:45 DEBUG Processing request ID-12345\\n2023-06-17T13:24:45 ERROR ERROR_VALIDATION: Invalid request format\\n2023-06-17T13:24:46 INFO Request rejected', stack_trace='ERROR: sync_engine.service.ServiceException: Failed to process request\\n\\tat sync_engine.handler.process(sync_engine.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='grateful', previous_tickets=1, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 6, 18, 19, 48, 45, tzinfo=datetime.timezone.utc), agent_id='AGENT-026', agent_actions=['ran_diagnostics', 'created_workaround', 'applied_fix'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['configuration', 'bug'], environment='staging', business_impact='high', affected_users=217, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000518', created_at=datetime.datetime(2023, 9, 11, 2, 28, 13, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 11, 2, 58, 13, tzinfo=datetime.timezone.utc), customer_id='CUST-03755', customer_tier='starter', organization_id='ORG-152', product='API Gateway', product_version='4.3.12', product_module='auth_service', category='Data Issue', subcategory='Data Loss', priority='high', severity='P0', channel='portal', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=0, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 9, 11, 2, 58, 13, tzinfo=datetime.timezone.utc), agent_id='AGENT-021', agent_actions=['updated_documentation', 'contacted_customer', 'verified_resolution'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['security', 'database', 'error', 'configuration', 'sync'], environment='production', business_impact='medium', affected_users=72, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000519', created_at=datetime.datetime(2023, 1, 9, 1, 57, 22, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 9, 3, 35, 10, tzinfo=datetime.timezone.utc), customer_id='CUST-02894', customer_tier='starter', organization_id='ORG-368', product='Analytics Dashboard', product_version='4.3.10', product_module='report_builder', category='Account Management', subcategory='Subscription', priority='high', severity='P0', channel='slack', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-01-09T01:57:22 ERROR ERROR_CONNECTION_REFUSED: Connection timeout after 30s\\n2023-01-09T01:57:23 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='grateful', previous_tickets=8, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 1, 9, 3, 35, 10, tzinfo=datetime.timezone.utc), agent_id='AGENT-001', agent_actions=['viewed_logs', 'checked_config', 'ran_diagnostics', 'created_workaround', 'applied_fix'], escalated=True, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['performance', 'bug', 'security'], environment='production', business_impact='medium', affected_users=571, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000520', created_at=datetime.datetime(2024, 3, 28, 14, 32, 6, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 30, 1, 32, 42, tzinfo=datetime.timezone.utc), customer_id='CUST-03301', customer_tier='premium', organization_id='ORG-209', product='Analytics Dashboard', product_version='3.9.3', product_module='report_builder', category='Security', subcategory='Authorization', priority='medium', severity='P4', channel='phone', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_PERMISSION_403 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-03-28T14:32:06 WARN Rate limit approaching threshold\\n2024-03-28T14:32:06 ERROR ERROR_PERMISSION_403: Rate limit exceeded\\n2024-03-28T14:32:08 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='frustrated', previous_tickets=3, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 3, 30, 1, 32, 42, tzinfo=datetime.timezone.utc), agent_id='AGENT-049', agent_actions=['updated_documentation', 'viewed_logs', 'checked_config'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['api', 'authentication', 'sync', 'integration'], environment='development', business_impact='medium', affected_users=31, language='zh', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000521', created_at=datetime.datetime(2023, 6, 20, 22, 59, 1, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 21, 2, 51, 13, tzinfo=datetime.timezone.utc), customer_id='CUST-01588', customer_tier='starter', organization_id='ORG-496', product='DataSync Pro', product_version='3.4.14', product_module='sync_engine', category='Account Management', subcategory='Subscription', priority='critical', severity='P1', channel='api', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-06-20T22:59:01 ERROR ERROR_DEADLOCK: Database connection lost\\n2023-06-20T22:59:02 INFO Attempting to reconnect...\\n2023-06-20T22:59:04 ERROR Connection failed', stack_trace='at sync_engine.execute(sync_engine.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='grateful', previous_tickets=0, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 6, 21, 2, 51, 13, tzinfo=datetime.timezone.utc), agent_id='AGENT-025', agent_actions=['updated_documentation', 'checked_config', 'consulted_kb'], escalated=True, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['authentication', 'configuration'], environment='production', business_impact='high', affected_users=411, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000522', created_at=datetime.datetime(2024, 2, 22, 14, 36, 51, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 22, 21, 15, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-02643', customer_tier='free', organization_id='ORG-016', product='DataSync Pro', product_version='3.6.1', product_module='data_validator', category='Feature Request', subcategory='New Feature', priority='low', severity='P1', channel='slack', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-02-22T14:36:51 ERROR ERROR_NOTFOUND_404: Database connection lost\\n2024-02-22T14:36:52 INFO Attempting to reconnect...\\n2024-02-22T14:36:54 ERROR Connection failed', stack_trace='at data_validator.execute(data_validator.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='angry', previous_tickets=9, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 2, 22, 21, 15, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-017', agent_actions=['viewed_logs', 'consulted_kb', 'escalated_to_specialist', 'verified_resolution'], escalated=True, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['configuration', 'authentication', 'data', 'bug', 'sync'], environment='staging', business_impact='critical', affected_users=1, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000523', created_at=datetime.datetime(2023, 5, 2, 2, 45, 8, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 2, 6, 34, 56, tzinfo=datetime.timezone.utc), customer_id='CUST-00901', customer_tier='enterprise', organization_id='ORG-061', product='Analytics Dashboard', product_version='2.7.5', product_module='data_aggregator', category='Account Management', subcategory='Access Control', priority='low', severity='P1', channel='phone', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-05-02T02:45:08 ERROR ERROR_PERMISSION_403: Connection timeout after 30s\\n2023-05-02T02:45:09 RETRY_FAILED: Max retries exceeded', stack_trace='Stack trace:\\n  data_aggregator::processData() at data_aggregator.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='confused', previous_tickets=3, resolution='Applied hotfix version 3.2.2 to address the ERROR_PERMISSION_403. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 5, 2, 6, 34, 56, tzinfo=datetime.timezone.utc), agent_id='AGENT-028', agent_actions=['viewed_logs', 'applied_fix', 'escalated_to_specialist', 'verified_resolution'], escalated=True, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['timeout', 'database'], environment='test', business_impact='high', affected_users=11, language='es', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000524', created_at=datetime.datetime(2023, 6, 10, 11, 0, 27, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 10, 13, 43, 3, tzinfo=datetime.timezone.utc), customer_id='CUST-04553', customer_tier='starter', organization_id='ORG-031', product='Analytics Dashboard', product_version='3.5.9', product_module='export_module', category='Security', subcategory='Vulnerability', priority='critical', severity='P2', channel='email', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_MEMORY_OOM errors. We need to ensure our system meets compliance requirements.', error_logs='2023-06-10T11:00:27 ERROR ERROR_MEMORY_OOM: Connection timeout after 30s\\n2023-06-10T11:00:28 RETRY_FAILED: Max retries exceeded', stack_trace='ERROR: export_module.service.ServiceException: Failed to process request\\n\\tat export_module.handler.process(export_module.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='frustrated', previous_tickets=5, resolution='Root cause identified as Vulnerability issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 6, 10, 13, 43, 3, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['viewed_logs', 'applied_fix', 'verified_resolution'], escalated=False, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['security', 'performance', 'integration', 'data', 'timeout'], environment='production', business_impact='low', affected_users=951, language='de', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000525', created_at=datetime.datetime(2024, 11, 5, 13, 26, 29, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 5, 15, 0, 5, tzinfo=datetime.timezone.utc), customer_id='CUST-00885', customer_tier='premium', organization_id='ORG-156', product='API Gateway', product_version='3.2.10', product_module='rate_limiter', category='Technical Issue', subcategory='Bug', priority='high', severity='P0', channel='slack', subject='API Gateway throwing ERROR_TIMEOUT_429 during operation', description=\"We're experiencing issues with API Gateway. The system is throwing ERROR_TIMEOUT_429 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-11-05T13:26:29 ERROR ERROR_TIMEOUT_429: Connection timeout after 30s\\n2024-11-05T13:26:30 RETRY_FAILED: Max retries exceeded', stack_trace='at rate_limiter.execute(rate_limiter.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='angry', previous_tickets=4, resolution='Applied hotfix version 3.2.2 to address the ERROR_TIMEOUT_429. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 11, 5, 15, 0, 5, tzinfo=datetime.timezone.utc), agent_id='AGENT-034', agent_actions=['applied_fix', 'checked_config', 'contacted_customer', 'created_workaround'], escalated=True, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['database', 'configuration', 'integration'], environment='sandbox', business_impact='medium', affected_users=135, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000526', created_at=datetime.datetime(2023, 8, 12, 19, 40, 46, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 12, 20, 19, 10, tzinfo=datetime.timezone.utc), customer_id='CUST-00895', customer_tier='starter', organization_id='ORG-053', product='CloudBackup Enterprise', product_version='2.8.13', product_module='backup_service', category='Account Management', subcategory='Billing', priority='critical', severity='P0', channel='phone', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=2, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 8, 12, 20, 19, 10, tzinfo=datetime.timezone.utc), agent_id='AGENT-049', agent_actions=['ran_diagnostics', 'verified_resolution'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['bug', 'api'], environment='test', business_impact='high', affected_users=162, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000527', created_at=datetime.datetime(2024, 6, 8, 1, 24, 28, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 8, 11, 4, 40, tzinfo=datetime.timezone.utc), customer_id='CUST-03260', customer_tier='starter', organization_id='ORG-024', product='Analytics Dashboard', product_version='2.5.12', product_module='visualization', category='Account Management', subcategory='Access Control', priority='critical', severity='P2', channel='phone', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-06-08T01:24:28 DEBUG Processing request ID-12345\\n2024-06-08T01:24:28 ERROR ERROR_SSL_CERT: Invalid request format\\n2024-06-08T01:24:29 INFO Request rejected', stack_trace='ERROR: visualization.service.ServiceException: Failed to process request\\n\\tat visualization.handler.process(visualization.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='frustrated', previous_tickets=3, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 6, 8, 11, 4, 40, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['viewed_logs', 'checked_config', 'created_workaround', 'ran_diagnostics', 'contacted_customer', 'updated_documentation'], escalated=True, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['performance', 'data', 'sync'], environment='test', business_impact='high', affected_users=171, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000528', created_at=datetime.datetime(2023, 1, 28, 2, 40, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 29, 12, 53, 48, tzinfo=datetime.timezone.utc), customer_id='CUST-03200', customer_tier='starter', organization_id='ORG-162', product='API Gateway', product_version='3.1.2', product_module='rate_limiter', category='Account Management', subcategory='Upgrade', priority='low', severity='P3', channel='api', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=4, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 1, 29, 12, 53, 48, tzinfo=datetime.timezone.utc), agent_id='AGENT-017', agent_actions=['ran_diagnostics', 'checked_config', 'applied_fix', 'consulted_kb'], escalated=False, transferred_count=1, satisfaction_score=1, resolution_helpful=False, tags=['data', 'security'], environment='development', business_impact='high', affected_users=2, language='zh', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000529', created_at=datetime.datetime(2024, 7, 20, 11, 27, 2, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 21, 10, 10, 50, tzinfo=datetime.timezone.utc), customer_id='CUST-03625', customer_tier='premium', organization_id='ORG-013', product='StreamProcessor', product_version='2.2.2', product_module='event_handler', category='Account Management', subcategory='Upgrade', priority='high', severity='P2', channel='email', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=1, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 7, 21, 10, 10, 50, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['escalated_to_specialist', 'created_workaround'], escalated=False, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['performance', 'integration'], environment='sandbox', business_impact='critical', affected_users=746, language='it', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000530', created_at=datetime.datetime(2023, 2, 6, 2, 41, 50, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 8, 14, 20, 50, tzinfo=datetime.timezone.utc), customer_id='CUST-00031', customer_tier='enterprise', organization_id='ORG-461', product='API Gateway', product_version='3.1.5', product_module='auth_service', category='Security', subcategory='Compliance', priority='low', severity='P4', channel='portal', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_MEMORY_OOM errors. We need to ensure our system meets compliance requirements.', error_logs='2023-02-06T02:41:50 ERROR ERROR_MEMORY_OOM: Database connection lost\\n2023-02-06T02:41:51 INFO Attempting to reconnect...\\n2023-02-06T02:41:53 ERROR Connection failed', stack_trace='ERROR: auth_service.service.ServiceException: Failed to process request\\n\\tat auth_service.handler.process(auth_service.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='neutral', previous_tickets=7, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 2, 8, 14, 20, 50, tzinfo=datetime.timezone.utc), agent_id='AGENT-009', agent_actions=['escalated_to_specialist', 'contacted_customer', 'updated_documentation', 'created_workaround', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['sync', 'security', 'error'], environment='staging', business_impact='high', affected_users=2, language='fr', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000531', created_at=datetime.datetime(2023, 8, 20, 15, 12, 8, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 20, 18, 49, 56, tzinfo=datetime.timezone.utc), customer_id='CUST-03202', customer_tier='free', organization_id='ORG-248', product='Analytics Dashboard', product_version='2.5.9', product_module='data_aggregator', category='Data Issue', subcategory='Validation', priority='critical', severity='P1', channel='portal', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=2, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 8, 20, 18, 49, 56, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['applied_fix', 'ran_diagnostics', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['integration', 'security', 'bug'], environment='staging', business_impact='critical', affected_users=567, language='zh', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000532', created_at=datetime.datetime(2024, 12, 26, 16, 1, 11, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 30, 2, 35, 59, tzinfo=datetime.timezone.utc), customer_id='CUST-04995', customer_tier='professional', organization_id='ORG-229', product='CloudBackup Enterprise', product_version='2.5.15', product_module='encryption_layer', category='Account Management', subcategory='Upgrade', priority='low', severity='P3', channel='email', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-12-26T16:01:11 DEBUG Processing request ID-12345\\n2024-12-26T16:01:11 ERROR ERROR_CONFLICT_409: Invalid request format\\n2024-12-26T16:01:12 INFO Request rejected', stack_trace=\"Traceback (most recent call last):\\n  File 'encryption_layer.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='angry', previous_tickets=8, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 12, 30, 2, 35, 59, tzinfo=datetime.timezone.utc), agent_id='AGENT-023', agent_actions=['ran_diagnostics', 'created_workaround', 'consulted_kb', 'updated_documentation', 'viewed_logs', 'contacted_customer'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['data', 'performance', 'authentication'], environment='production', business_impact='critical', affected_users=10, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000533', created_at=datetime.datetime(2024, 4, 27, 6, 3, 51, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 30, 1, 11, 3, tzinfo=datetime.timezone.utc), customer_id='CUST-04188', customer_tier='professional', organization_id='ORG-337', product='CloudBackup Enterprise', product_version='4.5.9', product_module='encryption_layer', category='Data Issue', subcategory='Data Loss', priority='high', severity='P4', channel='portal', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_CONNECTION_REFUSED appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-04-27T06:03:51 WARN Rate limit approaching threshold\\n2024-04-27T06:03:51 ERROR ERROR_CONNECTION_REFUSED: Rate limit exceeded\\n2024-04-27T06:03:53 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='neutral', previous_tickets=3, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 4, 30, 1, 11, 3, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['escalated_to_specialist', 'verified_resolution', 'applied_fix'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=False, tags=['timeout', 'integration', 'api', 'database'], environment='staging', business_impact='critical', affected_users=753, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000534', created_at=datetime.datetime(2024, 11, 24, 5, 3, 55, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 24, 12, 18, 19, tzinfo=datetime.timezone.utc), customer_id='CUST-02779', customer_tier='premium', organization_id='ORG-011', product='Analytics Dashboard', product_version='3.9.7', product_module='report_builder', category='Data Issue', subcategory='Sync Error', priority='critical', severity='P3', channel='chat', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_AUTH_401 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-11-24T05:03:55 ERROR ERROR_AUTH_401: Database connection lost\\n2024-11-24T05:03:56 INFO Attempting to reconnect...\\n2024-11-24T05:03:58 ERROR Connection failed', stack_trace='', customer_sentiment='confused', previous_tickets=8, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 11, 24, 12, 18, 19, tzinfo=datetime.timezone.utc), agent_id='AGENT-005', agent_actions=['verified_resolution', 'created_workaround'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['api', 'data', 'database', 'authentication'], environment='sandbox', business_impact='high', affected_users=580, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000535', created_at=datetime.datetime(2024, 6, 17, 4, 14, 34, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 17, 20, 55, 22, tzinfo=datetime.timezone.utc), customer_id='CUST-03432', customer_tier='professional', organization_id='ORG-113', product='API Gateway', product_version='3.6.1', product_module='request_router', category='Feature Request', subcategory='New Feature', priority='medium', severity='P2', channel='slack', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-06-17T04:14:34 DEBUG Processing request ID-12345\\n2024-06-17T04:14:34 ERROR ERROR_SERVER_500: Invalid request format\\n2024-06-17T04:14:35 INFO Request rejected', stack_trace=\"Traceback (most recent call last):\\n  File 'request_router.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='neutral', previous_tickets=9, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 6, 17, 20, 55, 22, tzinfo=datetime.timezone.utc), agent_id='AGENT-009', agent_actions=['updated_documentation', 'contacted_customer', 'verified_resolution', 'ran_diagnostics', 'applied_fix'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['security', 'performance', 'timeout', 'database'], environment='development', business_impact='low', affected_users=46, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000536', created_at=datetime.datetime(2024, 3, 20, 20, 16, 52, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 21, 10, 25, 16, tzinfo=datetime.timezone.utc), customer_id='CUST-03978', customer_tier='enterprise', organization_id='ORG-440', product='Analytics Dashboard', product_version='2.4.7', product_module='report_builder', category='Account Management', subcategory='Billing', priority='critical', severity='P4', channel='portal', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-03-20T20:16:52 ERROR ERROR_DEADLOCK: Connection timeout after 30s\\n2024-03-20T20:16:53 RETRY_FAILED: Max retries exceeded', stack_trace='ERROR: report_builder.service.ServiceException: Failed to process request\\n\\tat report_builder.handler.process(report_builder.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='frustrated', previous_tickets=1, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 3, 21, 10, 25, 16, tzinfo=datetime.timezone.utc), agent_id='AGENT-036', agent_actions=['updated_documentation', 'contacted_customer', 'checked_config', 'viewed_logs', 'escalated_to_specialist'], escalated=True, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['bug', 'configuration', 'api', 'database', 'authentication'], environment='staging', business_impact='low', affected_users=358, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000537', created_at=datetime.datetime(2023, 6, 30, 23, 32, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 1, 0, 20, 2, tzinfo=datetime.timezone.utc), customer_id='CUST-03792', customer_tier='enterprise', organization_id='ORG-441', product='StreamProcessor', product_version='3.1.11', product_module='error_handler', category='Feature Request', subcategory='New Feature', priority='critical', severity='P0', channel='phone', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=1, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 7, 1, 0, 20, 2, tzinfo=datetime.timezone.utc), agent_id='AGENT-012', agent_actions=['escalated_to_specialist', 'verified_resolution'], escalated=True, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['bug', 'security', 'authentication'], environment='test', business_impact='high', affected_users=103, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000538', created_at=datetime.datetime(2023, 11, 21, 16, 1, 31, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 21, 17, 17, 43, tzinfo=datetime.timezone.utc), customer_id='CUST-03752', customer_tier='starter', organization_id='ORG-157', product='API Gateway', product_version='4.4.4', product_module='auth_service', category='Security', subcategory='Authorization', priority='critical', severity='P0', channel='chat', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=10, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 11, 21, 17, 17, 43, tzinfo=datetime.timezone.utc), agent_id='AGENT-033', agent_actions=['verified_resolution', 'applied_fix'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=False, tags=['integration', 'sync', 'database'], environment='development', business_impact='medium', affected_users=666, language='fr', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000539', created_at=datetime.datetime(2023, 11, 16, 20, 0, 26, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 16, 20, 53, 14, tzinfo=datetime.timezone.utc), customer_id='CUST-00056', customer_tier='starter', organization_id='ORG-311', product='Analytics Dashboard', product_version='2.9.7', product_module='visualization', category='Account Management', subcategory='Billing', priority='medium', severity='P0', channel='email', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-11-16T20:00:26 ERROR ERROR_VALIDATION: Database connection lost\\n2023-11-16T20:00:27 INFO Attempting to reconnect...\\n2023-11-16T20:00:29 ERROR Connection failed', stack_trace='', customer_sentiment='confused', previous_tickets=3, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 11, 16, 20, 53, 14, tzinfo=datetime.timezone.utc), agent_id='AGENT-005', agent_actions=['created_workaround', 'applied_fix', 'checked_config', 'consulted_kb'], escalated=True, transferred_count=1, satisfaction_score=1, resolution_helpful=False, tags=['configuration', 'security', 'authentication'], environment='staging', business_impact='high', affected_users=29, language='en', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000540', created_at=datetime.datetime(2024, 8, 15, 11, 57, 13, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 15, 17, 11, 1, tzinfo=datetime.timezone.utc), customer_id='CUST-00854', customer_tier='free', organization_id='ORG-318', product='CloudBackup Enterprise', product_version='4.8.7', product_module='backup_service', category='Data Issue', subcategory='Sync Error', priority='medium', severity='P1', channel='phone', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_DEADLOCK appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-08-15T11:57:13 WARN Rate limit approaching threshold\\n2024-08-15T11:57:13 ERROR ERROR_DEADLOCK: Rate limit exceeded\\n2024-08-15T11:57:15 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'backup_service.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='angry', previous_tickets=4, resolution='Root cause identified as Sync Error issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 8, 15, 17, 11, 1, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['applied_fix', 'verified_resolution'], escalated=True, transferred_count=3, satisfaction_score=3, resolution_helpful=False, tags=['configuration', 'database', 'authentication', 'error', 'api'], environment='production', business_impact='critical', affected_users=20, language='es', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000541', created_at=datetime.datetime(2024, 10, 22, 17, 9, 17, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 22, 20, 15, 17, tzinfo=datetime.timezone.utc), customer_id='CUST-02551', customer_tier='enterprise', organization_id='ORG-104', product='Analytics Dashboard', product_version='4.6.9', product_module='visualization', category='Account Management', subcategory='License', priority='low', severity='P1', channel='phone', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-10-22T17:09:17 WARN Rate limit approaching threshold\\n2024-10-22T17:09:17 ERROR ERROR_RATELIMIT_429: Rate limit exceeded\\n2024-10-22T17:09:19 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='grateful', previous_tickets=2, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 10, 22, 20, 15, 17, tzinfo=datetime.timezone.utc), agent_id='AGENT-027', agent_actions=['consulted_kb', 'updated_documentation', 'verified_resolution', 'applied_fix'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=True, tags=['error', 'data', 'authentication', 'timeout', 'api'], environment='test', business_impact='critical', affected_users=13, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000542', created_at=datetime.datetime(2023, 4, 8, 6, 41, 50, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 8, 11, 0, 26, tzinfo=datetime.timezone.utc), customer_id='CUST-02957', customer_tier='premium', organization_id='ORG-089', product='CloudBackup Enterprise', product_version='2.2.11', product_module='restore_module', category='Technical Issue', subcategory='Integration', priority='medium', severity='P1', channel='slack', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=9, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 4, 8, 11, 0, 26, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['consulted_kb', 'updated_documentation', 'escalated_to_specialist'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['integration', 'configuration', 'timeout', 'authentication'], environment='staging', business_impact='high', affected_users=10, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000543', created_at=datetime.datetime(2024, 7, 19, 1, 5, 24, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 21, 17, 28, 12, tzinfo=datetime.timezone.utc), customer_id='CUST-03223', customer_tier='starter', organization_id='ORG-041', product='StreamProcessor', product_version='4.1.11', product_module='batch_processor', category='Feature Request', subcategory='Enhancement', priority='low', severity='P3', channel='slack', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=10, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 7, 21, 17, 28, 12, tzinfo=datetime.timezone.utc), agent_id='AGENT-040', agent_actions=['contacted_customer', 'escalated_to_specialist', 'applied_fix', 'ran_diagnostics'], escalated=False, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['security', 'database'], environment='test', business_impact='low', affected_users=36, language='zh', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000544', created_at=datetime.datetime(2024, 3, 2, 3, 43, 46, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 4, 19, 20, 58, tzinfo=datetime.timezone.utc), customer_id='CUST-04999', customer_tier='premium', organization_id='ORG-174', product='Analytics Dashboard', product_version='2.3.4', product_module='data_aggregator', category='Technical Issue', subcategory='Performance', priority='low', severity='P3', channel='chat', subject='Performance degradation in Analytics Dashboard', description=\"The Analytics Dashboard has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=10, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 3, 4, 19, 20, 58, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['contacted_customer', 'viewed_logs', 'created_workaround'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['configuration', 'bug', 'integration', 'performance'], environment='sandbox', business_impact='high', affected_users=7, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000545', created_at=datetime.datetime(2024, 10, 21, 3, 38, 51, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 22, 1, 3, 27, tzinfo=datetime.timezone.utc), customer_id='CUST-01411', customer_tier='free', organization_id='ORG-064', product='API Gateway', product_version='2.2.1', product_module='auth_service', category='Security', subcategory='Authorization', priority='high', severity='P2', channel='slack', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_VALIDATION errors. We need to ensure our system meets compliance requirements.', error_logs='2024-10-21T03:38:51 WARN Rate limit approaching threshold\\n2024-10-21T03:38:51 ERROR ERROR_VALIDATION: Rate limit exceeded\\n2024-10-21T03:38:53 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='confused', previous_tickets=3, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 10, 22, 1, 3, 27, tzinfo=datetime.timezone.utc), agent_id='AGENT-006', agent_actions=['contacted_customer', 'viewed_logs', 'updated_documentation', 'verified_resolution', 'created_workaround', 'ran_diagnostics'], escalated=True, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['timeout', 'error', 'performance', 'security'], environment='staging', business_impact='critical', affected_users=126, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000546', created_at=datetime.datetime(2024, 5, 26, 2, 31, 52, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 26, 4, 48, 40, tzinfo=datetime.timezone.utc), customer_id='CUST-02570', customer_tier='starter', organization_id='ORG-433', product='API Gateway', product_version='4.2.14', product_module='auth_service', category='Feature Request', subcategory='UI/UX', priority='critical', severity='P0', channel='chat', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-05-26T02:31:52 DEBUG Processing request ID-12345\\n2024-05-26T02:31:52 ERROR ERROR_DISK_FULL: Invalid request format\\n2024-05-26T02:31:53 INFO Request rejected', stack_trace='', customer_sentiment='neutral', previous_tickets=1, resolution='Applied hotfix version 3.2.2 to address the ERROR_DISK_FULL. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 5, 26, 4, 48, 40, tzinfo=datetime.timezone.utc), agent_id='AGENT-029', agent_actions=['contacted_customer', 'updated_documentation', 'ran_diagnostics'], escalated=True, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['api', 'database', 'timeout', 'authentication', 'bug'], environment='production', business_impact='critical', affected_users=428, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000547', created_at=datetime.datetime(2024, 6, 6, 17, 52, 26, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 6, 19, 21, 14, tzinfo=datetime.timezone.utc), customer_id='CUST-00034', customer_tier='starter', organization_id='ORG-316', product='StreamProcessor', product_version='2.8.9', product_module='monitoring', category='Technical Issue', subcategory='Performance', priority='critical', severity='P1', channel='slack', subject='Performance degradation in StreamProcessor', description=\"The StreamProcessor has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_CONFLICT_409 in the logs. This is affecting our entire team's productivity.\", error_logs='2024-06-06T17:52:26 ERROR ERROR_CONFLICT_409: Connection timeout after 30s\\n2024-06-06T17:52:27 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='grateful', previous_tickets=7, resolution='Root cause identified as Performance issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 6, 6, 19, 21, 14, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['consulted_kb', 'escalated_to_specialist', 'contacted_customer', 'checked_config', 'applied_fix'], escalated=True, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['performance', 'sync', 'api'], environment='staging', business_impact='medium', affected_users=216, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000548', created_at=datetime.datetime(2024, 1, 7, 16, 40, 18, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 10, 17, 51, 6, tzinfo=datetime.timezone.utc), customer_id='CUST-01115', customer_tier='starter', organization_id='ORG-168', product='API Gateway', product_version='3.3.6', product_module='rate_limiter', category='Feature Request', subcategory='Documentation', priority='medium', severity='P4', channel='phone', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-01-07T16:40:18 ERROR ERROR_PERMISSION_403: Database connection lost\\n2024-01-07T16:40:19 INFO Attempting to reconnect...\\n2024-01-07T16:40:21 ERROR Connection failed', stack_trace='', customer_sentiment='grateful', previous_tickets=0, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 1, 10, 17, 51, 6, tzinfo=datetime.timezone.utc), agent_id='AGENT-010', agent_actions=['applied_fix', 'created_workaround'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['timeout', 'error', 'performance'], environment='staging', business_impact='high', affected_users=20, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000549', created_at=datetime.datetime(2024, 7, 22, 1, 2, 18, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 22, 2, 50, 54, tzinfo=datetime.timezone.utc), customer_id='CUST-01993', customer_tier='starter', organization_id='ORG-428', product='StreamProcessor', product_version='3.1.8', product_module='event_handler', category='Feature Request', subcategory='UI/UX', priority='high', severity='P1', channel='chat', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-07-22T01:02:18 WARN Rate limit approaching threshold\\n2024-07-22T01:02:18 ERROR ERROR_INVALID_400: Rate limit exceeded\\n2024-07-22T01:02:20 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='grateful', previous_tickets=8, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 7, 22, 2, 50, 54, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['created_workaround', 'applied_fix', 'contacted_customer', 'verified_resolution', 'consulted_kb'], escalated=True, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['database', 'authentication', 'performance', 'sync'], environment='production', business_impact='low', affected_users=353, language='it', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000550', created_at=datetime.datetime(2023, 8, 24, 3, 18, 51, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 24, 14, 9, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-00285', customer_tier='enterprise', organization_id='ORG-125', product='Analytics Dashboard', product_version='2.9.14', product_module='report_builder', category='Security', subcategory='Authentication', priority='critical', severity='P2', channel='portal', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_AUTH_401 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-08-24T03:18:51 WARN Rate limit approaching threshold\\n2023-08-24T03:18:51 ERROR ERROR_AUTH_401: Rate limit exceeded\\n2023-08-24T03:18:53 INFO Backing off for 60 seconds', stack_trace='at report_builder.execute(report_builder.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='angry', previous_tickets=7, resolution='Root cause identified as Authentication issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 8, 24, 14, 9, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['consulted_kb', 'verified_resolution', 'created_workaround'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=True, tags=['authentication', 'performance', 'configuration', 'sync', 'bug'], environment='sandbox', business_impact='high', affected_users=184, language='zh', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000551', created_at=datetime.datetime(2024, 9, 29, 17, 53, 47, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 29, 20, 33, 23, tzinfo=datetime.timezone.utc), customer_id='CUST-01108', customer_tier='enterprise', organization_id='ORG-100', product='CloudBackup Enterprise', product_version='2.8.10', product_module='encryption_layer', category='Feature Request', subcategory='Documentation', priority='low', severity='P0', channel='email', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-09-29T17:53:47 DEBUG Processing request ID-12345\\n2024-09-29T17:53:47 ERROR ERROR_CONFLICT_409: Invalid request format\\n2024-09-29T17:53:48 INFO Request rejected', stack_trace='', customer_sentiment='confused', previous_tickets=6, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 9, 29, 20, 33, 23, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['checked_config', 'verified_resolution'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['api', 'performance'], environment='development', business_impact='critical', affected_users=1, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000552', created_at=datetime.datetime(2024, 1, 16, 0, 54, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 17, 3, 56, 33, tzinfo=datetime.timezone.utc), customer_id='CUST-02646', customer_tier='professional', organization_id='ORG-433', product='DataSync Pro', product_version='4.1.0', product_module='scheduler', category='Data Issue', subcategory='Validation', priority='critical', severity='P4', channel='email', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_RATELIMIT_429 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-01-16T00:54:45 DEBUG Processing request ID-12345\\n2024-01-16T00:54:45 ERROR ERROR_RATELIMIT_429: Invalid request format\\n2024-01-16T00:54:46 INFO Request rejected', stack_trace='ERROR: scheduler.service.ServiceException: Failed to process request\\n\\tat scheduler.handler.process(scheduler.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='grateful', previous_tickets=7, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 1, 17, 3, 56, 33, tzinfo=datetime.timezone.utc), agent_id='AGENT-024', agent_actions=['applied_fix', 'contacted_customer', 'verified_resolution', 'checked_config'], escalated=False, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['database', 'configuration', 'performance', 'security', 'error'], environment='staging', business_impact='medium', affected_users=206, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000553', created_at=datetime.datetime(2023, 8, 18, 20, 38, 43, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 18, 23, 12, 19, tzinfo=datetime.timezone.utc), customer_id='CUST-00485', customer_tier='free', organization_id='ORG-457', product='CloudBackup Enterprise', product_version='2.2.11', product_module='backup_service', category='Technical Issue', subcategory='Compatibility', priority='low', severity='P0', channel='email', subject='CloudBackup Enterprise throwing ERROR_PARSING during operation', description=\"We're experiencing issues with CloudBackup Enterprise. The system is throwing ERROR_PARSING when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-08-18T20:38:43 ERROR ERROR_PARSING: Database connection lost\\n2023-08-18T20:38:44 INFO Attempting to reconnect...\\n2023-08-18T20:38:46 ERROR Connection failed', stack_trace='', customer_sentiment='angry', previous_tickets=1, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 8, 18, 23, 12, 19, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['escalated_to_specialist', 'consulted_kb', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['api', 'integration', 'timeout', 'configuration'], environment='production', business_impact='medium', affected_users=33, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000554', created_at=datetime.datetime(2024, 6, 4, 8, 20, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 5, 4, 4, 27, tzinfo=datetime.timezone.utc), customer_id='CUST-01637', customer_tier='professional', organization_id='ORG-359', product='Analytics Dashboard', product_version='4.2.0', product_module='visualization', category='Account Management', subcategory='License', priority='medium', severity='P2', channel='api', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=0, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 6, 5, 4, 4, 27, tzinfo=datetime.timezone.utc), agent_id='AGENT-042', agent_actions=['contacted_customer', 'applied_fix', 'viewed_logs', 'ran_diagnostics', 'consulted_kb'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['configuration', 'authentication', 'database', 'error', 'sync'], environment='development', business_impact='high', affected_users=1, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000555', created_at=datetime.datetime(2023, 1, 29, 6, 48, 13, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 29, 12, 6, 49, tzinfo=datetime.timezone.utc), customer_id='CUST-01741', customer_tier='enterprise', organization_id='ORG-423', product='API Gateway', product_version='2.6.14', product_module='rate_limiter', category='Data Issue', subcategory='Import/Export', priority='low', severity='P0', channel='chat', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_DEADLOCK appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-01-29T06:48:13 WARN Rate limit approaching threshold\\n2023-01-29T06:48:13 ERROR ERROR_DEADLOCK: Rate limit exceeded\\n2023-01-29T06:48:15 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'rate_limiter.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='frustrated', previous_tickets=6, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 1, 29, 12, 6, 49, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['consulted_kb', 'updated_documentation', 'contacted_customer'], escalated=True, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['api', 'sync', 'performance'], environment='production', business_impact='medium', affected_users=5, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000556', created_at=datetime.datetime(2024, 7, 9, 12, 40, 33, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 10, 14, 30, 57, tzinfo=datetime.timezone.utc), customer_id='CUST-04357', customer_tier='enterprise', organization_id='ORG-330', product='Analytics Dashboard', product_version='4.1.6', product_module='data_aggregator', category='Account Management', subcategory='License', priority='low', severity='P2', channel='portal', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-07-09T12:40:33 ERROR ERROR_CONFLICT_409: Connection timeout after 30s\\n2024-07-09T12:40:34 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='confused', previous_tickets=3, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 7, 10, 14, 30, 57, tzinfo=datetime.timezone.utc), agent_id='AGENT-042', agent_actions=['escalated_to_specialist', 'updated_documentation'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['timeout', 'authentication', 'sync'], environment='test', business_impact='medium', affected_users=8, language='zh', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000557', created_at=datetime.datetime(2024, 10, 10, 13, 56, 9, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 10, 21, 3, 21, tzinfo=datetime.timezone.utc), customer_id='CUST-03786', customer_tier='professional', organization_id='ORG-389', product='StreamProcessor', product_version='2.2.11', product_module='monitoring', category='Technical Issue', subcategory='Performance', priority='medium', severity='P2', channel='email', subject='StreamProcessor throwing ERROR_PERMISSION_403 during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing ERROR_PERMISSION_403 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-10-10T13:56:09 DEBUG Processing request ID-12345\\n2024-10-10T13:56:09 ERROR ERROR_PERMISSION_403: Invalid request format\\n2024-10-10T13:56:10 INFO Request rejected', stack_trace='', customer_sentiment='frustrated', previous_tickets=7, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 10, 10, 21, 3, 21, tzinfo=datetime.timezone.utc), agent_id='AGENT-028', agent_actions=['viewed_logs', 'verified_resolution', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=1, resolution_helpful=True, tags=['bug', 'data', 'configuration'], environment='production', business_impact='low', affected_users=29, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000558', created_at=datetime.datetime(2024, 3, 31, 22, 22, 3, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 6, 5, 13, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-00542', customer_tier='enterprise', organization_id='ORG-132', product='CloudBackup Enterprise', product_version='4.3.3', product_module='compression_engine', category='Data Issue', subcategory='Sync Error', priority='low', severity='P4', channel='slack', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_DISK_FULL appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-03-31T22:22:03 DEBUG Processing request ID-12345\\n2024-03-31T22:22:03 ERROR ERROR_DISK_FULL: Invalid request format\\n2024-03-31T22:22:04 INFO Request rejected', stack_trace=\"Traceback (most recent call last):\\n  File 'compression_engine.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='frustrated', previous_tickets=2, resolution='Applied hotfix version 3.2.2 to address the ERROR_DISK_FULL. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 4, 6, 5, 13, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-038', agent_actions=['checked_config', 'viewed_logs'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=False, tags=['authentication', 'data', 'sync', 'bug'], environment='sandbox', business_impact='high', affected_users=16, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000559', created_at=datetime.datetime(2023, 4, 23, 22, 24, 29, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 23, 23, 28, 5, tzinfo=datetime.timezone.utc), customer_id='CUST-03626', customer_tier='free', organization_id='ORG-457', product='StreamProcessor', product_version='3.3.6', product_module='event_handler', category='Data Issue', subcategory='Corruption', priority='critical', severity='P0', channel='chat', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=2, resolution='Root cause identified as Corruption issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 4, 23, 23, 28, 5, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['created_workaround', 'applied_fix', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['configuration', 'timeout', 'performance', 'authentication'], environment='test', business_impact='high', affected_users=742, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000560', created_at=datetime.datetime(2024, 3, 29, 8, 43, 43, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 29, 21, 44, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-00244', customer_tier='starter', organization_id='ORG-236', product='StreamProcessor', product_version='3.3.9', product_module='error_handler', category='Technical Issue', subcategory='Compatibility', priority='low', severity='P1', channel='email', subject='StreamProcessor throwing ERROR_DEADLOCK during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing ERROR_DEADLOCK when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-03-29T08:43:43 DEBUG Processing request ID-12345\\n2024-03-29T08:43:43 ERROR ERROR_DEADLOCK: Invalid request format\\n2024-03-29T08:43:44 INFO Request rejected', stack_trace='', customer_sentiment='satisfied', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 3, 29, 21, 44, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-036', agent_actions=['ran_diagnostics', 'created_workaround', 'verified_resolution'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['timeout', 'error', 'configuration', 'api', 'sync'], environment='development', business_impact='critical', affected_users=34, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000561', created_at=datetime.datetime(2023, 1, 29, 17, 29, 29, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 30, 5, 10, 53, tzinfo=datetime.timezone.utc), customer_id='CUST-04111', customer_tier='enterprise', organization_id='ORG-207', product='API Gateway', product_version='4.3.10', product_module='rate_limiter', category='Account Management', subcategory='License', priority='high', severity='P2', channel='portal', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=4, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 1, 30, 5, 10, 53, tzinfo=datetime.timezone.utc), agent_id='AGENT-021', agent_actions=['updated_documentation', 'viewed_logs'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['performance', 'error'], environment='test', business_impact='high', affected_users=269, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000562', created_at=datetime.datetime(2023, 1, 13, 16, 55, 30, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 14, 16, 14, 42, tzinfo=datetime.timezone.utc), customer_id='CUST-04032', customer_tier='professional', organization_id='ORG-357', product='API Gateway', product_version='4.1.12', product_module='request_router', category='Security', subcategory='Vulnerability', priority='medium', severity='P3', channel='chat', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=10, resolution='Root cause identified as Vulnerability issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 1, 14, 16, 14, 42, tzinfo=datetime.timezone.utc), agent_id='AGENT-047', agent_actions=['escalated_to_specialist', 'contacted_customer'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['security', 'database', 'data'], environment='production', business_impact='medium', affected_users=27, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000563', created_at=datetime.datetime(2023, 5, 15, 18, 38, 51, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 17, 5, 12, 27, tzinfo=datetime.timezone.utc), customer_id='CUST-04343', customer_tier='enterprise', organization_id='ORG-214', product='DataSync Pro', product_version='3.8.8', product_module='scheduler', category='Data Issue', subcategory='Import/Export', priority='low', severity='P2', channel='chat', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_CONFLICT_409 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-05-15T18:38:51 WARN Rate limit approaching threshold\\n2023-05-15T18:38:51 ERROR ERROR_CONFLICT_409: Rate limit exceeded\\n2023-05-15T18:38:53 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'scheduler.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='satisfied', previous_tickets=8, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 5, 17, 5, 12, 27, tzinfo=datetime.timezone.utc), agent_id='AGENT-024', agent_actions=['created_workaround', 'applied_fix', 'verified_resolution', 'ran_diagnostics'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=False, tags=['database', 'integration', 'error'], environment='staging', business_impact='low', affected_users=44, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000564', created_at=datetime.datetime(2023, 4, 26, 15, 21, 6, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 27, 4, 34, 18, tzinfo=datetime.timezone.utc), customer_id='CUST-04981', customer_tier='enterprise', organization_id='ORG-267', product='API Gateway', product_version='4.6.1', product_module='auth_service', category='Feature Request', subcategory='Documentation', priority='high', severity='P2', channel='phone', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-04-26T15:21:06 WARN Rate limit approaching threshold\\n2023-04-26T15:21:06 ERROR ERROR_CORRUPTION: Rate limit exceeded\\n2023-04-26T15:21:08 INFO Backing off for 60 seconds', stack_trace='Stack trace:\\n  auth_service::processData() at auth_service.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='confused', previous_tickets=8, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 4, 27, 4, 34, 18, tzinfo=datetime.timezone.utc), agent_id='AGENT-029', agent_actions=['created_workaround', 'contacted_customer'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['authentication', 'data', 'api', 'integration'], environment='production', business_impact='low', affected_users=487, language='es', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000565', created_at=datetime.datetime(2023, 11, 11, 0, 38, 5, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 11, 11, 19, 29, tzinfo=datetime.timezone.utc), customer_id='CUST-03573', customer_tier='starter', organization_id='ORG-462', product='StreamProcessor', product_version='2.5.2', product_module='monitoring', category='Data Issue', subcategory='Corruption', priority='medium', severity='P2', channel='api', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_PARSING appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-11-11T00:38:05 DEBUG Processing request ID-12345\\n2023-11-11T00:38:05 ERROR ERROR_PARSING: Invalid request format\\n2023-11-11T00:38:06 INFO Request rejected', stack_trace='', customer_sentiment='confused', previous_tickets=7, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 11, 11, 11, 19, 29, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['ran_diagnostics', 'viewed_logs', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['error', 'integration', 'sync', 'bug', 'security'], environment='staging', business_impact='critical', affected_users=7, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000566', created_at=datetime.datetime(2024, 8, 29, 9, 7, 1, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 29, 10, 38, 13, tzinfo=datetime.timezone.utc), customer_id='CUST-02020', customer_tier='starter', organization_id='ORG-342', product='StreamProcessor', product_version='2.1.4', product_module='batch_processor', category='Account Management', subcategory='License', priority='high', severity='P0', channel='portal', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-08-29T09:07:01 ERROR ERROR_AUTH_401: Connection timeout after 30s\\n2024-08-29T09:07:02 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='angry', previous_tickets=0, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 8, 29, 10, 38, 13, tzinfo=datetime.timezone.utc), agent_id='AGENT-042', agent_actions=['escalated_to_specialist', 'created_workaround'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['integration', 'authentication'], environment='sandbox', business_impact='high', affected_users=922, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000567', created_at=datetime.datetime(2023, 9, 25, 6, 58, 43, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 27, 18, 56, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-01384', customer_tier='free', organization_id='ORG-411', product='DataSync Pro', product_version='4.4.4', product_module='sync_engine', category='Security', subcategory='Authentication', priority='low', severity='P4', channel='slack', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=9, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 9, 27, 18, 56, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-001', agent_actions=['created_workaround', 'updated_documentation', 'escalated_to_specialist'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'configuration', 'authentication'], environment='production', business_impact='medium', affected_users=10, language='pt', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000568', created_at=datetime.datetime(2024, 12, 22, 7, 28, 29, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 24, 2, 38, 5, tzinfo=datetime.timezone.utc), customer_id='CUST-02993', customer_tier='free', organization_id='ORG-219', product='DataSync Pro', product_version='4.5.10', product_module='data_validator', category='Data Issue', subcategory='Data Loss', priority='low', severity='P2', channel='portal', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_CORRUPTION appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-12-22T07:28:29 ERROR ERROR_CORRUPTION: Connection timeout after 30s\\n2024-12-22T07:28:30 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'data_validator.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='satisfied', previous_tickets=6, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 12, 24, 2, 38, 5, tzinfo=datetime.timezone.utc), agent_id='AGENT-027', agent_actions=['escalated_to_specialist', 'checked_config', 'contacted_customer', 'verified_resolution'], escalated=True, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['error', 'authentication'], environment='production', business_impact='medium', affected_users=29, language='it', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000569', created_at=datetime.datetime(2023, 8, 22, 11, 42, 5, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 22, 21, 56, 29, tzinfo=datetime.timezone.utc), customer_id='CUST-00113', customer_tier='enterprise', organization_id='ORG-293', product='CloudBackup Enterprise', product_version='4.8.13', product_module='backup_service', category='Data Issue', subcategory='Sync Error', priority='high', severity='P2', channel='phone', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_TIMEOUT_429 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-08-22T11:42:05 WARN Rate limit approaching threshold\\n2023-08-22T11:42:05 ERROR ERROR_TIMEOUT_429: Rate limit exceeded\\n2023-08-22T11:42:07 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'backup_service.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='frustrated', previous_tickets=4, resolution='Root cause identified as Sync Error issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 8, 22, 21, 56, 29, tzinfo=datetime.timezone.utc), agent_id='AGENT-040', agent_actions=['consulted_kb', 'contacted_customer', 'ran_diagnostics'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['integration', 'security'], environment='production', business_impact='high', affected_users=31, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000570', created_at=datetime.datetime(2023, 12, 13, 8, 16, 23, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 13, 10, 54, 11, tzinfo=datetime.timezone.utc), customer_id='CUST-04632', customer_tier='professional', organization_id='ORG-094', product='DataSync Pro', product_version='2.8.13', product_module='scheduler', category='Data Issue', subcategory='Sync Error', priority='medium', severity='P0', channel='api', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=0, resolution='Root cause identified as Sync Error issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 12, 13, 10, 54, 11, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['created_workaround', 'checked_config', 'viewed_logs', 'contacted_customer', 'applied_fix', 'escalated_to_specialist'], escalated=True, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['security', 'sync', 'error', 'bug'], environment='development', business_impact='high', affected_users=43, language='de', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000571', created_at=datetime.datetime(2024, 1, 4, 19, 16, 54, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 5, 21, 45, 6, tzinfo=datetime.timezone.utc), customer_id='CUST-01095', customer_tier='professional', organization_id='ORG-436', product='Analytics Dashboard', product_version='3.6.8', product_module='visualization', category='Data Issue', subcategory='Corruption', priority='critical', severity='P3', channel='phone', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=7, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 1, 5, 21, 45, 6, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['applied_fix', 'created_workaround'], escalated=True, transferred_count=1, satisfaction_score=1, resolution_helpful=False, tags=['integration', 'configuration'], environment='sandbox', business_impact='high', affected_users=223, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000572', created_at=datetime.datetime(2024, 6, 11, 3, 55, 42, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 11, 7, 40, 6, tzinfo=datetime.timezone.utc), customer_id='CUST-02752', customer_tier='starter', organization_id='ORG-466', product='Analytics Dashboard', product_version='3.4.2', product_module='export_module', category='Security', subcategory='Authorization', priority='medium', severity='P0', channel='api', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_DISK_FULL errors. We need to ensure our system meets compliance requirements.', error_logs='2024-06-11T03:55:42 WARN Rate limit approaching threshold\\n2024-06-11T03:55:42 ERROR ERROR_DISK_FULL: Rate limit exceeded\\n2024-06-11T03:55:44 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='grateful', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 6, 11, 7, 40, 6, tzinfo=datetime.timezone.utc), agent_id='AGENT-033', agent_actions=['viewed_logs', 'updated_documentation', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['database', 'timeout'], environment='staging', business_impact='critical', affected_users=46, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000573', created_at=datetime.datetime(2024, 5, 15, 12, 18, 56, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 15, 16, 50, 44, tzinfo=datetime.timezone.utc), customer_id='CUST-02295', customer_tier='free', organization_id='ORG-204', product='Analytics Dashboard', product_version='3.7.10', product_module='data_aggregator', category='Technical Issue', subcategory='Performance', priority='medium', severity='P1', channel='slack', subject='Performance degradation in Analytics Dashboard', description=\"The Analytics Dashboard has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_TIMEOUT_429 in the logs. This is affecting our entire team's productivity.\", error_logs='2024-05-15T12:18:56 ERROR ERROR_TIMEOUT_429: Connection timeout after 30s\\n2024-05-15T12:18:57 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='confused', previous_tickets=4, resolution='Applied hotfix version 3.2.2 to address the ERROR_TIMEOUT_429. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 5, 15, 16, 50, 44, tzinfo=datetime.timezone.utc), agent_id='AGENT-044', agent_actions=['escalated_to_specialist', 'viewed_logs'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['performance', 'data', 'timeout', 'security'], environment='test', business_impact='high', affected_users=29, language='de', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000574', created_at=datetime.datetime(2024, 11, 27, 7, 18, 53, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 28, 8, 9, 53, tzinfo=datetime.timezone.utc), customer_id='CUST-03062', customer_tier='enterprise', organization_id='ORG-298', product='DataSync Pro', product_version='4.1.14', product_module='scheduler', category='Data Issue', subcategory='Sync Error', priority='medium', severity='P2', channel='chat', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_SSL_CERT appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-11-27T07:18:53 ERROR ERROR_SSL_CERT: Connection timeout after 30s\\n2024-11-27T07:18:54 RETRY_FAILED: Max retries exceeded', stack_trace='Stack trace:\\n  scheduler::processData() at scheduler.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='frustrated', previous_tickets=8, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 11, 28, 8, 9, 53, tzinfo=datetime.timezone.utc), agent_id='AGENT-048', agent_actions=['escalated_to_specialist', 'consulted_kb', 'viewed_logs', 'contacted_customer', 'applied_fix', 'ran_diagnostics'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['data', 'security', 'error'], environment='production', business_impact='low', affected_users=34, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000575', created_at=datetime.datetime(2024, 7, 21, 15, 18, 44, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 23, 7, 51, 44, tzinfo=datetime.timezone.utc), customer_id='CUST-00754', customer_tier='professional', organization_id='ORG-478', product='API Gateway', product_version='3.3.3', product_module='auth_service', category='Data Issue', subcategory='Sync Error', priority='critical', severity='P4', channel='email', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=8, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 7, 23, 7, 51, 44, tzinfo=datetime.timezone.utc), agent_id='AGENT-012', agent_actions=['created_workaround', 'consulted_kb'], escalated=False, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['authentication', 'configuration'], environment='development', business_impact='low', affected_users=903, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000576', created_at=datetime.datetime(2023, 12, 10, 1, 39, 22, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 11, 19, 29, 46, tzinfo=datetime.timezone.utc), customer_id='CUST-03919', customer_tier='enterprise', organization_id='ORG-023', product='CloudBackup Enterprise', product_version='3.8.1', product_module='backup_service', category='Data Issue', subcategory='Import/Export', priority='high', severity='P4', channel='email', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_NOTFOUND_404 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-12-10T01:39:22 ERROR ERROR_NOTFOUND_404: Database connection lost\\n2023-12-10T01:39:23 INFO Attempting to reconnect...\\n2023-12-10T01:39:25 ERROR Connection failed', stack_trace='', customer_sentiment='neutral', previous_tickets=6, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 12, 11, 19, 29, 46, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['created_workaround', 'ran_diagnostics'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['performance', 'data', 'api', 'configuration', 'security'], environment='test', business_impact='critical', affected_users=922, language='pt', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000577', created_at=datetime.datetime(2024, 3, 19, 14, 4, 10, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 22, 11, 8, 22, tzinfo=datetime.timezone.utc), customer_id='CUST-03275', customer_tier='free', organization_id='ORG-432', product='DataSync Pro', product_version='3.0.15', product_module='scheduler', category='Account Management', subcategory='Access Control', priority='high', severity='P4', channel='portal', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-03-19T14:04:10 WARN Rate limit approaching threshold\\n2024-03-19T14:04:10 ERROR ERROR_MEMORY_OOM: Rate limit exceeded\\n2024-03-19T14:04:12 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='frustrated', previous_tickets=0, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 3, 22, 11, 8, 22, tzinfo=datetime.timezone.utc), agent_id='AGENT-021', agent_actions=['applied_fix', 'escalated_to_specialist', 'consulted_kb'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['error', 'database', 'bug'], environment='staging', business_impact='high', affected_users=506, language='zh', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000578', created_at=datetime.datetime(2024, 7, 7, 22, 44, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 8, 5, 44, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-00203', customer_tier='professional', organization_id='ORG-053', product='API Gateway', product_version='4.3.3', product_module='cache_layer', category='Feature Request', subcategory='Enhancement', priority='medium', severity='P2', channel='api', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-07-07T22:44:39 WARN Rate limit approaching threshold\\n2024-07-07T22:44:39 ERROR ERROR_NOTFOUND_404: Rate limit exceeded\\n2024-07-07T22:44:41 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'cache_layer.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='grateful', previous_tickets=9, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 7, 8, 5, 44, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-010', agent_actions=['updated_documentation', 'viewed_logs', 'ran_diagnostics', 'escalated_to_specialist', 'created_workaround'], escalated=False, transferred_count=1, satisfaction_score=1, resolution_helpful=True, tags=['security', 'integration'], environment='staging', business_impact='critical', affected_users=38, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000579', created_at=datetime.datetime(2023, 6, 30, 23, 15, 47, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 4, 14, 21, 47, tzinfo=datetime.timezone.utc), customer_id='CUST-02368', customer_tier='premium', organization_id='ORG-367', product='DataSync Pro', product_version='4.1.14', product_module='sync_engine', category='Technical Issue', subcategory='Compatibility', priority='medium', severity='P4', channel='phone', subject='Performance degradation in DataSync Pro', description=\"The DataSync Pro has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_SERVER_500 in the logs. This is affecting our entire team's productivity.\", error_logs='2023-06-30T23:15:47 DEBUG Processing request ID-12345\\n2023-06-30T23:15:47 ERROR ERROR_SERVER_500: Invalid request format\\n2023-06-30T23:15:48 INFO Request rejected', stack_trace='', customer_sentiment='angry', previous_tickets=3, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 7, 4, 14, 21, 47, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['viewed_logs', 'checked_config', 'verified_resolution', 'consulted_kb', 'escalated_to_specialist'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['timeout', 'database', 'performance'], environment='staging', business_impact='medium', affected_users=18, language='it', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000580', created_at=datetime.datetime(2023, 6, 15, 16, 20, 2, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 19, 23, 3, 50, tzinfo=datetime.timezone.utc), customer_id='CUST-00811', customer_tier='free', organization_id='ORG-293', product='CloudBackup Enterprise', product_version='3.6.11', product_module='compression_engine', category='Data Issue', subcategory='Import/Export', priority='medium', severity='P4', channel='email', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_NOTFOUND_404 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-06-15T16:20:02 ERROR ERROR_NOTFOUND_404: Database connection lost\\n2023-06-15T16:20:03 INFO Attempting to reconnect...\\n2023-06-15T16:20:05 ERROR Connection failed', stack_trace='at compression_engine.execute(compression_engine.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='satisfied', previous_tickets=7, resolution='Root cause identified as Import/Export issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 6, 19, 23, 3, 50, tzinfo=datetime.timezone.utc), agent_id='AGENT-036', agent_actions=['created_workaround', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=False, tags=['configuration', 'error', 'performance'], environment='test', business_impact='medium', affected_users=23, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000581', created_at=datetime.datetime(2023, 10, 25, 9, 2, 49, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 25, 16, 12, 25, tzinfo=datetime.timezone.utc), customer_id='CUST-00157', customer_tier='free', organization_id='ORG-224', product='StreamProcessor', product_version='4.0.2', product_module='event_handler', category='Technical Issue', subcategory='Integration', priority='medium', severity='P1', channel='api', subject='Performance degradation in StreamProcessor', description=\"The StreamProcessor has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_VALIDATION in the logs. This is affecting our entire team's productivity.\", error_logs='2023-10-25T09:02:49 DEBUG Processing request ID-12345\\n2023-10-25T09:02:49 ERROR ERROR_VALIDATION: Invalid request format\\n2023-10-25T09:02:50 INFO Request rejected', stack_trace='Stack trace:\\n  event_handler::processData() at event_handler.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='grateful', previous_tickets=1, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 10, 25, 16, 12, 25, tzinfo=datetime.timezone.utc), agent_id='AGENT-018', agent_actions=['updated_documentation', 'contacted_customer', 'ran_diagnostics'], escalated=True, transferred_count=1, satisfaction_score=1, resolution_helpful=False, tags=['error', 'sync', 'database', 'security'], environment='production', business_impact='medium', affected_users=3, language='pt', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000582', created_at=datetime.datetime(2024, 2, 3, 5, 14, 18, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 5, 12, 22, 42, tzinfo=datetime.timezone.utc), customer_id='CUST-03628', customer_tier='free', organization_id='ORG-274', product='Analytics Dashboard', product_version='2.2.5', product_module='report_builder', category='Data Issue', subcategory='Data Loss', priority='critical', severity='P4', channel='email', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=3, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 2, 5, 12, 22, 42, tzinfo=datetime.timezone.utc), agent_id='AGENT-049', agent_actions=['ran_diagnostics', 'contacted_customer', 'consulted_kb'], escalated=False, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['database', 'error', 'authentication', 'timeout', 'data'], environment='test', business_impact='critical', affected_users=251, language='pt', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000583', created_at=datetime.datetime(2024, 3, 14, 16, 17, 8, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 15, 18, 1, 32, tzinfo=datetime.timezone.utc), customer_id='CUST-01974', customer_tier='professional', organization_id='ORG-214', product='CloudBackup Enterprise', product_version='4.2.14', product_module='restore_module', category='Technical Issue', subcategory='Configuration', priority='medium', severity='P3', channel='api', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=10, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 3, 15, 18, 1, 32, tzinfo=datetime.timezone.utc), agent_id='AGENT-010', agent_actions=['viewed_logs', 'updated_documentation', 'contacted_customer', 'applied_fix', 'consulted_kb'], escalated=True, transferred_count=1, satisfaction_score=1, resolution_helpful=False, tags=['configuration', 'authentication', 'data', 'bug'], environment='sandbox', business_impact='high', affected_users=49, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000584', created_at=datetime.datetime(2023, 9, 25, 7, 53, 48, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 26, 1, 12, 24, tzinfo=datetime.timezone.utc), customer_id='CUST-00296', customer_tier='professional', organization_id='ORG-087', product='API Gateway', product_version='3.5.4', product_module='request_router', category='Feature Request', subcategory='New Feature', priority='low', severity='P1', channel='email', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-09-25T07:53:48 ERROR ERROR_SSL_CERT: Database connection lost\\n2023-09-25T07:53:49 INFO Attempting to reconnect...\\n2023-09-25T07:53:51 ERROR Connection failed', stack_trace='', customer_sentiment='frustrated', previous_tickets=2, resolution='Root cause identified as New Feature issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 9, 26, 1, 12, 24, tzinfo=datetime.timezone.utc), agent_id='AGENT-035', agent_actions=['consulted_kb', 'verified_resolution', 'escalated_to_specialist', 'checked_config'], escalated=True, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['timeout', 'api', 'integration', 'configuration'], environment='test', business_impact='low', affected_users=41, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000585', created_at=datetime.datetime(2024, 1, 5, 4, 21, 20, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 7, 2, 44, 44, tzinfo=datetime.timezone.utc), customer_id='CUST-04492', customer_tier='enterprise', organization_id='ORG-487', product='API Gateway', product_version='2.3.15', product_module='auth_service', category='Security', subcategory='Vulnerability', priority='high', severity='P4', channel='api', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=5, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 1, 7, 2, 44, 44, tzinfo=datetime.timezone.utc), agent_id='AGENT-050', agent_actions=['checked_config', 'applied_fix', 'escalated_to_specialist', 'verified_resolution'], escalated=True, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['data', 'authentication', 'timeout', 'api', 'security'], environment='sandbox', business_impact='medium', affected_users=523, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000586', created_at=datetime.datetime(2024, 3, 19, 2, 33, 12, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 20, 18, 6, 48, tzinfo=datetime.timezone.utc), customer_id='CUST-03952', customer_tier='enterprise', organization_id='ORG-024', product='API Gateway', product_version='3.1.6', product_module='rate_limiter', category='Account Management', subcategory='Access Control', priority='medium', severity='P3', channel='phone', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-03-19T02:33:12 ERROR ERROR_AUTH_401: Connection timeout after 30s\\n2024-03-19T02:33:13 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='confused', previous_tickets=0, resolution='Root cause identified as Access Control issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 3, 20, 18, 6, 48, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['consulted_kb', 'contacted_customer', 'ran_diagnostics', 'checked_config'], escalated=True, transferred_count=1, satisfaction_score=1, resolution_helpful=False, tags=['configuration', 'security', 'integration'], environment='staging', business_impact='high', affected_users=29, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000587', created_at=datetime.datetime(2024, 7, 25, 3, 38, 49, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 25, 5, 18, 25, tzinfo=datetime.timezone.utc), customer_id='CUST-01975', customer_tier='starter', organization_id='ORG-135', product='StreamProcessor', product_version='3.8.13', product_module='event_handler', category='Account Management', subcategory='Subscription', priority='critical', severity='P0', channel='email', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-07-25T03:38:49 ERROR ERROR_SERVER_500: Connection timeout after 30s\\n2024-07-25T03:38:50 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'event_handler.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='confused', previous_tickets=4, resolution='Root cause identified as Subscription issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 7, 25, 5, 18, 25, tzinfo=datetime.timezone.utc), agent_id='AGENT-037', agent_actions=['contacted_customer', 'applied_fix'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['error', 'integration'], environment='test', business_impact='critical', affected_users=511, language='de', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000588', created_at=datetime.datetime(2023, 6, 29, 20, 56, 7, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 30, 23, 54, 19, tzinfo=datetime.timezone.utc), customer_id='CUST-02388', customer_tier='free', organization_id='ORG-047', product='CloudBackup Enterprise', product_version='3.5.14', product_module='compression_engine', category='Feature Request', subcategory='UI/UX', priority='low', severity='P2', channel='chat', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-06-29T20:56:07 DEBUG Processing request ID-12345\\n2023-06-29T20:56:07 ERROR ERROR_VALIDATION: Invalid request format\\n2023-06-29T20:56:08 INFO Request rejected', stack_trace='at compression_engine.execute(compression_engine.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='grateful', previous_tickets=5, resolution='Root cause identified as UI/UX issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 6, 30, 23, 54, 19, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['ran_diagnostics', 'verified_resolution', 'updated_documentation'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['bug', 'api', 'database', 'sync', 'performance'], environment='development', business_impact='high', affected_users=11, language='de', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000589', created_at=datetime.datetime(2024, 5, 11, 14, 0, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 11, 14, 57, 2, tzinfo=datetime.timezone.utc), customer_id='CUST-02905', customer_tier='professional', organization_id='ORG-196', product='StreamProcessor', product_version='3.5.13', product_module='monitoring', category='Technical Issue', subcategory='Integration', priority='low', severity='P0', channel='slack', subject='StreamProcessor throwing ERROR_SERVER_500 during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing ERROR_SERVER_500 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-05-11T14:00:38 ERROR ERROR_SERVER_500: Connection timeout after 30s\\n2024-05-11T14:00:39 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='angry', previous_tickets=9, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 5, 11, 14, 57, 2, tzinfo=datetime.timezone.utc), agent_id='AGENT-020', agent_actions=['escalated_to_specialist', 'checked_config', 'viewed_logs', 'applied_fix'], escalated=True, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['security', 'timeout'], environment='production', business_impact='critical', affected_users=41, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000590', created_at=datetime.datetime(2023, 6, 3, 3, 34, 11, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 3, 16, 48, 35, tzinfo=datetime.timezone.utc), customer_id='CUST-00854', customer_tier='free', organization_id='ORG-318', product='API Gateway', product_version='4.4.4', product_module='request_router', category='Account Management', subcategory='Subscription', priority='low', severity='P1', channel='portal', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=0, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 6, 3, 16, 48, 35, tzinfo=datetime.timezone.utc), agent_id='AGENT-022', agent_actions=['ran_diagnostics', 'verified_resolution'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['bug', 'configuration'], environment='development', business_impact='high', affected_users=45, language='es', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000591', created_at=datetime.datetime(2023, 7, 12, 9, 52, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 19, 13, 15, 29, tzinfo=datetime.timezone.utc), customer_id='CUST-01249', customer_tier='premium', organization_id='ORG-373', product='StreamProcessor', product_version='3.8.1', product_module='event_handler', category='Technical Issue', subcategory='Performance', priority='low', severity='P4', channel='chat', subject='StreamProcessor throwing ERROR_CORRUPTION during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing ERROR_CORRUPTION when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-07-12T09:52:41 ERROR ERROR_CORRUPTION: Connection timeout after 30s\\n2023-07-12T09:52:42 RETRY_FAILED: Max retries exceeded', stack_trace='at event_handler.execute(event_handler.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='angry', previous_tickets=6, resolution='Root cause identified as Performance issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 7, 19, 13, 15, 29, tzinfo=datetime.timezone.utc), agent_id='AGENT-033', agent_actions=['viewed_logs', 'applied_fix', 'verified_resolution'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['bug', 'database'], environment='test', business_impact='critical', affected_users=25, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000592', created_at=datetime.datetime(2023, 7, 26, 13, 7, 58, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 26, 19, 17, 34, tzinfo=datetime.timezone.utc), customer_id='CUST-00658', customer_tier='premium', organization_id='ORG-357', product='CloudBackup Enterprise', product_version='2.3.14', product_module='restore_module', category='Feature Request', subcategory='New Feature', priority='high', severity='P2', channel='portal', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=7, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 7, 26, 19, 17, 34, tzinfo=datetime.timezone.utc), agent_id='AGENT-015', agent_actions=['updated_documentation', 'verified_resolution'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['security', 'bug', 'authentication', 'database'], environment='production', business_impact='critical', affected_users=610, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000593', created_at=datetime.datetime(2023, 2, 14, 14, 46, 16, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 18, 22, 52, 52, tzinfo=datetime.timezone.utc), customer_id='CUST-02185', customer_tier='free', organization_id='ORG-244', product='API Gateway', product_version='2.3.13', product_module='request_router', category='Security', subcategory='Encryption', priority='medium', severity='P4', channel='email', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_CORRUPTION errors. We need to ensure our system meets compliance requirements.', error_logs='2023-02-14T14:46:16 ERROR ERROR_CORRUPTION: Database connection lost\\n2023-02-14T14:46:17 INFO Attempting to reconnect...\\n2023-02-14T14:46:19 ERROR Connection failed', stack_trace='at request_router.execute(request_router.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='confused', previous_tickets=4, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 2, 18, 22, 52, 52, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['applied_fix', 'updated_documentation'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['performance', 'timeout'], environment='test', business_impact='critical', affected_users=26, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000594', created_at=datetime.datetime(2023, 5, 12, 16, 2, 50, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 12, 18, 37, 2, tzinfo=datetime.timezone.utc), customer_id='CUST-04782', customer_tier='enterprise', organization_id='ORG-359', product='StreamProcessor', product_version='3.1.0', product_module='monitoring', category='Feature Request', subcategory='UI/UX', priority='high', severity='P1', channel='api', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-05-12T16:02:50 ERROR ERROR_TIMEOUT_429: Connection timeout after 30s\\n2023-05-12T16:02:51 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='confused', previous_tickets=3, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 5, 12, 18, 37, 2, tzinfo=datetime.timezone.utc), agent_id='AGENT-012', agent_actions=['viewed_logs', 'verified_resolution', 'ran_diagnostics', 'updated_documentation', 'applied_fix', 'created_workaround'], escalated=True, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['bug', 'data', 'configuration', 'error', 'security'], environment='production', business_impact='low', affected_users=694, language='es', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000595', created_at=datetime.datetime(2023, 2, 8, 19, 3, 22, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 9, 16, 13, 34, tzinfo=datetime.timezone.utc), customer_id='CUST-04483', customer_tier='starter', organization_id='ORG-070', product='DataSync Pro', product_version='3.0.10', product_module='sync_engine', category='Security', subcategory='Authentication', priority='critical', severity='P3', channel='api', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_SERVER_500 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-02-08T19:03:22 ERROR ERROR_SERVER_500: Database connection lost\\n2023-02-08T19:03:23 INFO Attempting to reconnect...\\n2023-02-08T19:03:25 ERROR Connection failed', stack_trace='', customer_sentiment='angry', previous_tickets=6, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 2, 9, 16, 13, 34, tzinfo=datetime.timezone.utc), agent_id='AGENT-037', agent_actions=['checked_config', 'escalated_to_specialist', 'created_workaround', 'applied_fix', 'contacted_customer'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=False, tags=['error', 'integration', 'authentication', 'bug'], environment='staging', business_impact='medium', affected_users=750, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000596', created_at=datetime.datetime(2024, 4, 2, 23, 17, 6, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 3, 16, 59, 6, tzinfo=datetime.timezone.utc), customer_id='CUST-03063', customer_tier='starter', organization_id='ORG-099', product='Analytics Dashboard', product_version='4.4.15', product_module='data_aggregator', category='Technical Issue', subcategory='Configuration', priority='high', severity='P2', channel='chat', subject='Performance degradation in Analytics Dashboard', description=\"The Analytics Dashboard has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_TIMEOUT_429 in the logs. This is affecting our entire team's productivity.\", error_logs='2024-04-02T23:17:06 ERROR ERROR_TIMEOUT_429: Connection timeout after 30s\\n2024-04-02T23:17:07 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='frustrated', previous_tickets=5, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 4, 3, 16, 59, 6, tzinfo=datetime.timezone.utc), agent_id='AGENT-009', agent_actions=['created_workaround', 'consulted_kb'], escalated=True, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['authentication', 'data'], environment='sandbox', business_impact='critical', affected_users=145, language='de', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000597', created_at=datetime.datetime(2024, 12, 29, 14, 15, 55, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 30, 17, 3, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-03262', customer_tier='premium', organization_id='ORG-143', product='API Gateway', product_version='2.7.12', product_module='cache_layer', category='Technical Issue', subcategory='Performance', priority='high', severity='P3', channel='email', subject='Performance degradation in API Gateway', description=\"The API Gateway has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_CONNECTION_REFUSED in the logs. This is affecting our entire team's productivity.\", error_logs='2024-12-29T14:15:55 DEBUG Processing request ID-12345\\n2024-12-29T14:15:55 ERROR ERROR_CONNECTION_REFUSED: Invalid request format\\n2024-12-29T14:15:56 INFO Request rejected', stack_trace='', customer_sentiment='confused', previous_tickets=8, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 12, 30, 17, 3, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['updated_documentation', 'consulted_kb', 'created_workaround', 'contacted_customer', 'verified_resolution', 'viewed_logs'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['api', 'data', 'authentication'], environment='sandbox', business_impact='high', affected_users=874, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000598', created_at=datetime.datetime(2024, 9, 9, 14, 0, 4, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 12, 3, 32, 28, tzinfo=datetime.timezone.utc), customer_id='CUST-02455', customer_tier='starter', organization_id='ORG-135', product='API Gateway', product_version='3.9.14', product_module='auth_service', category='Feature Request', subcategory='UI/UX', priority='high', severity='P4', channel='chat', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-09-09T14:00:04 WARN Rate limit approaching threshold\\n2024-09-09T14:00:04 ERROR ERROR_NOTFOUND_404: Rate limit exceeded\\n2024-09-09T14:00:06 INFO Backing off for 60 seconds', stack_trace='at auth_service.execute(auth_service.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='confused', previous_tickets=2, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 9, 12, 3, 32, 28, tzinfo=datetime.timezone.utc), agent_id='AGENT-049', agent_actions=['escalated_to_specialist', 'consulted_kb'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['timeout', 'configuration', 'security', 'bug', 'sync'], environment='development', business_impact='low', affected_users=25, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000599', created_at=datetime.datetime(2024, 10, 18, 3, 16, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 19, 8, 40, 5, tzinfo=datetime.timezone.utc), customer_id='CUST-01471', customer_tier='enterprise', organization_id='ORG-013', product='StreamProcessor', product_version='3.7.3', product_module='monitoring', category='Data Issue', subcategory='Data Loss', priority='high', severity='P3', channel='phone', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=8, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 10, 19, 8, 40, 5, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['updated_documentation', 'escalated_to_specialist', 'checked_config', 'viewed_logs', 'applied_fix', 'ran_diagnostics'], escalated=True, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'security'], environment='production', business_impact='critical', affected_users=860, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000600', created_at=datetime.datetime(2023, 2, 17, 2, 41, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 19, 13, 29, 5, tzinfo=datetime.timezone.utc), customer_id='CUST-04781', customer_tier='starter', organization_id='ORG-004', product='API Gateway', product_version='2.2.10', product_module='rate_limiter', category='Account Management', subcategory='Access Control', priority='medium', severity='P4', channel='phone', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-02-17T02:41:41 ERROR ERROR_RATELIMIT_429: Connection timeout after 30s\\n2023-02-17T02:41:42 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='neutral', previous_tickets=8, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 2, 19, 13, 29, 5, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['escalated_to_specialist', 'contacted_customer', 'applied_fix'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['database', 'api'], environment='test', business_impact='medium', affected_users=45, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000601', created_at=datetime.datetime(2024, 12, 23, 5, 35, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 23, 5, 58, 24, tzinfo=datetime.timezone.utc), customer_id='CUST-00646', customer_tier='enterprise', organization_id='ORG-191', product='DataSync Pro', product_version='4.2.9', product_module='sync_engine', category='Security', subcategory='Vulnerability', priority='high', severity='P0', channel='chat', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_SERVER_500 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-12-23T05:35:00 ERROR ERROR_SERVER_500: Database connection lost\\n2024-12-23T05:35:01 INFO Attempting to reconnect...\\n2024-12-23T05:35:03 ERROR Connection failed', stack_trace='ERROR: sync_engine.service.ServiceException: Failed to process request\\n\\tat sync_engine.handler.process(sync_engine.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='confused', previous_tickets=2, resolution='Applied hotfix version 3.2.2 to address the ERROR_SERVER_500. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 12, 23, 5, 58, 24, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['created_workaround', 'checked_config', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['integration', 'api', 'timeout', 'configuration'], environment='staging', business_impact='medium', affected_users=318, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000602', created_at=datetime.datetime(2024, 7, 18, 23, 13, 58, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 19, 0, 4, 22, tzinfo=datetime.timezone.utc), customer_id='CUST-04369', customer_tier='enterprise', organization_id='ORG-141', product='Analytics Dashboard', product_version='3.8.9', product_module='data_aggregator', category='Feature Request', subcategory='UI/UX', priority='critical', severity='P0', channel='portal', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-07-18T23:13:58 WARN Rate limit approaching threshold\\n2024-07-18T23:13:58 ERROR ERROR_AUTH_401: Rate limit exceeded\\n2024-07-18T23:14:00 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'data_aggregator.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='neutral', previous_tickets=8, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 7, 19, 0, 4, 22, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['applied_fix', 'viewed_logs', 'verified_resolution', 'updated_documentation', 'created_workaround', 'checked_config'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['error', 'api', 'authentication'], environment='development', business_impact='high', affected_users=677, language='zh', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000603', created_at=datetime.datetime(2024, 5, 27, 8, 50, 7, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 28, 18, 59, 7, tzinfo=datetime.timezone.utc), customer_id='CUST-03827', customer_tier='professional', organization_id='ORG-424', product='StreamProcessor', product_version='3.5.8', product_module='event_handler', category='Feature Request', subcategory='API', priority='high', severity='P3', channel='slack', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-05-27T08:50:07 ERROR ERROR_SERVER_500: Database connection lost\\n2024-05-27T08:50:08 INFO Attempting to reconnect...\\n2024-05-27T08:50:10 ERROR Connection failed', stack_trace='ERROR: event_handler.service.ServiceException: Failed to process request\\n\\tat event_handler.handler.process(event_handler.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='neutral', previous_tickets=3, resolution='Root cause identified as API issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 5, 28, 18, 59, 7, tzinfo=datetime.timezone.utc), agent_id='AGENT-046', agent_actions=['contacted_customer', 'viewed_logs', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=False, tags=['authentication', 'security', 'error'], environment='development', business_impact='medium', affected_users=177, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000604', created_at=datetime.datetime(2023, 11, 14, 20, 44, 28, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 15, 16, 55, 52, tzinfo=datetime.timezone.utc), customer_id='CUST-01599', customer_tier='enterprise', organization_id='ORG-151', product='API Gateway', product_version='2.3.0', product_module='auth_service', category='Security', subcategory='Compliance', priority='medium', severity='P2', channel='email', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_CONNECTION_REFUSED errors. We need to ensure our system meets compliance requirements.', error_logs='2023-11-14T20:44:28 WARN Rate limit approaching threshold\\n2023-11-14T20:44:28 ERROR ERROR_CONNECTION_REFUSED: Rate limit exceeded\\n2023-11-14T20:44:30 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='satisfied', previous_tickets=1, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 11, 15, 16, 55, 52, tzinfo=datetime.timezone.utc), agent_id='AGENT-019', agent_actions=['verified_resolution', 'viewed_logs', 'created_workaround', 'checked_config'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['api', 'configuration', 'error'], environment='test', business_impact='medium', affected_users=18, language='de', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000605', created_at=datetime.datetime(2024, 11, 6, 4, 16, 5, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 8, 1, 47, 53, tzinfo=datetime.timezone.utc), customer_id='CUST-04196', customer_tier='premium', organization_id='ORG-239', product='Analytics Dashboard', product_version='3.3.4', product_module='report_builder', category='Security', subcategory='Authentication', priority='medium', severity='P3', channel='chat', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_NOTFOUND_404 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-11-06T04:16:05 ERROR ERROR_NOTFOUND_404: Database connection lost\\n2024-11-06T04:16:06 INFO Attempting to reconnect...\\n2024-11-06T04:16:08 ERROR Connection failed', stack_trace='', customer_sentiment='satisfied', previous_tickets=1, resolution='Root cause identified as Authentication issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 11, 8, 1, 47, 53, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['contacted_customer', 'consulted_kb', 'created_workaround'], escalated=False, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['authentication', 'database', 'security', 'integration', 'configuration'], environment='development', business_impact='medium', affected_users=29, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000606', created_at=datetime.datetime(2024, 8, 16, 10, 35, 53, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 17, 7, 3, 29, tzinfo=datetime.timezone.utc), customer_id='CUST-02927', customer_tier='premium', organization_id='ORG-270', product='DataSync Pro', product_version='2.0.5', product_module='api_connector', category='Security', subcategory='Authorization', priority='low', severity='P2', channel='api', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=6, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 8, 17, 7, 3, 29, tzinfo=datetime.timezone.utc), agent_id='AGENT-003', agent_actions=['escalated_to_specialist', 'created_workaround'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['configuration', 'api', 'sync', 'database'], environment='development', business_impact='high', affected_users=46, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000607', created_at=datetime.datetime(2023, 4, 6, 10, 23, 20, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 7, 11, 7, 44, tzinfo=datetime.timezone.utc), customer_id='CUST-04333', customer_tier='enterprise', organization_id='ORG-171', product='CloudBackup Enterprise', product_version='3.3.9', product_module='encryption_layer', category='Technical Issue', subcategory='Bug', priority='critical', severity='P3', channel='email', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_INVALID_400 in the logs. This is affecting our entire team's productivity.\", error_logs='2023-04-06T10:23:20 ERROR ERROR_INVALID_400: Database connection lost\\n2023-04-06T10:23:21 INFO Attempting to reconnect...\\n2023-04-06T10:23:23 ERROR Connection failed', stack_trace='', customer_sentiment='neutral', previous_tickets=4, resolution='Applied hotfix version 3.2.2 to address the ERROR_INVALID_400. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 4, 7, 11, 7, 44, tzinfo=datetime.timezone.utc), agent_id='AGENT-040', agent_actions=['applied_fix', 'created_workaround', 'consulted_kb'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=True, tags=['authentication', 'integration', 'api', 'data', 'bug'], environment='test', business_impact='low', affected_users=268, language='pt', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000608', created_at=datetime.datetime(2023, 7, 9, 7, 59, 25, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 9, 8, 46, 49, tzinfo=datetime.timezone.utc), customer_id='CUST-00937', customer_tier='enterprise', organization_id='ORG-340', product='API Gateway', product_version='3.0.7', product_module='cache_layer', category='Account Management', subcategory='Billing', priority='high', severity='P0', channel='phone', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-07-09T07:59:25 DEBUG Processing request ID-12345\\n2023-07-09T07:59:25 ERROR ERROR_CORRUPTION: Invalid request format\\n2023-07-09T07:59:26 INFO Request rejected', stack_trace='ERROR: cache_layer.service.ServiceException: Failed to process request\\n\\tat cache_layer.handler.process(cache_layer.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='satisfied', previous_tickets=3, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 7, 9, 8, 46, 49, tzinfo=datetime.timezone.utc), agent_id='AGENT-049', agent_actions=['checked_config', 'created_workaround'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['integration', 'timeout', 'bug', 'data'], environment='production', business_impact='high', affected_users=673, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000609', created_at=datetime.datetime(2023, 10, 23, 4, 51, 48, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 23, 6, 48, 12, tzinfo=datetime.timezone.utc), customer_id='CUST-02357', customer_tier='enterprise', organization_id='ORG-238', product='DataSync Pro', product_version='2.6.11', product_module='api_connector', category='Data Issue', subcategory='Data Loss', priority='critical', severity='P1', channel='email', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_CORRUPTION appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-10-23T04:51:48 ERROR ERROR_CORRUPTION: Database connection lost\\n2023-10-23T04:51:49 INFO Attempting to reconnect...\\n2023-10-23T04:51:51 ERROR Connection failed', stack_trace='', customer_sentiment='grateful', previous_tickets=1, resolution='Applied hotfix version 3.2.2 to address the ERROR_CORRUPTION. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 10, 23, 6, 48, 12, tzinfo=datetime.timezone.utc), agent_id='AGENT-037', agent_actions=['verified_resolution', 'checked_config', 'updated_documentation', 'contacted_customer', 'ran_diagnostics'], escalated=True, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['timeout', 'api', 'bug'], environment='staging', business_impact='critical', affected_users=867, language='de', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000610', created_at=datetime.datetime(2023, 4, 27, 17, 40, 46, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 28, 1, 54, 34, tzinfo=datetime.timezone.utc), customer_id='CUST-00389', customer_tier='starter', organization_id='ORG-131', product='DataSync Pro', product_version='3.7.5', product_module='scheduler', category='Security', subcategory='Encryption', priority='medium', severity='P2', channel='slack', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=9, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 4, 28, 1, 54, 34, tzinfo=datetime.timezone.utc), agent_id='AGENT-022', agent_actions=['consulted_kb', 'created_workaround', 'escalated_to_specialist', 'viewed_logs', 'updated_documentation', 'verified_resolution'], escalated=True, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['timeout', 'sync', 'bug', 'authentication'], environment='test', business_impact='low', affected_users=7, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000611', created_at=datetime.datetime(2023, 5, 19, 18, 33, 28, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 20, 23, 29, 16, tzinfo=datetime.timezone.utc), customer_id='CUST-04719', customer_tier='free', organization_id='ORG-155', product='API Gateway', product_version='4.2.15', product_module='cache_layer', category='Feature Request', subcategory='API', priority='medium', severity='P3', channel='chat', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-05-19T18:33:28 ERROR ERROR_SERVER_500: Database connection lost\\n2023-05-19T18:33:29 INFO Attempting to reconnect...\\n2023-05-19T18:33:31 ERROR Connection failed', stack_trace='', customer_sentiment='satisfied', previous_tickets=9, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 5, 20, 23, 29, 16, tzinfo=datetime.timezone.utc), agent_id='AGENT-017', agent_actions=['checked_config', 'viewed_logs', 'created_workaround'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['configuration', 'bug', 'error'], environment='development', business_impact='critical', affected_users=40, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000612', created_at=datetime.datetime(2024, 5, 26, 16, 27, 17, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 28, 8, 10, 29, tzinfo=datetime.timezone.utc), customer_id='CUST-03558', customer_tier='starter', organization_id='ORG-268', product='API Gateway', product_version='3.0.13', product_module='cache_layer', category='Technical Issue', subcategory='Configuration', priority='low', severity='P3', channel='slack', subject='Performance degradation in API Gateway', description=\"The API Gateway has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_PARSING in the logs. This is affecting our entire team's productivity.\", error_logs='2024-05-26T16:27:17 WARN Rate limit approaching threshold\\n2024-05-26T16:27:17 ERROR ERROR_PARSING: Rate limit exceeded\\n2024-05-26T16:27:19 INFO Backing off for 60 seconds', stack_trace='Stack trace:\\n  cache_layer::processData() at cache_layer.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='grateful', previous_tickets=6, resolution='Applied hotfix version 3.2.2 to address the ERROR_PARSING. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 5, 28, 8, 10, 29, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['checked_config', 'updated_documentation'], escalated=False, transferred_count=1, satisfaction_score=1, resolution_helpful=True, tags=['security', 'database', 'bug'], environment='staging', business_impact='high', affected_users=6, language='ja', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000613', created_at=datetime.datetime(2023, 8, 18, 12, 38, 23, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 19, 7, 44, 23, tzinfo=datetime.timezone.utc), customer_id='CUST-04290', customer_tier='free', organization_id='ORG-225', product='Analytics Dashboard', product_version='3.8.15', product_module='export_module', category='Feature Request', subcategory='Enhancement', priority='high', severity='P3', channel='slack', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-08-18T12:38:23 DEBUG Processing request ID-12345\\n2023-08-18T12:38:23 ERROR ERROR_CORRUPTION: Invalid request format\\n2023-08-18T12:38:24 INFO Request rejected', stack_trace='Stack trace:\\n  export_module::processData() at export_module.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='grateful', previous_tickets=5, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 8, 19, 7, 44, 23, tzinfo=datetime.timezone.utc), agent_id='AGENT-018', agent_actions=['checked_config', 'updated_documentation', 'viewed_logs', 'consulted_kb'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['timeout', 'performance', 'api'], environment='development', business_impact='medium', affected_users=406, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000614', created_at=datetime.datetime(2023, 9, 13, 17, 16, 18, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 13, 23, 52, 18, tzinfo=datetime.timezone.utc), customer_id='CUST-04272', customer_tier='enterprise', organization_id='ORG-013', product='DataSync Pro', product_version='3.9.4', product_module='api_connector', category='Technical Issue', subcategory='Performance', priority='high', severity='P2', channel='api', subject='DataSync Pro throwing ERROR_PARSING during operation', description=\"We're experiencing issues with DataSync Pro. The system is throwing ERROR_PARSING when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-09-13T17:16:18 ERROR ERROR_PARSING: Connection timeout after 30s\\n2023-09-13T17:16:19 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'api_connector.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='angry', previous_tickets=2, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 9, 13, 23, 52, 18, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['ran_diagnostics', 'applied_fix', 'created_workaround', 'checked_config'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=False, tags=['configuration', 'performance', 'integration'], environment='development', business_impact='critical', affected_users=932, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000615', created_at=datetime.datetime(2024, 3, 5, 5, 10, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 5, 7, 56, 53, tzinfo=datetime.timezone.utc), customer_id='CUST-01194', customer_tier='free', organization_id='ORG-384', product='CloudBackup Enterprise', product_version='3.5.12', product_module='compression_engine', category='Account Management', subcategory='Upgrade', priority='high', severity='P0', channel='slack', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=0, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 3, 5, 7, 56, 53, tzinfo=datetime.timezone.utc), agent_id='AGENT-041', agent_actions=['checked_config', 'ran_diagnostics', 'viewed_logs', 'escalated_to_specialist'], escalated=True, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['api', 'error', 'timeout', 'performance', 'security'], environment='sandbox', business_impact='critical', affected_users=825, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000616', created_at=datetime.datetime(2024, 5, 24, 23, 52, 32, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 25, 8, 41, 8, tzinfo=datetime.timezone.utc), customer_id='CUST-04908', customer_tier='enterprise', organization_id='ORG-067', product='Analytics Dashboard', product_version='4.8.3', product_module='data_aggregator', category='Technical Issue', subcategory='Compatibility', priority='high', severity='P2', channel='phone', subject='Performance degradation in Analytics Dashboard', description=\"The Analytics Dashboard has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=0, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 5, 25, 8, 41, 8, tzinfo=datetime.timezone.utc), agent_id='AGENT-050', agent_actions=['updated_documentation', 'consulted_kb', 'checked_config', 'applied_fix'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['authentication', 'bug', 'sync', 'security', 'integration'], environment='production', business_impact='low', affected_users=886, language='it', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000617', created_at=datetime.datetime(2024, 9, 28, 3, 2, 56, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 28, 4, 29, 56, tzinfo=datetime.timezone.utc), customer_id='CUST-01271', customer_tier='professional', organization_id='ORG-021', product='API Gateway', product_version='4.8.9', product_module='auth_service', category='Feature Request', subcategory='UI/UX', priority='low', severity='P0', channel='portal', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-09-28T03:02:56 ERROR ERROR_MEMORY_OOM: Database connection lost\\n2024-09-28T03:02:57 INFO Attempting to reconnect...\\n2024-09-28T03:02:59 ERROR Connection failed', stack_trace='', customer_sentiment='confused', previous_tickets=5, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 9, 28, 4, 29, 56, tzinfo=datetime.timezone.utc), agent_id='AGENT-025', agent_actions=['verified_resolution', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['database', 'error', 'security', 'integration'], environment='test', business_impact='low', affected_users=35, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000618', created_at=datetime.datetime(2024, 4, 30, 17, 29, 34, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 30, 20, 15, 10, tzinfo=datetime.timezone.utc), customer_id='CUST-04329', customer_tier='enterprise', organization_id='ORG-318', product='DataSync Pro', product_version='4.5.1', product_module='scheduler', category='Technical Issue', subcategory='Integration', priority='high', severity='P0', channel='portal', subject='Performance degradation in DataSync Pro', description=\"The DataSync Pro has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_DISK_FULL in the logs. This is affecting our entire team's productivity.\", error_logs='2024-04-30T17:29:34 ERROR ERROR_DISK_FULL: Connection timeout after 30s\\n2024-04-30T17:29:35 RETRY_FAILED: Max retries exceeded', stack_trace='ERROR: scheduler.service.ServiceException: Failed to process request\\n\\tat scheduler.handler.process(scheduler.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='satisfied', previous_tickets=3, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 4, 30, 20, 15, 10, tzinfo=datetime.timezone.utc), agent_id='AGENT-050', agent_actions=['created_workaround', 'viewed_logs', 'verified_resolution'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['configuration', 'security', 'error'], environment='production', business_impact='critical', affected_users=133, language='it', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000619', created_at=datetime.datetime(2024, 11, 17, 4, 49, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 21, 19, 38, 53, tzinfo=datetime.timezone.utc), customer_id='CUST-00265', customer_tier='premium', organization_id='ORG-468', product='DataSync Pro', product_version='3.2.10', product_module='data_validator', category='Technical Issue', subcategory='Configuration', priority='low', severity='P4', channel='phone', subject='DataSync Pro throwing errors during operation', description=\"We're experiencing issues with DataSync Pro. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=0, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 11, 21, 19, 38, 53, tzinfo=datetime.timezone.utc), agent_id='AGENT-033', agent_actions=['verified_resolution', 'viewed_logs', 'applied_fix'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['error', 'sync', 'data', 'authentication'], environment='test', business_impact='high', affected_users=29, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000620', created_at=datetime.datetime(2024, 4, 4, 0, 4, 52, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 6, 17, 43, 16, tzinfo=datetime.timezone.utc), customer_id='CUST-04143', customer_tier='premium', organization_id='ORG-053', product='API Gateway', product_version='2.4.5', product_module='auth_service', category='Data Issue', subcategory='Validation', priority='low', severity='P4', channel='email', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_NOTFOUND_404 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-04-04T00:04:52 ERROR ERROR_NOTFOUND_404: Database connection lost\\n2024-04-04T00:04:53 INFO Attempting to reconnect...\\n2024-04-04T00:04:55 ERROR Connection failed', stack_trace=\"Traceback (most recent call last):\\n  File 'auth_service.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='angry', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 4, 6, 17, 43, 16, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['checked_config', 'created_workaround', 'applied_fix', 'consulted_kb'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=True, tags=['timeout', 'integration', 'database'], environment='production', business_impact='medium', affected_users=10, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000621', created_at=datetime.datetime(2023, 9, 15, 20, 4, 14, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 16, 13, 42, 38, tzinfo=datetime.timezone.utc), customer_id='CUST-00049', customer_tier='enterprise', organization_id='ORG-113', product='StreamProcessor', product_version='3.9.6', product_module='batch_processor', category='Technical Issue', subcategory='Bug', priority='low', severity='P2', channel='api', subject='Performance degradation in StreamProcessor', description=\"The StreamProcessor has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_VALIDATION in the logs. This is affecting our entire team's productivity.\", error_logs='2023-09-15T20:04:14 ERROR ERROR_VALIDATION: Connection timeout after 30s\\n2023-09-15T20:04:15 RETRY_FAILED: Max retries exceeded', stack_trace='at batch_processor.execute(batch_processor.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='neutral', previous_tickets=0, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 9, 16, 13, 42, 38, tzinfo=datetime.timezone.utc), agent_id='AGENT-048', agent_actions=['verified_resolution', 'applied_fix', 'updated_documentation', 'contacted_customer', 'consulted_kb', 'viewed_logs'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['integration', 'error', 'database', 'timeout', 'sync'], environment='staging', business_impact='low', affected_users=2, language='pt', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000622', created_at=datetime.datetime(2024, 6, 3, 23, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 6, 22, 54, 12, tzinfo=datetime.timezone.utc), customer_id='CUST-03784', customer_tier='free', organization_id='ORG-197', product='CloudBackup Enterprise', product_version='2.8.10', product_module='compression_engine', category='Technical Issue', subcategory='Performance', priority='low', severity='P4', channel='phone', subject='CloudBackup Enterprise throwing ERROR_SSL_CERT during operation', description=\"We're experiencing issues with CloudBackup Enterprise. The system is throwing ERROR_SSL_CERT when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-06-03T23:38:00 DEBUG Processing request ID-12345\\n2024-06-03T23:38:00 ERROR ERROR_SSL_CERT: Invalid request format\\n2024-06-03T23:38:01 INFO Request rejected', stack_trace='', customer_sentiment='angry', previous_tickets=3, resolution='Root cause identified as Performance issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 6, 6, 22, 54, 12, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['ran_diagnostics', 'consulted_kb', 'checked_config', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['security', 'configuration', 'sync'], environment='production', business_impact='high', affected_users=24, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000623', created_at=datetime.datetime(2023, 3, 17, 8, 37, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 17, 11, 29, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-03789', customer_tier='professional', organization_id='ORG-491', product='CloudBackup Enterprise', product_version='2.2.2', product_module='encryption_layer', category='Technical Issue', subcategory='Performance', priority='critical', severity='P1', channel='phone', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_TIMEOUT_429 in the logs. This is affecting our entire team's productivity.\", error_logs='2023-03-17T08:37:39 ERROR ERROR_TIMEOUT_429: Database connection lost\\n2023-03-17T08:37:40 INFO Attempting to reconnect...\\n2023-03-17T08:37:42 ERROR Connection failed', stack_trace=\"Traceback (most recent call last):\\n  File 'encryption_layer.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='confused', previous_tickets=5, resolution='Applied hotfix version 3.2.2 to address the ERROR_TIMEOUT_429. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 3, 17, 11, 29, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-018', agent_actions=['checked_config', 'escalated_to_specialist', 'created_workaround'], escalated=True, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['sync', 'security', 'authentication'], environment='development', business_impact='critical', affected_users=987, language='zh', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000624', created_at=datetime.datetime(2024, 9, 3, 3, 48, 3, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 3, 10, 7, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-04645', customer_tier='professional', organization_id='ORG-257', product='CloudBackup Enterprise', product_version='2.3.2', product_module='restore_module', category='Security', subcategory='Authentication', priority='low', severity='P0', channel='api', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Getting ERROR_DEADLOCK errors. We need to ensure our system meets compliance requirements.', error_logs='2024-09-03T03:48:03 WARN Rate limit approaching threshold\\n2024-09-03T03:48:03 ERROR ERROR_DEADLOCK: Rate limit exceeded\\n2024-09-03T03:48:05 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='angry', previous_tickets=9, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 9, 3, 10, 7, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['applied_fix', 'viewed_logs', 'ran_diagnostics'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['performance', 'api', 'database', 'authentication'], environment='test', business_impact='medium', affected_users=4, language='pt', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000625', created_at=datetime.datetime(2024, 11, 7, 14, 24, 16, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 7, 15, 47, 40, tzinfo=datetime.timezone.utc), customer_id='CUST-01451', customer_tier='enterprise', organization_id='ORG-408', product='CloudBackup Enterprise', product_version='3.9.3', product_module='backup_service', category='Account Management', subcategory='Upgrade', priority='critical', severity='P0', channel='chat', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-11-07T14:24:16 WARN Rate limit approaching threshold\\n2024-11-07T14:24:16 ERROR ERROR_SSL_CERT: Rate limit exceeded\\n2024-11-07T14:24:18 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='angry', previous_tickets=4, resolution='Applied hotfix version 3.2.2 to address the ERROR_SSL_CERT. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 11, 7, 15, 47, 40, tzinfo=datetime.timezone.utc), agent_id='AGENT-032', agent_actions=['escalated_to_specialist', 'viewed_logs', 'verified_resolution'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['data', 'security', 'authentication', 'api'], environment='production', business_impact='low', affected_users=86, language='it', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000626', created_at=datetime.datetime(2023, 5, 19, 16, 18, 4, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 20, 3, 32, 28, tzinfo=datetime.timezone.utc), customer_id='CUST-03490', customer_tier='professional', organization_id='ORG-138', product='API Gateway', product_version='3.6.14', product_module='auth_service', category='Account Management', subcategory='Subscription', priority='critical', severity='P3', channel='slack', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-05-19T16:18:04 ERROR ERROR_NOTFOUND_404: Connection timeout after 30s\\n2023-05-19T16:18:05 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='grateful', previous_tickets=8, resolution='Applied hotfix version 3.2.2 to address the ERROR_NOTFOUND_404. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 5, 20, 3, 32, 28, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['escalated_to_specialist', 'checked_config'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=False, tags=['performance', 'timeout'], environment='staging', business_impact='low', affected_users=40, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000627', created_at=datetime.datetime(2023, 4, 9, 3, 25, 58, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 9, 5, 16, 22, tzinfo=datetime.timezone.utc), customer_id='CUST-04162', customer_tier='enterprise', organization_id='ORG-489', product='StreamProcessor', product_version='2.7.9', product_module='monitoring', category='Security', subcategory='Compliance', priority='critical', severity='P1', channel='portal', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=8, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 4, 9, 5, 16, 22, tzinfo=datetime.timezone.utc), agent_id='AGENT-019', agent_actions=['escalated_to_specialist', 'consulted_kb'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['integration', 'error'], environment='production', business_impact='medium', affected_users=905, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000628', created_at=datetime.datetime(2024, 11, 28, 22, 40, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 29, 3, 0, 24, tzinfo=datetime.timezone.utc), customer_id='CUST-03785', customer_tier='starter', organization_id='ORG-497', product='Analytics Dashboard', product_version='2.8.5', product_module='report_builder', category='Technical Issue', subcategory='Performance', priority='critical', severity='P1', channel='chat', subject='Analytics Dashboard throwing errors during operation', description=\"We're experiencing issues with Analytics Dashboard. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 11, 29, 3, 0, 24, tzinfo=datetime.timezone.utc), agent_id='AGENT-006', agent_actions=['checked_config', 'created_workaround', 'applied_fix'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['authentication', 'integration'], environment='sandbox', business_impact='medium', affected_users=154, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000629', created_at=datetime.datetime(2024, 12, 1, 2, 58, 49, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 1, 13, 19, 13, tzinfo=datetime.timezone.utc), customer_id='CUST-00978', customer_tier='premium', organization_id='ORG-161', product='CloudBackup Enterprise', product_version='4.0.12', product_module='encryption_layer', category='Security', subcategory='Compliance', priority='critical', severity='P3', channel='api', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=5, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 12, 1, 13, 19, 13, tzinfo=datetime.timezone.utc), agent_id='AGENT-015', agent_actions=['consulted_kb', 'updated_documentation', 'ran_diagnostics'], escalated=True, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['security', 'timeout', 'sync', 'bug', 'integration'], environment='production', business_impact='high', affected_users=220, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000630', created_at=datetime.datetime(2024, 12, 6, 15, 44, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 7, 0, 25, 33, tzinfo=datetime.timezone.utc), customer_id='CUST-04895', customer_tier='free', organization_id='ORG-157', product='StreamProcessor', product_version='2.4.0', product_module='monitoring', category='Security', subcategory='Authorization', priority='low', severity='P1', channel='api', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Getting ERROR_TIMEOUT_429 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-12-06T15:44:45 ERROR ERROR_TIMEOUT_429: Connection timeout after 30s\\n2024-12-06T15:44:46 RETRY_FAILED: Max retries exceeded', stack_trace='at monitoring.execute(monitoring.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='frustrated', previous_tickets=5, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 12, 7, 0, 25, 33, tzinfo=datetime.timezone.utc), agent_id='AGENT-033', agent_actions=['contacted_customer', 'checked_config'], escalated=False, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['integration', 'configuration', 'data', 'error', 'authentication'], environment='test', business_impact='critical', affected_users=16, language='pt', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000631', created_at=datetime.datetime(2024, 1, 1, 11, 9, 33, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 3, 5, 47, 57, tzinfo=datetime.timezone.utc), customer_id='CUST-01511', customer_tier='premium', organization_id='ORG-458', product='DataSync Pro', product_version='4.0.10', product_module='data_validator', category='Data Issue', subcategory='Data Loss', priority='medium', severity='P3', channel='slack', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_CORRUPTION appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-01-01T11:09:33 WARN Rate limit approaching threshold\\n2024-01-01T11:09:33 ERROR ERROR_CORRUPTION: Rate limit exceeded\\n2024-01-01T11:09:35 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='angry', previous_tickets=5, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 1, 3, 5, 47, 57, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['consulted_kb', 'ran_diagnostics', 'escalated_to_specialist'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['performance', 'authentication'], environment='development', business_impact='critical', affected_users=42, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000632', created_at=datetime.datetime(2024, 3, 19, 13, 16, 50, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 21, 15, 2, 26, tzinfo=datetime.timezone.utc), customer_id='CUST-01374', customer_tier='enterprise', organization_id='ORG-211', product='DataSync Pro', product_version='2.9.11', product_module='scheduler', category='Security', subcategory='Vulnerability', priority='critical', severity='P4', channel='email', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=7, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 3, 21, 15, 2, 26, tzinfo=datetime.timezone.utc), agent_id='AGENT-025', agent_actions=['escalated_to_specialist', 'viewed_logs', 'ran_diagnostics'], escalated=True, transferred_count=1, satisfaction_score=1, resolution_helpful=False, tags=['security', 'api', 'error', 'sync'], environment='test', business_impact='critical', affected_users=319, language='es', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000633', created_at=datetime.datetime(2024, 2, 18, 17, 14, 20, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 18, 19, 58, 8, tzinfo=datetime.timezone.utc), customer_id='CUST-04088', customer_tier='enterprise', organization_id='ORG-457', product='StreamProcessor', product_version='2.3.6', product_module='monitoring', category='Technical Issue', subcategory='Integration', priority='high', severity='P0', channel='portal', subject='Performance degradation in StreamProcessor', description=\"The StreamProcessor has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=6, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 2, 18, 19, 58, 8, tzinfo=datetime.timezone.utc), agent_id='AGENT-003', agent_actions=['ran_diagnostics', 'applied_fix', 'viewed_logs', 'created_workaround'], escalated=True, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['performance', 'integration', 'timeout'], environment='sandbox', business_impact='high', affected_users=588, language='en', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000634', created_at=datetime.datetime(2024, 7, 31, 22, 19, 56, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 1, 14, 48, 8, tzinfo=datetime.timezone.utc), customer_id='CUST-03248', customer_tier='professional', organization_id='ORG-375', product='API Gateway', product_version='4.9.12', product_module='rate_limiter', category='Security', subcategory='Encryption', priority='high', severity='P2', channel='email', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_SERVER_500 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-07-31T22:19:56 WARN Rate limit approaching threshold\\n2024-07-31T22:19:56 ERROR ERROR_SERVER_500: Rate limit exceeded\\n2024-07-31T22:19:58 INFO Backing off for 60 seconds', stack_trace='at rate_limiter.execute(rate_limiter.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='grateful', previous_tickets=10, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 8, 1, 14, 48, 8, tzinfo=datetime.timezone.utc), agent_id='AGENT-006', agent_actions=['applied_fix', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['integration', 'database', 'bug', 'sync'], environment='production', business_impact='high', affected_users=197, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000635', created_at=datetime.datetime(2023, 2, 26, 22, 49, 18, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 27, 3, 37, 54, tzinfo=datetime.timezone.utc), customer_id='CUST-03040', customer_tier='professional', organization_id='ORG-090', product='API Gateway', product_version='3.9.11', product_module='rate_limiter', category='Data Issue', subcategory='Data Loss', priority='low', severity='P0', channel='portal', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_RATELIMIT_429 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-02-26T22:49:18 WARN Rate limit approaching threshold\\n2023-02-26T22:49:18 ERROR ERROR_RATELIMIT_429: Rate limit exceeded\\n2023-02-26T22:49:20 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='grateful', previous_tickets=0, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 2, 27, 3, 37, 54, tzinfo=datetime.timezone.utc), agent_id='AGENT-046', agent_actions=['created_workaround', 'viewed_logs', 'updated_documentation', 'escalated_to_specialist'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=False, tags=['sync', 'data', 'database', 'timeout', 'error'], environment='test', business_impact='medium', affected_users=41, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000636', created_at=datetime.datetime(2024, 6, 22, 14, 48, 35, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 25, 16, 32, 23, tzinfo=datetime.timezone.utc), customer_id='CUST-00574', customer_tier='starter', organization_id='ORG-040', product='Analytics Dashboard', product_version='2.5.3', product_module='visualization', category='Data Issue', subcategory='Sync Error', priority='medium', severity='P4', channel='portal', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_CORRUPTION appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-06-22T14:48:35 DEBUG Processing request ID-12345\\n2024-06-22T14:48:35 ERROR ERROR_CORRUPTION: Invalid request format\\n2024-06-22T14:48:36 INFO Request rejected', stack_trace='', customer_sentiment='confused', previous_tickets=5, resolution='Root cause identified as Sync Error issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 6, 25, 16, 32, 23, tzinfo=datetime.timezone.utc), agent_id='AGENT-036', agent_actions=['viewed_logs', 'consulted_kb', 'checked_config'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['data', 'sync'], environment='development', business_impact='low', affected_users=29, language='zh', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000637', created_at=datetime.datetime(2024, 4, 10, 17, 56, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 10, 23, 30, 17, tzinfo=datetime.timezone.utc), customer_id='CUST-04413', customer_tier='premium', organization_id='ORG-420', product='StreamProcessor', product_version='3.7.7', product_module='event_handler', category='Data Issue', subcategory='Data Loss', priority='critical', severity='P1', channel='chat', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=3, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 4, 10, 23, 30, 17, tzinfo=datetime.timezone.utc), agent_id='AGENT-035', agent_actions=['checked_config', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=False, tags=['performance', 'authentication'], environment='test', business_impact='high', affected_users=486, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000638', created_at=datetime.datetime(2023, 12, 29, 1, 50, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 31, 22, 25, 25, tzinfo=datetime.timezone.utc), customer_id='CUST-03332', customer_tier='starter', organization_id='ORG-208', product='API Gateway', product_version='2.5.14', product_module='auth_service', category='Technical Issue', subcategory='Integration', priority='low', severity='P3', channel='chat', subject='API Gateway throwing ERROR_INVALID_400 during operation', description=\"We're experiencing issues with API Gateway. The system is throwing ERROR_INVALID_400 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-12-29T01:50:37 WARN Rate limit approaching threshold\\n2023-12-29T01:50:37 ERROR ERROR_INVALID_400: Rate limit exceeded\\n2023-12-29T01:50:39 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='neutral', previous_tickets=7, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 12, 31, 22, 25, 25, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['verified_resolution', 'viewed_logs'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['performance', 'timeout', 'data', 'authentication'], environment='sandbox', business_impact='low', affected_users=13, language='it', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000639', created_at=datetime.datetime(2024, 11, 20, 3, 10, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 20, 5, 44, 48, tzinfo=datetime.timezone.utc), customer_id='CUST-01673', customer_tier='starter', organization_id='ORG-293', product='API Gateway', product_version='3.3.8', product_module='cache_layer', category='Feature Request', subcategory='API', priority='medium', severity='P0', channel='phone', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=4, resolution='Root cause identified as API issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 11, 20, 5, 44, 48, tzinfo=datetime.timezone.utc), agent_id='AGENT-001', agent_actions=['created_workaround', 'applied_fix', 'consulted_kb', 'escalated_to_specialist'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['timeout', 'sync', 'performance', 'api'], environment='development', business_impact='high', affected_users=12, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000640', created_at=datetime.datetime(2023, 7, 11, 8, 39, 58, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 12, 7, 24, 58, tzinfo=datetime.timezone.utc), customer_id='CUST-01401', customer_tier='enterprise', organization_id='ORG-053', product='Analytics Dashboard', product_version='3.3.4', product_module='visualization', category='Feature Request', subcategory='New Feature', priority='high', severity='P3', channel='chat', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-07-11T08:39:58 WARN Rate limit approaching threshold\\n2023-07-11T08:39:58 ERROR ERROR_INVALID_400: Rate limit exceeded\\n2023-07-11T08:40:00 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='angry', previous_tickets=9, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 7, 12, 7, 24, 58, tzinfo=datetime.timezone.utc), agent_id='AGENT-048', agent_actions=['contacted_customer', 'updated_documentation', 'checked_config', 'consulted_kb'], escalated=True, transferred_count=1, satisfaction_score=1, resolution_helpful=True, tags=['timeout', 'error'], environment='development', business_impact='low', affected_users=95, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000641', created_at=datetime.datetime(2024, 12, 16, 23, 42, 31, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 17, 12, 59, 19, tzinfo=datetime.timezone.utc), customer_id='CUST-04450', customer_tier='professional', organization_id='ORG-230', product='CloudBackup Enterprise', product_version='2.6.13', product_module='encryption_layer', category='Feature Request', subcategory='API', priority='critical', severity='P3', channel='api', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-12-16T23:42:31 ERROR ERROR_CONNECTION_REFUSED: Database connection lost\\n2024-12-16T23:42:32 INFO Attempting to reconnect...\\n2024-12-16T23:42:34 ERROR Connection failed', stack_trace='', customer_sentiment='angry', previous_tickets=1, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 12, 17, 12, 59, 19, tzinfo=datetime.timezone.utc), agent_id='AGENT-032', agent_actions=['consulted_kb', 'updated_documentation', 'escalated_to_specialist', 'created_workaround', 'ran_diagnostics'], escalated=True, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['authentication', 'bug', 'data', 'security'], environment='production', business_impact='high', affected_users=322, language='ja', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000642', created_at=datetime.datetime(2024, 10, 21, 13, 23, 19, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 22, 19, 13, 7, tzinfo=datetime.timezone.utc), customer_id='CUST-03202', customer_tier='free', organization_id='ORG-248', product='Analytics Dashboard', product_version='3.8.2', product_module='report_builder', category='Feature Request', subcategory='New Feature', priority='medium', severity='P2', channel='chat', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=2, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 10, 22, 19, 13, 7, tzinfo=datetime.timezone.utc), agent_id='AGENT-001', agent_actions=['updated_documentation', 'applied_fix'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['sync', 'bug'], environment='staging', business_impact='medium', affected_users=32, language='zh', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000643', created_at=datetime.datetime(2024, 8, 14, 2, 21, 55, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 18, 17, 34, 31, tzinfo=datetime.timezone.utc), customer_id='CUST-01919', customer_tier='enterprise', organization_id='ORG-326', product='Analytics Dashboard', product_version='2.9.3', product_module='export_module', category='Account Management', subcategory='Upgrade', priority='medium', severity='P4', channel='api', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-08-14T02:21:55 ERROR ERROR_INVALID_400: Connection timeout after 30s\\n2024-08-14T02:21:56 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='grateful', previous_tickets=7, resolution='Root cause identified as Upgrade issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 8, 18, 17, 34, 31, tzinfo=datetime.timezone.utc), agent_id='AGENT-018', agent_actions=['ran_diagnostics', 'updated_documentation', 'verified_resolution', 'consulted_kb', 'escalated_to_specialist'], escalated=True, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['error', 'performance', 'bug', 'configuration', 'timeout'], environment='staging', business_impact='low', affected_users=27, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000644', created_at=datetime.datetime(2023, 7, 30, 2, 58, 4, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 1, 1, 44, 16, tzinfo=datetime.timezone.utc), customer_id='CUST-04625', customer_tier='enterprise', organization_id='ORG-100', product='DataSync Pro', product_version='3.4.7', product_module='api_connector', category='Feature Request', subcategory='API', priority='medium', severity='P4', channel='phone', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-07-30T02:58:04 WARN Rate limit approaching threshold\\n2023-07-30T02:58:04 ERROR ERROR_CONFLICT_409: Rate limit exceeded\\n2023-07-30T02:58:06 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='frustrated', previous_tickets=9, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 8, 1, 1, 44, 16, tzinfo=datetime.timezone.utc), agent_id='AGENT-020', agent_actions=['updated_documentation', 'contacted_customer', 'ran_diagnostics', 'consulted_kb'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['bug', 'api', 'sync', 'configuration'], environment='production', business_impact='critical', affected_users=21, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000645', created_at=datetime.datetime(2024, 10, 9, 14, 34, 47, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 9, 15, 24, 35, tzinfo=datetime.timezone.utc), customer_id='CUST-03432', customer_tier='professional', organization_id='ORG-113', product='StreamProcessor', product_version='3.3.7', product_module='event_handler', category='Technical Issue', subcategory='Performance', priority='high', severity='P0', channel='slack', subject='StreamProcessor throwing errors during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=0, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 10, 9, 15, 24, 35, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['created_workaround', 'escalated_to_specialist', 'ran_diagnostics', 'checked_config', 'consulted_kb', 'viewed_logs'], escalated=True, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['sync', 'integration', 'timeout'], environment='staging', business_impact='medium', affected_users=637, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000646', created_at=datetime.datetime(2023, 4, 4, 18, 28, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 5, 7, 51, 27, tzinfo=datetime.timezone.utc), customer_id='CUST-00467', customer_tier='starter', organization_id='ORG-130', product='CloudBackup Enterprise', product_version='3.4.7', product_module='restore_module', category='Feature Request', subcategory='Enhancement', priority='medium', severity='P2', channel='email', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=9, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 4, 5, 7, 51, 27, tzinfo=datetime.timezone.utc), agent_id='AGENT-029', agent_actions=['consulted_kb', 'updated_documentation', 'viewed_logs', 'applied_fix'], escalated=True, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['configuration', 'timeout', 'sync'], environment='staging', business_impact='low', affected_users=33, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000647', created_at=datetime.datetime(2023, 3, 25, 19, 25, 8, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 26, 0, 8, 20, tzinfo=datetime.timezone.utc), customer_id='CUST-03403', customer_tier='premium', organization_id='ORG-194', product='API Gateway', product_version='2.3.10', product_module='auth_service', category='Data Issue', subcategory='Sync Error', priority='high', severity='P1', channel='portal', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 3, 26, 0, 8, 20, tzinfo=datetime.timezone.utc), agent_id='AGENT-046', agent_actions=['consulted_kb', 'viewed_logs'], escalated=True, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['configuration', 'bug', 'api'], environment='development', business_impact='critical', affected_users=655, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000648', created_at=datetime.datetime(2023, 6, 21, 8, 40, 4, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 27, 15, 3, 28, tzinfo=datetime.timezone.utc), customer_id='CUST-00118', customer_tier='premium', organization_id='ORG-257', product='DataSync Pro', product_version='4.7.12', product_module='api_connector', category='Account Management', subcategory='Billing', priority='low', severity='P4', channel='portal', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-06-21T08:40:04 DEBUG Processing request ID-12345\\n2023-06-21T08:40:04 ERROR ERROR_SSL_CERT: Invalid request format\\n2023-06-21T08:40:05 INFO Request rejected', stack_trace='ERROR: api_connector.service.ServiceException: Failed to process request\\n\\tat api_connector.handler.process(api_connector.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='angry', previous_tickets=1, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 6, 27, 15, 3, 28, tzinfo=datetime.timezone.utc), agent_id='AGENT-009', agent_actions=['checked_config', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['configuration', 'error', 'timeout'], environment='sandbox', business_impact='low', affected_users=26, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000649', created_at=datetime.datetime(2024, 2, 27, 6, 55, 25, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 4, 0, 20, 1, tzinfo=datetime.timezone.utc), customer_id='CUST-00568', customer_tier='free', organization_id='ORG-113', product='CloudBackup Enterprise', product_version='4.1.2', product_module='backup_service', category='Security', subcategory='Authentication', priority='low', severity='P4', channel='api', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=6, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 3, 4, 0, 20, 1, tzinfo=datetime.timezone.utc), agent_id='AGENT-023', agent_actions=['escalated_to_specialist', 'updated_documentation'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['sync', 'bug', 'configuration'], environment='test', business_impact='critical', affected_users=43, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000650', created_at=datetime.datetime(2024, 3, 12, 9, 42, 40, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 12, 11, 44, 28, tzinfo=datetime.timezone.utc), customer_id='CUST-01374', customer_tier='enterprise', organization_id='ORG-211', product='Analytics Dashboard', product_version='3.8.8', product_module='report_builder', category='Security', subcategory='Authentication', priority='medium', severity='P1', channel='email', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_PARSING errors. We need to ensure our system meets compliance requirements.', error_logs='2024-03-12T09:42:40 ERROR ERROR_PARSING: Connection timeout after 30s\\n2024-03-12T09:42:41 RETRY_FAILED: Max retries exceeded', stack_trace='at report_builder.execute(report_builder.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='frustrated', previous_tickets=1, resolution='Root cause identified as Authentication issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 3, 12, 11, 44, 28, tzinfo=datetime.timezone.utc), agent_id='AGENT-013', agent_actions=['checked_config', 'applied_fix', 'consulted_kb'], escalated=True, transferred_count=1, satisfaction_score=1, resolution_helpful=False, tags=['security', 'sync', 'configuration'], environment='staging', business_impact='low', affected_users=13, language='es', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000651', created_at=datetime.datetime(2023, 2, 8, 21, 35, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 9, 20, 12, 57, tzinfo=datetime.timezone.utc), customer_id='CUST-01542', customer_tier='enterprise', organization_id='ORG-403', product='CloudBackup Enterprise', product_version='2.6.3', product_module='compression_engine', category='Feature Request', subcategory='New Feature', priority='high', severity='P4', channel='email', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-02-08T21:35:45 WARN Rate limit approaching threshold\\n2023-02-08T21:35:45 ERROR ERROR_INVALID_400: Rate limit exceeded\\n2023-02-08T21:35:47 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='satisfied', previous_tickets=7, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 2, 9, 20, 12, 57, tzinfo=datetime.timezone.utc), agent_id='AGENT-042', agent_actions=['verified_resolution', 'updated_documentation', 'contacted_customer', 'consulted_kb'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['integration', 'authentication', 'api'], environment='development', business_impact='critical', affected_users=315, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000652', created_at=datetime.datetime(2024, 4, 21, 11, 40, 23, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 21, 15, 0, 47, tzinfo=datetime.timezone.utc), customer_id='CUST-04818', customer_tier='premium', organization_id='ORG-346', product='API Gateway', product_version='4.7.1', product_module='auth_service', category='Data Issue', subcategory='Import/Export', priority='low', severity='P1', channel='portal', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_SERVER_500 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-04-21T11:40:23 DEBUG Processing request ID-12345\\n2024-04-21T11:40:23 ERROR ERROR_SERVER_500: Invalid request format\\n2024-04-21T11:40:24 INFO Request rejected', stack_trace='Stack trace:\\n  auth_service::processData() at auth_service.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='confused', previous_tickets=9, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 4, 21, 15, 0, 47, tzinfo=datetime.timezone.utc), agent_id='AGENT-003', agent_actions=['escalated_to_specialist', 'updated_documentation', 'consulted_kb', 'checked_config', 'applied_fix'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['sync', 'security', 'performance', 'database'], environment='staging', business_impact='critical', affected_users=36, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000653', created_at=datetime.datetime(2024, 3, 8, 9, 17, 16, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 8, 20, 10, 40, tzinfo=datetime.timezone.utc), customer_id='CUST-00065', customer_tier='professional', organization_id='ORG-451', product='StreamProcessor', product_version='4.8.15', product_module='error_handler', category='Data Issue', subcategory='Data Loss', priority='high', severity='P2', channel='slack', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_PARSING appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-03-08T09:17:16 DEBUG Processing request ID-12345\\n2024-03-08T09:17:16 ERROR ERROR_PARSING: Invalid request format\\n2024-03-08T09:17:17 INFO Request rejected', stack_trace='at error_handler.execute(error_handler.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='confused', previous_tickets=8, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 3, 8, 20, 10, 40, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['created_workaround', 'applied_fix', 'checked_config', 'updated_documentation'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=False, tags=['api', 'authentication'], environment='production', business_impact='high', affected_users=571, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000654', created_at=datetime.datetime(2024, 8, 10, 20, 58, 42, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 11, 6, 0, 30, tzinfo=datetime.timezone.utc), customer_id='CUST-00242', customer_tier='starter', organization_id='ORG-212', product='CloudBackup Enterprise', product_version='4.0.10', product_module='restore_module', category='Account Management', subcategory='Billing', priority='critical', severity='P3', channel='slack', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-08-10T20:58:42 ERROR ERROR_DISK_FULL: Connection timeout after 30s\\n2024-08-10T20:58:43 RETRY_FAILED: Max retries exceeded', stack_trace='Stack trace:\\n  restore_module::processData() at restore_module.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='confused', previous_tickets=2, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 8, 11, 6, 0, 30, tzinfo=datetime.timezone.utc), agent_id='AGENT-026', agent_actions=['checked_config', 'escalated_to_specialist', 'created_workaround', 'updated_documentation', 'viewed_logs'], escalated=True, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['api', 'integration'], environment='staging', business_impact='critical', affected_users=260, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000655', created_at=datetime.datetime(2023, 10, 31, 19, 3, 6, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 2, 19, 15, 6, tzinfo=datetime.timezone.utc), customer_id='CUST-01412', customer_tier='premium', organization_id='ORG-011', product='DataSync Pro', product_version='3.7.14', product_module='sync_engine', category='Data Issue', subcategory='Sync Error', priority='critical', severity='P4', channel='email', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_NOTFOUND_404 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-10-31T19:03:06 ERROR ERROR_NOTFOUND_404: Connection timeout after 30s\\n2023-10-31T19:03:07 RETRY_FAILED: Max retries exceeded', stack_trace='Stack trace:\\n  sync_engine::processData() at sync_engine.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='neutral', previous_tickets=3, resolution='Applied hotfix version 3.2.2 to address the ERROR_NOTFOUND_404. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 11, 2, 19, 15, 6, tzinfo=datetime.timezone.utc), agent_id='AGENT-010', agent_actions=['checked_config', 'verified_resolution', 'consulted_kb', 'escalated_to_specialist'], escalated=True, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['data', 'integration', 'bug'], environment='development', business_impact='high', affected_users=504, language='it', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000656', created_at=datetime.datetime(2023, 9, 24, 10, 21, 42, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 27, 4, 0, 42, tzinfo=datetime.timezone.utc), customer_id='CUST-01289', customer_tier='free', organization_id='ORG-301', product='CloudBackup Enterprise', product_version='2.8.14', product_module='backup_service', category='Data Issue', subcategory='Import/Export', priority='high', severity='P4', channel='phone', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_MEMORY_OOM appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-09-24T10:21:42 DEBUG Processing request ID-12345\\n2023-09-24T10:21:42 ERROR ERROR_MEMORY_OOM: Invalid request format\\n2023-09-24T10:21:43 INFO Request rejected', stack_trace='at backup_service.execute(backup_service.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='satisfied', previous_tickets=7, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 9, 27, 4, 0, 42, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['checked_config', 'applied_fix'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['timeout', 'performance'], environment='staging', business_impact='high', affected_users=90, language='es', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000657', created_at=datetime.datetime(2023, 11, 3, 9, 35, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 6, 1, 27, 49, tzinfo=datetime.timezone.utc), customer_id='CUST-03258', customer_tier='enterprise', organization_id='ORG-479', product='DataSync Pro', product_version='4.2.4', product_module='scheduler', category='Technical Issue', subcategory='Performance', priority='high', severity='P4', channel='api', subject='Performance degradation in DataSync Pro', description=\"The DataSync Pro has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_PARSING in the logs. This is affecting our entire team's productivity.\", error_logs='2023-11-03T09:35:37 WARN Rate limit approaching threshold\\n2023-11-03T09:35:37 ERROR ERROR_PARSING: Rate limit exceeded\\n2023-11-03T09:35:39 INFO Backing off for 60 seconds', stack_trace='ERROR: scheduler.service.ServiceException: Failed to process request\\n\\tat scheduler.handler.process(scheduler.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='frustrated', previous_tickets=8, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 11, 6, 1, 27, 49, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['ran_diagnostics', 'checked_config', 'created_workaround', 'applied_fix', 'contacted_customer', 'viewed_logs'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=True, tags=['configuration', 'api', 'timeout'], environment='test', business_impact='low', affected_users=977, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000658', created_at=datetime.datetime(2024, 11, 24, 22, 44, 48, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 28, 9, 52, 36, tzinfo=datetime.timezone.utc), customer_id='CUST-02261', customer_tier='free', organization_id='ORG-456', product='DataSync Pro', product_version='3.9.4', product_module='api_connector', category='Security', subcategory='Vulnerability', priority='low', severity='P4', channel='chat', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_TIMEOUT_429 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-11-24T22:44:48 ERROR ERROR_TIMEOUT_429: Connection timeout after 30s\\n2024-11-24T22:44:49 RETRY_FAILED: Max retries exceeded', stack_trace='at api_connector.execute(api_connector.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='satisfied', previous_tickets=5, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 11, 28, 9, 52, 36, tzinfo=datetime.timezone.utc), agent_id='AGENT-046', agent_actions=['checked_config', 'updated_documentation'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['authentication', 'error'], environment='test', business_impact='low', affected_users=29, language='pt', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000659', created_at=datetime.datetime(2023, 6, 13, 17, 11, 10, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 14, 2, 10, 34, tzinfo=datetime.timezone.utc), customer_id='CUST-04374', customer_tier='professional', organization_id='ORG-429', product='Analytics Dashboard', product_version='4.2.14', product_module='data_aggregator', category='Account Management', subcategory='License', priority='medium', severity='P2', channel='email', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=1, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 6, 14, 2, 10, 34, tzinfo=datetime.timezone.utc), agent_id='AGENT-035', agent_actions=['updated_documentation', 'viewed_logs'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['error', 'performance', 'database'], environment='test', business_impact='low', affected_users=3, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000660', created_at=datetime.datetime(2023, 4, 16, 20, 24, 27, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 16, 23, 31, 3, tzinfo=datetime.timezone.utc), customer_id='CUST-00466', customer_tier='premium', organization_id='ORG-011', product='StreamProcessor', product_version='4.2.15', product_module='event_handler', category='Data Issue', subcategory='Validation', priority='critical', severity='P1', channel='chat', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_CONFLICT_409 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-04-16T20:24:27 ERROR ERROR_CONFLICT_409: Database connection lost\\n2023-04-16T20:24:28 INFO Attempting to reconnect...\\n2023-04-16T20:24:30 ERROR Connection failed', stack_trace='Stack trace:\\n  event_handler::processData() at event_handler.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='angry', previous_tickets=0, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 4, 16, 23, 31, 3, tzinfo=datetime.timezone.utc), agent_id='AGENT-026', agent_actions=['checked_config', 'escalated_to_specialist'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['timeout', 'security', 'authentication', 'integration', 'api'], environment='sandbox', business_impact='medium', affected_users=523, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000661', created_at=datetime.datetime(2023, 10, 29, 20, 11, 17, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 1, 1, 46, 5, tzinfo=datetime.timezone.utc), customer_id='CUST-01077', customer_tier='free', organization_id='ORG-276', product='DataSync Pro', product_version='2.9.11', product_module='data_validator', category='Account Management', subcategory='Subscription', priority='medium', severity='P3', channel='email', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-10-29T20:11:17 DEBUG Processing request ID-12345\\n2023-10-29T20:11:17 ERROR ERROR_PERMISSION_403: Invalid request format\\n2023-10-29T20:11:18 INFO Request rejected', stack_trace='', customer_sentiment='satisfied', previous_tickets=10, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 11, 1, 1, 46, 5, tzinfo=datetime.timezone.utc), agent_id='AGENT-015', agent_actions=['escalated_to_specialist', 'consulted_kb', 'applied_fix', 'created_workaround'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['security', 'configuration'], environment='sandbox', business_impact='medium', affected_users=25, language='zh', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000662', created_at=datetime.datetime(2023, 6, 17, 21, 12, 31, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 18, 1, 17, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-00810', customer_tier='premium', organization_id='ORG-330', product='Analytics Dashboard', product_version='2.1.7', product_module='data_aggregator', category='Data Issue', subcategory='Sync Error', priority='critical', severity='P1', channel='portal', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=2, resolution='Root cause identified as Sync Error issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 6, 18, 1, 17, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-019', agent_actions=['contacted_customer', 'viewed_logs'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['bug', 'security', 'integration', 'sync'], environment='sandbox', business_impact='high', affected_users=59, language='es', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000663', created_at=datetime.datetime(2023, 3, 3, 20, 16, 53, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 5, 18, 52, 17, tzinfo=datetime.timezone.utc), customer_id='CUST-02142', customer_tier='free', organization_id='ORG-305', product='API Gateway', product_version='2.6.6', product_module='rate_limiter', category='Data Issue', subcategory='Data Loss', priority='medium', severity='P3', channel='chat', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_SERVER_500 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-03-03T20:16:53 WARN Rate limit approaching threshold\\n2023-03-03T20:16:53 ERROR ERROR_SERVER_500: Rate limit exceeded\\n2023-03-03T20:16:55 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='satisfied', previous_tickets=9, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 3, 5, 18, 52, 17, tzinfo=datetime.timezone.utc), agent_id='AGENT-027', agent_actions=['updated_documentation', 'viewed_logs', 'contacted_customer'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['timeout', 'data', 'configuration'], environment='development', business_impact='critical', affected_users=38, language='it', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000664', created_at=datetime.datetime(2024, 3, 27, 20, 9, 23, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 28, 7, 15, 23, tzinfo=datetime.timezone.utc), customer_id='CUST-02941', customer_tier='premium', organization_id='ORG-408', product='API Gateway', product_version='4.4.2', product_module='rate_limiter', category='Data Issue', subcategory='Validation', priority='low', severity='P2', channel='portal', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_AUTH_401 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-03-27T20:09:23 ERROR ERROR_AUTH_401: Database connection lost\\n2024-03-27T20:09:24 INFO Attempting to reconnect...\\n2024-03-27T20:09:26 ERROR Connection failed', stack_trace='ERROR: rate_limiter.service.ServiceException: Failed to process request\\n\\tat rate_limiter.handler.process(rate_limiter.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='confused', previous_tickets=4, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 3, 28, 7, 15, 23, tzinfo=datetime.timezone.utc), agent_id='AGENT-021', agent_actions=['ran_diagnostics', 'contacted_customer', 'verified_resolution', 'updated_documentation', 'created_workaround'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['sync', 'api', 'data', 'error'], environment='staging', business_impact='medium', affected_users=3, language='pt', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000665', created_at=datetime.datetime(2024, 1, 27, 10, 12, 57, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 1, 5, 29, 9, tzinfo=datetime.timezone.utc), customer_id='CUST-04251', customer_tier='premium', organization_id='ORG-081', product='StreamProcessor', product_version='3.6.13', product_module='batch_processor', category='Account Management', subcategory='Access Control', priority='low', severity='P4', channel='portal', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-01-27T10:12:57 ERROR ERROR_NOTFOUND_404: Database connection lost\\n2024-01-27T10:12:58 INFO Attempting to reconnect...\\n2024-01-27T10:13:00 ERROR Connection failed', stack_trace='at batch_processor.execute(batch_processor.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='angry', previous_tickets=4, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 2, 1, 5, 29, 9, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['viewed_logs', 'escalated_to_specialist'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'api', 'performance', 'data'], environment='staging', business_impact='critical', affected_users=48, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000666', created_at=datetime.datetime(2024, 11, 7, 0, 59, 29, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 7, 8, 37, 17, tzinfo=datetime.timezone.utc), customer_id='CUST-01285', customer_tier='enterprise', organization_id='ORG-144', product='StreamProcessor', product_version='3.9.8', product_module='error_handler', category='Security', subcategory='Compliance', priority='low', severity='P1', channel='phone', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Getting ERROR_PARSING errors. We need to ensure our system meets compliance requirements.', error_logs='2024-11-07T00:59:29 DEBUG Processing request ID-12345\\n2024-11-07T00:59:29 ERROR ERROR_PARSING: Invalid request format\\n2024-11-07T00:59:30 INFO Request rejected', stack_trace='', customer_sentiment='neutral', previous_tickets=4, resolution='Applied hotfix version 3.2.2 to address the ERROR_PARSING. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 11, 7, 8, 37, 17, tzinfo=datetime.timezone.utc), agent_id='AGENT-015', agent_actions=['viewed_logs', 'consulted_kb', 'updated_documentation'], escalated=True, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['security', 'integration', 'performance'], environment='sandbox', business_impact='medium', affected_users=22, language='zh', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000667', created_at=datetime.datetime(2023, 10, 23, 6, 53, 18, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 27, 5, 29, 54, tzinfo=datetime.timezone.utc), customer_id='CUST-04894', customer_tier='enterprise', organization_id='ORG-384', product='Analytics Dashboard', product_version='2.9.1', product_module='data_aggregator', category='Feature Request', subcategory='Documentation', priority='low', severity='P4', channel='portal', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-10-23T06:53:18 ERROR ERROR_CORRUPTION: Database connection lost\\n2023-10-23T06:53:19 INFO Attempting to reconnect...\\n2023-10-23T06:53:21 ERROR Connection failed', stack_trace='at data_aggregator.execute(data_aggregator.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='neutral', previous_tickets=6, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 10, 27, 5, 29, 54, tzinfo=datetime.timezone.utc), agent_id='AGENT-042', agent_actions=['contacted_customer', 'ran_diagnostics', 'viewed_logs'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['performance', 'integration', 'error', 'bug'], environment='staging', business_impact='medium', affected_users=7, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000668', created_at=datetime.datetime(2023, 5, 16, 12, 5, 24, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 20, 10, 18, 36, tzinfo=datetime.timezone.utc), customer_id='CUST-04588', customer_tier='enterprise', organization_id='ORG-498', product='API Gateway', product_version='2.6.2', product_module='auth_service', category='Data Issue', subcategory='Validation', priority='medium', severity='P4', channel='chat', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_SERVER_500 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-05-16T12:05:24 DEBUG Processing request ID-12345\\n2023-05-16T12:05:24 ERROR ERROR_SERVER_500: Invalid request format\\n2023-05-16T12:05:25 INFO Request rejected', stack_trace='Stack trace:\\n  auth_service::processData() at auth_service.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='satisfied', previous_tickets=1, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 5, 20, 10, 18, 36, tzinfo=datetime.timezone.utc), agent_id='AGENT-049', agent_actions=['updated_documentation', 'ran_diagnostics', 'viewed_logs', 'checked_config', 'consulted_kb'], escalated=True, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['database', 'integration'], environment='test', business_impact='high', affected_users=43, language='de', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000669', created_at=datetime.datetime(2024, 1, 24, 19, 52, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 24, 23, 40, 1, tzinfo=datetime.timezone.utc), customer_id='CUST-01792', customer_tier='starter', organization_id='ORG-473', product='StreamProcessor', product_version='3.9.6', product_module='batch_processor', category='Account Management', subcategory='Upgrade', priority='critical', severity='P1', channel='api', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-01-24T19:52:37 DEBUG Processing request ID-12345\\n2024-01-24T19:52:37 ERROR ERROR_DISK_FULL: Invalid request format\\n2024-01-24T19:52:38 INFO Request rejected', stack_trace='', customer_sentiment='confused', previous_tickets=4, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 1, 24, 23, 40, 1, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['contacted_customer', 'applied_fix', 'verified_resolution', 'escalated_to_specialist', 'updated_documentation'], escalated=True, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['data', 'timeout', 'performance'], environment='test', business_impact='medium', affected_users=88, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000670', created_at=datetime.datetime(2024, 5, 6, 19, 20, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 6, 21, 8, 2, tzinfo=datetime.timezone.utc), customer_id='CUST-01340', customer_tier='free', organization_id='ORG-109', product='API Gateway', product_version='3.8.6', product_module='auth_service', category='Technical Issue', subcategory='Integration', priority='medium', severity='P0', channel='phone', subject='API Gateway throwing errors during operation', description=\"We're experiencing issues with API Gateway. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=0, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 5, 6, 21, 8, 2, tzinfo=datetime.timezone.utc), agent_id='AGENT-032', agent_actions=['checked_config', 'contacted_customer', 'ran_diagnostics'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['performance', 'sync', 'api', 'integration', 'error'], environment='test', business_impact='critical', affected_users=12, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000671', created_at=datetime.datetime(2024, 10, 3, 20, 6, 59, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 3, 21, 48, 59, tzinfo=datetime.timezone.utc), customer_id='CUST-02249', customer_tier='free', organization_id='ORG-484', product='API Gateway', product_version='3.7.8', product_module='auth_service', category='Account Management', subcategory='Subscription', priority='critical', severity='P1', channel='api', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-10-03T20:06:59 WARN Rate limit approaching threshold\\n2024-10-03T20:06:59 ERROR ERROR_RATELIMIT_429: Rate limit exceeded\\n2024-10-03T20:07:01 INFO Backing off for 60 seconds', stack_trace='ERROR: auth_service.service.ServiceException: Failed to process request\\n\\tat auth_service.handler.process(auth_service.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='confused', previous_tickets=9, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 10, 3, 21, 48, 59, tzinfo=datetime.timezone.utc), agent_id='AGENT-013', agent_actions=['ran_diagnostics', 'verified_resolution', 'contacted_customer'], escalated=True, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['sync', 'configuration', 'security', 'error'], environment='sandbox', business_impact='critical', affected_users=799, language='pt', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000672', created_at=datetime.datetime(2023, 4, 13, 5, 18, 27, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 18, 12, 26, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-00408', customer_tier='free', organization_id='ORG-488', product='Analytics Dashboard', product_version='2.8.6', product_module='export_module', category='Technical Issue', subcategory='Configuration', priority='low', severity='P4', channel='slack', subject='Analytics Dashboard throwing ERROR_MEMORY_OOM during operation', description=\"We're experiencing issues with Analytics Dashboard. The system is throwing ERROR_MEMORY_OOM when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-04-13T05:18:27 DEBUG Processing request ID-12345\\n2023-04-13T05:18:27 ERROR ERROR_MEMORY_OOM: Invalid request format\\n2023-04-13T05:18:28 INFO Request rejected', stack_trace=\"Traceback (most recent call last):\\n  File 'export_module.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='grateful', previous_tickets=4, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 4, 18, 12, 26, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-005', agent_actions=['applied_fix', 'escalated_to_specialist', 'contacted_customer', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['bug', 'data', 'timeout', 'integration'], environment='sandbox', business_impact='medium', affected_users=47, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000673', created_at=datetime.datetime(2024, 5, 11, 16, 16, 31, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 11, 18, 6, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-03549', customer_tier='premium', organization_id='ORG-086', product='CloudBackup Enterprise', product_version='3.0.2', product_module='restore_module', category='Account Management', subcategory='Access Control', priority='low', severity='P0', channel='slack', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=7, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 5, 11, 18, 6, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-033', agent_actions=['created_workaround', 'applied_fix', 'checked_config', 'escalated_to_specialist'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['authentication', 'data', 'integration'], environment='production', business_impact='low', affected_users=2, language='fr', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000674', created_at=datetime.datetime(2023, 5, 9, 7, 51, 26, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 11, 18, 15, 26, tzinfo=datetime.timezone.utc), customer_id='CUST-00665', customer_tier='enterprise', organization_id='ORG-270', product='StreamProcessor', product_version='4.6.6', product_module='event_handler', category='Technical Issue', subcategory='Performance', priority='low', severity='P4', channel='slack', subject='StreamProcessor throwing ERROR_PERMISSION_403 during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing ERROR_PERMISSION_403 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-05-09T07:51:26 ERROR ERROR_PERMISSION_403: Connection timeout after 30s\\n2023-05-09T07:51:27 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='neutral', previous_tickets=3, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 5, 11, 18, 15, 26, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['created_workaround', 'applied_fix', 'checked_config'], escalated=True, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['database', 'bug'], environment='production', business_impact='critical', affected_users=27, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000675', created_at=datetime.datetime(2024, 6, 25, 19, 4, 22, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 30, 1, 31, 22, tzinfo=datetime.timezone.utc), customer_id='CUST-02942', customer_tier='enterprise', organization_id='ORG-133', product='CloudBackup Enterprise', product_version='2.2.9', product_module='restore_module', category='Account Management', subcategory='License', priority='low', severity='P4', channel='portal', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-06-25T19:04:22 WARN Rate limit approaching threshold\\n2024-06-25T19:04:22 ERROR ERROR_PERMISSION_403: Rate limit exceeded\\n2024-06-25T19:04:24 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='neutral', previous_tickets=1, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 6, 30, 1, 31, 22, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['applied_fix', 'escalated_to_specialist', 'viewed_logs'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['security', 'data', 'error'], environment='sandbox', business_impact='high', affected_users=50, language='ja', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000676', created_at=datetime.datetime(2023, 10, 26, 12, 3, 54, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 29, 20, 8, 42, tzinfo=datetime.timezone.utc), customer_id='CUST-01843', customer_tier='professional', organization_id='ORG-050', product='API Gateway', product_version='2.3.5', product_module='rate_limiter', category='Feature Request', subcategory='Enhancement', priority='low', severity='P3', channel='email', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=1, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 10, 29, 20, 8, 42, tzinfo=datetime.timezone.utc), agent_id='AGENT-042', agent_actions=['updated_documentation', 'created_workaround', 'ran_diagnostics'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['sync', 'bug'], environment='staging', business_impact='low', affected_users=44, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000677', created_at=datetime.datetime(2024, 10, 24, 7, 30, 29, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 24, 10, 26, 53, tzinfo=datetime.timezone.utc), customer_id='CUST-00865', customer_tier='professional', organization_id='ORG-249', product='DataSync Pro', product_version='2.7.15', product_module='api_connector', category='Data Issue', subcategory='Corruption', priority='medium', severity='P1', channel='portal', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_PARSING appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-10-24T07:30:29 WARN Rate limit approaching threshold\\n2024-10-24T07:30:29 ERROR ERROR_PARSING: Rate limit exceeded\\n2024-10-24T07:30:31 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='angry', previous_tickets=4, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 10, 24, 10, 26, 53, tzinfo=datetime.timezone.utc), agent_id='AGENT-045', agent_actions=['applied_fix', 'checked_config'], escalated=True, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['security', 'performance', 'api'], environment='sandbox', business_impact='critical', affected_users=42, language='de', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000678', created_at=datetime.datetime(2023, 10, 24, 7, 32, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 24, 8, 24, 15, tzinfo=datetime.timezone.utc), customer_id='CUST-04483', customer_tier='starter', organization_id='ORG-070', product='API Gateway', product_version='3.7.1', product_module='cache_layer', category='Data Issue', subcategory='Data Loss', priority='critical', severity='P0', channel='slack', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_TIMEOUT_429 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-10-24T07:32:39 WARN Rate limit approaching threshold\\n2023-10-24T07:32:39 ERROR ERROR_TIMEOUT_429: Rate limit exceeded\\n2023-10-24T07:32:41 INFO Backing off for 60 seconds', stack_trace='Stack trace:\\n  cache_layer::processData() at cache_layer.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='neutral', previous_tickets=7, resolution='Root cause identified as Data Loss issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 10, 24, 8, 24, 15, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['checked_config', 'escalated_to_specialist'], escalated=True, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['performance', 'timeout'], environment='sandbox', business_impact='medium', affected_users=579, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000679', created_at=datetime.datetime(2024, 9, 3, 21, 55, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 7, 3, 34, 38, tzinfo=datetime.timezone.utc), customer_id='CUST-03155', customer_tier='free', organization_id='ORG-039', product='Analytics Dashboard', product_version='2.2.15', product_module='report_builder', category='Technical Issue', subcategory='Compatibility', priority='medium', severity='P4', channel='portal', subject='Performance degradation in Analytics Dashboard', description=\"The Analytics Dashboard has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_SERVER_500 in the logs. This is affecting our entire team's productivity.\", error_logs='2024-09-03T21:55:38 DEBUG Processing request ID-12345\\n2024-09-03T21:55:38 ERROR ERROR_SERVER_500: Invalid request format\\n2024-09-03T21:55:39 INFO Request rejected', stack_trace='ERROR: report_builder.service.ServiceException: Failed to process request\\n\\tat report_builder.handler.process(report_builder.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='angry', previous_tickets=0, resolution='Root cause identified as Compatibility issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 9, 7, 3, 34, 38, tzinfo=datetime.timezone.utc), agent_id='AGENT-003', agent_actions=['viewed_logs', 'contacted_customer', 'updated_documentation', 'verified_resolution'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['integration', 'sync', 'data'], environment='sandbox', business_impact='critical', affected_users=23, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000680', created_at=datetime.datetime(2023, 8, 14, 23, 11, 53, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 15, 0, 17, 17, tzinfo=datetime.timezone.utc), customer_id='CUST-03595', customer_tier='enterprise', organization_id='ORG-292', product='Analytics Dashboard', product_version='3.2.6', product_module='visualization', category='Technical Issue', subcategory='Configuration', priority='high', severity='P0', channel='email', subject='Performance degradation in Analytics Dashboard', description=\"The Analytics Dashboard has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_SSL_CERT in the logs. This is affecting our entire team's productivity.\", error_logs='2023-08-14T23:11:53 DEBUG Processing request ID-12345\\n2023-08-14T23:11:53 ERROR ERROR_SSL_CERT: Invalid request format\\n2023-08-14T23:11:54 INFO Request rejected', stack_trace='', customer_sentiment='satisfied', previous_tickets=10, resolution='Applied hotfix version 3.2.2 to address the ERROR_SSL_CERT. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 8, 15, 0, 17, 17, tzinfo=datetime.timezone.utc), agent_id='AGENT-017', agent_actions=['checked_config', 'created_workaround'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['performance', 'api', 'security', 'authentication'], environment='staging', business_impact='medium', affected_users=342, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000681', created_at=datetime.datetime(2024, 3, 5, 15, 3, 2, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 5, 19, 48, 2, tzinfo=datetime.timezone.utc), customer_id='CUST-03349', customer_tier='enterprise', organization_id='ORG-317', product='Analytics Dashboard', product_version='2.2.12', product_module='export_module', category='Data Issue', subcategory='Corruption', priority='critical', severity='P1', channel='api', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_RATELIMIT_429 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-03-05T15:03:02 ERROR ERROR_RATELIMIT_429: Database connection lost\\n2024-03-05T15:03:03 INFO Attempting to reconnect...\\n2024-03-05T15:03:05 ERROR Connection failed', stack_trace='', customer_sentiment='neutral', previous_tickets=7, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 3, 5, 19, 48, 2, tzinfo=datetime.timezone.utc), agent_id='AGENT-022', agent_actions=['verified_resolution', 'checked_config', 'created_workaround', 'applied_fix'], escalated=True, transferred_count=1, satisfaction_score=2, resolution_helpful=True, tags=['database', 'authentication', 'sync', 'performance'], environment='development', business_impact='high', affected_users=645, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000682', created_at=datetime.datetime(2024, 4, 17, 5, 1, 58, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 17, 17, 18, 10, tzinfo=datetime.timezone.utc), customer_id='CUST-04514', customer_tier='free', organization_id='ORG-383', product='CloudBackup Enterprise', product_version='3.7.3', product_module='backup_service', category='Security', subcategory='Authorization', priority='critical', severity='P2', channel='phone', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Getting ERROR_INVALID_400 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-04-17T05:01:58 ERROR ERROR_INVALID_400: Connection timeout after 30s\\n2024-04-17T05:01:59 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'backup_service.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='satisfied', previous_tickets=6, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 4, 17, 17, 18, 10, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['checked_config', 'updated_documentation', 'applied_fix'], escalated=True, transferred_count=3, satisfaction_score=1, resolution_helpful=True, tags=['security', 'database', 'api', 'integration'], environment='development', business_impact='critical', affected_users=390, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000683', created_at=datetime.datetime(2024, 3, 29, 9, 27, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 29, 10, 48, tzinfo=datetime.timezone.utc), customer_id='CUST-04680', customer_tier='premium', organization_id='ORG-006', product='CloudBackup Enterprise', product_version='4.4.8', product_module='backup_service', category='Technical Issue', subcategory='Configuration', priority='medium', severity='P0', channel='portal', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_CONFLICT_409 in the logs. This is affecting our entire team's productivity.\", error_logs='2024-03-29T09:27:00 ERROR ERROR_CONFLICT_409: Connection timeout after 30s\\n2024-03-29T09:27:01 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='satisfied', previous_tickets=7, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 3, 29, 10, 48, tzinfo=datetime.timezone.utc), agent_id='AGENT-025', agent_actions=['escalated_to_specialist', 'consulted_kb', 'created_workaround', 'checked_config'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['security', 'authentication', 'bug'], environment='development', business_impact='medium', affected_users=32, language='pt', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000684', created_at=datetime.datetime(2023, 5, 23, 16, 12, 9, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 23, 17, 27, 45, tzinfo=datetime.timezone.utc), customer_id='CUST-04581', customer_tier='professional', organization_id='ORG-456', product='StreamProcessor', product_version='4.1.13', product_module='batch_processor', category='Technical Issue', subcategory='Integration', priority='critical', severity='P1', channel='chat', subject='StreamProcessor throwing errors during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=10, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 5, 23, 17, 27, 45, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['checked_config', 'escalated_to_specialist', 'verified_resolution', 'consulted_kb', 'updated_documentation'], escalated=False, transferred_count=1, satisfaction_score=1, resolution_helpful=True, tags=['sync', 'data'], environment='production', business_impact='medium', affected_users=739, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000685', created_at=datetime.datetime(2023, 11, 2, 8, 41, 55, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 2, 10, 35, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-04324', customer_tier='free', organization_id='ORG-438', product='Analytics Dashboard', product_version='3.9.9', product_module='visualization', category='Feature Request', subcategory='Enhancement', priority='critical', severity='P1', channel='chat', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-11-02T08:41:55 WARN Rate limit approaching threshold\\n2023-11-02T08:41:55 ERROR ERROR_SSL_CERT: Rate limit exceeded\\n2023-11-02T08:41:57 INFO Backing off for 60 seconds', stack_trace='Stack trace:\\n  visualization::processData() at visualization.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='satisfied', previous_tickets=5, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 11, 2, 10, 35, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['updated_documentation', 'viewed_logs', 'created_workaround'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['integration', 'bug', 'security'], environment='development', business_impact='medium', affected_users=838, language='ja', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000686', created_at=datetime.datetime(2024, 9, 7, 19, 53, 18, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 8, 17, 25, 42, tzinfo=datetime.timezone.utc), customer_id='CUST-04631', customer_tier='free', organization_id='ORG-042', product='CloudBackup Enterprise', product_version='2.3.6', product_module='backup_service', category='Account Management', subcategory='Billing', priority='medium', severity='P3', channel='chat', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-09-07T19:53:18 ERROR ERROR_AUTH_401: Connection timeout after 30s\\n2024-09-07T19:53:19 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='frustrated', previous_tickets=7, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 9, 8, 17, 25, 42, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['contacted_customer', 'updated_documentation', 'verified_resolution'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['sync', 'authentication', 'performance', 'database', 'timeout'], environment='sandbox', business_impact='low', affected_users=7, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000687', created_at=datetime.datetime(2024, 5, 20, 12, 22, 24, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 25, 4, 30, 48, tzinfo=datetime.timezone.utc), customer_id='CUST-03508', customer_tier='free', organization_id='ORG-193', product='API Gateway', product_version='3.9.8', product_module='rate_limiter', category='Security', subcategory='Authorization', priority='medium', severity='P4', channel='chat', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_INVALID_400 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-05-20T12:22:24 ERROR ERROR_INVALID_400: Connection timeout after 30s\\n2024-05-20T12:22:25 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='neutral', previous_tickets=7, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 5, 25, 4, 30, 48, tzinfo=datetime.timezone.utc), agent_id='AGENT-017', agent_actions=['ran_diagnostics', 'applied_fix', 'escalated_to_specialist', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['timeout', 'security', 'bug'], environment='test', business_impact='medium', affected_users=6, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000688', created_at=datetime.datetime(2024, 6, 20, 18, 21, 33, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 24, 17, 10, 9, tzinfo=datetime.timezone.utc), customer_id='CUST-02871', customer_tier='enterprise', organization_id='ORG-036', product='Analytics Dashboard', product_version='3.8.5', product_module='export_module', category='Data Issue', subcategory='Data Loss', priority='medium', severity='P4', channel='slack', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=6, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 6, 24, 17, 10, 9, tzinfo=datetime.timezone.utc), agent_id='AGENT-042', agent_actions=['updated_documentation', 'contacted_customer', 'checked_config'], escalated=False, transferred_count=1, satisfaction_score=1, resolution_helpful=True, tags=['error', 'configuration', 'api'], environment='test', business_impact='low', affected_users=40, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000689', created_at=datetime.datetime(2023, 10, 11, 5, 20, 21, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 14, 20, 25, 45, tzinfo=datetime.timezone.utc), customer_id='CUST-00644', customer_tier='premium', organization_id='ORG-012', product='API Gateway', product_version='4.8.6', product_module='auth_service', category='Data Issue', subcategory='Validation', priority='medium', severity='P4', channel='portal', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=0, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 10, 14, 20, 25, 45, tzinfo=datetime.timezone.utc), agent_id='AGENT-009', agent_actions=['verified_resolution', 'contacted_customer', 'escalated_to_specialist'], escalated=False, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['sync', 'error', 'data', 'api'], environment='sandbox', business_impact='low', affected_users=47, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000690', created_at=datetime.datetime(2024, 6, 2, 7, 24, 9, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 3, 18, 3, 9, tzinfo=datetime.timezone.utc), customer_id='CUST-00200', customer_tier='professional', organization_id='ORG-140', product='CloudBackup Enterprise', product_version='4.7.11', product_module='compression_engine', category='Feature Request', subcategory='Documentation', priority='low', severity='P2', channel='portal', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-06-02T07:24:09 DEBUG Processing request ID-12345\\n2024-06-02T07:24:09 ERROR ERROR_CONFLICT_409: Invalid request format\\n2024-06-02T07:24:10 INFO Request rejected', stack_trace='ERROR: compression_engine.service.ServiceException: Failed to process request\\n\\tat compression_engine.handler.process(compression_engine.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='frustrated', previous_tickets=10, resolution='Root cause identified as Documentation issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 6, 3, 18, 3, 9, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['viewed_logs', 'applied_fix', 'consulted_kb', 'created_workaround'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['configuration', 'timeout', 'error', 'security', 'database'], environment='test', business_impact='critical', affected_users=24, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000691', created_at=datetime.datetime(2023, 3, 3, 17, 56, 15, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 4, 10, 17, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-03905', customer_tier='professional', organization_id='ORG-106', product='Analytics Dashboard', product_version='3.3.13', product_module='visualization', category='Security', subcategory='Compliance', priority='medium', severity='P2', channel='chat', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_CORRUPTION errors. We need to ensure our system meets compliance requirements.', error_logs='2023-03-03T17:56:15 DEBUG Processing request ID-12345\\n2023-03-03T17:56:15 ERROR ERROR_CORRUPTION: Invalid request format\\n2023-03-03T17:56:16 INFO Request rejected', stack_trace='', customer_sentiment='confused', previous_tickets=9, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 3, 4, 10, 17, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-006', agent_actions=['contacted_customer', 'applied_fix', 'viewed_logs'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['data', 'integration', 'database', 'authentication', 'sync'], environment='production', business_impact='critical', affected_users=20, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000692', created_at=datetime.datetime(2024, 1, 31, 9, 7, 28, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 31, 17, 59, 40, tzinfo=datetime.timezone.utc), customer_id='CUST-00002', customer_tier='premium', organization_id='ORG-296', product='CloudBackup Enterprise', product_version='3.5.5', product_module='restore_module', category='Technical Issue', subcategory='Bug', priority='high', severity='P3', channel='email', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=10, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 1, 31, 17, 59, 40, tzinfo=datetime.timezone.utc), agent_id='AGENT-010', agent_actions=['verified_resolution', 'viewed_logs'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['performance', 'bug', 'data', 'api'], environment='test', business_impact='high', affected_users=838, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000693', created_at=datetime.datetime(2024, 11, 25, 11, 3, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 27, 14, 36, 37, tzinfo=datetime.timezone.utc), customer_id='CUST-02671', customer_tier='free', organization_id='ORG-273', product='API Gateway', product_version='2.8.1', product_module='cache_layer', category='Technical Issue', subcategory='Compatibility', priority='low', severity='P3', channel='portal', subject='API Gateway throwing errors during operation', description=\"We're experiencing issues with API Gateway. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=10, resolution='Root cause identified as Compatibility issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 11, 27, 14, 36, 37, tzinfo=datetime.timezone.utc), agent_id='AGENT-012', agent_actions=['verified_resolution', 'viewed_logs', 'consulted_kb'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['authentication', 'integration', 'error', 'timeout', 'api'], environment='sandbox', business_impact='high', affected_users=21, language='es', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000694', created_at=datetime.datetime(2024, 7, 9, 6, 38, 7, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 14, 7, 15, 19, tzinfo=datetime.timezone.utc), customer_id='CUST-02970', customer_tier='starter', organization_id='ORG-297', product='API Gateway', product_version='3.2.0', product_module='auth_service', category='Account Management', subcategory='Subscription', priority='low', severity='P4', channel='portal', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-07-09T06:38:07 WARN Rate limit approaching threshold\\n2024-07-09T06:38:07 ERROR ERROR_PERMISSION_403: Rate limit exceeded\\n2024-07-09T06:38:09 INFO Backing off for 60 seconds', stack_trace='at auth_service.execute(auth_service.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='frustrated', previous_tickets=7, resolution='Applied hotfix version 3.2.2 to address the ERROR_PERMISSION_403. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 7, 14, 7, 15, 19, tzinfo=datetime.timezone.utc), agent_id='AGENT-015', agent_actions=['verified_resolution', 'created_workaround', 'applied_fix', 'checked_config', 'ran_diagnostics', 'consulted_kb'], escalated=True, transferred_count=2, satisfaction_score=2, resolution_helpful=True, tags=['performance', 'bug', 'database'], environment='sandbox', business_impact='medium', affected_users=31, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000695', created_at=datetime.datetime(2023, 7, 20, 16, 52, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 22, 19, 32, 21, tzinfo=datetime.timezone.utc), customer_id='CUST-03564', customer_tier='enterprise', organization_id='ORG-410', product='CloudBackup Enterprise', product_version='3.2.14', product_module='backup_service', category='Technical Issue', subcategory='Bug', priority='medium', severity='P3', channel='slack', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_DEADLOCK in the logs. This is affecting our entire team's productivity.\", error_logs='2023-07-20T16:52:45 ERROR ERROR_DEADLOCK: Database connection lost\\n2023-07-20T16:52:46 INFO Attempting to reconnect...\\n2023-07-20T16:52:48 ERROR Connection failed', stack_trace='Stack trace:\\n  backup_service::processData() at backup_service.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='confused', previous_tickets=4, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 7, 22, 19, 32, 21, tzinfo=datetime.timezone.utc), agent_id='AGENT-042', agent_actions=['created_workaround', 'verified_resolution', 'updated_documentation', 'consulted_kb'], escalated=True, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['bug', 'sync', 'integration', 'error', 'database'], environment='test', business_impact='low', affected_users=19, language='it', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000696', created_at=datetime.datetime(2023, 5, 26, 20, 13, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 27, 0, 41, 21, tzinfo=datetime.timezone.utc), customer_id='CUST-02938', customer_tier='free', organization_id='ORG-130', product='DataSync Pro', product_version='4.8.2', product_module='sync_engine', category='Feature Request', subcategory='UI/UX', priority='medium', severity='P1', channel='slack', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-05-26T20:13:45 WARN Rate limit approaching threshold\\n2023-05-26T20:13:45 ERROR ERROR_CORRUPTION: Rate limit exceeded\\n2023-05-26T20:13:47 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'sync_engine.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='frustrated', previous_tickets=2, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 5, 27, 0, 41, 21, tzinfo=datetime.timezone.utc), agent_id='AGENT-010', agent_actions=['consulted_kb', 'verified_resolution', 'viewed_logs', 'ran_diagnostics', 'escalated_to_specialist'], escalated=True, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['bug', 'performance', 'integration'], environment='development', business_impact='medium', affected_users=35, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000697', created_at=datetime.datetime(2023, 11, 28, 13, 50, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 3, 12, 45, 14, tzinfo=datetime.timezone.utc), customer_id='CUST-01961', customer_tier='free', organization_id='ORG-103', product='StreamProcessor', product_version='4.6.11', product_module='monitoring', category='Data Issue', subcategory='Validation', priority='low', severity='P4', channel='api', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_INVALID_400 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-11-28T13:50:38 DEBUG Processing request ID-12345\\n2023-11-28T13:50:38 ERROR ERROR_INVALID_400: Invalid request format\\n2023-11-28T13:50:39 INFO Request rejected', stack_trace=\"Traceback (most recent call last):\\n  File 'monitoring.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='grateful', previous_tickets=4, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 12, 3, 12, 45, 14, tzinfo=datetime.timezone.utc), agent_id='AGENT-044', agent_actions=['escalated_to_specialist', 'consulted_kb'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'performance'], environment='test', business_impact='low', affected_users=34, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000698', created_at=datetime.datetime(2023, 10, 10, 22, 16, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 12, 14, 32, 15, tzinfo=datetime.timezone.utc), customer_id='CUST-01614', customer_tier='starter', organization_id='ORG-485', product='Analytics Dashboard', product_version='2.5.7', product_module='visualization', category='Data Issue', subcategory='Corruption', priority='high', severity='P4', channel='portal', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_CONNECTION_REFUSED appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-10-10T22:16:39 DEBUG Processing request ID-12345\\n2023-10-10T22:16:39 ERROR ERROR_CONNECTION_REFUSED: Invalid request format\\n2023-10-10T22:16:40 INFO Request rejected', stack_trace='at visualization.execute(visualization.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='confused', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 10, 12, 14, 32, 15, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['contacted_customer', 'viewed_logs', 'updated_documentation', 'applied_fix'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=False, tags=['configuration', 'data', 'bug', 'performance', 'api'], environment='development', business_impact='critical', affected_users=473, language='it', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000699', created_at=datetime.datetime(2024, 4, 6, 15, 25, 51, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 7, 5, 33, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-04664', customer_tier='enterprise', organization_id='ORG-224', product='API Gateway', product_version='2.7.3', product_module='cache_layer', category='Account Management', subcategory='Access Control', priority='medium', severity='P3', channel='phone', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=9, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 4, 7, 5, 33, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-034', agent_actions=['escalated_to_specialist', 'contacted_customer', 'applied_fix', 'checked_config'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'performance', 'authentication', 'data', 'configuration'], environment='production', business_impact='critical', affected_users=46, language='es', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000700', created_at=datetime.datetime(2023, 2, 20, 5, 6, 49, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 20, 6, 9, 49, tzinfo=datetime.timezone.utc), customer_id='CUST-01606', customer_tier='professional', organization_id='ORG-320', product='CloudBackup Enterprise', product_version='4.7.1', product_module='compression_engine', category='Data Issue', subcategory='Sync Error', priority='critical', severity='P1', channel='chat', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_AUTH_401 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-02-20T05:06:49 ERROR ERROR_AUTH_401: Connection timeout after 30s\\n2023-02-20T05:06:50 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='neutral', previous_tickets=8, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 2, 20, 6, 9, 49, tzinfo=datetime.timezone.utc), agent_id='AGENT-033', agent_actions=['contacted_customer', 'updated_documentation'], escalated=True, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['bug', 'timeout', 'sync'], environment='test', business_impact='low', affected_users=991, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000701', created_at=datetime.datetime(2024, 6, 4, 2, 3, 4, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 4, 3, 43, 16, tzinfo=datetime.timezone.utc), customer_id='CUST-03948', customer_tier='enterprise', organization_id='ORG-481', product='Analytics Dashboard', product_version='4.5.9', product_module='visualization', category='Data Issue', subcategory='Sync Error', priority='critical', severity='P0', channel='phone', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=5, resolution='Root cause identified as Sync Error issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 6, 4, 3, 43, 16, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['escalated_to_specialist', 'viewed_logs', 'verified_resolution', 'updated_documentation', 'checked_config', 'contacted_customer'], escalated=True, transferred_count=1, satisfaction_score=1, resolution_helpful=True, tags=['performance', 'timeout', 'integration', 'authentication'], environment='development', business_impact='critical', affected_users=499, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000702', created_at=datetime.datetime(2023, 2, 19, 10, 7, 13, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 19, 13, 25, 49, tzinfo=datetime.timezone.utc), customer_id='CUST-00332', customer_tier='professional', organization_id='ORG-495', product='StreamProcessor', product_version='2.3.15', product_module='error_handler', category='Security', subcategory='Vulnerability', priority='high', severity='P1', channel='chat', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=8, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 2, 19, 13, 25, 49, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['created_workaround', 'escalated_to_specialist', 'ran_diagnostics'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['error', 'database', 'bug', 'timeout'], environment='development', business_impact='low', affected_users=768, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000703', created_at=datetime.datetime(2024, 5, 13, 16, 16, 52, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 14, 6, 1, 52, tzinfo=datetime.timezone.utc), customer_id='CUST-04443', customer_tier='professional', organization_id='ORG-416', product='StreamProcessor', product_version='4.3.10', product_module='event_handler', category='Feature Request', subcategory='API', priority='critical', severity='P3', channel='slack', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-05-13T16:16:52 ERROR ERROR_NOTFOUND_404: Database connection lost\\n2024-05-13T16:16:53 INFO Attempting to reconnect...\\n2024-05-13T16:16:55 ERROR Connection failed', stack_trace='', customer_sentiment='confused', previous_tickets=7, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 5, 14, 6, 1, 52, tzinfo=datetime.timezone.utc), agent_id='AGENT-005', agent_actions=['checked_config', 'viewed_logs'], escalated=True, transferred_count=3, satisfaction_score=3, resolution_helpful=False, tags=['timeout', 'configuration', 'data'], environment='sandbox', business_impact='high', affected_users=319, language='zh', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000704', created_at=datetime.datetime(2023, 12, 11, 10, 47, 25, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 11, 14, 9, 37, tzinfo=datetime.timezone.utc), customer_id='CUST-00735', customer_tier='free', organization_id='ORG-356', product='Analytics Dashboard', product_version='2.8.8', product_module='report_builder', category='Security', subcategory='Compliance', priority='critical', severity='P1', channel='phone', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_PERMISSION_403 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-12-11T10:47:25 DEBUG Processing request ID-12345\\n2023-12-11T10:47:25 ERROR ERROR_PERMISSION_403: Invalid request format\\n2023-12-11T10:47:26 INFO Request rejected', stack_trace=\"Traceback (most recent call last):\\n  File 'report_builder.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='frustrated', previous_tickets=4, resolution='Applied hotfix version 3.2.2 to address the ERROR_PERMISSION_403. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 12, 11, 14, 9, 37, tzinfo=datetime.timezone.utc), agent_id='AGENT-047', agent_actions=['escalated_to_specialist', 'viewed_logs'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['api', 'integration'], environment='staging', business_impact='critical', affected_users=533, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000705', created_at=datetime.datetime(2024, 4, 23, 20, 5, 3, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 24, 2, 50, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-03729', customer_tier='free', organization_id='ORG-209', product='CloudBackup Enterprise', product_version='3.5.14', product_module='encryption_layer', category='Feature Request', subcategory='Enhancement', priority='medium', severity='P2', channel='api', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-04-23T20:05:03 ERROR ERROR_MEMORY_OOM: Connection timeout after 30s\\n2024-04-23T20:05:04 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='angry', previous_tickets=7, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 4, 24, 2, 50, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-037', agent_actions=['viewed_logs', 'consulted_kb', 'applied_fix'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=False, tags=['data', 'configuration', 'sync', 'error'], environment='development', business_impact='high', affected_users=34, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000706', created_at=datetime.datetime(2024, 3, 2, 20, 32, 40, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 2, 22, 47, 40, tzinfo=datetime.timezone.utc), customer_id='CUST-01781', customer_tier='enterprise', organization_id='ORG-110', product='StreamProcessor', product_version='4.8.12', product_module='monitoring', category='Technical Issue', subcategory='Configuration', priority='medium', severity='P0', channel='chat', subject='StreamProcessor throwing ERROR_DISK_FULL during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing ERROR_DISK_FULL when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-03-02T20:32:40 WARN Rate limit approaching threshold\\n2024-03-02T20:32:40 ERROR ERROR_DISK_FULL: Rate limit exceeded\\n2024-03-02T20:32:42 INFO Backing off for 60 seconds', stack_trace='at monitoring.execute(monitoring.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='grateful', previous_tickets=1, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 3, 2, 22, 47, 40, tzinfo=datetime.timezone.utc), agent_id='AGENT-038', agent_actions=['verified_resolution', 'created_workaround', 'viewed_logs'], escalated=False, transferred_count=2, satisfaction_score=1, resolution_helpful=True, tags=['integration', 'configuration', 'security'], environment='test', business_impact='low', affected_users=8, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000707', created_at=datetime.datetime(2024, 10, 3, 3, 24, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 4, 11, 5, 25, tzinfo=datetime.timezone.utc), customer_id='CUST-04935', customer_tier='enterprise', organization_id='ORG-227', product='Analytics Dashboard', product_version='2.7.3', product_module='data_aggregator', category='Technical Issue', subcategory='Compatibility', priority='medium', severity='P3', channel='chat', subject='Analytics Dashboard throwing errors during operation', description=\"We're experiencing issues with Analytics Dashboard. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=10, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 10, 4, 11, 5, 25, tzinfo=datetime.timezone.utc), agent_id='AGENT-012', agent_actions=['verified_resolution', 'applied_fix'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['database', 'data', 'timeout', 'integration'], environment='test', business_impact='low', affected_users=39, language='pt', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000708', created_at=datetime.datetime(2024, 4, 3, 19, 20, 31, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 6, 11, 24, 43, tzinfo=datetime.timezone.utc), customer_id='CUST-00411', customer_tier='free', organization_id='ORG-012', product='DataSync Pro', product_version='3.6.6', product_module='api_connector', category='Feature Request', subcategory='Documentation', priority='low', severity='P3', channel='phone', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-04-03T19:20:31 ERROR ERROR_DISK_FULL: Database connection lost\\n2024-04-03T19:20:32 INFO Attempting to reconnect...\\n2024-04-03T19:20:34 ERROR Connection failed', stack_trace='', customer_sentiment='confused', previous_tickets=6, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 4, 6, 11, 24, 43, tzinfo=datetime.timezone.utc), agent_id='AGENT-003', agent_actions=['contacted_customer', 'escalated_to_specialist', 'ran_diagnostics', 'viewed_logs', 'updated_documentation'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['security', 'error', 'configuration'], environment='staging', business_impact='low', affected_users=32, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000709', created_at=datetime.datetime(2023, 11, 17, 16, 8, 50, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 17, 17, 13, 38, tzinfo=datetime.timezone.utc), customer_id='CUST-03488', customer_tier='professional', organization_id='ORG-301', product='DataSync Pro', product_version='2.0.5', product_module='api_connector', category='Account Management', subcategory='Access Control', priority='high', severity='P0', channel='email', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=10, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 11, 17, 17, 13, 38, tzinfo=datetime.timezone.utc), agent_id='AGENT-026', agent_actions=['escalated_to_specialist', 'ran_diagnostics', 'consulted_kb'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['database', 'timeout', 'data', 'authentication', 'configuration'], environment='production', business_impact='high', affected_users=251, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000710', created_at=datetime.datetime(2024, 4, 18, 20, 1, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 19, 0, 35, 13, tzinfo=datetime.timezone.utc), customer_id='CUST-01763', customer_tier='enterprise', organization_id='ORG-009', product='StreamProcessor', product_version='4.6.1', product_module='event_handler', category='Security', subcategory='Compliance', priority='critical', severity='P1', channel='slack', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Getting ERROR_TIMEOUT_429 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-04-18T20:01:37 ERROR ERROR_TIMEOUT_429: Database connection lost\\n2024-04-18T20:01:38 INFO Attempting to reconnect...\\n2024-04-18T20:01:40 ERROR Connection failed', stack_trace='', customer_sentiment='frustrated', previous_tickets=0, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 4, 19, 0, 35, 13, tzinfo=datetime.timezone.utc), agent_id='AGENT-049', agent_actions=['created_workaround', 'viewed_logs', 'applied_fix'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['authentication', 'bug', 'security'], environment='development', business_impact='medium', affected_users=338, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000711', created_at=datetime.datetime(2023, 5, 12, 11, 2, 25, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 12, 13, 38, 25, tzinfo=datetime.timezone.utc), customer_id='CUST-00365', customer_tier='free', organization_id='ORG-051', product='API Gateway', product_version='2.9.4', product_module='request_router', category='Feature Request', subcategory='Documentation', priority='critical', severity='P0', channel='api', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-05-12T11:02:25 ERROR ERROR_AUTH_401: Database connection lost\\n2023-05-12T11:02:26 INFO Attempting to reconnect...\\n2023-05-12T11:02:28 ERROR Connection failed', stack_trace='', customer_sentiment='satisfied', previous_tickets=6, resolution='Root cause identified as Documentation issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 5, 12, 13, 38, 25, tzinfo=datetime.timezone.utc), agent_id='AGENT-050', agent_actions=['created_workaround', 'updated_documentation'], escalated=True, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['data', 'performance', 'security'], environment='production', business_impact='medium', affected_users=932, language='it', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000712', created_at=datetime.datetime(2023, 6, 9, 16, 28, 5, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 11, 21, 6, 29, tzinfo=datetime.timezone.utc), customer_id='CUST-04251', customer_tier='premium', organization_id='ORG-081', product='CloudBackup Enterprise', product_version='2.4.11', product_module='restore_module', category='Feature Request', subcategory='Enhancement', priority='high', severity='P4', channel='slack', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=4, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 6, 11, 21, 6, 29, tzinfo=datetime.timezone.utc), agent_id='AGENT-024', agent_actions=['consulted_kb', 'contacted_customer', 'escalated_to_specialist', 'applied_fix', 'viewed_logs'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['data', 'integration', 'bug', 'security'], environment='sandbox', business_impact='critical', affected_users=577, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000713', created_at=datetime.datetime(2023, 7, 2, 12, 40, 51, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 2, 16, 48, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-04537', customer_tier='enterprise', organization_id='ORG-099', product='CloudBackup Enterprise', product_version='4.5.11', product_module='backup_service', category='Technical Issue', subcategory='Compatibility', priority='critical', severity='P2', channel='api', subject='CloudBackup Enterprise throwing ERROR_PARSING during operation', description=\"We're experiencing issues with CloudBackup Enterprise. The system is throwing ERROR_PARSING when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-07-02T12:40:51 WARN Rate limit approaching threshold\\n2023-07-02T12:40:51 ERROR ERROR_PARSING: Rate limit exceeded\\n2023-07-02T12:40:53 INFO Backing off for 60 seconds', stack_trace='at backup_service.execute(backup_service.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='satisfied', previous_tickets=8, resolution='Root cause identified as Compatibility issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 7, 2, 16, 48, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-029', agent_actions=['checked_config', 'ran_diagnostics', 'updated_documentation', 'applied_fix', 'escalated_to_specialist'], escalated=False, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['security', 'sync', 'api', 'performance', 'data'], environment='sandbox', business_impact='critical', affected_users=775, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000714', created_at=datetime.datetime(2024, 10, 31, 10, 4, 30, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 31, 19, 15, 54, tzinfo=datetime.timezone.utc), customer_id='CUST-03104', customer_tier='enterprise', organization_id='ORG-154', product='DataSync Pro', product_version='2.8.10', product_module='sync_engine', category='Security', subcategory='Encryption', priority='critical', severity='P2', channel='email', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_PARSING errors. We need to ensure our system meets compliance requirements.', error_logs='2024-10-31T10:04:30 ERROR ERROR_PARSING: Connection timeout after 30s\\n2024-10-31T10:04:31 RETRY_FAILED: Max retries exceeded', stack_trace='ERROR: sync_engine.service.ServiceException: Failed to process request\\n\\tat sync_engine.handler.process(sync_engine.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='grateful', previous_tickets=6, resolution='Root cause identified as Encryption issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 10, 31, 19, 15, 54, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['verified_resolution', 'checked_config', 'viewed_logs', 'applied_fix', 'ran_diagnostics', 'updated_documentation'], escalated=True, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['configuration', 'authentication', 'integration', 'data', 'api'], environment='sandbox', business_impact='medium', affected_users=697, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000715', created_at=datetime.datetime(2024, 6, 16, 17, 12, 7, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 16, 23, 59, 31, tzinfo=datetime.timezone.utc), customer_id='CUST-03769', customer_tier='starter', organization_id='ORG-132', product='API Gateway', product_version='3.1.12', product_module='rate_limiter', category='Account Management', subcategory='License', priority='high', severity='P1', channel='portal', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=10, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 6, 16, 23, 59, 31, tzinfo=datetime.timezone.utc), agent_id='AGENT-019', agent_actions=['applied_fix', 'ran_diagnostics', 'viewed_logs', 'created_workaround', 'escalated_to_specialist'], escalated=True, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['data', 'configuration', 'database', 'integration'], environment='development', business_impact='critical', affected_users=272, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000716', created_at=datetime.datetime(2023, 7, 19, 16, 46, 6, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 21, 13, 49, 42, tzinfo=datetime.timezone.utc), customer_id='CUST-01728', customer_tier='enterprise', organization_id='ORG-345', product='API Gateway', product_version='4.3.7', product_module='cache_layer', category='Feature Request', subcategory='Documentation', priority='critical', severity='P4', channel='email', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=4, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 7, 21, 13, 49, 42, tzinfo=datetime.timezone.utc), agent_id='AGENT-048', agent_actions=['contacted_customer', 'applied_fix', 'created_workaround', 'verified_resolution', 'escalated_to_specialist'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['integration', 'bug', 'configuration', 'error', 'database'], environment='test', business_impact='high', affected_users=706, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000717', created_at=datetime.datetime(2024, 4, 6, 14, 16, 28, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 8, 5, 2, 40, tzinfo=datetime.timezone.utc), customer_id='CUST-04989', customer_tier='free', organization_id='ORG-458', product='StreamProcessor', product_version='4.3.5', product_module='event_handler', category='Feature Request', subcategory='New Feature', priority='medium', severity='P4', channel='slack', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=2, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 4, 8, 5, 2, 40, tzinfo=datetime.timezone.utc), agent_id='AGENT-025', agent_actions=['ran_diagnostics', 'created_workaround', 'viewed_logs', 'applied_fix'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['data', 'database', 'bug', 'api', 'authentication'], environment='staging', business_impact='critical', affected_users=11, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000718', created_at=datetime.datetime(2023, 9, 19, 6, 48, 5, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 19, 14, 14, 29, tzinfo=datetime.timezone.utc), customer_id='CUST-00315', customer_tier='professional', organization_id='ORG-185', product='API Gateway', product_version='2.2.5', product_module='cache_layer', category='Technical Issue', subcategory='Compatibility', priority='high', severity='P2', channel='portal', subject='Performance degradation in API Gateway', description=\"The API Gateway has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_CORRUPTION in the logs. This is affecting our entire team's productivity.\", error_logs='2023-09-19T06:48:05 WARN Rate limit approaching threshold\\n2023-09-19T06:48:05 ERROR ERROR_CORRUPTION: Rate limit exceeded\\n2023-09-19T06:48:07 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='frustrated', previous_tickets=7, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 9, 19, 14, 14, 29, tzinfo=datetime.timezone.utc), agent_id='AGENT-013', agent_actions=['applied_fix', 'verified_resolution', 'escalated_to_specialist'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['bug', 'sync'], environment='sandbox', business_impact='medium', affected_users=369, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000719', created_at=datetime.datetime(2023, 8, 3, 6, 46, 42, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 3, 19, 53, 54, tzinfo=datetime.timezone.utc), customer_id='CUST-03899', customer_tier='starter', organization_id='ORG-286', product='DataSync Pro', product_version='3.5.7', product_module='api_connector', category='Technical Issue', subcategory='Compatibility', priority='critical', severity='P4', channel='chat', subject='Performance degradation in DataSync Pro', description=\"The DataSync Pro has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=2, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 8, 3, 19, 53, 54, tzinfo=datetime.timezone.utc), agent_id='AGENT-036', agent_actions=['verified_resolution', 'updated_documentation', 'created_workaround', 'checked_config', 'ran_diagnostics'], escalated=False, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['sync', 'security', 'bug', 'api'], environment='development', business_impact='medium', affected_users=420, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000720', created_at=datetime.datetime(2024, 6, 23, 20, 35, 36, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 23, 23, 58, 24, tzinfo=datetime.timezone.utc), customer_id='CUST-02251', customer_tier='professional', organization_id='ORG-482', product='StreamProcessor', product_version='3.7.12', product_module='monitoring', category='Feature Request', subcategory='Enhancement', priority='critical', severity='P1', channel='chat', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=8, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 6, 23, 23, 58, 24, tzinfo=datetime.timezone.utc), agent_id='AGENT-013', agent_actions=['checked_config', 'consulted_kb', 'verified_resolution'], escalated=True, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['error', 'api'], environment='sandbox', business_impact='high', affected_users=4, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000721', created_at=datetime.datetime(2024, 4, 10, 18, 20, 50, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 11, 1, 32, 50, tzinfo=datetime.timezone.utc), customer_id='CUST-04932', customer_tier='starter', organization_id='ORG-403', product='StreamProcessor', product_version='3.3.8', product_module='monitoring', category='Account Management', subcategory='License', priority='low', severity='P1', channel='email', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=7, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 4, 11, 1, 32, 50, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['created_workaround', 'checked_config', 'consulted_kb', 'viewed_logs'], escalated=True, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['security', 'configuration', 'authentication', 'performance', 'api'], environment='staging', business_impact='medium', affected_users=38, language='pt', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000722', created_at=datetime.datetime(2023, 9, 15, 4, 27, 21, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 15, 9, 35, 9, tzinfo=datetime.timezone.utc), customer_id='CUST-04542', customer_tier='premium', organization_id='ORG-222', product='DataSync Pro', product_version='3.6.15', product_module='api_connector', category='Feature Request', subcategory='Documentation', priority='low', severity='P1', channel='api', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-09-15T04:27:21 ERROR ERROR_INVALID_400: Connection timeout after 30s\\n2023-09-15T04:27:22 RETRY_FAILED: Max retries exceeded', stack_trace='Stack trace:\\n  api_connector::processData() at api_connector.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='neutral', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 9, 15, 9, 35, 9, tzinfo=datetime.timezone.utc), agent_id='AGENT-009', agent_actions=['applied_fix', 'created_workaround'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['authentication', 'security'], environment='development', business_impact='medium', affected_users=44, language='en', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000723', created_at=datetime.datetime(2023, 3, 6, 11, 25, 21, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 6, 16, 9, 45, tzinfo=datetime.timezone.utc), customer_id='CUST-02895', customer_tier='premium', organization_id='ORG-423', product='StreamProcessor', product_version='4.7.5', product_module='batch_processor', category='Feature Request', subcategory='Enhancement', priority='medium', severity='P1', channel='portal', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-03-06T11:25:21 ERROR ERROR_SSL_CERT: Connection timeout after 30s\\n2023-03-06T11:25:22 RETRY_FAILED: Max retries exceeded', stack_trace='ERROR: batch_processor.service.ServiceException: Failed to process request\\n\\tat batch_processor.handler.process(batch_processor.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='frustrated', previous_tickets=4, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 3, 6, 16, 9, 45, tzinfo=datetime.timezone.utc), agent_id='AGENT-018', agent_actions=['escalated_to_specialist', 'created_workaround', 'ran_diagnostics', 'updated_documentation'], escalated=True, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['security', 'error', 'timeout'], environment='staging', business_impact='low', affected_users=10, language='pt', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000724', created_at=datetime.datetime(2023, 7, 2, 16, 24, 13, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 2, 22, 19, 25, tzinfo=datetime.timezone.utc), customer_id='CUST-02803', customer_tier='premium', organization_id='ORG-436', product='Analytics Dashboard', product_version='4.9.9', product_module='report_builder', category='Feature Request', subcategory='UI/UX', priority='high', severity='P1', channel='phone', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-07-02T16:24:13 WARN Rate limit approaching threshold\\n2023-07-02T16:24:13 ERROR ERROR_SERVER_500: Rate limit exceeded\\n2023-07-02T16:24:15 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='confused', previous_tickets=10, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 7, 2, 22, 19, 25, tzinfo=datetime.timezone.utc), agent_id='AGENT-042', agent_actions=['verified_resolution', 'viewed_logs', 'updated_documentation', 'escalated_to_specialist'], escalated=True, transferred_count=1, satisfaction_score=1, resolution_helpful=True, tags=['performance', 'authentication'], environment='test', business_impact='high', affected_users=52, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000725', created_at=datetime.datetime(2024, 12, 2, 14, 55, 33, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 3, 14, 56, 45, tzinfo=datetime.timezone.utc), customer_id='CUST-00626', customer_tier='premium', organization_id='ORG-147', product='Analytics Dashboard', product_version='4.9.7', product_module='report_builder', category='Feature Request', subcategory='Enhancement', priority='high', severity='P2', channel='api', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-12-02T14:55:33 ERROR ERROR_TIMEOUT_429: Database connection lost\\n2024-12-02T14:55:34 INFO Attempting to reconnect...\\n2024-12-02T14:55:36 ERROR Connection failed', stack_trace='ERROR: report_builder.service.ServiceException: Failed to process request\\n\\tat report_builder.handler.process(report_builder.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='neutral', previous_tickets=5, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 12, 3, 14, 56, 45, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['verified_resolution', 'viewed_logs'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['integration', 'performance', 'sync'], environment='development', business_impact='low', affected_users=112, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000726', created_at=datetime.datetime(2023, 6, 6, 13, 25, 9, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 7, 3, 32, 21, tzinfo=datetime.timezone.utc), customer_id='CUST-03281', customer_tier='starter', organization_id='ORG-422', product='API Gateway', product_version='2.4.12', product_module='request_router', category='Security', subcategory='Compliance', priority='critical', severity='P3', channel='api', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_INVALID_400 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-06-06T13:25:09 DEBUG Processing request ID-12345\\n2023-06-06T13:25:09 ERROR ERROR_INVALID_400: Invalid request format\\n2023-06-06T13:25:10 INFO Request rejected', stack_trace='ERROR: request_router.service.ServiceException: Failed to process request\\n\\tat request_router.handler.process(request_router.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='neutral', previous_tickets=7, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 6, 7, 3, 32, 21, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['escalated_to_specialist', 'verified_resolution', 'consulted_kb', 'contacted_customer'], escalated=True, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['sync', 'timeout', 'performance', 'security'], environment='test', business_impact='low', affected_users=606, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000727', created_at=datetime.datetime(2024, 11, 8, 16, 32, 13, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 10, 12, 29, 49, tzinfo=datetime.timezone.utc), customer_id='CUST-03685', customer_tier='enterprise', organization_id='ORG-059', product='CloudBackup Enterprise', product_version='4.5.12', product_module='encryption_layer', category='Security', subcategory='Vulnerability', priority='low', severity='P4', channel='email', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Getting ERROR_NOTFOUND_404 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-11-08T16:32:13 DEBUG Processing request ID-12345\\n2024-11-08T16:32:13 ERROR ERROR_NOTFOUND_404: Invalid request format\\n2024-11-08T16:32:14 INFO Request rejected', stack_trace='at encryption_layer.execute(encryption_layer.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='grateful', previous_tickets=7, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 11, 10, 12, 29, 49, tzinfo=datetime.timezone.utc), agent_id='AGENT-018', agent_actions=['checked_config', 'escalated_to_specialist', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['bug', 'configuration', 'timeout', 'database'], environment='development', business_impact='medium', affected_users=49, language='it', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000728', created_at=datetime.datetime(2023, 12, 5, 23, 31, 22, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 6, 9, 7, 22, tzinfo=datetime.timezone.utc), customer_id='CUST-00632', customer_tier='free', organization_id='ORG-336', product='CloudBackup Enterprise', product_version='2.9.11', product_module='backup_service', category='Feature Request', subcategory='Documentation', priority='low', severity='P1', channel='portal', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-12-05T23:31:22 ERROR ERROR_CONNECTION_REFUSED: Database connection lost\\n2023-12-05T23:31:23 INFO Attempting to reconnect...\\n2023-12-05T23:31:25 ERROR Connection failed', stack_trace='ERROR: backup_service.service.ServiceException: Failed to process request\\n\\tat backup_service.handler.process(backup_service.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='confused', previous_tickets=5, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 12, 6, 9, 7, 22, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['ran_diagnostics', 'checked_config'], escalated=True, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['timeout', 'integration', 'security', 'performance', 'authentication'], environment='development', business_impact='medium', affected_users=32, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000729', created_at=datetime.datetime(2024, 9, 12, 16, 54, 22, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 12, 21, 14, 46, tzinfo=datetime.timezone.utc), customer_id='CUST-02233', customer_tier='free', organization_id='ORG-047', product='API Gateway', product_version='4.8.5', product_module='cache_layer', category='Feature Request', subcategory='Enhancement', priority='critical', severity='P1', channel='chat', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-09-12T16:54:22 ERROR ERROR_PARSING: Database connection lost\\n2024-09-12T16:54:23 INFO Attempting to reconnect...\\n2024-09-12T16:54:25 ERROR Connection failed', stack_trace='Stack trace:\\n  cache_layer::processData() at cache_layer.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='satisfied', previous_tickets=9, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 9, 12, 21, 14, 46, tzinfo=datetime.timezone.utc), agent_id='AGENT-050', agent_actions=['applied_fix', 'contacted_customer'], escalated=True, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['data', 'api', 'database', 'security'], environment='development', business_impact='low', affected_users=160, language='en', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000730', created_at=datetime.datetime(2023, 3, 31, 3, 20, 5, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 31, 8, 28, 29, tzinfo=datetime.timezone.utc), customer_id='CUST-01507', customer_tier='free', organization_id='ORG-030', product='Analytics Dashboard', product_version='3.6.11', product_module='export_module', category='Account Management', subcategory='Subscription', priority='low', severity='P0', channel='phone', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=8, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 3, 31, 8, 28, 29, tzinfo=datetime.timezone.utc), agent_id='AGENT-024', agent_actions=['checked_config', 'updated_documentation', 'viewed_logs'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['timeout', 'error'], environment='sandbox', business_impact='low', affected_users=27, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000731', created_at=datetime.datetime(2024, 3, 4, 9, 27, 25, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 11, 10, 42, 25, tzinfo=datetime.timezone.utc), customer_id='CUST-04571', customer_tier='free', organization_id='ORG-394', product='Analytics Dashboard', product_version='2.4.10', product_module='visualization', category='Data Issue', subcategory='Sync Error', priority='low', severity='P4', channel='api', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_CONFLICT_409 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-03-04T09:27:25 WARN Rate limit approaching threshold\\n2024-03-04T09:27:25 ERROR ERROR_CONFLICT_409: Rate limit exceeded\\n2024-03-04T09:27:27 INFO Backing off for 60 seconds', stack_trace='ERROR: visualization.service.ServiceException: Failed to process request\\n\\tat visualization.handler.process(visualization.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='satisfied', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 3, 11, 10, 42, 25, tzinfo=datetime.timezone.utc), agent_id='AGENT-023', agent_actions=['ran_diagnostics', 'escalated_to_specialist', 'created_workaround', 'updated_documentation', 'verified_resolution', 'viewed_logs'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['data', 'timeout', 'database', 'error'], environment='staging', business_impact='medium', affected_users=42, language='pt', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000732', created_at=datetime.datetime(2023, 4, 6, 12, 11, 2, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 6, 21, 11, 2, tzinfo=datetime.timezone.utc), customer_id='CUST-04923', customer_tier='enterprise', organization_id='ORG-240', product='DataSync Pro', product_version='3.9.15', product_module='api_connector', category='Feature Request', subcategory='API', priority='low', severity='P1', channel='email', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-04-06T12:11:02 ERROR ERROR_PARSING: Database connection lost\\n2023-04-06T12:11:03 INFO Attempting to reconnect...\\n2023-04-06T12:11:05 ERROR Connection failed', stack_trace='at api_connector.execute(api_connector.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='angry', previous_tickets=2, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 4, 6, 21, 11, 2, tzinfo=datetime.timezone.utc), agent_id='AGENT-017', agent_actions=['checked_config', 'contacted_customer'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['configuration', 'api', 'data'], environment='staging', business_impact='low', affected_users=27, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000733', created_at=datetime.datetime(2023, 10, 26, 12, 15, 20, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 26, 14, 55, 32, tzinfo=datetime.timezone.utc), customer_id='CUST-02292', customer_tier='enterprise', organization_id='ORG-039', product='API Gateway', product_version='2.2.10', product_module='rate_limiter', category='Feature Request', subcategory='UI/UX', priority='critical', severity='P1', channel='phone', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-10-26T12:15:20 DEBUG Processing request ID-12345\\n2023-10-26T12:15:20 ERROR ERROR_NOTFOUND_404: Invalid request format\\n2023-10-26T12:15:21 INFO Request rejected', stack_trace='', customer_sentiment='frustrated', previous_tickets=9, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 10, 26, 14, 55, 32, tzinfo=datetime.timezone.utc), agent_id='AGENT-006', agent_actions=['viewed_logs', 'created_workaround', 'escalated_to_specialist'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['api', 'authentication', 'integration', 'database', 'performance'], environment='production', business_impact='critical', affected_users=793, language='en', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000734', created_at=datetime.datetime(2024, 11, 30, 12, 10, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 2, 23, 52, 41, tzinfo=datetime.timezone.utc), customer_id='CUST-00278', customer_tier='enterprise', organization_id='ORG-307', product='CloudBackup Enterprise', product_version='4.2.2', product_module='compression_engine', category='Technical Issue', subcategory='Performance', priority='high', severity='P4', channel='api', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_CORRUPTION in the logs. This is affecting our entire team's productivity.\", error_logs='2024-11-30T12:10:41 ERROR ERROR_CORRUPTION: Connection timeout after 30s\\n2024-11-30T12:10:42 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='grateful', previous_tickets=7, resolution='Root cause identified as Performance issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 12, 2, 23, 52, 41, tzinfo=datetime.timezone.utc), agent_id='AGENT-046', agent_actions=['checked_config', 'consulted_kb', 'updated_documentation', 'ran_diagnostics', 'created_workaround'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=False, tags=['sync', 'performance', 'api'], environment='sandbox', business_impact='critical', affected_users=856, language='it', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000735', created_at=datetime.datetime(2024, 12, 9, 15, 31, 13, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 11, 21, 43, 49, tzinfo=datetime.timezone.utc), customer_id='CUST-03442', customer_tier='professional', organization_id='ORG-257', product='DataSync Pro', product_version='3.7.12', product_module='sync_engine', category='Data Issue', subcategory='Corruption', priority='low', severity='P3', channel='portal', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_RATELIMIT_429 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-12-09T15:31:13 DEBUG Processing request ID-12345\\n2024-12-09T15:31:13 ERROR ERROR_RATELIMIT_429: Invalid request format\\n2024-12-09T15:31:14 INFO Request rejected', stack_trace='', customer_sentiment='angry', previous_tickets=1, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 12, 11, 21, 43, 49, tzinfo=datetime.timezone.utc), agent_id='AGENT-020', agent_actions=['created_workaround', 'applied_fix', 'verified_resolution', 'escalated_to_specialist'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['error', 'database'], environment='sandbox', business_impact='low', affected_users=43, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000736', created_at=datetime.datetime(2023, 1, 29, 6, 50, 28, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 30, 3, 31, 52, tzinfo=datetime.timezone.utc), customer_id='CUST-03946', customer_tier='premium', organization_id='ORG-495', product='CloudBackup Enterprise', product_version='4.2.14', product_module='backup_service', category='Feature Request', subcategory='API', priority='critical', severity='P3', channel='portal', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-01-29T06:50:28 WARN Rate limit approaching threshold\\n2023-01-29T06:50:28 ERROR ERROR_MEMORY_OOM: Rate limit exceeded\\n2023-01-29T06:50:30 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='angry', previous_tickets=10, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 1, 30, 3, 31, 52, tzinfo=datetime.timezone.utc), agent_id='AGENT-050', agent_actions=['consulted_kb', 'created_workaround'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['security', 'database', 'authentication'], environment='production', business_impact='low', affected_users=261, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000737', created_at=datetime.datetime(2024, 8, 28, 3, 1, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 28, 5, 12, 25, tzinfo=datetime.timezone.utc), customer_id='CUST-01539', customer_tier='professional', organization_id='ORG-138', product='DataSync Pro', product_version='3.8.6', product_module='scheduler', category='Technical Issue', subcategory='Bug', priority='medium', severity='P0', channel='slack', subject='Performance degradation in DataSync Pro', description=\"The DataSync Pro has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_PERMISSION_403 in the logs. This is affecting our entire team's productivity.\", error_logs='2024-08-28T03:01:37 ERROR ERROR_PERMISSION_403: Database connection lost\\n2024-08-28T03:01:38 INFO Attempting to reconnect...\\n2024-08-28T03:01:40 ERROR Connection failed', stack_trace='', customer_sentiment='satisfied', previous_tickets=2, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 8, 28, 5, 12, 25, tzinfo=datetime.timezone.utc), agent_id='AGENT-001', agent_actions=['verified_resolution', 'consulted_kb', 'created_workaround'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['data', 'error'], environment='sandbox', business_impact='critical', affected_users=22, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000738', created_at=datetime.datetime(2023, 6, 20, 0, 3, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 21, 17, 36, 5, tzinfo=datetime.timezone.utc), customer_id='CUST-03685', customer_tier='enterprise', organization_id='ORG-059', product='StreamProcessor', product_version='3.7.10', product_module='monitoring', category='Feature Request', subcategory='New Feature', priority='high', severity='P4', channel='email', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-06-20T00:03:41 ERROR ERROR_RATELIMIT_429: Connection timeout after 30s\\n2023-06-20T00:03:42 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='confused', previous_tickets=3, resolution='Applied hotfix version 3.2.2 to address the ERROR_RATELIMIT_429. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 6, 21, 17, 36, 5, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['escalated_to_specialist', 'checked_config', 'ran_diagnostics'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=False, tags=['configuration', 'error', 'api', 'security'], environment='development', business_impact='critical', affected_users=700, language='it', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000739', created_at=datetime.datetime(2024, 12, 15, 10, 24, 47, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 18, 2, 41, 35, tzinfo=datetime.timezone.utc), customer_id='CUST-04228', customer_tier='free', organization_id='ORG-363', product='DataSync Pro', product_version='2.0.4', product_module='scheduler', category='Feature Request', subcategory='New Feature', priority='critical', severity='P4', channel='email', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=7, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 12, 18, 2, 41, 35, tzinfo=datetime.timezone.utc), agent_id='AGENT-023', agent_actions=['checked_config', 'updated_documentation', 'ran_diagnostics'], escalated=True, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['integration', 'authentication', 'data', 'database', 'bug'], environment='staging', business_impact='medium', affected_users=773, language='ja', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000740', created_at=datetime.datetime(2023, 6, 16, 22, 3, 14, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 18, 7, 53, 38, tzinfo=datetime.timezone.utc), customer_id='CUST-00309', customer_tier='premium', organization_id='ORG-428', product='CloudBackup Enterprise', product_version='2.0.3', product_module='encryption_layer', category='Technical Issue', subcategory='Bug', priority='low', severity='P3', channel='portal', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=2, resolution='Root cause identified as Bug issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 6, 18, 7, 53, 38, tzinfo=datetime.timezone.utc), agent_id='AGENT-027', agent_actions=['escalated_to_specialist', 'updated_documentation', 'checked_config', 'contacted_customer'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['bug', 'performance', 'integration', 'configuration'], environment='staging', business_impact='high', affected_users=27, language='pt', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000741', created_at=datetime.datetime(2023, 4, 17, 5, 2, 56, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 17, 8, 8, 56, tzinfo=datetime.timezone.utc), customer_id='CUST-00156', customer_tier='enterprise', organization_id='ORG-273', product='Analytics Dashboard', product_version='3.2.5', product_module='data_aggregator', category='Technical Issue', subcategory='Compatibility', priority='high', severity='P1', channel='chat', subject='Analytics Dashboard throwing ERROR_DEADLOCK during operation', description=\"We're experiencing issues with Analytics Dashboard. The system is throwing ERROR_DEADLOCK when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-04-17T05:02:56 WARN Rate limit approaching threshold\\n2023-04-17T05:02:56 ERROR ERROR_DEADLOCK: Rate limit exceeded\\n2023-04-17T05:02:58 INFO Backing off for 60 seconds', stack_trace='ERROR: data_aggregator.service.ServiceException: Failed to process request\\n\\tat data_aggregator.handler.process(data_aggregator.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='frustrated', previous_tickets=4, resolution='Root cause identified as Compatibility issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 4, 17, 8, 8, 56, tzinfo=datetime.timezone.utc), agent_id='AGENT-022', agent_actions=['checked_config', 'updated_documentation', 'contacted_customer', 'applied_fix', 'consulted_kb', 'viewed_logs'], escalated=True, transferred_count=1, satisfaction_score=1, resolution_helpful=False, tags=['error', 'configuration', 'authentication', 'timeout', 'api'], environment='development', business_impact='medium', affected_users=825, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000742', created_at=datetime.datetime(2023, 9, 1, 22, 12, 6, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 2, 2, 36, 42, tzinfo=datetime.timezone.utc), customer_id='CUST-02360', customer_tier='enterprise', organization_id='ORG-028', product='StreamProcessor', product_version='3.1.9', product_module='error_handler', category='Account Management', subcategory='Upgrade', priority='critical', severity='P1', channel='api', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-09-01T22:12:06 ERROR ERROR_DISK_FULL: Database connection lost\\n2023-09-01T22:12:07 INFO Attempting to reconnect...\\n2023-09-01T22:12:09 ERROR Connection failed', stack_trace='', customer_sentiment='angry', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 9, 2, 2, 36, 42, tzinfo=datetime.timezone.utc), agent_id='AGENT-006', agent_actions=['consulted_kb', 'created_workaround', 'ran_diagnostics', 'contacted_customer', 'verified_resolution'], escalated=True, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['api', 'database'], environment='production', business_impact='critical', affected_users=606, language='de', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000743', created_at=datetime.datetime(2024, 3, 4, 14, 49, 19, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 8, 15, 19, 19, tzinfo=datetime.timezone.utc), customer_id='CUST-03775', customer_tier='premium', organization_id='ORG-448', product='DataSync Pro', product_version='4.0.3', product_module='api_connector', category='Data Issue', subcategory='Import/Export', priority='medium', severity='P4', channel='slack', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_NOTFOUND_404 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-03-04T14:49:19 ERROR ERROR_NOTFOUND_404: Connection timeout after 30s\\n2024-03-04T14:49:20 RETRY_FAILED: Max retries exceeded', stack_trace='at api_connector.execute(api_connector.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='angry', previous_tickets=0, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 3, 8, 15, 19, 19, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['applied_fix', 'viewed_logs'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'integration'], environment='staging', business_impact='high', affected_users=9, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000744', created_at=datetime.datetime(2024, 6, 21, 2, 44, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 21, 6, 18, 49, tzinfo=datetime.timezone.utc), customer_id='CUST-02164', customer_tier='professional', organization_id='ORG-167', product='Analytics Dashboard', product_version='3.8.4', product_module='visualization', category='Data Issue', subcategory='Data Loss', priority='medium', severity='P0', channel='api', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_INVALID_400 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-06-21T02:44:37 WARN Rate limit approaching threshold\\n2024-06-21T02:44:37 ERROR ERROR_INVALID_400: Rate limit exceeded\\n2024-06-21T02:44:39 INFO Backing off for 60 seconds', stack_trace='Stack trace:\\n  visualization::processData() at visualization.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='angry', previous_tickets=3, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 6, 21, 6, 18, 49, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['created_workaround', 'viewed_logs', 'updated_documentation'], escalated=True, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['bug', 'authentication', 'configuration'], environment='development', business_impact='high', affected_users=42, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000745', created_at=datetime.datetime(2023, 1, 3, 18, 57, 15, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 4, 1, 42, 15, tzinfo=datetime.timezone.utc), customer_id='CUST-04643', customer_tier='enterprise', organization_id='ORG-003', product='DataSync Pro', product_version='2.6.5', product_module='api_connector', category='Account Management', subcategory='Upgrade', priority='medium', severity='P1', channel='phone', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-01-03T18:57:15 ERROR ERROR_RATELIMIT_429: Database connection lost\\n2023-01-03T18:57:16 INFO Attempting to reconnect...\\n2023-01-03T18:57:18 ERROR Connection failed', stack_trace='', customer_sentiment='frustrated', previous_tickets=8, resolution='Applied hotfix version 3.2.2 to address the ERROR_RATELIMIT_429. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 1, 4, 1, 42, 15, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['consulted_kb', 'updated_documentation', 'created_workaround'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['bug', 'timeout', 'authentication'], environment='sandbox', business_impact='low', affected_users=48, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000746', created_at=datetime.datetime(2023, 7, 25, 6, 2, 48, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 25, 9, 4, tzinfo=datetime.timezone.utc), customer_id='CUST-04484', customer_tier='premium', organization_id='ORG-484', product='StreamProcessor', product_version='2.9.9', product_module='event_handler', category='Feature Request', subcategory='UI/UX', priority='critical', severity='P1', channel='portal', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-07-25T06:02:48 ERROR ERROR_AUTH_401: Connection timeout after 30s\\n2023-07-25T06:02:49 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='satisfied', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 7, 25, 9, 4, tzinfo=datetime.timezone.utc), agent_id='AGENT-023', agent_actions=['ran_diagnostics', 'created_workaround', 'applied_fix'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['timeout', 'authentication', 'api', 'configuration'], environment='sandbox', business_impact='low', affected_users=560, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000747', created_at=datetime.datetime(2023, 6, 9, 8, 8, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 9, 21, 3, 49, tzinfo=datetime.timezone.utc), customer_id='CUST-03976', customer_tier='premium', organization_id='ORG-415', product='CloudBackup Enterprise', product_version='4.9.12', product_module='backup_service', category='Data Issue', subcategory='Validation', priority='critical', severity='P2', channel='slack', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=2, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 6, 9, 21, 3, 49, tzinfo=datetime.timezone.utc), agent_id='AGENT-016', agent_actions=['verified_resolution', 'consulted_kb'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['database', 'security', 'error', 'authentication'], environment='test', business_impact='medium', affected_users=567, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000748', created_at=datetime.datetime(2023, 9, 10, 12, 57, 44, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 10, 14, 48, 8, tzinfo=datetime.timezone.utc), customer_id='CUST-04899', customer_tier='premium', organization_id='ORG-079', product='Analytics Dashboard', product_version='2.2.13', product_module='data_aggregator', category='Account Management', subcategory='Access Control', priority='critical', severity='P0', channel='slack', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-09-10T12:57:44 ERROR ERROR_CORRUPTION: Connection timeout after 30s\\n2023-09-10T12:57:45 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='satisfied', previous_tickets=9, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 9, 10, 14, 48, 8, tzinfo=datetime.timezone.utc), agent_id='AGENT-040', agent_actions=['created_workaround', 'verified_resolution', 'updated_documentation', 'checked_config'], escalated=True, transferred_count=1, satisfaction_score=1, resolution_helpful=True, tags=['timeout', 'data'], environment='test', business_impact='critical', affected_users=973, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000749', created_at=datetime.datetime(2023, 11, 12, 1, 48, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 12, 3, 7, 48, tzinfo=datetime.timezone.utc), customer_id='CUST-01323', customer_tier='enterprise', organization_id='ORG-218', product='StreamProcessor', product_version='2.3.11', product_module='monitoring', category='Account Management', subcategory='Billing', priority='critical', severity='P1', channel='chat', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=5, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 11, 12, 3, 7, 48, tzinfo=datetime.timezone.utc), agent_id='AGENT-012', agent_actions=['viewed_logs', 'escalated_to_specialist', 'updated_documentation', 'applied_fix', 'contacted_customer'], escalated=True, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['data', 'error'], environment='staging', business_impact='low', affected_users=813, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000750', created_at=datetime.datetime(2023, 1, 6, 9, 6, 10, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 8, 16, 53, 34, tzinfo=datetime.timezone.utc), customer_id='CUST-04921', customer_tier='premium', organization_id='ORG-337', product='DataSync Pro', product_version='3.0.14', product_module='sync_engine', category='Feature Request', subcategory='Documentation', priority='high', severity='P4', channel='phone', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-01-06T09:06:10 ERROR ERROR_CORRUPTION: Database connection lost\\n2023-01-06T09:06:11 INFO Attempting to reconnect...\\n2023-01-06T09:06:13 ERROR Connection failed', stack_trace='Stack trace:\\n  sync_engine::processData() at sync_engine.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='neutral', previous_tickets=10, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 1, 8, 16, 53, 34, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['created_workaround', 'viewed_logs', 'applied_fix', 'ran_diagnostics', 'consulted_kb'], escalated=True, transferred_count=3, satisfaction_score=1, resolution_helpful=True, tags=['sync', 'integration', 'configuration'], environment='test', business_impact='medium', affected_users=17, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000751', created_at=datetime.datetime(2023, 7, 28, 12, 19, 2, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 28, 13, 2, 14, tzinfo=datetime.timezone.utc), customer_id='CUST-01096', customer_tier='enterprise', organization_id='ORG-197', product='API Gateway', product_version='3.9.15', product_module='request_router', category='Feature Request', subcategory='Documentation', priority='high', severity='P0', channel='phone', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-07-28T12:19:02 ERROR ERROR_RATELIMIT_429: Database connection lost\\n2023-07-28T12:19:03 INFO Attempting to reconnect...\\n2023-07-28T12:19:05 ERROR Connection failed', stack_trace='', customer_sentiment='neutral', previous_tickets=5, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 7, 28, 13, 2, 14, tzinfo=datetime.timezone.utc), agent_id='AGENT-018', agent_actions=['consulted_kb', 'applied_fix'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['security', 'authentication', 'data'], environment='production', business_impact='critical', affected_users=629, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000752', created_at=datetime.datetime(2024, 10, 4, 14, 15, 42, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 4, 23, 58, 18, tzinfo=datetime.timezone.utc), customer_id='CUST-00203', customer_tier='professional', organization_id='ORG-053', product='API Gateway', product_version='2.7.1', product_module='request_router', category='Account Management', subcategory='Subscription', priority='medium', severity='P1', channel='email', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=10, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 10, 4, 23, 58, 18, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['escalated_to_specialist', 'verified_resolution', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['bug', 'data', 'error', 'integration', 'database'], environment='staging', business_impact='high', affected_users=35, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000753', created_at=datetime.datetime(2024, 11, 29, 21, 35, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 29, 22, 57, 14, tzinfo=datetime.timezone.utc), customer_id='CUST-03290', customer_tier='enterprise', organization_id='ORG-157', product='StreamProcessor', product_version='4.1.0', product_module='event_handler', category='Data Issue', subcategory='Data Loss', priority='high', severity='P0', channel='portal', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_CONFLICT_409 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-11-29T21:35:38 DEBUG Processing request ID-12345\\n2024-11-29T21:35:38 ERROR ERROR_CONFLICT_409: Invalid request format\\n2024-11-29T21:35:39 INFO Request rejected', stack_trace='Stack trace:\\n  event_handler::processData() at event_handler.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='frustrated', previous_tickets=3, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 11, 29, 22, 57, 14, tzinfo=datetime.timezone.utc), agent_id='AGENT-017', agent_actions=['consulted_kb', 'updated_documentation', 'checked_config'], escalated=True, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['configuration', 'sync', 'performance', 'timeout', 'authentication'], environment='production', business_impact='high', affected_users=98, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000754', created_at=datetime.datetime(2024, 10, 2, 17, 39, 13, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 3, 4, 46, 25, tzinfo=datetime.timezone.utc), customer_id='CUST-00343', customer_tier='premium', organization_id='ORG-495', product='CloudBackup Enterprise', product_version='2.4.14', product_module='compression_engine', category='Technical Issue', subcategory='Compatibility', priority='critical', severity='P2', channel='api', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=7, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 10, 3, 4, 46, 25, tzinfo=datetime.timezone.utc), agent_id='AGENT-050', agent_actions=['viewed_logs', 'contacted_customer'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['integration', 'configuration', 'performance', 'api'], environment='staging', business_impact='medium', affected_users=937, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000755', created_at=datetime.datetime(2024, 7, 24, 14, 44, 2, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 24, 19, 2, 38, tzinfo=datetime.timezone.utc), customer_id='CUST-02772', customer_tier='enterprise', organization_id='ORG-327', product='DataSync Pro', product_version='3.1.2', product_module='sync_engine', category='Data Issue', subcategory='Import/Export', priority='medium', severity='P1', channel='slack', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_VALIDATION appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-07-24T14:44:02 WARN Rate limit approaching threshold\\n2024-07-24T14:44:02 ERROR ERROR_VALIDATION: Rate limit exceeded\\n2024-07-24T14:44:04 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='frustrated', previous_tickets=9, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 7, 24, 19, 2, 38, tzinfo=datetime.timezone.utc), agent_id='AGENT-047', agent_actions=['verified_resolution', 'ran_diagnostics'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['integration', 'security', 'error', 'database', 'configuration'], environment='development', business_impact='critical', affected_users=13, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000756', created_at=datetime.datetime(2024, 12, 27, 10, 46, 27, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 29, 21, 49, 27, tzinfo=datetime.timezone.utc), customer_id='CUST-03729', customer_tier='free', organization_id='ORG-209', product='API Gateway', product_version='2.6.6', product_module='auth_service', category='Data Issue', subcategory='Import/Export', priority='low', severity='P4', channel='chat', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_PERMISSION_403 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-12-27T10:46:27 ERROR ERROR_PERMISSION_403: Database connection lost\\n2024-12-27T10:46:28 INFO Attempting to reconnect...\\n2024-12-27T10:46:30 ERROR Connection failed', stack_trace='', customer_sentiment='confused', previous_tickets=7, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 12, 29, 21, 49, 27, tzinfo=datetime.timezone.utc), agent_id='AGENT-040', agent_actions=['ran_diagnostics', 'consulted_kb', 'viewed_logs'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=False, tags=['data', 'authentication', 'integration', 'error', 'api'], environment='test', business_impact='critical', affected_users=39, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000757', created_at=datetime.datetime(2024, 10, 6, 13, 54, 31, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 6, 19, 52, 43, tzinfo=datetime.timezone.utc), customer_id='CUST-00289', customer_tier='free', organization_id='ORG-383', product='Analytics Dashboard', product_version='3.9.9', product_module='visualization', category='Security', subcategory='Authentication', priority='medium', severity='P1', channel='api', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_RATELIMIT_429 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-10-06T13:54:31 ERROR ERROR_RATELIMIT_429: Connection timeout after 30s\\n2024-10-06T13:54:32 RETRY_FAILED: Max retries exceeded', stack_trace='ERROR: visualization.service.ServiceException: Failed to process request\\n\\tat visualization.handler.process(visualization.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='frustrated', previous_tickets=5, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 10, 6, 19, 52, 43, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['created_workaround', 'updated_documentation'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['sync', 'performance', 'configuration', 'security', 'bug'], environment='production', business_impact='critical', affected_users=33, language='pt', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000758', created_at=datetime.datetime(2024, 3, 1, 23, 30, 24, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 3, 12, 27, 24, tzinfo=datetime.timezone.utc), customer_id='CUST-03031', customer_tier='premium', organization_id='ORG-215', product='API Gateway', product_version='3.0.10', product_module='cache_layer', category='Account Management', subcategory='Access Control', priority='medium', severity='P4', channel='phone', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=6, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 3, 3, 12, 27, 24, tzinfo=datetime.timezone.utc), agent_id='AGENT-047', agent_actions=['viewed_logs', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['configuration', 'sync', 'bug', 'data'], environment='sandbox', business_impact='medium', affected_users=41, language='ja', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000759', created_at=datetime.datetime(2024, 5, 29, 5, 22, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 30, 7, 16, 2, tzinfo=datetime.timezone.utc), customer_id='CUST-01661', customer_tier='enterprise', organization_id='ORG-217', product='Analytics Dashboard', product_version='4.3.2', product_module='visualization', category='Account Management', subcategory='Billing', priority='critical', severity='P4', channel='email', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-05-29T05:22:38 DEBUG Processing request ID-12345\\n2024-05-29T05:22:38 ERROR ERROR_PARSING: Invalid request format\\n2024-05-29T05:22:39 INFO Request rejected', stack_trace='', customer_sentiment='satisfied', previous_tickets=1, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 5, 30, 7, 16, 2, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['applied_fix', 'viewed_logs', 'created_workaround'], escalated=False, transferred_count=2, satisfaction_score=1, resolution_helpful=True, tags=['configuration', 'api'], environment='test', business_impact='critical', affected_users=366, language='it', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000760', created_at=datetime.datetime(2023, 5, 4, 22, 12, 40, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 8, 15, 25, 16, tzinfo=datetime.timezone.utc), customer_id='CUST-02908', customer_tier='premium', organization_id='ORG-185', product='StreamProcessor', product_version='3.2.1', product_module='event_handler', category='Technical Issue', subcategory='Compatibility', priority='medium', severity='P4', channel='portal', subject='Performance degradation in StreamProcessor', description=\"The StreamProcessor has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_MEMORY_OOM in the logs. This is affecting our entire team's productivity.\", error_logs='2023-05-04T22:12:40 WARN Rate limit approaching threshold\\n2023-05-04T22:12:40 ERROR ERROR_MEMORY_OOM: Rate limit exceeded\\n2023-05-04T22:12:42 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='satisfied', previous_tickets=4, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 5, 8, 15, 25, 16, tzinfo=datetime.timezone.utc), agent_id='AGENT-041', agent_actions=['verified_resolution', 'viewed_logs', 'ran_diagnostics', 'contacted_customer', 'consulted_kb', 'applied_fix'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['authentication', 'bug', 'data', 'error'], environment='production', business_impact='medium', affected_users=10, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000761', created_at=datetime.datetime(2023, 5, 23, 12, 34, 22, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 23, 16, 37, 22, tzinfo=datetime.timezone.utc), customer_id='CUST-01616', customer_tier='starter', organization_id='ORG-013', product='StreamProcessor', product_version='2.4.7', product_module='error_handler', category='Technical Issue', subcategory='Integration', priority='medium', severity='P1', channel='email', subject='Performance degradation in StreamProcessor', description=\"The StreamProcessor has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_VALIDATION in the logs. This is affecting our entire team's productivity.\", error_logs='2023-05-23T12:34:22 DEBUG Processing request ID-12345\\n2023-05-23T12:34:22 ERROR ERROR_VALIDATION: Invalid request format\\n2023-05-23T12:34:23 INFO Request rejected', stack_trace='', customer_sentiment='angry', previous_tickets=2, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 5, 23, 16, 37, 22, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['applied_fix', 'verified_resolution', 'consulted_kb'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['bug', 'error', 'api', 'sync'], environment='test', business_impact='high', affected_users=1, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000762', created_at=datetime.datetime(2024, 4, 30, 7, 51, 2, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 30, 15, 36, 2, tzinfo=datetime.timezone.utc), customer_id='CUST-03406', customer_tier='professional', organization_id='ORG-299', product='Analytics Dashboard', product_version='3.8.15', product_module='report_builder', category='Account Management', subcategory='Billing', priority='high', severity='P2', channel='email', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-04-30T07:51:02 DEBUG Processing request ID-12345\\n2024-04-30T07:51:02 ERROR ERROR_RATELIMIT_429: Invalid request format\\n2024-04-30T07:51:03 INFO Request rejected', stack_trace='at report_builder.execute(report_builder.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='neutral', previous_tickets=8, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 4, 30, 15, 36, 2, tzinfo=datetime.timezone.utc), agent_id='AGENT-028', agent_actions=['created_workaround', 'verified_resolution', 'checked_config', 'applied_fix', 'contacted_customer', 'escalated_to_specialist'], escalated=False, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['database', 'api'], environment='sandbox', business_impact='low', affected_users=956, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000763', created_at=datetime.datetime(2024, 12, 27, 1, 13, 50, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 27, 6, 21, 2, tzinfo=datetime.timezone.utc), customer_id='CUST-01347', customer_tier='enterprise', organization_id='ORG-403', product='DataSync Pro', product_version='3.0.2', product_module='api_connector', category='Feature Request', subcategory='New Feature', priority='high', severity='P1', channel='slack', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-12-27T01:13:50 ERROR ERROR_AUTH_401: Connection timeout after 30s\\n2024-12-27T01:13:51 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='grateful', previous_tickets=0, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 12, 27, 6, 21, 2, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['applied_fix', 'consulted_kb', 'viewed_logs'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['sync', 'api'], environment='staging', business_impact='medium', affected_users=323, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000764', created_at=datetime.datetime(2023, 1, 10, 18, 37, 47, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 13, 9, 58, 47, tzinfo=datetime.timezone.utc), customer_id='CUST-01659', customer_tier='professional', organization_id='ORG-352', product='StreamProcessor', product_version='3.9.12', product_module='error_handler', category='Security', subcategory='Vulnerability', priority='low', severity='P3', channel='api', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Getting ERROR_DISK_FULL errors. We need to ensure our system meets compliance requirements.', error_logs='2023-01-10T18:37:47 ERROR ERROR_DISK_FULL: Connection timeout after 30s\\n2023-01-10T18:37:48 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='angry', previous_tickets=10, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 1, 13, 9, 58, 47, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['checked_config', 'escalated_to_specialist'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['database', 'api', 'integration'], environment='test', business_impact='high', affected_users=33, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000765', created_at=datetime.datetime(2023, 12, 22, 21, 23, 40, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 22, 22, 52, 28, tzinfo=datetime.timezone.utc), customer_id='CUST-00581', customer_tier='starter', organization_id='ORG-371', product='Analytics Dashboard', product_version='4.4.1', product_module='data_aggregator', category='Account Management', subcategory='Upgrade', priority='high', severity='P0', channel='email', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-12-22T21:23:40 DEBUG Processing request ID-12345\\n2023-12-22T21:23:40 ERROR ERROR_SERVER_500: Invalid request format\\n2023-12-22T21:23:41 INFO Request rejected', stack_trace='', customer_sentiment='confused', previous_tickets=2, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 12, 22, 22, 52, 28, tzinfo=datetime.timezone.utc), agent_id='AGENT-029', agent_actions=['updated_documentation', 'checked_config'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['error', 'configuration'], environment='development', business_impact='low', affected_users=427, language='fr', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000766', created_at=datetime.datetime(2024, 10, 21, 13, 50, 47, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 24, 7, 23, 11, tzinfo=datetime.timezone.utc), customer_id='CUST-01840', customer_tier='free', organization_id='ORG-451', product='Analytics Dashboard', product_version='4.5.10', product_module='data_aggregator', category='Feature Request', subcategory='UI/UX', priority='medium', severity='P4', channel='api', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=4, resolution='Root cause identified as UI/UX issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 10, 24, 7, 23, 11, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['viewed_logs', 'verified_resolution'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['performance', 'api', 'security', 'database', 'integration'], environment='staging', business_impact='high', affected_users=35, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000767', created_at=datetime.datetime(2024, 10, 30, 8, 11, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 30, 8, 40, 33, tzinfo=datetime.timezone.utc), customer_id='CUST-01803', customer_tier='starter', organization_id='ORG-300', product='API Gateway', product_version='4.4.6', product_module='request_router', category='Feature Request', subcategory='Enhancement', priority='high', severity='P0', channel='phone', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-10-30T08:11:45 ERROR ERROR_TIMEOUT_429: Connection timeout after 30s\\n2024-10-30T08:11:46 RETRY_FAILED: Max retries exceeded', stack_trace='ERROR: request_router.service.ServiceException: Failed to process request\\n\\tat request_router.handler.process(request_router.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='angry', previous_tickets=6, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 10, 30, 8, 40, 33, tzinfo=datetime.timezone.utc), agent_id='AGENT-024', agent_actions=['ran_diagnostics', 'viewed_logs', 'created_workaround', 'checked_config', 'escalated_to_specialist', 'updated_documentation'], escalated=True, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['api', 'database', 'timeout'], environment='test', business_impact='low', affected_users=62, language='it', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000768', created_at=datetime.datetime(2024, 2, 5, 2, 53, 27, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 5, 10, 46, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-04796', customer_tier='starter', organization_id='ORG-478', product='Analytics Dashboard', product_version='2.8.7', product_module='data_aggregator', category='Data Issue', subcategory='Sync Error', priority='medium', severity='P2', channel='slack', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_RATELIMIT_429 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-02-05T02:53:27 ERROR ERROR_RATELIMIT_429: Database connection lost\\n2024-02-05T02:53:28 INFO Attempting to reconnect...\\n2024-02-05T02:53:30 ERROR Connection failed', stack_trace='ERROR: data_aggregator.service.ServiceException: Failed to process request\\n\\tat data_aggregator.handler.process(data_aggregator.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='neutral', previous_tickets=9, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 2, 5, 10, 46, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-050', agent_actions=['updated_documentation', 'verified_resolution', 'contacted_customer'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['configuration', 'sync', 'integration', 'api', 'error'], environment='staging', business_impact='high', affected_users=43, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000769', created_at=datetime.datetime(2024, 3, 20, 18, 31, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 20, 19, 14, 50, tzinfo=datetime.timezone.utc), customer_id='CUST-04873', customer_tier='premium', organization_id='ORG-092', product='StreamProcessor', product_version='4.5.3', product_module='event_handler', category='Account Management', subcategory='License', priority='critical', severity='P0', channel='slack', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-03-20T18:31:38 DEBUG Processing request ID-12345\\n2024-03-20T18:31:38 ERROR ERROR_SSL_CERT: Invalid request format\\n2024-03-20T18:31:39 INFO Request rejected', stack_trace='', customer_sentiment='frustrated', previous_tickets=8, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 3, 20, 19, 14, 50, tzinfo=datetime.timezone.utc), agent_id='AGENT-033', agent_actions=['applied_fix', 'checked_config', 'created_workaround'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['performance', 'api'], environment='production', business_impact='medium', affected_users=256, language='zh', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000770', created_at=datetime.datetime(2024, 3, 17, 7, 40, 29, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 19, 22, 36, 17, tzinfo=datetime.timezone.utc), customer_id='CUST-03997', customer_tier='starter', organization_id='ORG-027', product='Analytics Dashboard', product_version='2.2.12', product_module='export_module', category='Feature Request', subcategory='API', priority='medium', severity='P4', channel='api', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-03-17T07:40:29 DEBUG Processing request ID-12345\\n2024-03-17T07:40:29 ERROR ERROR_MEMORY_OOM: Invalid request format\\n2024-03-17T07:40:30 INFO Request rejected', stack_trace='', customer_sentiment='frustrated', previous_tickets=10, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 3, 19, 22, 36, 17, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['verified_resolution', 'checked_config', 'ran_diagnostics'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['api', 'authentication', 'database', 'performance', 'bug'], environment='production', business_impact='critical', affected_users=42, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000771', created_at=datetime.datetime(2023, 12, 9, 14, 47, 59, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 12, 3, 33, 35, tzinfo=datetime.timezone.utc), customer_id='CUST-00770', customer_tier='premium', organization_id='ORG-429', product='API Gateway', product_version='3.4.9', product_module='rate_limiter', category='Data Issue', subcategory='Import/Export', priority='low', severity='P4', channel='phone', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_NOTFOUND_404 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-12-09T14:47:59 WARN Rate limit approaching threshold\\n2023-12-09T14:47:59 ERROR ERROR_NOTFOUND_404: Rate limit exceeded\\n2023-12-09T14:48:01 INFO Backing off for 60 seconds', stack_trace='ERROR: rate_limiter.service.ServiceException: Failed to process request\\n\\tat rate_limiter.handler.process(rate_limiter.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='confused', previous_tickets=8, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 12, 12, 3, 33, 35, tzinfo=datetime.timezone.utc), agent_id='AGENT-021', agent_actions=['viewed_logs', 'created_workaround'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=True, tags=['database', 'data', 'configuration', 'authentication'], environment='sandbox', business_impact='high', affected_users=23, language='es', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000772', created_at=datetime.datetime(2024, 3, 28, 1, 6, 54, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 28, 20, 2, 42, tzinfo=datetime.timezone.utc), customer_id='CUST-04414', customer_tier='premium', organization_id='ORG-216', product='API Gateway', product_version='2.3.7', product_module='cache_layer', category='Feature Request', subcategory='Documentation', priority='critical', severity='P3', channel='slack', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-03-28T01:06:54 ERROR ERROR_CONFLICT_409: Connection timeout after 30s\\n2024-03-28T01:06:55 RETRY_FAILED: Max retries exceeded', stack_trace='Stack trace:\\n  cache_layer::processData() at cache_layer.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='frustrated', previous_tickets=0, resolution='Root cause identified as Documentation issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 3, 28, 20, 2, 42, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['verified_resolution', 'ran_diagnostics', 'escalated_to_specialist'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['api', 'sync'], environment='staging', business_impact='critical', affected_users=933, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000773', created_at=datetime.datetime(2023, 10, 15, 8, 38, 32, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 15, 22, 43, 20, tzinfo=datetime.timezone.utc), customer_id='CUST-02091', customer_tier='enterprise', organization_id='ORG-248', product='StreamProcessor', product_version='4.5.14', product_module='batch_processor', category='Account Management', subcategory='License', priority='high', severity='P3', channel='api', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=4, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 10, 15, 22, 43, 20, tzinfo=datetime.timezone.utc), agent_id='AGENT-019', agent_actions=['verified_resolution', 'checked_config', 'consulted_kb', 'ran_diagnostics'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['data', 'security', 'database', 'bug'], environment='test', business_impact='high', affected_users=843, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000774', created_at=datetime.datetime(2024, 12, 2, 2, 38, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 2, 8, 39, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-01193', customer_tier='enterprise', organization_id='ORG-094', product='Analytics Dashboard', product_version='3.4.2', product_module='export_module', category='Technical Issue', subcategory='Integration', priority='critical', severity='P2', channel='portal', subject='Analytics Dashboard throwing ERROR_SERVER_500 during operation', description=\"We're experiencing issues with Analytics Dashboard. The system is throwing ERROR_SERVER_500 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-12-02T02:38:39 ERROR ERROR_SERVER_500: Database connection lost\\n2024-12-02T02:38:40 INFO Attempting to reconnect...\\n2024-12-02T02:38:42 ERROR Connection failed', stack_trace='', customer_sentiment='grateful', previous_tickets=8, resolution='Root cause identified as Integration issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 12, 2, 8, 39, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-033', agent_actions=['applied_fix', 'contacted_customer', 'verified_resolution'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['bug', 'configuration', 'sync', 'performance'], environment='production', business_impact='medium', affected_users=361, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000775', created_at=datetime.datetime(2024, 8, 6, 16, 37, 28, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 6, 17, 16, 28, tzinfo=datetime.timezone.utc), customer_id='CUST-04697', customer_tier='starter', organization_id='ORG-446', product='Analytics Dashboard', product_version='2.9.11', product_module='visualization', category='Feature Request', subcategory='Documentation', priority='low', severity='P0', channel='phone', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=1, resolution='Root cause identified as Documentation issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 8, 6, 17, 16, 28, tzinfo=datetime.timezone.utc), agent_id='AGENT-022', agent_actions=['consulted_kb', 'checked_config'], escalated=True, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'performance', 'data'], environment='sandbox', business_impact='high', affected_users=8, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000776', created_at=datetime.datetime(2024, 3, 17, 1, 58, 23, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 17, 6, 51, 11, tzinfo=datetime.timezone.utc), customer_id='CUST-01548', customer_tier='professional', organization_id='ORG-061', product='CloudBackup Enterprise', product_version='4.6.0', product_module='encryption_layer', category='Account Management', subcategory='License', priority='low', severity='P0', channel='portal', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-03-17T01:58:23 DEBUG Processing request ID-12345\\n2024-03-17T01:58:23 ERROR ERROR_SSL_CERT: Invalid request format\\n2024-03-17T01:58:24 INFO Request rejected', stack_trace='Stack trace:\\n  encryption_layer::processData() at encryption_layer.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='confused', previous_tickets=4, resolution='Root cause identified as License issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 3, 17, 6, 51, 11, tzinfo=datetime.timezone.utc), agent_id='AGENT-036', agent_actions=['applied_fix', 'created_workaround', 'escalated_to_specialist'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['sync', 'bug', 'configuration', 'security'], environment='test', business_impact='low', affected_users=2, language='es', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000777', created_at=datetime.datetime(2024, 3, 10, 6, 26, 29, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 12, 11, 37, 53, tzinfo=datetime.timezone.utc), customer_id='CUST-03115', customer_tier='free', organization_id='ORG-305', product='CloudBackup Enterprise', product_version='3.4.11', product_module='backup_service', category='Security', subcategory='Authorization', priority='low', severity='P3', channel='slack', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Getting ERROR_CONNECTION_REFUSED errors. We need to ensure our system meets compliance requirements.', error_logs='2024-03-10T06:26:29 ERROR ERROR_CONNECTION_REFUSED: Connection timeout after 30s\\n2024-03-10T06:26:30 RETRY_FAILED: Max retries exceeded', stack_trace='at backup_service.execute(backup_service.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='angry', previous_tickets=1, resolution='Applied hotfix version 3.2.2 to address the ERROR_CONNECTION_REFUSED. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 3, 12, 11, 37, 53, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['updated_documentation', 'verified_resolution', 'checked_config', 'created_workaround'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['api', 'data', 'performance', 'security'], environment='development', business_impact='medium', affected_users=50, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000778', created_at=datetime.datetime(2024, 11, 22, 22, 31, 19, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 23, 18, 24, 7, tzinfo=datetime.timezone.utc), customer_id='CUST-04515', customer_tier='premium', organization_id='ORG-454', product='StreamProcessor', product_version='2.8.5', product_module='batch_processor', category='Feature Request', subcategory='Enhancement', priority='high', severity='P2', channel='portal', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-11-22T22:31:19 WARN Rate limit approaching threshold\\n2024-11-22T22:31:19 ERROR ERROR_NOTFOUND_404: Rate limit exceeded\\n2024-11-22T22:31:21 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='satisfied', previous_tickets=5, resolution='Root cause identified as Enhancement issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 11, 23, 18, 24, 7, tzinfo=datetime.timezone.utc), agent_id='AGENT-033', agent_actions=['escalated_to_specialist', 'contacted_customer', 'viewed_logs', 'updated_documentation', 'consulted_kb', 'ran_diagnostics'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['security', 'data', 'error'], environment='sandbox', business_impact='high', affected_users=154, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000779', created_at=datetime.datetime(2024, 2, 14, 19, 51, 28, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 15, 16, 22, 40, tzinfo=datetime.timezone.utc), customer_id='CUST-00461', customer_tier='free', organization_id='ORG-128', product='DataSync Pro', product_version='3.7.4', product_module='scheduler', category='Security', subcategory='Authentication', priority='high', severity='P2', channel='slack', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_PARSING errors. We need to ensure our system meets compliance requirements.', error_logs='2024-02-14T19:51:28 DEBUG Processing request ID-12345\\n2024-02-14T19:51:28 ERROR ERROR_PARSING: Invalid request format\\n2024-02-14T19:51:29 INFO Request rejected', stack_trace='', customer_sentiment='satisfied', previous_tickets=1, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 2, 15, 16, 22, 40, tzinfo=datetime.timezone.utc), agent_id='AGENT-038', agent_actions=['applied_fix', 'ran_diagnostics', 'verified_resolution'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['data', 'sync', 'performance'], environment='development', business_impact='low', affected_users=304, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000780', created_at=datetime.datetime(2023, 8, 8, 6, 18, 40, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 8, 8, 35, 28, tzinfo=datetime.timezone.utc), customer_id='CUST-04673', customer_tier='free', organization_id='ORG-359', product='DataSync Pro', product_version='2.7.3', product_module='sync_engine', category='Technical Issue', subcategory='Bug', priority='high', severity='P0', channel='portal', subject='Performance degradation in DataSync Pro', description=\"The DataSync Pro has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_DISK_FULL in the logs. This is affecting our entire team's productivity.\", error_logs='2023-08-08T06:18:40 ERROR ERROR_DISK_FULL: Connection timeout after 30s\\n2023-08-08T06:18:41 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='neutral', previous_tickets=9, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 8, 8, 8, 35, 28, tzinfo=datetime.timezone.utc), agent_id='AGENT-019', agent_actions=['verified_resolution', 'viewed_logs', 'created_workaround', 'contacted_customer'], escalated=True, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['configuration', 'bug'], environment='sandbox', business_impact='medium', affected_users=475, language='it', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000781', created_at=datetime.datetime(2024, 9, 21, 13, 31, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 21, 15, 13, 37, tzinfo=datetime.timezone.utc), customer_id='CUST-04001', customer_tier='free', organization_id='ORG-070', product='Analytics Dashboard', product_version='3.2.0', product_module='export_module', category='Data Issue', subcategory='Data Loss', priority='high', severity='P0', channel='email', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_SSL_CERT appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-09-21T13:31:37 WARN Rate limit approaching threshold\\n2024-09-21T13:31:37 ERROR ERROR_SSL_CERT: Rate limit exceeded\\n2024-09-21T13:31:39 INFO Backing off for 60 seconds', stack_trace='ERROR: export_module.service.ServiceException: Failed to process request\\n\\tat export_module.handler.process(export_module.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='frustrated', previous_tickets=6, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 9, 21, 15, 13, 37, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['created_workaround', 'escalated_to_specialist', 'verified_resolution'], escalated=True, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['timeout', 'security', 'data'], environment='development', business_impact='critical', affected_users=548, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000782', created_at=datetime.datetime(2024, 9, 7, 3, 47, 4, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 7, 20, 24, 52, tzinfo=datetime.timezone.utc), customer_id='CUST-02119', customer_tier='premium', organization_id='ORG-201', product='StreamProcessor', product_version='3.4.8', product_module='error_handler', category='Data Issue', subcategory='Import/Export', priority='critical', severity='P3', channel='chat', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=10, resolution='Root cause identified as Import/Export issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 9, 7, 20, 24, 52, tzinfo=datetime.timezone.utc), agent_id='AGENT-005', agent_actions=['ran_diagnostics', 'created_workaround', 'viewed_logs', 'updated_documentation'], escalated=True, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['configuration', 'security', 'integration', 'data', 'performance'], environment='development', business_impact='medium', affected_users=619, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000783', created_at=datetime.datetime(2023, 7, 2, 7, 29, 19, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 2, 12, 24, 31, tzinfo=datetime.timezone.utc), customer_id='CUST-04717', customer_tier='starter', organization_id='ORG-491', product='DataSync Pro', product_version='2.8.1', product_module='data_validator', category='Data Issue', subcategory='Corruption', priority='low', severity='P0', channel='portal', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_INVALID_400 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-07-02T07:29:19 DEBUG Processing request ID-12345\\n2023-07-02T07:29:19 ERROR ERROR_INVALID_400: Invalid request format\\n2023-07-02T07:29:20 INFO Request rejected', stack_trace='at data_validator.execute(data_validator.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='confused', previous_tickets=1, resolution='Applied hotfix version 3.2.2 to address the ERROR_INVALID_400. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 7, 2, 12, 24, 31, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['viewed_logs', 'contacted_customer'], escalated=True, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['configuration', 'security'], environment='development', business_impact='medium', affected_users=13, language='zh', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000784', created_at=datetime.datetime(2023, 4, 5, 3, 3, 48, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 5, 4, 33, 48, tzinfo=datetime.timezone.utc), customer_id='CUST-03266', customer_tier='free', organization_id='ORG-367', product='API Gateway', product_version='4.3.14', product_module='cache_layer', category='Data Issue', subcategory='Sync Error', priority='critical', severity='P1', channel='slack', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=5, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 4, 5, 4, 33, 48, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['verified_resolution', 'updated_documentation', 'escalated_to_specialist'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['security', 'api', 'bug'], environment='production', business_impact='high', affected_users=800, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000785', created_at=datetime.datetime(2024, 9, 25, 12, 49, 18, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 25, 14, 39, 42, tzinfo=datetime.timezone.utc), customer_id='CUST-02302', customer_tier='starter', organization_id='ORG-461', product='DataSync Pro', product_version='3.0.8', product_module='api_connector', category='Data Issue', subcategory='Sync Error', priority='high', severity='P0', channel='phone', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_MEMORY_OOM appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-09-25T12:49:18 WARN Rate limit approaching threshold\\n2024-09-25T12:49:18 ERROR ERROR_MEMORY_OOM: Rate limit exceeded\\n2024-09-25T12:49:20 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='neutral', previous_tickets=6, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 9, 25, 14, 39, 42, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['checked_config', 'contacted_customer'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['data', 'timeout', 'error'], environment='test', business_impact='low', affected_users=814, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000786', created_at=datetime.datetime(2024, 1, 4, 21, 28, 18, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 5, 1, 13, 54, tzinfo=datetime.timezone.utc), customer_id='CUST-02742', customer_tier='premium', organization_id='ORG-401', product='StreamProcessor', product_version='4.0.7', product_module='error_handler', category='Technical Issue', subcategory='Compatibility', priority='critical', severity='P1', channel='email', subject='Performance degradation in StreamProcessor', description=\"The StreamProcessor has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_VALIDATION in the logs. This is affecting our entire team's productivity.\", error_logs='2024-01-04T21:28:18 ERROR ERROR_VALIDATION: Connection timeout after 30s\\n2024-01-04T21:28:19 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='frustrated', previous_tickets=3, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 1, 5, 1, 13, 54, tzinfo=datetime.timezone.utc), agent_id='AGENT-015', agent_actions=['ran_diagnostics', 'created_workaround', 'verified_resolution'], escalated=True, transferred_count=0, satisfaction_score=2, resolution_helpful=True, tags=['authentication', 'data'], environment='sandbox', business_impact='critical', affected_users=754, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000787', created_at=datetime.datetime(2023, 7, 10, 18, 8, 35, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 11, 2, 21, 11, tzinfo=datetime.timezone.utc), customer_id='CUST-04870', customer_tier='free', organization_id='ORG-124', product='CloudBackup Enterprise', product_version='2.8.5', product_module='backup_service', category='Account Management', subcategory='Subscription', priority='low', severity='P1', channel='email', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-07-10T18:08:35 ERROR ERROR_DISK_FULL: Connection timeout after 30s\\n2023-07-10T18:08:36 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='satisfied', previous_tickets=8, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 7, 11, 2, 21, 11, tzinfo=datetime.timezone.utc), agent_id='AGENT-017', agent_actions=['viewed_logs', 'verified_resolution'], escalated=True, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['authentication', 'performance', 'configuration'], environment='staging', business_impact='high', affected_users=34, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000788', created_at=datetime.datetime(2024, 12, 28, 10, 8, 34, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 28, 11, 48, 10, tzinfo=datetime.timezone.utc), customer_id='CUST-03844', customer_tier='professional', organization_id='ORG-315', product='API Gateway', product_version='3.0.11', product_module='cache_layer', category='Security', subcategory='Encryption', priority='critical', severity='P0', channel='email', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_TIMEOUT_429 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-12-28T10:08:34 ERROR ERROR_TIMEOUT_429: Database connection lost\\n2024-12-28T10:08:35 INFO Attempting to reconnect...\\n2024-12-28T10:08:37 ERROR Connection failed', stack_trace='at cache_layer.execute(cache_layer.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='grateful', previous_tickets=0, resolution='Applied hotfix version 3.2.2 to address the ERROR_TIMEOUT_429. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 12, 28, 11, 48, 10, tzinfo=datetime.timezone.utc), agent_id='AGENT-047', agent_actions=['checked_config', 'escalated_to_specialist', 'created_workaround'], escalated=True, transferred_count=0, satisfaction_score=2, resolution_helpful=True, tags=['data', 'api', 'database'], environment='test', business_impact='medium', affected_users=149, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000789', created_at=datetime.datetime(2024, 5, 5, 12, 47, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 5, 19, 17, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-04548', customer_tier='enterprise', organization_id='ORG-080', product='DataSync Pro', product_version='2.3.14', product_module='sync_engine', category='Data Issue', subcategory='Sync Error', priority='high', severity='P1', channel='email', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_DISK_FULL appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-05-05T12:47:39 ERROR ERROR_DISK_FULL: Database connection lost\\n2024-05-05T12:47:40 INFO Attempting to reconnect...\\n2024-05-05T12:47:42 ERROR Connection failed', stack_trace='', customer_sentiment='neutral', previous_tickets=5, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 5, 5, 19, 17, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-041', agent_actions=['consulted_kb', 'applied_fix'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['authentication', 'performance', 'security'], environment='production', business_impact='low', affected_users=799, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000790', created_at=datetime.datetime(2024, 1, 2, 13, 35, 3, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 2, 15, 56, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-02609', customer_tier='starter', organization_id='ORG-357', product='CloudBackup Enterprise', product_version='4.8.2', product_module='encryption_layer', category='Account Management', subcategory='Subscription', priority='low', severity='P0', channel='api', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=6, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 1, 2, 15, 56, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-020', agent_actions=['ran_diagnostics', 'checked_config', 'updated_documentation', 'contacted_customer'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['performance', 'integration', 'database'], environment='staging', business_impact='low', affected_users=46, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000791', created_at=datetime.datetime(2024, 7, 1, 20, 8, 17, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 2, 12, 23, 17, tzinfo=datetime.timezone.utc), customer_id='CUST-02312', customer_tier='premium', organization_id='ORG-260', product='CloudBackup Enterprise', product_version='4.5.1', product_module='backup_service', category='Account Management', subcategory='Billing', priority='critical', severity='P4', channel='slack', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=4, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 7, 2, 12, 23, 17, tzinfo=datetime.timezone.utc), agent_id='AGENT-038', agent_actions=['consulted_kb', 'applied_fix', 'viewed_logs', 'created_workaround', 'verified_resolution'], escalated=True, transferred_count=3, satisfaction_score=1, resolution_helpful=True, tags=['sync', 'configuration', 'authentication', 'api', 'bug'], environment='production', business_impact='high', affected_users=37, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000792', created_at=datetime.datetime(2023, 8, 3, 9, 56, 59, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 7, 13, 9, 35, tzinfo=datetime.timezone.utc), customer_id='CUST-03288', customer_tier='premium', organization_id='ORG-330', product='StreamProcessor', product_version='2.8.8', product_module='error_handler', category='Account Management', subcategory='License', priority='low', severity='P4', channel='chat', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-08-03T09:56:59 ERROR ERROR_NOTFOUND_404: Connection timeout after 30s\\n2023-08-03T09:57:00 RETRY_FAILED: Max retries exceeded', stack_trace='ERROR: error_handler.service.ServiceException: Failed to process request\\n\\tat error_handler.handler.process(error_handler.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='neutral', previous_tickets=9, resolution='Root cause identified as License issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 8, 7, 13, 9, 35, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['contacted_customer', 'checked_config', 'verified_resolution'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['configuration', 'database'], environment='production', business_impact='medium', affected_users=37, language='es', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000793', created_at=datetime.datetime(2024, 8, 8, 8, 9, 46, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 8, 19, 30, 46, tzinfo=datetime.timezone.utc), customer_id='CUST-00153', customer_tier='enterprise', organization_id='ORG-057', product='API Gateway', product_version='4.5.10', product_module='cache_layer', category='Feature Request', subcategory='Documentation', priority='medium', severity='P2', channel='phone', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=7, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 8, 8, 19, 30, 46, tzinfo=datetime.timezone.utc), agent_id='AGENT-001', agent_actions=['ran_diagnostics', 'applied_fix'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['data', 'sync', 'api', 'configuration'], environment='development', business_impact='high', affected_users=37, language='fr', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000794', created_at=datetime.datetime(2023, 5, 19, 2, 25, 12, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 19, 5, 3, tzinfo=datetime.timezone.utc), customer_id='CUST-02666', customer_tier='starter', organization_id='ORG-167', product='API Gateway', product_version='3.5.14', product_module='cache_layer', category='Data Issue', subcategory='Validation', priority='critical', severity='P0', channel='slack', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_DEADLOCK appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-05-19T02:25:12 ERROR ERROR_DEADLOCK: Connection timeout after 30s\\n2023-05-19T02:25:13 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='angry', previous_tickets=10, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 5, 19, 5, 3, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['contacted_customer', 'ran_diagnostics', 'verified_resolution'], escalated=True, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['configuration', 'sync', 'performance'], environment='production', business_impact='low', affected_users=186, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000795', created_at=datetime.datetime(2024, 2, 4, 7, 17, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 4, 9, 36, 14, tzinfo=datetime.timezone.utc), customer_id='CUST-03511', customer_tier='free', organization_id='ORG-493', product='StreamProcessor', product_version='3.0.15', product_module='batch_processor', category='Technical Issue', subcategory='Configuration', priority='high', severity='P0', channel='portal', subject='StreamProcessor throwing errors during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=8, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 2, 4, 9, 36, 14, tzinfo=datetime.timezone.utc), agent_id='AGENT-050', agent_actions=['escalated_to_specialist', 'checked_config'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=False, tags=['configuration', 'sync'], environment='development', business_impact='low', affected_users=520, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000796', created_at=datetime.datetime(2023, 1, 22, 2, 54, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 22, 9, 21, 2, tzinfo=datetime.timezone.utc), customer_id='CUST-02950', customer_tier='premium', organization_id='ORG-078', product='Analytics Dashboard', product_version='2.7.12', product_module='report_builder', category='Data Issue', subcategory='Import/Export', priority='medium', severity='P1', channel='chat', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces. Error code ERROR_VALIDATION appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-01-22T02:54:38 ERROR ERROR_VALIDATION: Connection timeout after 30s\\n2023-01-22T02:54:39 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='frustrated', previous_tickets=8, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 1, 22, 9, 21, 2, tzinfo=datetime.timezone.utc), agent_id='AGENT-034', agent_actions=['escalated_to_specialist', 'contacted_customer', 'applied_fix', 'updated_documentation', 'ran_diagnostics', 'created_workaround'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['security', 'sync', 'configuration', 'timeout'], environment='development', business_impact='medium', affected_users=3, language='ja', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000797', created_at=datetime.datetime(2024, 7, 30, 17, 46, 30, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 30, 21, 18, 54, tzinfo=datetime.timezone.utc), customer_id='CUST-04187', customer_tier='starter', organization_id='ORG-166', product='CloudBackup Enterprise', product_version='2.1.0', product_module='encryption_layer', category='Technical Issue', subcategory='Configuration', priority='medium', severity='P1', channel='portal', subject='CloudBackup Enterprise throwing ERROR_CORRUPTION during operation', description=\"We're experiencing issues with CloudBackup Enterprise. The system is throwing ERROR_CORRUPTION when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-07-30T17:46:30 ERROR ERROR_CORRUPTION: Connection timeout after 30s\\n2024-07-30T17:46:31 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='grateful', previous_tickets=3, resolution='Applied hotfix version 3.2.2 to address the ERROR_CORRUPTION. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 7, 30, 21, 18, 54, tzinfo=datetime.timezone.utc), agent_id='AGENT-025', agent_actions=['consulted_kb', 'contacted_customer', 'applied_fix', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['integration', 'sync', 'timeout'], environment='production', business_impact='high', affected_users=6, language='zh', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000798', created_at=datetime.datetime(2024, 3, 15, 3, 19, 52, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 17, 23, 9, 4, tzinfo=datetime.timezone.utc), customer_id='CUST-04586', customer_tier='free', organization_id='ORG-492', product='StreamProcessor', product_version='3.2.5', product_module='monitoring', category='Security', subcategory='Authorization', priority='high', severity='P4', channel='email', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=7, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 3, 17, 23, 9, 4, tzinfo=datetime.timezone.utc), agent_id='AGENT-019', agent_actions=['contacted_customer', 'updated_documentation', 'created_workaround', 'viewed_logs', 'ran_diagnostics'], escalated=True, transferred_count=2, satisfaction_score=2, resolution_helpful=True, tags=['data', 'database', 'integration', 'sync'], environment='development', business_impact='critical', affected_users=157, language='pt', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000799', created_at=datetime.datetime(2024, 5, 30, 0, 37, 29, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 2, 5, 30, 53, tzinfo=datetime.timezone.utc), customer_id='CUST-04780', customer_tier='professional', organization_id='ORG-201', product='API Gateway', product_version='2.4.12', product_module='cache_layer', category='Security', subcategory='Authentication', priority='high', severity='P4', channel='email', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 6, 2, 5, 30, 53, tzinfo=datetime.timezone.utc), agent_id='AGENT-024', agent_actions=['contacted_customer', 'created_workaround', 'verified_resolution'], escalated=True, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['bug', 'api', 'authentication', 'timeout'], environment='staging', business_impact='high', affected_users=393, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000800', created_at=datetime.datetime(2023, 10, 7, 10, 49, 58, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 7, 13, 41, 34, tzinfo=datetime.timezone.utc), customer_id='CUST-00305', customer_tier='enterprise', organization_id='ORG-433', product='DataSync Pro', product_version='3.1.9', product_module='data_validator', category='Data Issue', subcategory='Corruption', priority='medium', severity='P0', channel='slack', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=7, resolution='Root cause identified as Corruption issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 10, 7, 13, 41, 34, tzinfo=datetime.timezone.utc), agent_id='AGENT-013', agent_actions=['created_workaround', 'verified_resolution', 'consulted_kb'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['integration', 'performance', 'authentication', 'api'], environment='sandbox', business_impact='low', affected_users=30, language='en', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000801', created_at=datetime.datetime(2023, 7, 30, 20, 51, 40, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 2, 22, 45, 40, tzinfo=datetime.timezone.utc), customer_id='CUST-03292', customer_tier='premium', organization_id='ORG-124', product='API Gateway', product_version='4.3.2', product_module='rate_limiter', category='Feature Request', subcategory='API', priority='high', severity='P4', channel='slack', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=9, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 8, 2, 22, 45, 40, tzinfo=datetime.timezone.utc), agent_id='AGENT-005', agent_actions=['consulted_kb', 'contacted_customer'], escalated=True, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['integration', 'timeout', 'sync', 'authentication'], environment='production', business_impact='low', affected_users=318, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000802', created_at=datetime.datetime(2023, 4, 27, 4, 12, 22, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 27, 6, 26, 10, tzinfo=datetime.timezone.utc), customer_id='CUST-00288', customer_tier='starter', organization_id='ORG-446', product='DataSync Pro', product_version='4.5.3', product_module='api_connector', category='Feature Request', subcategory='Enhancement', priority='critical', severity='P0', channel='api', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-04-27T04:12:22 DEBUG Processing request ID-12345\\n2023-04-27T04:12:22 ERROR ERROR_DEADLOCK: Invalid request format\\n2023-04-27T04:12:23 INFO Request rejected', stack_trace='ERROR: api_connector.service.ServiceException: Failed to process request\\n\\tat api_connector.handler.process(api_connector.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='frustrated', previous_tickets=3, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 4, 27, 6, 26, 10, tzinfo=datetime.timezone.utc), agent_id='AGENT-026', agent_actions=['updated_documentation', 'created_workaround'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=True, tags=['integration', 'api', 'authentication', 'database'], environment='development', business_impact='low', affected_users=252, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000803', created_at=datetime.datetime(2024, 8, 21, 15, 44, 35, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 22, 17, 0, 47, tzinfo=datetime.timezone.utc), customer_id='CUST-02797', customer_tier='professional', organization_id='ORG-357', product='StreamProcessor', product_version='4.6.4', product_module='event_handler', category='Data Issue', subcategory='Corruption', priority='medium', severity='P2', channel='api', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_NOTFOUND_404 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-08-21T15:44:35 DEBUG Processing request ID-12345\\n2024-08-21T15:44:35 ERROR ERROR_NOTFOUND_404: Invalid request format\\n2024-08-21T15:44:36 INFO Request rejected', stack_trace='', customer_sentiment='grateful', previous_tickets=4, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 8, 22, 17, 0, 47, tzinfo=datetime.timezone.utc), agent_id='AGENT-032', agent_actions=['contacted_customer', 'verified_resolution', 'checked_config', 'created_workaround', 'viewed_logs'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['sync', 'integration', 'api'], environment='sandbox', business_impact='critical', affected_users=18, language='zh', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000804', created_at=datetime.datetime(2023, 8, 18, 11, 48, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 18, 14, 40, 15, tzinfo=datetime.timezone.utc), customer_id='CUST-01084', customer_tier='starter', organization_id='ORG-435', product='CloudBackup Enterprise', product_version='3.4.9', product_module='encryption_layer', category='Security', subcategory='Vulnerability', priority='high', severity='P0', channel='email', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=4, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 8, 18, 14, 40, 15, tzinfo=datetime.timezone.utc), agent_id='AGENT-026', agent_actions=['verified_resolution', 'checked_config', 'consulted_kb', 'ran_diagnostics'], escalated=True, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['error', 'performance', 'bug', 'api', 'database'], environment='production', business_impact='medium', affected_users=256, language='ja', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000805', created_at=datetime.datetime(2023, 7, 22, 4, 7, 29, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 22, 19, 48, 17, tzinfo=datetime.timezone.utc), customer_id='CUST-01023', customer_tier='free', organization_id='ORG-401', product='API Gateway', product_version='3.1.15', product_module='auth_service', category='Feature Request', subcategory='UI/UX', priority='medium', severity='P2', channel='slack', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-07-22T04:07:29 ERROR ERROR_AUTH_401: Connection timeout after 30s\\n2023-07-22T04:07:30 RETRY_FAILED: Max retries exceeded', stack_trace='at auth_service.execute(auth_service.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='confused', previous_tickets=7, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 7, 22, 19, 48, 17, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['checked_config', 'contacted_customer', 'created_workaround'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['sync', 'configuration', 'timeout', 'database'], environment='sandbox', business_impact='high', affected_users=34, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000806', created_at=datetime.datetime(2024, 9, 19, 22, 20, 23, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 20, 0, 32, 23, tzinfo=datetime.timezone.utc), customer_id='CUST-01557', customer_tier='premium', organization_id='ORG-430', product='Analytics Dashboard', product_version='2.4.11', product_module='report_builder', category='Account Management', subcategory='Upgrade', priority='high', severity='P0', channel='slack', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-09-19T22:20:23 ERROR ERROR_INVALID_400: Database connection lost\\n2024-09-19T22:20:24 INFO Attempting to reconnect...\\n2024-09-19T22:20:26 ERROR Connection failed', stack_trace='Stack trace:\\n  report_builder::processData() at report_builder.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='neutral', previous_tickets=10, resolution='Root cause identified as Upgrade issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 9, 20, 0, 32, 23, tzinfo=datetime.timezone.utc), agent_id='AGENT-044', agent_actions=['contacted_customer', 'checked_config'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['database', 'authentication'], environment='sandbox', business_impact='low', affected_users=989, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000807', created_at=datetime.datetime(2023, 5, 29, 20, 15, 14, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 30, 14, 55, 26, tzinfo=datetime.timezone.utc), customer_id='CUST-03722', customer_tier='free', organization_id='ORG-279', product='API Gateway', product_version='4.8.2', product_module='rate_limiter', category='Data Issue', subcategory='Sync Error', priority='medium', severity='P2', channel='slack', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_PARSING appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-05-29T20:15:14 ERROR ERROR_PARSING: Connection timeout after 30s\\n2023-05-29T20:15:15 RETRY_FAILED: Max retries exceeded', stack_trace='Stack trace:\\n  rate_limiter::processData() at rate_limiter.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='confused', previous_tickets=3, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 5, 30, 14, 55, 26, tzinfo=datetime.timezone.utc), agent_id='AGENT-046', agent_actions=['updated_documentation', 'viewed_logs', 'consulted_kb', 'checked_config'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['security', 'configuration', 'integration', 'sync', 'performance'], environment='staging', business_impact='medium', affected_users=30, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000808', created_at=datetime.datetime(2023, 9, 24, 21, 17, 12, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 25, 4, 19, 36, tzinfo=datetime.timezone.utc), customer_id='CUST-04454', customer_tier='starter', organization_id='ORG-025', product='Analytics Dashboard', product_version='4.1.14', product_module='export_module', category='Account Management', subcategory='Upgrade', priority='medium', severity='P1', channel='phone', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-09-24T21:17:12 DEBUG Processing request ID-12345\\n2023-09-24T21:17:12 ERROR ERROR_RATELIMIT_429: Invalid request format\\n2023-09-24T21:17:13 INFO Request rejected', stack_trace='', customer_sentiment='grateful', previous_tickets=8, resolution='Applied hotfix version 3.2.2 to address the ERROR_RATELIMIT_429. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 9, 25, 4, 19, 36, tzinfo=datetime.timezone.utc), agent_id='AGENT-034', agent_actions=['contacted_customer', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=False, tags=['database', 'performance', 'security', 'api', 'integration'], environment='staging', business_impact='medium', affected_users=9, language='ja', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000809', created_at=datetime.datetime(2023, 5, 30, 9, 0, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 31, 20, 35, 27, tzinfo=datetime.timezone.utc), customer_id='CUST-01705', customer_tier='professional', organization_id='ORG-152', product='DataSync Pro', product_version='2.5.12', product_module='scheduler', category='Security', subcategory='Authorization', priority='critical', severity='P4', channel='api', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_PERMISSION_403 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-05-30T09:00:39 ERROR ERROR_PERMISSION_403: Database connection lost\\n2023-05-30T09:00:40 INFO Attempting to reconnect...\\n2023-05-30T09:00:42 ERROR Connection failed', stack_trace='', customer_sentiment='grateful', previous_tickets=6, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 5, 31, 20, 35, 27, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['checked_config', 'applied_fix'], escalated=True, transferred_count=1, satisfaction_score=2, resolution_helpful=True, tags=['security', 'database'], environment='sandbox', business_impact='low', affected_users=409, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000810', created_at=datetime.datetime(2024, 11, 13, 14, 5, 47, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 13, 20, 21, 23, tzinfo=datetime.timezone.utc), customer_id='CUST-00057', customer_tier='professional', organization_id='ORG-295', product='StreamProcessor', product_version='3.9.10', product_module='batch_processor', category='Technical Issue', subcategory='Performance', priority='critical', severity='P2', channel='email', subject='StreamProcessor throwing ERROR_AUTH_401 during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing ERROR_AUTH_401 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-11-13T14:05:47 DEBUG Processing request ID-12345\\n2024-11-13T14:05:47 ERROR ERROR_AUTH_401: Invalid request format\\n2024-11-13T14:05:48 INFO Request rejected', stack_trace='', customer_sentiment='satisfied', previous_tickets=6, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 11, 13, 20, 21, 23, tzinfo=datetime.timezone.utc), agent_id='AGENT-001', agent_actions=['viewed_logs', 'ran_diagnostics', 'checked_config', 'escalated_to_specialist'], escalated=True, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['error', 'integration', 'api'], environment='staging', business_impact='critical', affected_users=442, language='fr', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000811', created_at=datetime.datetime(2024, 10, 26, 9, 13, 7, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 28, 12, 49, 7, tzinfo=datetime.timezone.utc), customer_id='CUST-01137', customer_tier='starter', organization_id='ORG-102', product='CloudBackup Enterprise', product_version='4.0.2', product_module='encryption_layer', category='Data Issue', subcategory='Corruption', priority='high', severity='P4', channel='email', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_CORRUPTION appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-10-26T09:13:07 WARN Rate limit approaching threshold\\n2024-10-26T09:13:07 ERROR ERROR_CORRUPTION: Rate limit exceeded\\n2024-10-26T09:13:09 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'encryption_layer.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='frustrated', previous_tickets=8, resolution='Applied hotfix version 3.2.2 to address the ERROR_CORRUPTION. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 10, 28, 12, 49, 7, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['created_workaround', 'ran_diagnostics', 'updated_documentation'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['sync', 'timeout', 'data', 'integration'], environment='staging', business_impact='high', affected_users=821, language='es', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000812', created_at=datetime.datetime(2024, 4, 17, 11, 9, 3, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 17, 16, 51, 3, tzinfo=datetime.timezone.utc), customer_id='CUST-03273', customer_tier='free', organization_id='ORG-346', product='API Gateway', product_version='2.7.12', product_module='rate_limiter', category='Security', subcategory='Authentication', priority='medium', severity='P2', channel='portal', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_PARSING errors. We need to ensure our system meets compliance requirements.', error_logs='2024-04-17T11:09:03 ERROR ERROR_PARSING: Connection timeout after 30s\\n2024-04-17T11:09:04 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='frustrated', previous_tickets=1, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 4, 17, 16, 51, 3, tzinfo=datetime.timezone.utc), agent_id='AGENT-015', agent_actions=['ran_diagnostics', 'updated_documentation', 'created_workaround'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['configuration', 'integration'], environment='staging', business_impact='high', affected_users=46, language='de', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000813', created_at=datetime.datetime(2024, 7, 16, 6, 43, 55, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 16, 9, 57, 7, tzinfo=datetime.timezone.utc), customer_id='CUST-01066', customer_tier='enterprise', organization_id='ORG-284', product='API Gateway', product_version='2.3.13', product_module='request_router', category='Account Management', subcategory='Billing', priority='low', severity='P0', channel='chat', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-07-16T06:43:55 WARN Rate limit approaching threshold\\n2024-07-16T06:43:55 ERROR ERROR_DEADLOCK: Rate limit exceeded\\n2024-07-16T06:43:57 INFO Backing off for 60 seconds', stack_trace='at request_router.execute(request_router.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='confused', previous_tickets=2, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 7, 16, 9, 57, 7, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['consulted_kb', 'updated_documentation'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['integration', 'data', 'bug', 'configuration', 'sync'], environment='production', business_impact='high', affected_users=2, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000814', created_at=datetime.datetime(2023, 12, 9, 19, 32, 53, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 11, 19, 1, 5, tzinfo=datetime.timezone.utc), customer_id='CUST-01557', customer_tier='premium', organization_id='ORG-430', product='StreamProcessor', product_version='3.2.1', product_module='monitoring', category='Feature Request', subcategory='Enhancement', priority='high', severity='P4', channel='api', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-12-09T19:32:53 ERROR ERROR_SERVER_500: Connection timeout after 30s\\n2023-12-09T19:32:54 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='angry', previous_tickets=9, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 12, 11, 19, 1, 5, tzinfo=datetime.timezone.utc), agent_id='AGENT-038', agent_actions=['viewed_logs', 'ran_diagnostics'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['data', 'authentication'], environment='staging', business_impact='low', affected_users=574, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000815', created_at=datetime.datetime(2024, 4, 12, 22, 19, 22, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 14, 10, 13, 22, tzinfo=datetime.timezone.utc), customer_id='CUST-03345', customer_tier='professional', organization_id='ORG-135', product='API Gateway', product_version='2.3.11', product_module='cache_layer', category='Feature Request', subcategory='Documentation', priority='medium', severity='P3', channel='slack', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=7, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 4, 14, 10, 13, 22, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['ran_diagnostics', 'verified_resolution', 'escalated_to_specialist'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['timeout', 'sync', 'error', 'performance'], environment='test', business_impact='low', affected_users=33, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000816', created_at=datetime.datetime(2024, 7, 30, 7, 26, 56, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 30, 13, 43, 8, tzinfo=datetime.timezone.utc), customer_id='CUST-04827', customer_tier='premium', organization_id='ORG-140', product='DataSync Pro', product_version='4.2.5', product_module='data_validator', category='Security', subcategory='Authentication', priority='low', severity='P0', channel='email', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_NOTFOUND_404 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-07-30T07:26:56 WARN Rate limit approaching threshold\\n2024-07-30T07:26:56 ERROR ERROR_NOTFOUND_404: Rate limit exceeded\\n2024-07-30T07:26:58 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='neutral', previous_tickets=5, resolution='Root cause identified as Authentication issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 7, 30, 13, 43, 8, tzinfo=datetime.timezone.utc), agent_id='AGENT-042', agent_actions=['created_workaround', 'checked_config'], escalated=True, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['configuration', 'integration'], environment='sandbox', business_impact='medium', affected_users=27, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000817', created_at=datetime.datetime(2023, 3, 22, 22, 37, 40, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 24, 14, 29, 16, tzinfo=datetime.timezone.utc), customer_id='CUST-03226', customer_tier='professional', organization_id='ORG-119', product='CloudBackup Enterprise', product_version='4.4.15', product_module='backup_service', category='Data Issue', subcategory='Import/Export', priority='low', severity='P3', channel='email', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=6, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 3, 24, 14, 29, 16, tzinfo=datetime.timezone.utc), agent_id='AGENT-024', agent_actions=['consulted_kb', 'viewed_logs', 'contacted_customer'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['error', 'configuration', 'api', 'data'], environment='development', business_impact='critical', affected_users=36, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000818', created_at=datetime.datetime(2024, 9, 7, 6, 31, 43, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 7, 11, 17, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-01702', customer_tier='free', organization_id='ORG-075', product='CloudBackup Enterprise', product_version='2.4.13', product_module='restore_module', category='Account Management', subcategory='Subscription', priority='medium', severity='P1', channel='phone', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=0, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 9, 7, 11, 17, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-005', agent_actions=['ran_diagnostics', 'viewed_logs', 'verified_resolution', 'applied_fix', 'escalated_to_specialist'], escalated=True, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['timeout', 'database', 'integration', 'bug'], environment='test', business_impact='medium', affected_users=15, language='zh', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000819', created_at=datetime.datetime(2023, 5, 27, 11, 48, 11, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 27, 17, 19, 23, tzinfo=datetime.timezone.utc), customer_id='CUST-04596', customer_tier='free', organization_id='ORG-351', product='CloudBackup Enterprise', product_version='3.1.2', product_module='backup_service', category='Technical Issue', subcategory='Bug', priority='low', severity='P1', channel='api', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_VALIDATION in the logs. This is affecting our entire team's productivity.\", error_logs='2023-05-27T11:48:11 DEBUG Processing request ID-12345\\n2023-05-27T11:48:11 ERROR ERROR_VALIDATION: Invalid request format\\n2023-05-27T11:48:12 INFO Request rejected', stack_trace='', customer_sentiment='confused', previous_tickets=1, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 5, 27, 17, 19, 23, tzinfo=datetime.timezone.utc), agent_id='AGENT-006', agent_actions=['updated_documentation', 'escalated_to_specialist', 'applied_fix', 'checked_config', 'created_workaround'], escalated=True, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['authentication', 'integration'], environment='staging', business_impact='low', affected_users=19, language='zh', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000820', created_at=datetime.datetime(2023, 6, 27, 16, 0, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 27, 23, 38, 29, tzinfo=datetime.timezone.utc), customer_id='CUST-01277', customer_tier='starter', organization_id='ORG-144', product='Analytics Dashboard', product_version='4.4.5', product_module='data_aggregator', category='Account Management', subcategory='Subscription', priority='medium', severity='P2', channel='portal', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=5, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 6, 27, 23, 38, 29, tzinfo=datetime.timezone.utc), agent_id='AGENT-048', agent_actions=['viewed_logs', 'created_workaround', 'contacted_customer', 'verified_resolution', 'escalated_to_specialist'], escalated=True, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['sync', 'data'], environment='production', business_impact='medium', affected_users=17, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000821', created_at=datetime.datetime(2023, 2, 8, 22, 41, 3, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 9, 5, 9, 15, tzinfo=datetime.timezone.utc), customer_id='CUST-03511', customer_tier='free', organization_id='ORG-493', product='StreamProcessor', product_version='2.6.0', product_module='event_handler', category='Data Issue', subcategory='Validation', priority='high', severity='P2', channel='api', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=3, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 2, 9, 5, 9, 15, tzinfo=datetime.timezone.utc), agent_id='AGENT-037', agent_actions=['contacted_customer', 'created_workaround', 'checked_config'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['timeout', 'configuration', 'error', 'api'], environment='production', business_impact='high', affected_users=383, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000822', created_at=datetime.datetime(2024, 10, 19, 11, 53, 43, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 19, 16, 32, 43, tzinfo=datetime.timezone.utc), customer_id='CUST-02643', customer_tier='free', organization_id='ORG-016', product='StreamProcessor', product_version='3.5.14', product_module='monitoring', category='Data Issue', subcategory='Sync Error', priority='critical', severity='P1', channel='email', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_PERMISSION_403 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-10-19T11:53:43 WARN Rate limit approaching threshold\\n2024-10-19T11:53:43 ERROR ERROR_PERMISSION_403: Rate limit exceeded\\n2024-10-19T11:53:45 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='grateful', previous_tickets=6, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 10, 19, 16, 32, 43, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['viewed_logs', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['data', 'error', 'database', 'performance'], environment='staging', business_impact='medium', affected_users=370, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000823', created_at=datetime.datetime(2024, 5, 17, 10, 51, 24, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 19, 2, 26, 48, tzinfo=datetime.timezone.utc), customer_id='CUST-01780', customer_tier='enterprise', organization_id='ORG-166', product='StreamProcessor', product_version='3.7.4', product_module='error_handler', category='Data Issue', subcategory='Import/Export', priority='medium', severity='P3', channel='slack', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_RATELIMIT_429 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-05-17T10:51:24 DEBUG Processing request ID-12345\\n2024-05-17T10:51:24 ERROR ERROR_RATELIMIT_429: Invalid request format\\n2024-05-17T10:51:25 INFO Request rejected', stack_trace=\"Traceback (most recent call last):\\n  File 'error_handler.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='satisfied', previous_tickets=1, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 5, 19, 2, 26, 48, tzinfo=datetime.timezone.utc), agent_id='AGENT-050', agent_actions=['updated_documentation', 'consulted_kb', 'ran_diagnostics', 'applied_fix', 'escalated_to_specialist'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=False, tags=['authentication', 'performance', 'integration', 'sync', 'timeout'], environment='staging', business_impact='high', affected_users=2, language='pt', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000824', created_at=datetime.datetime(2024, 4, 15, 5, 3, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 15, 20, 3, 1, tzinfo=datetime.timezone.utc), customer_id='CUST-03896', customer_tier='enterprise', organization_id='ORG-070', product='DataSync Pro', product_version='3.5.10', product_module='sync_engine', category='Data Issue', subcategory='Validation', priority='medium', severity='P3', channel='slack', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_AUTH_401 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-04-15T05:03:37 ERROR ERROR_AUTH_401: Database connection lost\\n2024-04-15T05:03:38 INFO Attempting to reconnect...\\n2024-04-15T05:03:40 ERROR Connection failed', stack_trace='Stack trace:\\n  sync_engine::processData() at sync_engine.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='grateful', previous_tickets=10, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 4, 15, 20, 3, 1, tzinfo=datetime.timezone.utc), agent_id='AGENT-017', agent_actions=['viewed_logs', 'created_workaround'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['integration', 'api', 'error', 'configuration'], environment='production', business_impact='medium', affected_users=24, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000825', created_at=datetime.datetime(2023, 8, 4, 20, 15, 55, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 4, 22, 54, 19, tzinfo=datetime.timezone.utc), customer_id='CUST-04871', customer_tier='premium', organization_id='ORG-366', product='CloudBackup Enterprise', product_version='3.8.11', product_module='compression_engine', category='Feature Request', subcategory='Enhancement', priority='critical', severity='P2', channel='slack', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-08-04T20:15:55 ERROR ERROR_VALIDATION: Database connection lost\\n2023-08-04T20:15:56 INFO Attempting to reconnect...\\n2023-08-04T20:15:58 ERROR Connection failed', stack_trace=\"Traceback (most recent call last):\\n  File 'compression_engine.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='confused', previous_tickets=0, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 8, 4, 22, 54, 19, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['created_workaround', 'updated_documentation'], escalated=True, transferred_count=1, satisfaction_score=2, resolution_helpful=True, tags=['api', 'performance', 'error'], environment='test', business_impact='critical', affected_users=645, language='zh', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000826', created_at=datetime.datetime(2024, 11, 23, 12, 25, 31, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 24, 12, 9, 19, tzinfo=datetime.timezone.utc), customer_id='CUST-02945', customer_tier='professional', organization_id='ORG-169', product='DataSync Pro', product_version='4.3.11', product_module='data_validator', category='Security', subcategory='Vulnerability', priority='high', severity='P3', channel='slack', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_CONFLICT_409 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-11-23T12:25:31 ERROR ERROR_CONFLICT_409: Connection timeout after 30s\\n2024-11-23T12:25:32 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='satisfied', previous_tickets=5, resolution='Root cause identified as Vulnerability issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 11, 24, 12, 9, 19, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['checked_config', 'escalated_to_specialist'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['security', 'integration'], environment='staging', business_impact='medium', affected_users=167, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000827', created_at=datetime.datetime(2023, 10, 11, 8, 18, 40, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 12, 5, 10, 16, tzinfo=datetime.timezone.utc), customer_id='CUST-03573', customer_tier='starter', organization_id='ORG-462', product='StreamProcessor', product_version='3.3.0', product_module='batch_processor', category='Feature Request', subcategory='Documentation', priority='low', severity='P2', channel='api', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 10, 12, 5, 10, 16, tzinfo=datetime.timezone.utc), agent_id='AGENT-025', agent_actions=['ran_diagnostics', 'escalated_to_specialist', 'verified_resolution'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['integration', 'error', 'configuration', 'bug', 'sync'], environment='staging', business_impact='low', affected_users=42, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000828', created_at=datetime.datetime(2023, 1, 25, 2, 3, 36, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 25, 4, 30, 36, tzinfo=datetime.timezone.utc), customer_id='CUST-00842', customer_tier='starter', organization_id='ORG-324', product='StreamProcessor', product_version='3.4.0', product_module='error_handler', category='Technical Issue', subcategory='Bug', priority='low', severity='P0', channel='chat', subject='Performance degradation in StreamProcessor', description=\"The StreamProcessor has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_NOTFOUND_404 in the logs. This is affecting our entire team's productivity.\", error_logs='2023-01-25T02:03:36 DEBUG Processing request ID-12345\\n2023-01-25T02:03:36 ERROR ERROR_NOTFOUND_404: Invalid request format\\n2023-01-25T02:03:37 INFO Request rejected', stack_trace='', customer_sentiment='neutral', previous_tickets=2, resolution='Applied hotfix version 3.2.2 to address the ERROR_NOTFOUND_404. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 1, 25, 4, 30, 36, tzinfo=datetime.timezone.utc), agent_id='AGENT-019', agent_actions=['escalated_to_specialist', 'created_workaround', 'verified_resolution'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['security', 'performance'], environment='sandbox', business_impact='high', affected_users=45, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000829', created_at=datetime.datetime(2024, 4, 12, 19, 15, 8, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 12, 21, 0, 44, tzinfo=datetime.timezone.utc), customer_id='CUST-03641', customer_tier='starter', organization_id='ORG-131', product='StreamProcessor', product_version='4.7.8', product_module='event_handler', category='Account Management', subcategory='License', priority='high', severity='P1', channel='email', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-04-12T19:15:08 DEBUG Processing request ID-12345\\n2024-04-12T19:15:08 ERROR ERROR_INVALID_400: Invalid request format\\n2024-04-12T19:15:09 INFO Request rejected', stack_trace='', customer_sentiment='grateful', previous_tickets=4, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 4, 12, 21, 0, 44, tzinfo=datetime.timezone.utc), agent_id='AGENT-050', agent_actions=['consulted_kb', 'created_workaround'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['security', 'bug'], environment='production', business_impact='high', affected_users=768, language='pt', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000830', created_at=datetime.datetime(2023, 12, 31, 13, 49, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 3, 5, 19, 2, tzinfo=datetime.timezone.utc), customer_id='CUST-00229', customer_tier='professional', organization_id='ORG-255', product='DataSync Pro', product_version='3.2.10', product_module='sync_engine', category='Security', subcategory='Authorization', priority='high', severity='P4', channel='phone', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_AUTH_401 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-12-31T13:49:38 WARN Rate limit approaching threshold\\n2023-12-31T13:49:38 ERROR ERROR_AUTH_401: Rate limit exceeded\\n2023-12-31T13:49:40 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='neutral', previous_tickets=4, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 1, 3, 5, 19, 2, tzinfo=datetime.timezone.utc), agent_id='AGENT-042', agent_actions=['updated_documentation', 'ran_diagnostics', 'viewed_logs'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['performance', 'sync', 'security'], environment='test', business_impact='high', affected_users=444, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000831', created_at=datetime.datetime(2024, 1, 14, 23, 50, 57, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 16, 12, 38, 21, tzinfo=datetime.timezone.utc), customer_id='CUST-00062', customer_tier='enterprise', organization_id='ORG-423', product='CloudBackup Enterprise', product_version='2.8.11', product_module='compression_engine', category='Technical Issue', subcategory='Configuration', priority='low', severity='P2', channel='slack', subject='CloudBackup Enterprise throwing errors during operation', description=\"We're experiencing issues with CloudBackup Enterprise. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=10, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 1, 16, 12, 38, 21, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['consulted_kb', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['error', 'data', 'sync', 'configuration'], environment='sandbox', business_impact='critical', affected_users=10, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000832', created_at=datetime.datetime(2024, 10, 27, 7, 42, 12, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 28, 7, 3, 12, tzinfo=datetime.timezone.utc), customer_id='CUST-02254', customer_tier='premium', organization_id='ORG-426', product='StreamProcessor', product_version='4.1.13', product_module='error_handler', category='Account Management', subcategory='Subscription', priority='low', severity='P3', channel='phone', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-10-27T07:42:12 ERROR ERROR_RATELIMIT_429: Connection timeout after 30s\\n2024-10-27T07:42:13 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='angry', previous_tickets=6, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 10, 28, 7, 3, 12, tzinfo=datetime.timezone.utc), agent_id='AGENT-024', agent_actions=['verified_resolution', 'contacted_customer', 'consulted_kb'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['authentication', 'performance', 'api', 'bug', 'sync'], environment='staging', business_impact='low', affected_users=26, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000833', created_at=datetime.datetime(2023, 4, 14, 12, 24, 26, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 15, 10, 56, 14, tzinfo=datetime.timezone.utc), customer_id='CUST-02159', customer_tier='enterprise', organization_id='ORG-131', product='DataSync Pro', product_version='4.2.13', product_module='scheduler', category='Security', subcategory='Compliance', priority='critical', severity='P4', channel='phone', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_INVALID_400 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-04-14T12:24:26 WARN Rate limit approaching threshold\\n2023-04-14T12:24:26 ERROR ERROR_INVALID_400: Rate limit exceeded\\n2023-04-14T12:24:28 INFO Backing off for 60 seconds', stack_trace='at scheduler.execute(scheduler.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='angry', previous_tickets=6, resolution='Root cause identified as Compliance issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 4, 15, 10, 56, 14, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['updated_documentation', 'ran_diagnostics', 'created_workaround', 'escalated_to_specialist'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['configuration', 'database', 'error', 'sync', 'api'], environment='staging', business_impact='medium', affected_users=88, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000834', created_at=datetime.datetime(2023, 1, 5, 6, 56, 40, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 5, 10, 9, 16, tzinfo=datetime.timezone.utc), customer_id='CUST-00676', customer_tier='premium', organization_id='ORG-070', product='CloudBackup Enterprise', product_version='4.1.1', product_module='encryption_layer', category='Account Management', subcategory='License', priority='medium', severity='P0', channel='chat', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-01-05T06:56:40 ERROR ERROR_PERMISSION_403: Database connection lost\\n2023-01-05T06:56:41 INFO Attempting to reconnect...\\n2023-01-05T06:56:43 ERROR Connection failed', stack_trace='', customer_sentiment='neutral', previous_tickets=7, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 1, 5, 10, 9, 16, tzinfo=datetime.timezone.utc), agent_id='AGENT-005', agent_actions=['applied_fix', 'viewed_logs', 'contacted_customer'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['timeout', 'api', 'database'], environment='development', business_impact='high', affected_users=48, language='zh', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000835', created_at=datetime.datetime(2023, 6, 25, 21, 48, 34, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 25, 23, 1, 46, tzinfo=datetime.timezone.utc), customer_id='CUST-04189', customer_tier='premium', organization_id='ORG-101', product='DataSync Pro', product_version='4.1.4', product_module='data_validator', category='Security', subcategory='Vulnerability', priority='medium', severity='P0', channel='chat', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_CONFLICT_409 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-06-25T21:48:34 ERROR ERROR_CONFLICT_409: Database connection lost\\n2023-06-25T21:48:35 INFO Attempting to reconnect...\\n2023-06-25T21:48:37 ERROR Connection failed', stack_trace='', customer_sentiment='grateful', previous_tickets=7, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 6, 25, 23, 1, 46, tzinfo=datetime.timezone.utc), agent_id='AGENT-012', agent_actions=['viewed_logs', 'applied_fix', 'ran_diagnostics', 'updated_documentation'], escalated=True, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['error', 'configuration'], environment='test', business_impact='critical', affected_users=29, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000836', created_at=datetime.datetime(2023, 3, 8, 16, 15, 11, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 8, 17, 57, 47, tzinfo=datetime.timezone.utc), customer_id='CUST-04711', customer_tier='enterprise', organization_id='ORG-061', product='Analytics Dashboard', product_version='4.4.9', product_module='report_builder', category='Technical Issue', subcategory='Bug', priority='high', severity='P0', channel='api', subject='Performance degradation in Analytics Dashboard', description=\"The Analytics Dashboard has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_CORRUPTION in the logs. This is affecting our entire team's productivity.\", error_logs='2023-03-08T16:15:11 ERROR ERROR_CORRUPTION: Database connection lost\\n2023-03-08T16:15:12 INFO Attempting to reconnect...\\n2023-03-08T16:15:14 ERROR Connection failed', stack_trace='', customer_sentiment='satisfied', previous_tickets=1, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 3, 8, 17, 57, 47, tzinfo=datetime.timezone.utc), agent_id='AGENT-022', agent_actions=['checked_config', 'escalated_to_specialist', 'applied_fix'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['api', 'database'], environment='test', business_impact='low', affected_users=68, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000837', created_at=datetime.datetime(2024, 12, 4, 10, 17, 11, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 5, 16, 15, 59, tzinfo=datetime.timezone.utc), customer_id='CUST-01180', customer_tier='enterprise', organization_id='ORG-288', product='StreamProcessor', product_version='2.9.1', product_module='batch_processor', category='Data Issue', subcategory='Data Loss', priority='medium', severity='P2', channel='phone', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_INVALID_400 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-12-04T10:17:11 DEBUG Processing request ID-12345\\n2024-12-04T10:17:11 ERROR ERROR_INVALID_400: Invalid request format\\n2024-12-04T10:17:12 INFO Request rejected', stack_trace='', customer_sentiment='angry', previous_tickets=1, resolution='Applied hotfix version 3.2.2 to address the ERROR_INVALID_400. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 12, 5, 16, 15, 59, tzinfo=datetime.timezone.utc), agent_id='AGENT-048', agent_actions=['ran_diagnostics', 'created_workaround', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'bug', 'security'], environment='sandbox', business_impact='critical', affected_users=36, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000838', created_at=datetime.datetime(2023, 7, 30, 11, 50, 40, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 30, 17, 58, 28, tzinfo=datetime.timezone.utc), customer_id='CUST-01067', customer_tier='professional', organization_id='ORG-284', product='Analytics Dashboard', product_version='2.2.11', product_module='export_module', category='Data Issue', subcategory='Sync Error', priority='critical', severity='P2', channel='api', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=2, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 7, 30, 17, 58, 28, tzinfo=datetime.timezone.utc), agent_id='AGENT-006', agent_actions=['checked_config', 'escalated_to_specialist', 'contacted_customer'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['authentication', 'timeout', 'integration', 'configuration', 'error'], environment='production', business_impact='low', affected_users=494, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000839', created_at=datetime.datetime(2023, 7, 17, 18, 55, 23, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 19, 18, 13, 23, tzinfo=datetime.timezone.utc), customer_id='CUST-04120', customer_tier='premium', organization_id='ORG-291', product='DataSync Pro', product_version='3.0.6', product_module='api_connector', category='Feature Request', subcategory='API', priority='medium', severity='P4', channel='slack', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-07-17T18:55:23 WARN Rate limit approaching threshold\\n2023-07-17T18:55:23 ERROR ERROR_DEADLOCK: Rate limit exceeded\\n2023-07-17T18:55:25 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'api_connector.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='satisfied', previous_tickets=3, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 7, 19, 18, 13, 23, tzinfo=datetime.timezone.utc), agent_id='AGENT-037', agent_actions=['contacted_customer', 'consulted_kb', 'created_workaround'], escalated=False, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['api', 'timeout', 'bug'], environment='staging', business_impact='high', affected_users=6, language='de', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000840', created_at=datetime.datetime(2024, 11, 8, 18, 40, 13, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 13, 13, 48, 1, tzinfo=datetime.timezone.utc), customer_id='CUST-01839', customer_tier='starter', organization_id='ORG-180', product='CloudBackup Enterprise', product_version='2.4.8', product_module='encryption_layer', category='Feature Request', subcategory='New Feature', priority='low', severity='P4', channel='portal', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-11-08T18:40:13 ERROR ERROR_AUTH_401: Connection timeout after 30s\\n2024-11-08T18:40:14 RETRY_FAILED: Max retries exceeded', stack_trace='Stack trace:\\n  encryption_layer::processData() at encryption_layer.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='confused', previous_tickets=4, resolution='Root cause identified as New Feature issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 11, 13, 13, 48, 1, tzinfo=datetime.timezone.utc), agent_id='AGENT-024', agent_actions=['updated_documentation', 'consulted_kb', 'checked_config', 'viewed_logs', 'applied_fix'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['performance', 'database', 'integration', 'api', 'data'], environment='development', business_impact='medium', affected_users=10, language='ja', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000841', created_at=datetime.datetime(2024, 11, 19, 8, 53, 9, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 19, 10, 53, 9, tzinfo=datetime.timezone.utc), customer_id='CUST-01212', customer_tier='starter', organization_id='ORG-133', product='CloudBackup Enterprise', product_version='4.8.15', product_module='encryption_layer', category='Data Issue', subcategory='Import/Export', priority='medium', severity='P0', channel='email', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_RATELIMIT_429 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-11-19T08:53:09 ERROR ERROR_RATELIMIT_429: Database connection lost\\n2024-11-19T08:53:10 INFO Attempting to reconnect...\\n2024-11-19T08:53:12 ERROR Connection failed', stack_trace='at encryption_layer.execute(encryption_layer.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='grateful', previous_tickets=2, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 11, 19, 10, 53, 9, tzinfo=datetime.timezone.utc), agent_id='AGENT-003', agent_actions=['checked_config', 'consulted_kb', 'viewed_logs', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['error', 'sync', 'bug'], environment='test', business_impact='low', affected_users=45, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000842', created_at=datetime.datetime(2024, 2, 7, 10, 9, 42, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 9, 12, 27, 42, tzinfo=datetime.timezone.utc), customer_id='CUST-01545', customer_tier='starter', organization_id='ORG-449', product='CloudBackup Enterprise', product_version='4.2.0', product_module='backup_service', category='Technical Issue', subcategory='Compatibility', priority='critical', severity='P4', channel='slack', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_SERVER_500 in the logs. This is affecting our entire team's productivity.\", error_logs='2024-02-07T10:09:42 ERROR ERROR_SERVER_500: Database connection lost\\n2024-02-07T10:09:43 INFO Attempting to reconnect...\\n2024-02-07T10:09:45 ERROR Connection failed', stack_trace=\"Traceback (most recent call last):\\n  File 'backup_service.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='confused', previous_tickets=7, resolution='Applied hotfix version 3.2.2 to address the ERROR_SERVER_500. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 2, 9, 12, 27, 42, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['contacted_customer', 'updated_documentation', 'consulted_kb', 'verified_resolution', 'applied_fix', 'checked_config'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['error', 'configuration', 'authentication', 'performance'], environment='development', business_impact='critical', affected_users=120, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000843', created_at=datetime.datetime(2023, 2, 9, 5, 39, 12, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 9, 14, 4, 24, tzinfo=datetime.timezone.utc), customer_id='CUST-03647', customer_tier='professional', organization_id='ORG-154', product='StreamProcessor', product_version='4.1.4', product_module='monitoring', category='Account Management', subcategory='Upgrade', priority='high', severity='P2', channel='phone', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=4, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 2, 9, 14, 4, 24, tzinfo=datetime.timezone.utc), agent_id='AGENT-036', agent_actions=['contacted_customer', 'checked_config', 'escalated_to_specialist', 'applied_fix'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=False, tags=['database', 'bug', 'security'], environment='sandbox', business_impact='high', affected_users=992, language='en', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000844', created_at=datetime.datetime(2023, 4, 27, 19, 34, 54, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 27, 21, 18, 6, tzinfo=datetime.timezone.utc), customer_id='CUST-02064', customer_tier='professional', organization_id='ORG-263', product='StreamProcessor', product_version='4.4.1', product_module='error_handler', category='Data Issue', subcategory='Validation', priority='critical', severity='P0', channel='slack', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_SERVER_500 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-04-27T19:34:54 WARN Rate limit approaching threshold\\n2023-04-27T19:34:54 ERROR ERROR_SERVER_500: Rate limit exceeded\\n2023-04-27T19:34:56 INFO Backing off for 60 seconds', stack_trace='at error_handler.execute(error_handler.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='confused', previous_tickets=3, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 4, 27, 21, 18, 6, tzinfo=datetime.timezone.utc), agent_id='AGENT-040', agent_actions=['consulted_kb', 'contacted_customer'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['api', 'bug', 'timeout', 'error', 'database'], environment='test', business_impact='critical', affected_users=895, language='de', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000845', created_at=datetime.datetime(2023, 6, 10, 22, 56, 19, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 11, 12, 22, 43, tzinfo=datetime.timezone.utc), customer_id='CUST-00972', customer_tier='enterprise', organization_id='ORG-377', product='Analytics Dashboard', product_version='3.3.6', product_module='data_aggregator', category='Security', subcategory='Vulnerability', priority='high', severity='P3', channel='slack', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_CORRUPTION errors. We need to ensure our system meets compliance requirements.', error_logs='2023-06-10T22:56:19 ERROR ERROR_CORRUPTION: Database connection lost\\n2023-06-10T22:56:20 INFO Attempting to reconnect...\\n2023-06-10T22:56:22 ERROR Connection failed', stack_trace='', customer_sentiment='grateful', previous_tickets=5, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 6, 11, 12, 22, 43, tzinfo=datetime.timezone.utc), agent_id='AGENT-003', agent_actions=['applied_fix', 'checked_config'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['bug', 'integration'], environment='sandbox', business_impact='low', affected_users=835, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000846', created_at=datetime.datetime(2024, 4, 3, 18, 33, 11, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 4, 7, 28, 59, tzinfo=datetime.timezone.utc), customer_id='CUST-02649', customer_tier='starter', organization_id='ORG-240', product='Analytics Dashboard', product_version='2.1.5', product_module='export_module', category='Account Management', subcategory='Subscription', priority='critical', severity='P3', channel='slack', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=1, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 4, 4, 7, 28, 59, tzinfo=datetime.timezone.utc), agent_id='AGENT-012', agent_actions=['applied_fix', 'created_workaround'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['integration', 'database', 'bug'], environment='development', business_impact='medium', affected_users=100, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000847', created_at=datetime.datetime(2023, 7, 3, 9, 24, 21, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 3, 15, 10, 33, tzinfo=datetime.timezone.utc), customer_id='CUST-03234', customer_tier='enterprise', organization_id='ORG-022', product='CloudBackup Enterprise', product_version='3.4.11', product_module='compression_engine', category='Technical Issue', subcategory='Compatibility', priority='low', severity='P0', channel='slack', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=3, resolution='Root cause identified as Compatibility issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 7, 3, 15, 10, 33, tzinfo=datetime.timezone.utc), agent_id='AGENT-026', agent_actions=['applied_fix', 'ran_diagnostics', 'verified_resolution'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['timeout', 'authentication', 'performance', 'bug', 'database'], environment='development', business_impact='high', affected_users=9, language='zh', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000848', created_at=datetime.datetime(2024, 3, 3, 3, 46, 6, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 5, 11, 41, 54, tzinfo=datetime.timezone.utc), customer_id='CUST-03809', customer_tier='premium', organization_id='ORG-302', product='StreamProcessor', product_version='4.7.1', product_module='error_handler', category='Data Issue', subcategory='Data Loss', priority='low', severity='P4', channel='slack', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=2, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 3, 5, 11, 41, 54, tzinfo=datetime.timezone.utc), agent_id='AGENT-032', agent_actions=['checked_config', 'created_workaround', 'viewed_logs', 'contacted_customer'], escalated=True, transferred_count=1, satisfaction_score=1, resolution_helpful=False, tags=['configuration', 'bug'], environment='staging', business_impact='medium', affected_users=31, language='ja', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000849', created_at=datetime.datetime(2023, 10, 27, 16, 21, 36, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 27, 17, 35, 24, tzinfo=datetime.timezone.utc), customer_id='CUST-00461', customer_tier='free', organization_id='ORG-128', product='API Gateway', product_version='2.2.3', product_module='auth_service', category='Security', subcategory='Vulnerability', priority='medium', severity='P0', channel='email', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_INVALID_400 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-10-27T16:21:36 DEBUG Processing request ID-12345\\n2023-10-27T16:21:36 ERROR ERROR_INVALID_400: Invalid request format\\n2023-10-27T16:21:37 INFO Request rejected', stack_trace='', customer_sentiment='frustrated', previous_tickets=7, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 10, 27, 17, 35, 24, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['verified_resolution', 'applied_fix', 'created_workaround'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['api', 'bug', 'sync'], environment='development', business_impact='high', affected_users=42, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000850', created_at=datetime.datetime(2024, 6, 17, 3, 29, 42, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 17, 5, 0, 18, tzinfo=datetime.timezone.utc), customer_id='CUST-03539', customer_tier='starter', organization_id='ORG-404', product='CloudBackup Enterprise', product_version='4.4.10', product_module='restore_module', category='Security', subcategory='Compliance', priority='medium', severity='P0', channel='phone', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=0, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 6, 17, 5, 0, 18, tzinfo=datetime.timezone.utc), agent_id='AGENT-023', agent_actions=['created_workaround', 'applied_fix', 'checked_config', 'escalated_to_specialist', 'contacted_customer'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['api', 'sync', 'configuration', 'data', 'database'], environment='production', business_impact='medium', affected_users=36, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000851', created_at=datetime.datetime(2023, 9, 16, 18, 35, 18, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 17, 13, 49, 42, tzinfo=datetime.timezone.utc), customer_id='CUST-04101', customer_tier='starter', organization_id='ORG-007', product='StreamProcessor', product_version='3.7.8', product_module='monitoring', category='Security', subcategory='Vulnerability', priority='high', severity='P2', channel='portal', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Getting ERROR_SSL_CERT errors. We need to ensure our system meets compliance requirements.', error_logs='2023-09-16T18:35:18 DEBUG Processing request ID-12345\\n2023-09-16T18:35:18 ERROR ERROR_SSL_CERT: Invalid request format\\n2023-09-16T18:35:19 INFO Request rejected', stack_trace=\"Traceback (most recent call last):\\n  File 'monitoring.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='confused', previous_tickets=7, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 9, 17, 13, 49, 42, tzinfo=datetime.timezone.utc), agent_id='AGENT-009', agent_actions=['created_workaround', 'viewed_logs', 'contacted_customer', 'updated_documentation'], escalated=True, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['timeout', 'performance', 'security', 'data', 'configuration'], environment='sandbox', business_impact='medium', affected_users=604, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000852', created_at=datetime.datetime(2024, 5, 2, 8, 58, 57, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 2, 13, 57, 9, tzinfo=datetime.timezone.utc), customer_id='CUST-02948', customer_tier='professional', organization_id='ORG-298', product='StreamProcessor', product_version='2.7.6', product_module='batch_processor', category='Account Management', subcategory='Subscription', priority='medium', severity='P1', channel='phone', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=10, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 5, 2, 13, 57, 9, tzinfo=datetime.timezone.utc), agent_id='AGENT-018', agent_actions=['verified_resolution', 'updated_documentation', 'consulted_kb'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['configuration', 'bug'], environment='test', business_impact='low', affected_users=20, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000853', created_at=datetime.datetime(2023, 12, 14, 14, 45, 54, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 18, 0, 23, 6, tzinfo=datetime.timezone.utc), customer_id='CUST-00245', customer_tier='starter', organization_id='ORG-491', product='API Gateway', product_version='4.6.6', product_module='cache_layer', category='Data Issue', subcategory='Sync Error', priority='medium', severity='P4', channel='chat', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=3, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 12, 18, 0, 23, 6, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['consulted_kb', 'viewed_logs', 'updated_documentation', 'created_workaround'], escalated=True, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['error', 'authentication', 'data'], environment='test', business_impact='critical', affected_users=48, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000854', created_at=datetime.datetime(2024, 1, 28, 8, 24, 58, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 28, 10, 17, 10, tzinfo=datetime.timezone.utc), customer_id='CUST-03621', customer_tier='professional', organization_id='ORG-087', product='API Gateway', product_version='3.0.5', product_module='auth_service', category='Feature Request', subcategory='Documentation', priority='high', severity='P1', channel='email', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-01-28T08:24:58 DEBUG Processing request ID-12345\\n2024-01-28T08:24:58 ERROR ERROR_SSL_CERT: Invalid request format\\n2024-01-28T08:24:59 INFO Request rejected', stack_trace='', customer_sentiment='frustrated', previous_tickets=6, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 1, 28, 10, 17, 10, tzinfo=datetime.timezone.utc), agent_id='AGENT-001', agent_actions=['checked_config', 'escalated_to_specialist', 'applied_fix'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['authentication', 'configuration'], environment='sandbox', business_impact='high', affected_users=232, language='en', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000855', created_at=datetime.datetime(2024, 6, 21, 21, 25, 17, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 22, 12, 18, 41, tzinfo=datetime.timezone.utc), customer_id='CUST-01081', customer_tier='enterprise', organization_id='ORG-464', product='API Gateway', product_version='4.8.7', product_module='rate_limiter', category='Technical Issue', subcategory='Integration', priority='medium', severity='P3', channel='chat', subject='Performance degradation in API Gateway', description=\"The API Gateway has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_PARSING in the logs. This is affecting our entire team's productivity.\", error_logs='2024-06-21T21:25:17 ERROR ERROR_PARSING: Database connection lost\\n2024-06-21T21:25:18 INFO Attempting to reconnect...\\n2024-06-21T21:25:20 ERROR Connection failed', stack_trace='Stack trace:\\n  rate_limiter::processData() at rate_limiter.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='grateful', previous_tickets=5, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 6, 22, 12, 18, 41, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['consulted_kb', 'viewed_logs', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['configuration', 'database', 'authentication', 'security', 'api'], environment='production', business_impact='critical', affected_users=33, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000856', created_at=datetime.datetime(2023, 6, 27, 3, 15, 4, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 27, 5, 48, 40, tzinfo=datetime.timezone.utc), customer_id='CUST-04756', customer_tier='professional', organization_id='ORG-066', product='CloudBackup Enterprise', product_version='4.3.8', product_module='backup_service', category='Technical Issue', subcategory='Bug', priority='high', severity='P1', channel='slack', subject='Performance degradation in CloudBackup Enterprise', description=\"The CloudBackup Enterprise has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=2, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 6, 27, 5, 48, 40, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['created_workaround', 'escalated_to_specialist', 'updated_documentation', 'ran_diagnostics'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=True, tags=['sync', 'performance', 'security', 'integration'], environment='production', business_impact='critical', affected_users=994, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000857', created_at=datetime.datetime(2023, 4, 4, 0, 45, 30, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 4, 12, 56, 54, tzinfo=datetime.timezone.utc), customer_id='CUST-00686', customer_tier='premium', organization_id='ORG-382', product='StreamProcessor', product_version='3.4.6', product_module='batch_processor', category='Account Management', subcategory='Subscription', priority='low', severity='P2', channel='slack', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-04-04T00:45:30 DEBUG Processing request ID-12345\\n2023-04-04T00:45:30 ERROR ERROR_SERVER_500: Invalid request format\\n2023-04-04T00:45:31 INFO Request rejected', stack_trace='', customer_sentiment='neutral', previous_tickets=9, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 4, 4, 12, 56, 54, tzinfo=datetime.timezone.utc), agent_id='AGENT-049', agent_actions=['ran_diagnostics', 'escalated_to_specialist', 'checked_config'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['bug', 'error'], environment='development', business_impact='medium', affected_users=26, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000858', created_at=datetime.datetime(2023, 7, 31, 10, 48, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 31, 13, 19, 15, tzinfo=datetime.timezone.utc), customer_id='CUST-03283', customer_tier='free', organization_id='ORG-169', product='DataSync Pro', product_version='4.6.8', product_module='sync_engine', category='Technical Issue', subcategory='Integration', priority='medium', severity='P0', channel='portal', subject='DataSync Pro throwing ERROR_SSL_CERT during operation', description=\"We're experiencing issues with DataSync Pro. The system is throwing ERROR_SSL_CERT when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-07-31T10:48:39 ERROR ERROR_SSL_CERT: Connection timeout after 30s\\n2023-07-31T10:48:40 RETRY_FAILED: Max retries exceeded', stack_trace='ERROR: sync_engine.service.ServiceException: Failed to process request\\n\\tat sync_engine.handler.process(sync_engine.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='grateful', previous_tickets=6, resolution='Applied hotfix version 3.2.2 to address the ERROR_SSL_CERT. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 7, 31, 13, 19, 15, tzinfo=datetime.timezone.utc), agent_id='AGENT-024', agent_actions=['ran_diagnostics', 'viewed_logs', 'created_workaround'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['performance', 'data'], environment='staging', business_impact='critical', affected_users=26, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000859', created_at=datetime.datetime(2023, 8, 16, 22, 47, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 18, 15, 6, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-01461', customer_tier='premium', organization_id='ORG-094', product='StreamProcessor', product_version='4.9.15', product_module='monitoring', category='Feature Request', subcategory='Enhancement', priority='low', severity='P3', channel='portal', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=7, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 8, 18, 15, 6, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-028', agent_actions=['verified_resolution', 'ran_diagnostics', 'contacted_customer', 'escalated_to_specialist'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['api', 'data'], environment='sandbox', business_impact='critical', affected_users=6, language='zh', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000860', created_at=datetime.datetime(2024, 6, 12, 11, 44, 22, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 12, 14, 17, 22, tzinfo=datetime.timezone.utc), customer_id='CUST-04938', customer_tier='starter', organization_id='ORG-043', product='DataSync Pro', product_version='4.8.14', product_module='api_connector', category='Feature Request', subcategory='Documentation', priority='medium', severity='P1', channel='email', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=7, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 6, 12, 14, 17, 22, tzinfo=datetime.timezone.utc), agent_id='AGENT-049', agent_actions=['verified_resolution', 'applied_fix', 'contacted_customer', 'viewed_logs', 'updated_documentation'], escalated=True, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['bug', 'sync', 'security', 'configuration', 'performance'], environment='sandbox', business_impact='critical', affected_users=23, language='es', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000861', created_at=datetime.datetime(2023, 3, 8, 14, 7, 13, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 10, 4, 27, 1, tzinfo=datetime.timezone.utc), customer_id='CUST-03741', customer_tier='professional', organization_id='ORG-036', product='CloudBackup Enterprise', product_version='3.8.14', product_module='compression_engine', category='Security', subcategory='Vulnerability', priority='high', severity='P3', channel='email', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=6, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 3, 10, 4, 27, 1, tzinfo=datetime.timezone.utc), agent_id='AGENT-041', agent_actions=['checked_config', 'consulted_kb', 'applied_fix', 'contacted_customer', 'updated_documentation', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=1, resolution_helpful=True, tags=['security', 'sync', 'performance'], environment='test', business_impact='low', affected_users=449, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000862', created_at=datetime.datetime(2024, 6, 25, 0, 52, 6, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 26, 18, 20, 54, tzinfo=datetime.timezone.utc), customer_id='CUST-03914', customer_tier='premium', organization_id='ORG-248', product='DataSync Pro', product_version='3.8.2', product_module='sync_engine', category='Feature Request', subcategory='Enhancement', priority='critical', severity='P4', channel='email', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=3, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 6, 26, 18, 20, 54, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['viewed_logs', 'verified_resolution'], escalated=True, transferred_count=2, satisfaction_score=1, resolution_helpful=True, tags=['sync', 'database', 'api'], environment='staging', business_impact='medium', affected_users=846, language='zh', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000863', created_at=datetime.datetime(2024, 8, 3, 18, 39, 12, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 4, 2, 44, tzinfo=datetime.timezone.utc), customer_id='CUST-03296', customer_tier='professional', organization_id='ORG-052', product='CloudBackup Enterprise', product_version='3.7.14', product_module='compression_engine', category='Security', subcategory='Encryption', priority='critical', severity='P3', channel='chat', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Getting ERROR_SSL_CERT errors. We need to ensure our system meets compliance requirements.', error_logs='2024-08-03T18:39:12 WARN Rate limit approaching threshold\\n2024-08-03T18:39:12 ERROR ERROR_SSL_CERT: Rate limit exceeded\\n2024-08-03T18:39:14 INFO Backing off for 60 seconds', stack_trace='at compression_engine.execute(compression_engine.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='satisfied', previous_tickets=6, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 8, 4, 2, 44, tzinfo=datetime.timezone.utc), agent_id='AGENT-044', agent_actions=['updated_documentation', 'ran_diagnostics', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['timeout', 'sync', 'bug', 'api', 'error'], environment='production', business_impact='medium', affected_users=356, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000864', created_at=datetime.datetime(2023, 2, 1, 21, 38, 27, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 1, 22, 10, 15, tzinfo=datetime.timezone.utc), customer_id='CUST-03781', customer_tier='free', organization_id='ORG-434', product='DataSync Pro', product_version='3.8.11', product_module='api_connector', category='Technical Issue', subcategory='Configuration', priority='critical', severity='P0', channel='phone', subject='Performance degradation in DataSync Pro', description=\"The DataSync Pro has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_DEADLOCK in the logs. This is affecting our entire team's productivity.\", error_logs='2023-02-01T21:38:27 ERROR ERROR_DEADLOCK: Connection timeout after 30s\\n2023-02-01T21:38:28 RETRY_FAILED: Max retries exceeded', stack_trace='Stack trace:\\n  api_connector::processData() at api_connector.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='grateful', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 2, 1, 22, 10, 15, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['consulted_kb', 'contacted_customer'], escalated=True, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['performance', 'authentication', 'bug', 'data'], environment='sandbox', business_impact='high', affected_users=656, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000865', created_at=datetime.datetime(2023, 8, 8, 16, 59, 32, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 9, 17, 26, 32, tzinfo=datetime.timezone.utc), customer_id='CUST-02207', customer_tier='free', organization_id='ORG-353', product='API Gateway', product_version='2.2.9', product_module='rate_limiter', category='Security', subcategory='Authorization', priority='critical', severity='P3', channel='email', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_VALIDATION errors. We need to ensure our system meets compliance requirements.', error_logs='2023-08-08T16:59:32 WARN Rate limit approaching threshold\\n2023-08-08T16:59:32 ERROR ERROR_VALIDATION: Rate limit exceeded\\n2023-08-08T16:59:34 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'rate_limiter.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='frustrated', previous_tickets=4, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 8, 9, 17, 26, 32, tzinfo=datetime.timezone.utc), agent_id='AGENT-033', agent_actions=['escalated_to_specialist', 'created_workaround', 'checked_config'], escalated=True, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['bug', 'configuration'], environment='staging', business_impact='critical', affected_users=842, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000866', created_at=datetime.datetime(2023, 8, 12, 21, 42, 55, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 12, 23, 6, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-03495', customer_tier='starter', organization_id='ORG-428', product='StreamProcessor', product_version='4.1.13', product_module='monitoring', category='Data Issue', subcategory='Data Loss', priority='high', severity='P1', channel='chat', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_RATELIMIT_429 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-08-12T21:42:55 ERROR ERROR_RATELIMIT_429: Connection timeout after 30s\\n2023-08-12T21:42:56 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='frustrated', previous_tickets=2, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 8, 12, 23, 6, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['checked_config', 'contacted_customer'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['error', 'sync', 'performance'], environment='development', business_impact='low', affected_users=147, language='de', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000867', created_at=datetime.datetime(2024, 11, 5, 21, 30, 58, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 6, 16, 7, 34, tzinfo=datetime.timezone.utc), customer_id='CUST-01528', customer_tier='starter', organization_id='ORG-076', product='API Gateway', product_version='3.8.3', product_module='cache_layer', category='Data Issue', subcategory='Data Loss', priority='high', severity='P2', channel='api', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_VALIDATION appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-11-05T21:30:58 ERROR ERROR_VALIDATION: Database connection lost\\n2024-11-05T21:30:59 INFO Attempting to reconnect...\\n2024-11-05T21:31:01 ERROR Connection failed', stack_trace='ERROR: cache_layer.service.ServiceException: Failed to process request\\n\\tat cache_layer.handler.process(cache_layer.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='grateful', previous_tickets=2, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 11, 6, 16, 7, 34, tzinfo=datetime.timezone.utc), agent_id='AGENT-001', agent_actions=['viewed_logs', 'verified_resolution', 'escalated_to_specialist', 'checked_config', 'contacted_customer'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['configuration', 'sync'], environment='sandbox', business_impact='low', affected_users=226, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000868', created_at=datetime.datetime(2023, 5, 18, 17, 5, 5, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 19, 12, 23, 5, tzinfo=datetime.timezone.utc), customer_id='CUST-02914', customer_tier='enterprise', organization_id='ORG-406', product='API Gateway', product_version='2.5.1', product_module='request_router', category='Security', subcategory='Authorization', priority='medium', severity='P2', channel='chat', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=9, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 5, 19, 12, 23, 5, tzinfo=datetime.timezone.utc), agent_id='AGENT-013', agent_actions=['verified_resolution', 'ran_diagnostics', 'updated_documentation', 'checked_config'], escalated=True, transferred_count=1, satisfaction_score=1, resolution_helpful=False, tags=['data', 'sync', 'authentication', 'api', 'timeout'], environment='sandbox', business_impact='low', affected_users=6, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000869', created_at=datetime.datetime(2023, 10, 28, 0, 42, 32, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 28, 15, 11, 56, tzinfo=datetime.timezone.utc), customer_id='CUST-01677', customer_tier='premium', organization_id='ORG-405', product='API Gateway', product_version='4.1.12', product_module='auth_service', category='Feature Request', subcategory='Enhancement', priority='critical', severity='P3', channel='api', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=7, resolution='Root cause identified as Enhancement issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 10, 28, 15, 11, 56, tzinfo=datetime.timezone.utc), agent_id='AGENT-047', agent_actions=['verified_resolution', 'ran_diagnostics', 'created_workaround'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['performance', 'api', 'bug', 'sync', 'security'], environment='production', business_impact='high', affected_users=542, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000870', created_at=datetime.datetime(2023, 10, 11, 14, 13, 30, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 12, 23, 47, 6, tzinfo=datetime.timezone.utc), customer_id='CUST-04934', customer_tier='starter', organization_id='ORG-328', product='StreamProcessor', product_version='3.0.8', product_module='batch_processor', category='Account Management', subcategory='Subscription', priority='critical', severity='P4', channel='portal', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-10-11T14:13:30 ERROR ERROR_AUTH_401: Connection timeout after 30s\\n2023-10-11T14:13:31 RETRY_FAILED: Max retries exceeded', stack_trace='ERROR: batch_processor.service.ServiceException: Failed to process request\\n\\tat batch_processor.handler.process(batch_processor.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='angry', previous_tickets=9, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 10, 12, 23, 47, 6, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['viewed_logs', 'updated_documentation', 'verified_resolution'], escalated=False, transferred_count=0, satisfaction_score=1, resolution_helpful=True, tags=['performance', 'timeout'], environment='staging', business_impact='high', affected_users=669, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000871', created_at=datetime.datetime(2023, 12, 29, 21, 43, 56, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 30, 18, 24, 8, tzinfo=datetime.timezone.utc), customer_id='CUST-01011', customer_tier='enterprise', organization_id='ORG-205', product='Analytics Dashboard', product_version='2.8.5', product_module='data_aggregator', category='Feature Request', subcategory='Enhancement', priority='medium', severity='P3', channel='api', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-12-29T21:43:56 ERROR ERROR_SERVER_500: Connection timeout after 30s\\n2023-12-29T21:43:57 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='satisfied', previous_tickets=5, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 12, 30, 18, 24, 8, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['applied_fix', 'ran_diagnostics', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'performance'], environment='production', business_impact='high', affected_users=25, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000872', created_at=datetime.datetime(2023, 3, 19, 9, 30, 57, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 19, 12, 10, 33, tzinfo=datetime.timezone.utc), customer_id='CUST-02066', customer_tier='enterprise', organization_id='ORG-126', product='API Gateway', product_version='3.1.14', product_module='auth_service', category='Technical Issue', subcategory='Performance', priority='high', severity='P0', channel='slack', subject='Performance degradation in API Gateway', description=\"The API Gateway has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=4, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 3, 19, 12, 10, 33, tzinfo=datetime.timezone.utc), agent_id='AGENT-045', agent_actions=['viewed_logs', 'consulted_kb'], escalated=True, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['configuration', 'timeout', 'bug', 'error'], environment='staging', business_impact='low', affected_users=645, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000873', created_at=datetime.datetime(2024, 6, 1, 16, 48, 4, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 1, 18, 16, 16, tzinfo=datetime.timezone.utc), customer_id='CUST-01074', customer_tier='professional', organization_id='ORG-326', product='CloudBackup Enterprise', product_version='2.1.8', product_module='encryption_layer', category='Data Issue', subcategory='Sync Error', priority='medium', severity='P0', channel='chat', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_INVALID_400 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-06-01T16:48:04 DEBUG Processing request ID-12345\\n2024-06-01T16:48:04 ERROR ERROR_INVALID_400: Invalid request format\\n2024-06-01T16:48:05 INFO Request rejected', stack_trace=\"Traceback (most recent call last):\\n  File 'encryption_layer.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='frustrated', previous_tickets=8, resolution='Root cause identified as Sync Error issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 6, 1, 18, 16, 16, tzinfo=datetime.timezone.utc), agent_id='AGENT-047', agent_actions=['updated_documentation', 'contacted_customer', 'verified_resolution'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['performance', 'sync', 'integration', 'configuration', 'error'], environment='development', business_impact='critical', affected_users=7, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000874', created_at=datetime.datetime(2023, 8, 30, 7, 13, 44, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 30, 10, 52, 44, tzinfo=datetime.timezone.utc), customer_id='CUST-04535', customer_tier='starter', organization_id='ORG-111', product='Analytics Dashboard', product_version='3.4.9', product_module='report_builder', category='Account Management', subcategory='Subscription', priority='high', severity='P2', channel='email', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-08-30T07:13:44 WARN Rate limit approaching threshold\\n2023-08-30T07:13:44 ERROR ERROR_CONNECTION_REFUSED: Rate limit exceeded\\n2023-08-30T07:13:46 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='grateful', previous_tickets=2, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 8, 30, 10, 52, 44, tzinfo=datetime.timezone.utc), agent_id='AGENT-033', agent_actions=['escalated_to_specialist', 'viewed_logs', 'created_workaround', 'contacted_customer', 'applied_fix', 'updated_documentation'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['integration', 'error'], environment='staging', business_impact='low', affected_users=665, language='es', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000875', created_at=datetime.datetime(2024, 10, 18, 2, 57, 18, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 18, 21, 23, 6, tzinfo=datetime.timezone.utc), customer_id='CUST-02686', customer_tier='professional', organization_id='ORG-357', product='DataSync Pro', product_version='3.9.5', product_module='sync_engine', category='Data Issue', subcategory='Corruption', priority='high', severity='P3', channel='portal', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_VALIDATION appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-10-18T02:57:18 WARN Rate limit approaching threshold\\n2024-10-18T02:57:18 ERROR ERROR_VALIDATION: Rate limit exceeded\\n2024-10-18T02:57:20 INFO Backing off for 60 seconds', stack_trace='at sync_engine.execute(sync_engine.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='satisfied', previous_tickets=7, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 10, 18, 21, 23, 6, tzinfo=datetime.timezone.utc), agent_id='AGENT-029', agent_actions=['contacted_customer', 'applied_fix'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['integration', 'database'], environment='production', business_impact='critical', affected_users=837, language='pt', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000876', created_at=datetime.datetime(2023, 1, 18, 11, 48, 47, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 19, 15, 6, 11, tzinfo=datetime.timezone.utc), customer_id='CUST-00344', customer_tier='professional', organization_id='ORG-181', product='StreamProcessor', product_version='4.9.7', product_module='error_handler', category='Technical Issue', subcategory='Compatibility', priority='high', severity='P4', channel='email', subject='StreamProcessor throwing errors during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=6, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 1, 19, 15, 6, 11, tzinfo=datetime.timezone.utc), agent_id='AGENT-032', agent_actions=['updated_documentation', 'viewed_logs', 'ran_diagnostics'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['api', 'database', 'sync', 'security', 'error'], environment='staging', business_impact='medium', affected_users=924, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000877', created_at=datetime.datetime(2024, 6, 12, 4, 2, 15, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 12, 7, 58, 3, tzinfo=datetime.timezone.utc), customer_id='CUST-01106', customer_tier='starter', organization_id='ORG-247', product='API Gateway', product_version='4.7.8', product_module='rate_limiter', category='Account Management', subcategory='Subscription', priority='low', severity='P1', channel='portal', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-06-12T04:02:15 WARN Rate limit approaching threshold\\n2024-06-12T04:02:15 ERROR ERROR_CONFLICT_409: Rate limit exceeded\\n2024-06-12T04:02:17 INFO Backing off for 60 seconds', stack_trace='ERROR: rate_limiter.service.ServiceException: Failed to process request\\n\\tat rate_limiter.handler.process(rate_limiter.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='neutral', previous_tickets=7, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 6, 12, 7, 58, 3, tzinfo=datetime.timezone.utc), agent_id='AGENT-045', agent_actions=['updated_documentation', 'verified_resolution', 'contacted_customer'], escalated=True, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['integration', 'authentication'], environment='staging', business_impact='low', affected_users=18, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000878', created_at=datetime.datetime(2023, 1, 2, 5, 9, 59, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 5, 11, 16, 35, tzinfo=datetime.timezone.utc), customer_id='CUST-04383', customer_tier='professional', organization_id='ORG-252', product='API Gateway', product_version='4.7.12', product_module='auth_service', category='Security', subcategory='Authorization', priority='low', severity='P3', channel='chat', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_VALIDATION errors. We need to ensure our system meets compliance requirements.', error_logs='2023-01-02T05:09:59 ERROR ERROR_VALIDATION: Database connection lost\\n2023-01-02T05:10:00 INFO Attempting to reconnect...\\n2023-01-02T05:10:02 ERROR Connection failed', stack_trace='', customer_sentiment='confused', previous_tickets=9, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 1, 5, 11, 16, 35, tzinfo=datetime.timezone.utc), agent_id='AGENT-038', agent_actions=['contacted_customer', 'ran_diagnostics', 'consulted_kb'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['performance', 'authentication'], environment='production', business_impact='critical', affected_users=47, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000879', created_at=datetime.datetime(2023, 11, 5, 13, 9, 55, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 7, 3, 9, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-04422', customer_tier='starter', organization_id='ORG-273', product='CloudBackup Enterprise', product_version='3.9.1', product_module='restore_module', category='Feature Request', subcategory='Enhancement', priority='medium', severity='P3', channel='slack', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=5, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 11, 7, 3, 9, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['ran_diagnostics', 'applied_fix', 'created_workaround'], escalated=False, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['database', 'performance', 'configuration'], environment='development', business_impact='critical', affected_users=19, language='ja', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000880', created_at=datetime.datetime(2023, 10, 9, 23, 37, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 10, 4, 53, 13, tzinfo=datetime.timezone.utc), customer_id='CUST-02266', customer_tier='enterprise', organization_id='ORG-392', product='API Gateway', product_version='3.7.11', product_module='cache_layer', category='Feature Request', subcategory='Enhancement', priority='low', severity='P0', channel='portal', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-10-09T23:37:37 ERROR ERROR_PARSING: Connection timeout after 30s\\n2023-10-09T23:37:38 RETRY_FAILED: Max retries exceeded', stack_trace='at cache_layer.execute(cache_layer.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='confused', previous_tickets=5, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 10, 10, 4, 53, 13, tzinfo=datetime.timezone.utc), agent_id='AGENT-047', agent_actions=['verified_resolution', 'created_workaround'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['data', 'authentication', 'performance', 'database', 'timeout'], environment='sandbox', business_impact='high', affected_users=13, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000881', created_at=datetime.datetime(2023, 9, 8, 11, 42, 33, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 8, 18, 10, 45, tzinfo=datetime.timezone.utc), customer_id='CUST-04159', customer_tier='enterprise', organization_id='ORG-107', product='CloudBackup Enterprise', product_version='2.2.7', product_module='restore_module', category='Account Management', subcategory='Subscription', priority='medium', severity='P1', channel='portal', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-09-08T11:42:33 ERROR ERROR_INVALID_400: Connection timeout after 30s\\n2023-09-08T11:42:34 RETRY_FAILED: Max retries exceeded', stack_trace='Stack trace:\\n  restore_module::processData() at restore_module.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='satisfied', previous_tickets=0, resolution='Applied hotfix version 3.2.2 to address the ERROR_INVALID_400. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 9, 8, 18, 10, 45, tzinfo=datetime.timezone.utc), agent_id='AGENT-003', agent_actions=['applied_fix', 'viewed_logs'], escalated=True, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['configuration', 'integration', 'authentication', 'bug', 'security'], environment='test', business_impact='high', affected_users=39, language='es', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000882', created_at=datetime.datetime(2024, 3, 27, 17, 16, 58, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 27, 22, 30, 10, tzinfo=datetime.timezone.utc), customer_id='CUST-04145', customer_tier='free', organization_id='ORG-484', product='Analytics Dashboard', product_version='3.0.11', product_module='visualization', category='Security', subcategory='Authorization', priority='medium', severity='P0', channel='slack', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_SSL_CERT errors. We need to ensure our system meets compliance requirements.', error_logs='2024-03-27T17:16:58 DEBUG Processing request ID-12345\\n2024-03-27T17:16:58 ERROR ERROR_SSL_CERT: Invalid request format\\n2024-03-27T17:16:59 INFO Request rejected', stack_trace='', customer_sentiment='satisfied', previous_tickets=2, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 3, 27, 22, 30, 10, tzinfo=datetime.timezone.utc), agent_id='AGENT-017', agent_actions=['viewed_logs', 'contacted_customer', 'escalated_to_specialist'], escalated=False, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['authentication', 'database', 'timeout', 'data', 'error'], environment='development', business_impact='low', affected_users=8, language='it', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000883', created_at=datetime.datetime(2024, 8, 16, 3, 52, 57, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 19, 5, 37, 21, tzinfo=datetime.timezone.utc), customer_id='CUST-04603', customer_tier='premium', organization_id='ORG-240', product='StreamProcessor', product_version='2.5.3', product_module='batch_processor', category='Data Issue', subcategory='Sync Error', priority='low', severity='P4', channel='portal', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=5, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 8, 19, 5, 37, 21, tzinfo=datetime.timezone.utc), agent_id='AGENT-042', agent_actions=['verified_resolution', 'checked_config'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['performance', 'bug', 'authentication'], environment='sandbox', business_impact='low', affected_users=35, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000884', created_at=datetime.datetime(2023, 9, 29, 23, 54, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 30, 7, 23, 33, tzinfo=datetime.timezone.utc), customer_id='CUST-03028', customer_tier='premium', organization_id='ORG-027', product='API Gateway', product_version='2.6.15', product_module='rate_limiter', category='Account Management', subcategory='Upgrade', priority='low', severity='P1', channel='chat', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-09-29T23:54:45 ERROR ERROR_CONNECTION_REFUSED: Connection timeout after 30s\\n2023-09-29T23:54:46 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='grateful', previous_tickets=8, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 9, 30, 7, 23, 33, tzinfo=datetime.timezone.utc), agent_id='AGENT-041', agent_actions=['viewed_logs', 'applied_fix', 'contacted_customer', 'updated_documentation', 'escalated_to_specialist'], escalated=True, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['error', 'configuration', 'data', 'bug'], environment='development', business_impact='low', affected_users=43, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000885', created_at=datetime.datetime(2024, 5, 5, 16, 34, 51, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 5, 20, 25, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-00479', customer_tier='enterprise', organization_id='ORG-456', product='Analytics Dashboard', product_version='4.6.3', product_module='report_builder', category='Feature Request', subcategory='UI/UX', priority='high', severity='P2', channel='api', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-05-05T16:34:51 ERROR ERROR_MEMORY_OOM: Connection timeout after 30s\\n2024-05-05T16:34:52 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='confused', previous_tickets=5, resolution='Root cause identified as UI/UX issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2024, 5, 5, 20, 25, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-015', agent_actions=['created_workaround', 'updated_documentation', 'contacted_customer', 'verified_resolution', 'escalated_to_specialist'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=True, tags=['performance', 'integration', 'api', 'authentication'], environment='development', business_impact='high', affected_users=880, language='ja', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000886', created_at=datetime.datetime(2024, 12, 17, 3, 52, 12, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 18, 5, 7, 12, tzinfo=datetime.timezone.utc), customer_id='CUST-02923', customer_tier='free', organization_id='ORG-196', product='DataSync Pro', product_version='4.8.7', product_module='scheduler', category='Security', subcategory='Compliance', priority='critical', severity='P4', channel='portal', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_MEMORY_OOM errors. We need to ensure our system meets compliance requirements.', error_logs='2024-12-17T03:52:12 DEBUG Processing request ID-12345\\n2024-12-17T03:52:12 ERROR ERROR_MEMORY_OOM: Invalid request format\\n2024-12-17T03:52:13 INFO Request rejected', stack_trace='', customer_sentiment='grateful', previous_tickets=4, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 12, 18, 5, 7, 12, tzinfo=datetime.timezone.utc), agent_id='AGENT-003', agent_actions=['applied_fix', 'contacted_customer'], escalated=False, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['security', 'database', 'integration', 'api', 'bug'], environment='staging', business_impact='high', affected_users=367, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000887', created_at=datetime.datetime(2023, 8, 29, 17, 28, 26, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 29, 21, 9, 50, tzinfo=datetime.timezone.utc), customer_id='CUST-01399', customer_tier='enterprise', organization_id='ORG-103', product='DataSync Pro', product_version='4.0.1', product_module='scheduler', category='Security', subcategory='Authentication', priority='low', severity='P0', channel='portal', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_SSL_CERT errors. We need to ensure our system meets compliance requirements.', error_logs='2023-08-29T17:28:26 ERROR ERROR_SSL_CERT: Database connection lost\\n2023-08-29T17:28:27 INFO Attempting to reconnect...\\n2023-08-29T17:28:29 ERROR Connection failed', stack_trace='', customer_sentiment='neutral', previous_tickets=10, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 8, 29, 21, 9, 50, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['contacted_customer', 'ran_diagnostics', 'verified_resolution', 'viewed_logs', 'consulted_kb'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['data', 'timeout', 'configuration'], environment='sandbox', business_impact='critical', affected_users=2, language='it', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000888', created_at=datetime.datetime(2024, 1, 7, 7, 27, 20, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 7, 14, 55, 32, tzinfo=datetime.timezone.utc), customer_id='CUST-02609', customer_tier='starter', organization_id='ORG-357', product='API Gateway', product_version='3.0.14', product_module='auth_service', category='Data Issue', subcategory='Corruption', priority='high', severity='P2', channel='slack', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_VALIDATION appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-01-07T07:27:20 ERROR ERROR_VALIDATION: Connection timeout after 30s\\n2024-01-07T07:27:21 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='angry', previous_tickets=2, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 1, 7, 14, 55, 32, tzinfo=datetime.timezone.utc), agent_id='AGENT-009', agent_actions=['verified_resolution', 'updated_documentation', 'applied_fix'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['integration', 'performance', 'timeout', 'database'], environment='test', business_impact='high', affected_users=930, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000889', created_at=datetime.datetime(2024, 4, 22, 7, 7, 5, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 24, 16, 51, 29, tzinfo=datetime.timezone.utc), customer_id='CUST-01463', customer_tier='enterprise', organization_id='ORG-237', product='API Gateway', product_version='4.2.4', product_module='cache_layer', category='Feature Request', subcategory='API', priority='critical', severity='P4', channel='portal', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-04-22T07:07:05 DEBUG Processing request ID-12345\\n2024-04-22T07:07:05 ERROR ERROR_SERVER_500: Invalid request format\\n2024-04-22T07:07:06 INFO Request rejected', stack_trace='ERROR: cache_layer.service.ServiceException: Failed to process request\\n\\tat cache_layer.handler.process(cache_layer.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='confused', previous_tickets=2, resolution='Applied hotfix version 3.2.2 to address the ERROR_SERVER_500. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 4, 24, 16, 51, 29, tzinfo=datetime.timezone.utc), agent_id='AGENT-019', agent_actions=['consulted_kb', 'applied_fix'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['sync', 'performance', 'configuration'], environment='development', business_impact='critical', affected_users=540, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000890', created_at=datetime.datetime(2024, 11, 21, 13, 51, 27, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 26, 15, 18, 27, tzinfo=datetime.timezone.utc), customer_id='CUST-02135', customer_tier='free', organization_id='ORG-467', product='StreamProcessor', product_version='3.2.10', product_module='error_handler', category='Security', subcategory='Authentication', priority='low', severity='P4', channel='portal', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Getting ERROR_AUTH_401 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-11-21T13:51:27 DEBUG Processing request ID-12345\\n2024-11-21T13:51:27 ERROR ERROR_AUTH_401: Invalid request format\\n2024-11-21T13:51:28 INFO Request rejected', stack_trace='at error_handler.execute(error_handler.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='neutral', previous_tickets=8, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 11, 26, 15, 18, 27, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['verified_resolution', 'contacted_customer', 'created_workaround'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=True, tags=['configuration', 'database', 'timeout', 'sync'], environment='staging', business_impact='medium', affected_users=39, language='de', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000891', created_at=datetime.datetime(2024, 1, 26, 20, 8, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 26, 21, 23, 9, tzinfo=datetime.timezone.utc), customer_id='CUST-00449', customer_tier='free', organization_id='ORG-217', product='CloudBackup Enterprise', product_version='4.8.5', product_module='compression_engine', category='Account Management', subcategory='Billing', priority='medium', severity='P0', channel='slack', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=9, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 1, 26, 21, 23, 9, tzinfo=datetime.timezone.utc), agent_id='AGENT-006', agent_actions=['checked_config', 'created_workaround', 'escalated_to_specialist'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['data', 'error', 'configuration'], environment='production', business_impact='high', affected_users=17, language='ja', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000892', created_at=datetime.datetime(2024, 7, 5, 15, 17, 15, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 5, 15, 56, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-00637', customer_tier='starter', organization_id='ORG-156', product='CloudBackup Enterprise', product_version='3.1.13', product_module='restore_module', category='Data Issue', subcategory='Import/Export', priority='critical', severity='P0', channel='api', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_PERMISSION_403 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-07-05T15:17:15 ERROR ERROR_PERMISSION_403: Database connection lost\\n2024-07-05T15:17:16 INFO Attempting to reconnect...\\n2024-07-05T15:17:18 ERROR Connection failed', stack_trace='', customer_sentiment='neutral', previous_tickets=9, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 7, 5, 15, 56, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['contacted_customer', 'ran_diagnostics'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['data', 'api', 'integration', 'performance', 'bug'], environment='production', business_impact='high', affected_users=703, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000893', created_at=datetime.datetime(2023, 11, 30, 20, 23, 47, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 1, 21, 19, 35, tzinfo=datetime.timezone.utc), customer_id='CUST-00176', customer_tier='starter', organization_id='ORG-487', product='Analytics Dashboard', product_version='4.9.13', product_module='export_module', category='Technical Issue', subcategory='Performance', priority='medium', severity='P2', channel='slack', subject='Analytics Dashboard throwing ERROR_PARSING during operation', description=\"We're experiencing issues with Analytics Dashboard. The system is throwing ERROR_PARSING when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-11-30T20:23:47 ERROR ERROR_PARSING: Connection timeout after 30s\\n2023-11-30T20:23:48 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='satisfied', previous_tickets=0, resolution='Applied hotfix version 3.2.2 to address the ERROR_PARSING. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 12, 1, 21, 19, 35, tzinfo=datetime.timezone.utc), agent_id='AGENT-041', agent_actions=['viewed_logs', 'checked_config', 'verified_resolution', 'escalated_to_specialist', 'applied_fix', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['api', 'configuration', 'sync', 'integration', 'data'], environment='staging', business_impact='high', affected_users=8, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000894', created_at=datetime.datetime(2024, 10, 24, 10, 10, 47, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 24, 22, 58, 47, tzinfo=datetime.timezone.utc), customer_id='CUST-03124', customer_tier='free', organization_id='ORG-358', product='DataSync Pro', product_version='4.6.6', product_module='api_connector', category='Feature Request', subcategory='Documentation', priority='high', severity='P2', channel='slack', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=9, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 10, 24, 22, 58, 47, tzinfo=datetime.timezone.utc), agent_id='AGENT-027', agent_actions=['escalated_to_specialist', 'created_workaround', 'ran_diagnostics'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'database', 'configuration', 'performance'], environment='production', business_impact='high', affected_users=210, language='zh', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000895', created_at=datetime.datetime(2024, 9, 11, 14, 22, 55, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 13, 4, 18, 43, tzinfo=datetime.timezone.utc), customer_id='CUST-00463', customer_tier='premium', organization_id='ORG-229', product='API Gateway', product_version='3.9.7', product_module='auth_service', category='Technical Issue', subcategory='Configuration', priority='medium', severity='P3', channel='slack', subject='API Gateway throwing ERROR_TIMEOUT_429 during operation', description=\"We're experiencing issues with API Gateway. The system is throwing ERROR_TIMEOUT_429 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-09-11T14:22:55 ERROR ERROR_TIMEOUT_429: Connection timeout after 30s\\n2024-09-11T14:22:56 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'auth_service.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='confused', previous_tickets=1, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 9, 13, 4, 18, 43, tzinfo=datetime.timezone.utc), agent_id='AGENT-044', agent_actions=['consulted_kb', 'contacted_customer', 'applied_fix'], escalated=False, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['security', 'database', 'integration', 'data'], environment='sandbox', business_impact='high', affected_users=2, language='de', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000896', created_at=datetime.datetime(2024, 6, 16, 22, 37, 48, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 17, 0, 34, 48, tzinfo=datetime.timezone.utc), customer_id='CUST-00441', customer_tier='starter', organization_id='ORG-050', product='API Gateway', product_version='2.3.9', product_module='cache_layer', category='Security', subcategory='Authorization', priority='low', severity='P0', channel='email', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_AUTH_401 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-06-16T22:37:48 WARN Rate limit approaching threshold\\n2024-06-16T22:37:48 ERROR ERROR_AUTH_401: Rate limit exceeded\\n2024-06-16T22:37:50 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='confused', previous_tickets=7, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 6, 17, 0, 34, 48, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['applied_fix', 'verified_resolution', 'consulted_kb'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['configuration', 'api', 'bug', 'integration', 'security'], environment='production', business_impact='critical', affected_users=32, language='it', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000897', created_at=datetime.datetime(2024, 8, 13, 3, 3, 8, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 13, 18, 59, 32, tzinfo=datetime.timezone.utc), customer_id='CUST-03121', customer_tier='starter', organization_id='ORG-207', product='DataSync Pro', product_version='4.8.1', product_module='data_validator', category='Data Issue', subcategory='Data Loss', priority='critical', severity='P3', channel='portal', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_PERMISSION_403 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-08-13T03:03:08 ERROR ERROR_PERMISSION_403: Database connection lost\\n2024-08-13T03:03:09 INFO Attempting to reconnect...\\n2024-08-13T03:03:11 ERROR Connection failed', stack_trace='', customer_sentiment='grateful', previous_tickets=10, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 8, 13, 18, 59, 32, tzinfo=datetime.timezone.utc), agent_id='AGENT-045', agent_actions=['applied_fix', 'ran_diagnostics'], escalated=True, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['data', 'database', 'api', 'bug'], environment='production', business_impact='high', affected_users=529, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000898', created_at=datetime.datetime(2024, 10, 14, 4, 48, 40, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 16, 2, 42, 4, tzinfo=datetime.timezone.utc), customer_id='CUST-01368', customer_tier='free', organization_id='ORG-371', product='CloudBackup Enterprise', product_version='2.2.10', product_module='restore_module', category='Account Management', subcategory='License', priority='low', severity='P4', channel='api', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-10-14T04:48:40 ERROR ERROR_PERMISSION_403: Connection timeout after 30s\\n2024-10-14T04:48:41 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'restore_module.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='angry', previous_tickets=0, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 10, 16, 2, 42, 4, tzinfo=datetime.timezone.utc), agent_id='AGENT-044', agent_actions=['ran_diagnostics', 'verified_resolution', 'created_workaround', 'checked_config', 'consulted_kb', 'viewed_logs'], escalated=True, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['error', 'timeout', 'sync', 'security'], environment='production', business_impact='high', affected_users=13, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000899', created_at=datetime.datetime(2023, 12, 3, 22, 42, 2, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 4, 0, 43, 50, tzinfo=datetime.timezone.utc), customer_id='CUST-02187', customer_tier='free', organization_id='ORG-219', product='DataSync Pro', product_version='3.2.5', product_module='sync_engine', category='Security', subcategory='Encryption', priority='critical', severity='P0', channel='api', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_SSL_CERT errors. We need to ensure our system meets compliance requirements.', error_logs='2023-12-03T22:42:02 WARN Rate limit approaching threshold\\n2023-12-03T22:42:02 ERROR ERROR_SSL_CERT: Rate limit exceeded\\n2023-12-03T22:42:04 INFO Backing off for 60 seconds', stack_trace='at sync_engine.execute(sync_engine.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='neutral', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 12, 4, 0, 43, 50, tzinfo=datetime.timezone.utc), agent_id='AGENT-041', agent_actions=['applied_fix', 'escalated_to_specialist'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['performance', 'api', 'sync', 'timeout', 'data'], environment='staging', business_impact='medium', affected_users=528, language='de', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000900', created_at=datetime.datetime(2024, 4, 14, 4, 40, 51, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 14, 14, 30, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-01768', customer_tier='starter', organization_id='ORG-187', product='API Gateway', product_version='3.8.9', product_module='cache_layer', category='Account Management', subcategory='License', priority='critical', severity='P3', channel='slack', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-04-14T04:40:51 DEBUG Processing request ID-12345\\n2024-04-14T04:40:51 ERROR ERROR_VALIDATION: Invalid request format\\n2024-04-14T04:40:52 INFO Request rejected', stack_trace='Stack trace:\\n  cache_layer::processData() at cache_layer.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='angry', previous_tickets=10, resolution='Applied hotfix version 3.2.2 to address the ERROR_VALIDATION. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 4, 14, 14, 30, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-029', agent_actions=['viewed_logs', 'checked_config', 'created_workaround', 'applied_fix'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['authentication', 'api', 'timeout', 'bug'], environment='sandbox', business_impact='low', affected_users=538, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000901', created_at=datetime.datetime(2024, 3, 26, 0, 13, 32, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 26, 21, 41, 44, tzinfo=datetime.timezone.utc), customer_id='CUST-00984', customer_tier='enterprise', organization_id='ORG-472', product='DataSync Pro', product_version='4.7.3', product_module='data_validator', category='Account Management', subcategory='Subscription', priority='high', severity='P3', channel='portal', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-03-26T00:13:32 ERROR ERROR_PERMISSION_403: Database connection lost\\n2024-03-26T00:13:33 INFO Attempting to reconnect...\\n2024-03-26T00:13:35 ERROR Connection failed', stack_trace=\"Traceback (most recent call last):\\n  File 'data_validator.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='angry', previous_tickets=9, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 3, 26, 21, 41, 44, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['viewed_logs', 'updated_documentation', 'created_workaround'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['performance', 'timeout', 'error', 'configuration', 'security'], environment='development', business_impact='high', affected_users=582, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000902', created_at=datetime.datetime(2023, 7, 2, 16, 2, 28, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 6, 16, 40, 16, tzinfo=datetime.timezone.utc), customer_id='CUST-03510', customer_tier='starter', organization_id='ORG-001', product='CloudBackup Enterprise', product_version='4.8.5', product_module='backup_service', category='Technical Issue', subcategory='Bug', priority='low', severity='P4', channel='slack', subject='CloudBackup Enterprise throwing ERROR_VALIDATION during operation', description=\"We're experiencing issues with CloudBackup Enterprise. The system is throwing ERROR_VALIDATION when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-07-02T16:02:28 WARN Rate limit approaching threshold\\n2023-07-02T16:02:28 ERROR ERROR_VALIDATION: Rate limit exceeded\\n2023-07-02T16:02:30 INFO Backing off for 60 seconds', stack_trace='ERROR: backup_service.service.ServiceException: Failed to process request\\n\\tat backup_service.handler.process(backup_service.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='confused', previous_tickets=8, resolution='Root cause identified as Bug issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 7, 6, 16, 40, 16, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['updated_documentation', 'verified_resolution'], escalated=True, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['database', 'sync', 'api', 'configuration'], environment='staging', business_impact='critical', affected_users=12, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000903', created_at=datetime.datetime(2024, 11, 28, 5, 6, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 28, 10, 3, 5, tzinfo=datetime.timezone.utc), customer_id='CUST-03583', customer_tier='premium', organization_id='ORG-428', product='API Gateway', product_version='2.9.9', product_module='rate_limiter', category='Data Issue', subcategory='Corruption', priority='high', severity='P1', channel='chat', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=6, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 11, 28, 10, 3, 5, tzinfo=datetime.timezone.utc), agent_id='AGENT-028', agent_actions=['applied_fix', 'created_workaround'], escalated=True, transferred_count=2, satisfaction_score=2, resolution_helpful=True, tags=['database', 'api'], environment='production', business_impact='low', affected_users=315, language='it', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000904', created_at=datetime.datetime(2024, 1, 27, 10, 30, 17, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 27, 12, 27, 53, tzinfo=datetime.timezone.utc), customer_id='CUST-00514', customer_tier='premium', organization_id='ORG-288', product='StreamProcessor', product_version='4.2.4', product_module='batch_processor', category='Account Management', subcategory='Subscription', priority='critical', severity='P1', channel='portal', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-01-27T10:30:17 WARN Rate limit approaching threshold\\n2024-01-27T10:30:17 ERROR ERROR_AUTH_401: Rate limit exceeded\\n2024-01-27T10:30:19 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='grateful', previous_tickets=1, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 1, 27, 12, 27, 53, tzinfo=datetime.timezone.utc), agent_id='AGENT-044', agent_actions=['ran_diagnostics', 'applied_fix', 'checked_config'], escalated=True, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['configuration', 'security', 'authentication'], environment='staging', business_impact='low', affected_users=756, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000905', created_at=datetime.datetime(2023, 5, 9, 0, 20, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 9, 1, 43, 24, tzinfo=datetime.timezone.utc), customer_id='CUST-00228', customer_tier='premium', organization_id='ORG-370', product='DataSync Pro', product_version='2.3.7', product_module='data_validator', category='Technical Issue', subcategory='Compatibility', priority='critical', severity='P0', channel='api', subject='Performance degradation in DataSync Pro', description=\"The DataSync Pro has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_SSL_CERT in the logs. This is affecting our entire team's productivity.\", error_logs='2023-05-09T00:20:00 DEBUG Processing request ID-12345\\n2023-05-09T00:20:00 ERROR ERROR_SSL_CERT: Invalid request format\\n2023-05-09T00:20:01 INFO Request rejected', stack_trace='Stack trace:\\n  data_validator::processData() at data_validator.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='grateful', previous_tickets=4, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 5, 9, 1, 43, 24, tzinfo=datetime.timezone.utc), agent_id='AGENT-029', agent_actions=['updated_documentation', 'viewed_logs', 'consulted_kb'], escalated=True, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'performance', 'security'], environment='test', business_impact='medium', affected_users=627, language='it', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000906', created_at=datetime.datetime(2023, 5, 24, 20, 14, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 26, 5, 30, 13, tzinfo=datetime.timezone.utc), customer_id='CUST-00863', customer_tier='premium', organization_id='ORG-478', product='API Gateway', product_version='4.6.6', product_module='rate_limiter', category='Account Management', subcategory='Access Control', priority='high', severity='P4', channel='slack', subject='License upgrade needed for API Gateway', description='We need to upgrade our license for API Gateway. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-05-24T20:14:37 ERROR ERROR_SSL_CERT: Database connection lost\\n2023-05-24T20:14:38 INFO Attempting to reconnect...\\n2023-05-24T20:14:40 ERROR Connection failed', stack_trace=\"Traceback (most recent call last):\\n  File 'rate_limiter.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='neutral', previous_tickets=2, resolution='Root cause identified as Access Control issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 5, 26, 5, 30, 13, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['created_workaround', 'escalated_to_specialist', 'viewed_logs'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['sync', 'performance'], environment='staging', business_impact='high', affected_users=435, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000907', created_at=datetime.datetime(2024, 8, 19, 18, 10, 44, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 19, 20, 28, 44, tzinfo=datetime.timezone.utc), customer_id='CUST-04589', customer_tier='starter', organization_id='ORG-384', product='API Gateway', product_version='4.5.10', product_module='rate_limiter', category='Data Issue', subcategory='Sync Error', priority='low', severity='P0', channel='chat', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_SSL_CERT appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-08-19T18:10:44 ERROR ERROR_SSL_CERT: Database connection lost\\n2024-08-19T18:10:45 INFO Attempting to reconnect...\\n2024-08-19T18:10:47 ERROR Connection failed', stack_trace='', customer_sentiment='satisfied', previous_tickets=6, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 8, 19, 20, 28, 44, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['checked_config', 'escalated_to_specialist', 'viewed_logs'], escalated=True, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['database', 'sync', 'integration', 'security'], environment='test', business_impact='low', affected_users=11, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000908', created_at=datetime.datetime(2023, 2, 4, 17, 4, 10, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 4, 17, 32, 22, tzinfo=datetime.timezone.utc), customer_id='CUST-02353', customer_tier='free', organization_id='ORG-065', product='Analytics Dashboard', product_version='3.1.5', product_module='report_builder', category='Security', subcategory='Authorization', priority='high', severity='P0', channel='email', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_MEMORY_OOM errors. We need to ensure our system meets compliance requirements.', error_logs='2023-02-04T17:04:10 WARN Rate limit approaching threshold\\n2023-02-04T17:04:10 ERROR ERROR_MEMORY_OOM: Rate limit exceeded\\n2023-02-04T17:04:12 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'report_builder.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='frustrated', previous_tickets=3, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 2, 4, 17, 32, 22, tzinfo=datetime.timezone.utc), agent_id='AGENT-005', agent_actions=['checked_config', 'consulted_kb', 'escalated_to_specialist'], escalated=False, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['integration', 'configuration', 'sync'], environment='production', business_impact='critical', affected_users=221, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000909', created_at=datetime.datetime(2023, 2, 2, 3, 11, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 7, 4, 21, 57, tzinfo=datetime.timezone.utc), customer_id='CUST-03875', customer_tier='premium', organization_id='ORG-462', product='CloudBackup Enterprise', product_version='4.4.14', product_module='encryption_layer', category='Technical Issue', subcategory='Configuration', priority='medium', severity='P4', channel='email', subject='CloudBackup Enterprise throwing ERROR_TIMEOUT_429 during operation', description=\"We're experiencing issues with CloudBackup Enterprise. The system is throwing ERROR_TIMEOUT_429 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-02-02T03:11:45 WARN Rate limit approaching threshold\\n2023-02-02T03:11:45 ERROR ERROR_TIMEOUT_429: Rate limit exceeded\\n2023-02-02T03:11:47 INFO Backing off for 60 seconds', stack_trace='at encryption_layer.execute(encryption_layer.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='satisfied', previous_tickets=3, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 2, 7, 4, 21, 57, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['applied_fix', 'contacted_customer', 'created_workaround'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['sync', 'bug'], environment='staging', business_impact='high', affected_users=41, language='zh', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000910', created_at=datetime.datetime(2023, 1, 31, 13, 7, 16, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 1, 7, 55, 52, tzinfo=datetime.timezone.utc), customer_id='CUST-03227', customer_tier='starter', organization_id='ORG-192', product='API Gateway', product_version='4.5.14', product_module='auth_service', category='Technical Issue', subcategory='Integration', priority='high', severity='P2', channel='api', subject='Performance degradation in API Gateway', description=\"The API Gateway has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_CONNECTION_REFUSED in the logs. This is affecting our entire team's productivity.\", error_logs='2023-01-31T13:07:16 WARN Rate limit approaching threshold\\n2023-01-31T13:07:16 ERROR ERROR_CONNECTION_REFUSED: Rate limit exceeded\\n2023-01-31T13:07:18 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='grateful', previous_tickets=9, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 2, 1, 7, 55, 52, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['created_workaround', 'contacted_customer', 'updated_documentation'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=False, tags=['api', 'security', 'configuration', 'database', 'performance'], environment='staging', business_impact='critical', affected_users=719, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000911', created_at=datetime.datetime(2023, 1, 22, 2, 39, 11, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 24, 17, 40, 59, tzinfo=datetime.timezone.utc), customer_id='CUST-04121', customer_tier='professional', organization_id='ORG-434', product='DataSync Pro', product_version='4.7.2', product_module='sync_engine', category='Data Issue', subcategory='Validation', priority='medium', severity='P4', channel='slack', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_DEADLOCK appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-01-22T02:39:11 DEBUG Processing request ID-12345\\n2023-01-22T02:39:11 ERROR ERROR_DEADLOCK: Invalid request format\\n2023-01-22T02:39:12 INFO Request rejected', stack_trace='at sync_engine.execute(sync_engine.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='neutral', previous_tickets=0, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 1, 24, 17, 40, 59, tzinfo=datetime.timezone.utc), agent_id='AGENT-046', agent_actions=['verified_resolution', 'contacted_customer', 'applied_fix'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['api', 'database', 'sync', 'configuration'], environment='test', business_impact='high', affected_users=30, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000912', created_at=datetime.datetime(2023, 2, 22, 14, 8, 27, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 22, 16, 42, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-03284', customer_tier='free', organization_id='ORG-359', product='DataSync Pro', product_version='3.2.3', product_module='scheduler', category='Feature Request', subcategory='Enhancement', priority='critical', severity='P0', channel='api', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=6, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 2, 22, 16, 42, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['verified_resolution', 'escalated_to_specialist'], escalated=True, transferred_count=1, satisfaction_score=1, resolution_helpful=False, tags=['database', 'data'], environment='development', business_impact='high', affected_users=559, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000913', created_at=datetime.datetime(2024, 8, 13, 23, 56, 12, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 14, 5, 1, 36, tzinfo=datetime.timezone.utc), customer_id='CUST-01421', customer_tier='starter', organization_id='ORG-386', product='CloudBackup Enterprise', product_version='4.0.10', product_module='backup_service', category='Account Management', subcategory='Upgrade', priority='high', severity='P1', channel='chat', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=9, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 8, 14, 5, 1, 36, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['viewed_logs', 'escalated_to_specialist', 'applied_fix'], escalated=True, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['configuration', 'database', 'error'], environment='test', business_impact='high', affected_users=229, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000914', created_at=datetime.datetime(2024, 3, 4, 12, 9, 55, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 4, 13, 41, 7, tzinfo=datetime.timezone.utc), customer_id='CUST-02160', customer_tier='professional', organization_id='ORG-354', product='StreamProcessor', product_version='4.8.10', product_module='event_handler', category='Technical Issue', subcategory='Compatibility', priority='high', severity='P1', channel='phone', subject='StreamProcessor throwing ERROR_INVALID_400 during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing ERROR_INVALID_400 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-03-04T12:09:55 WARN Rate limit approaching threshold\\n2024-03-04T12:09:55 ERROR ERROR_INVALID_400: Rate limit exceeded\\n2024-03-04T12:09:57 INFO Backing off for 60 seconds', stack_trace='at event_handler.execute(event_handler.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='confused', previous_tickets=9, resolution='Applied hotfix version 3.2.2 to address the ERROR_INVALID_400. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 3, 4, 13, 41, 7, tzinfo=datetime.timezone.utc), agent_id='AGENT-009', agent_actions=['consulted_kb', 'created_workaround', 'escalated_to_specialist'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=False, tags=['error', 'database', 'bug', 'security'], environment='development', business_impact='high', affected_users=208, language='fr', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000915', created_at=datetime.datetime(2023, 7, 5, 13, 22, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 5, 19, 20, 15, tzinfo=datetime.timezone.utc), customer_id='CUST-02371', customer_tier='enterprise', organization_id='ORG-363', product='StreamProcessor', product_version='2.2.2', product_module='monitoring', category='Technical Issue', subcategory='Performance', priority='high', severity='P2', channel='slack', subject='StreamProcessor throwing errors during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=8, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 7, 5, 19, 20, 15, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['consulted_kb', 'verified_resolution', 'escalated_to_specialist', 'applied_fix', 'checked_config'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['database', 'authentication'], environment='development', business_impact='medium', affected_users=948, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000916', created_at=datetime.datetime(2024, 5, 19, 3, 23, 51, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 5, 19, 7, 1, 3, tzinfo=datetime.timezone.utc), customer_id='CUST-02210', customer_tier='professional', organization_id='ORG-252', product='StreamProcessor', product_version='3.0.9', product_module='event_handler', category='Security', subcategory='Authorization', priority='low', severity='P0', channel='email', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Getting ERROR_AUTH_401 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-05-19T03:23:51 ERROR ERROR_AUTH_401: Connection timeout after 30s\\n2024-05-19T03:23:52 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='satisfied', previous_tickets=3, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 5, 19, 7, 1, 3, tzinfo=datetime.timezone.utc), agent_id='AGENT-044', agent_actions=['updated_documentation', 'viewed_logs'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=False, tags=['data', 'api'], environment='development', business_impact='critical', affected_users=18, language='en', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000917', created_at=datetime.datetime(2024, 3, 7, 5, 39, 1, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 9, 14, 32, 25, tzinfo=datetime.timezone.utc), customer_id='CUST-04875', customer_tier='enterprise', organization_id='ORG-332', product='Analytics Dashboard', product_version='2.4.7', product_module='data_aggregator', category='Feature Request', subcategory='API', priority='critical', severity='P4', channel='api', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=6, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 3, 9, 14, 32, 25, tzinfo=datetime.timezone.utc), agent_id='AGENT-031', agent_actions=['created_workaround', 'updated_documentation', 'checked_config'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['integration', 'api'], environment='production', business_impact='high', affected_users=686, language='en', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000918', created_at=datetime.datetime(2024, 6, 24, 13, 4, 36, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 24, 14, 46, 36, tzinfo=datetime.timezone.utc), customer_id='CUST-01258', customer_tier='enterprise', organization_id='ORG-255', product='DataSync Pro', product_version='3.2.6', product_module='data_validator', category='Account Management', subcategory='Upgrade', priority='critical', severity='P0', channel='email', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-06-24T13:04:36 WARN Rate limit approaching threshold\\n2024-06-24T13:04:36 ERROR ERROR_MEMORY_OOM: Rate limit exceeded\\n2024-06-24T13:04:38 INFO Backing off for 60 seconds', stack_trace='at data_validator.execute(data_validator.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='angry', previous_tickets=0, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 6, 24, 14, 46, 36, tzinfo=datetime.timezone.utc), agent_id='AGENT-027', agent_actions=['created_workaround', 'applied_fix', 'consulted_kb'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['database', 'error'], environment='production', business_impact='critical', affected_users=501, language='fr', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000919', created_at=datetime.datetime(2024, 4, 9, 13, 25, 16, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 11, 17, 40, 52, tzinfo=datetime.timezone.utc), customer_id='CUST-03707', customer_tier='enterprise', organization_id='ORG-376', product='CloudBackup Enterprise', product_version='3.0.4', product_module='restore_module', category='Feature Request', subcategory='UI/UX', priority='low', severity='P4', channel='email', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=1, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 4, 11, 17, 40, 52, tzinfo=datetime.timezone.utc), agent_id='AGENT-015', agent_actions=['viewed_logs', 'contacted_customer'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['data', 'security', 'bug', 'database', 'authentication'], environment='sandbox', business_impact='medium', affected_users=15, language='pt', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000920', created_at=datetime.datetime(2024, 8, 28, 7, 45, 30, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 29, 23, 31, 6, tzinfo=datetime.timezone.utc), customer_id='CUST-04434', customer_tier='professional', organization_id='ORG-434', product='CloudBackup Enterprise', product_version='2.5.3', product_module='encryption_layer', category='Data Issue', subcategory='Validation', priority='high', severity='P4', channel='phone', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=0, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 8, 29, 23, 31, 6, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['contacted_customer', 'checked_config', 'ran_diagnostics', 'escalated_to_specialist'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['database', 'api', 'performance', 'data'], environment='staging', business_impact='critical', affected_users=530, language='en', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000921', created_at=datetime.datetime(2024, 7, 26, 16, 44, 42, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 30, 13, 9, 54, tzinfo=datetime.timezone.utc), customer_id='CUST-01480', customer_tier='starter', organization_id='ORG-143', product='DataSync Pro', product_version='3.4.8', product_module='data_validator', category='Feature Request', subcategory='Documentation', priority='high', severity='P4', channel='phone', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=3, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 7, 30, 13, 9, 54, tzinfo=datetime.timezone.utc), agent_id='AGENT-027', agent_actions=['updated_documentation', 'verified_resolution', 'checked_config'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['performance', 'api', 'integration'], environment='test', business_impact='critical', affected_users=71, language='it', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000922', created_at=datetime.datetime(2023, 11, 5, 0, 24, 3, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 5, 5, 38, 27, tzinfo=datetime.timezone.utc), customer_id='CUST-01035', customer_tier='free', organization_id='ORG-019', product='StreamProcessor', product_version='2.3.10', product_module='event_handler', category='Technical Issue', subcategory='Configuration', priority='high', severity='P1', channel='api', subject='StreamProcessor throwing ERROR_SSL_CERT during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing ERROR_SSL_CERT when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-11-05T00:24:03 WARN Rate limit approaching threshold\\n2023-11-05T00:24:03 ERROR ERROR_SSL_CERT: Rate limit exceeded\\n2023-11-05T00:24:05 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='frustrated', previous_tickets=2, resolution='Applied hotfix version 3.2.2 to address the ERROR_SSL_CERT. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 11, 5, 5, 38, 27, tzinfo=datetime.timezone.utc), agent_id='AGENT-021', agent_actions=['escalated_to_specialist', 'created_workaround'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['error', 'authentication', 'api', 'sync', 'security'], environment='staging', business_impact='critical', affected_users=131, language='ja', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000923', created_at=datetime.datetime(2023, 11, 26, 7, 26, 52, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 27, 6, 20, 16, tzinfo=datetime.timezone.utc), customer_id='CUST-01207', customer_tier='enterprise', organization_id='ORG-489', product='API Gateway', product_version='3.5.3', product_module='auth_service', category='Data Issue', subcategory='Validation', priority='low', severity='P2', channel='email', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_NOTFOUND_404 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-11-26T07:26:52 WARN Rate limit approaching threshold\\n2023-11-26T07:26:52 ERROR ERROR_NOTFOUND_404: Rate limit exceeded\\n2023-11-26T07:26:54 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='neutral', previous_tickets=2, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 11, 27, 6, 20, 16, tzinfo=datetime.timezone.utc), agent_id='AGENT-029', agent_actions=['ran_diagnostics', 'contacted_customer', 'viewed_logs', 'applied_fix', 'escalated_to_specialist'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['error', 'security', 'database', 'sync', 'performance'], environment='staging', business_impact='low', affected_users=41, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000924', created_at=datetime.datetime(2024, 10, 20, 0, 30, 53, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 20, 4, 3, 53, tzinfo=datetime.timezone.utc), customer_id='CUST-00549', customer_tier='premium', organization_id='ORG-024', product='CloudBackup Enterprise', product_version='3.2.3', product_module='encryption_layer', category='Feature Request', subcategory='UI/UX', priority='critical', severity='P2', channel='portal', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=0, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 10, 20, 4, 3, 53, tzinfo=datetime.timezone.utc), agent_id='AGENT-018', agent_actions=['updated_documentation', 'created_workaround'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['configuration', 'performance'], environment='sandbox', business_impact='critical', affected_users=340, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000925', created_at=datetime.datetime(2023, 2, 14, 1, 11, 46, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 14, 2, 58, 34, tzinfo=datetime.timezone.utc), customer_id='CUST-01207', customer_tier='enterprise', organization_id='ORG-489', product='Analytics Dashboard', product_version='3.3.14', product_module='visualization', category='Technical Issue', subcategory='Performance', priority='critical', severity='P0', channel='portal', subject='Analytics Dashboard throwing errors during operation', description=\"We're experiencing issues with Analytics Dashboard. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=1, resolution='Root cause identified as Performance issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 2, 14, 2, 58, 34, tzinfo=datetime.timezone.utc), agent_id='AGENT-048', agent_actions=['applied_fix', 'ran_diagnostics', 'created_workaround'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['database', 'bug'], environment='development', business_impact='medium', affected_users=90, language='fr', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000926', created_at=datetime.datetime(2023, 8, 5, 11, 17, 26, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 6, 23, 58, 50, tzinfo=datetime.timezone.utc), customer_id='CUST-02714', customer_tier='free', organization_id='ORG-070', product='DataSync Pro', product_version='2.9.12', product_module='data_validator', category='Security', subcategory='Authorization', priority='high', severity='P3', channel='chat', subject='Security concern with DataSync Pro authentication', description='We have concerns about the authentication mechanism in DataSync Pro. Getting ERROR_SSL_CERT errors. We need to ensure our system meets compliance requirements.', error_logs='2023-08-05T11:17:26 DEBUG Processing request ID-12345\\n2023-08-05T11:17:26 ERROR ERROR_SSL_CERT: Invalid request format\\n2023-08-05T11:17:27 INFO Request rejected', stack_trace='', customer_sentiment='grateful', previous_tickets=3, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 8, 6, 23, 58, 50, tzinfo=datetime.timezone.utc), agent_id='AGENT-012', agent_actions=['escalated_to_specialist', 'updated_documentation', 'viewed_logs'], escalated=True, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['bug', 'configuration', 'data', 'performance'], environment='sandbox', business_impact='high', affected_users=900, language='pt', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000927', created_at=datetime.datetime(2024, 4, 8, 12, 23, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 8, 14, 54, 53, tzinfo=datetime.timezone.utc), customer_id='CUST-01227', customer_tier='free', organization_id='ORG-061', product='API Gateway', product_version='2.6.4', product_module='cache_layer', category='Technical Issue', subcategory='Bug', priority='high', severity='P1', channel='api', subject='API Gateway throwing ERROR_CONFLICT_409 during operation', description=\"We're experiencing issues with API Gateway. The system is throwing ERROR_CONFLICT_409 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-04-08T12:23:41 WARN Rate limit approaching threshold\\n2024-04-08T12:23:41 ERROR ERROR_CONFLICT_409: Rate limit exceeded\\n2024-04-08T12:23:43 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'cache_layer.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='neutral', previous_tickets=0, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 4, 8, 14, 54, 53, tzinfo=datetime.timezone.utc), agent_id='AGENT-035', agent_actions=['verified_resolution', 'applied_fix', 'updated_documentation', 'escalated_to_specialist', 'created_workaround'], escalated=True, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['security', 'bug', 'authentication'], environment='sandbox', business_impact='critical', affected_users=268, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000928', created_at=datetime.datetime(2023, 11, 6, 19, 20, 24, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 7, 14, 15, tzinfo=datetime.timezone.utc), customer_id='CUST-03169', customer_tier='starter', organization_id='ORG-492', product='DataSync Pro', product_version='2.6.11', product_module='scheduler', category='Account Management', subcategory='Upgrade', priority='high', severity='P2', channel='api', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=9, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 11, 7, 14, 15, tzinfo=datetime.timezone.utc), agent_id='AGENT-026', agent_actions=['escalated_to_specialist', 'checked_config', 'verified_resolution', 'updated_documentation'], escalated=True, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['api', 'error', 'database', 'data'], environment='test', business_impact='medium', affected_users=282, language='it', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000929', created_at=datetime.datetime(2024, 4, 9, 18, 48, 32, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 10, 0, 39, 32, tzinfo=datetime.timezone.utc), customer_id='CUST-00657', customer_tier='professional', organization_id='ORG-371', product='API Gateway', product_version='3.6.15', product_module='rate_limiter', category='Data Issue', subcategory='Import/Export', priority='high', severity='P2', channel='email', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=2, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 4, 10, 0, 39, 32, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['consulted_kb', 'created_workaround', 'verified_resolution', 'applied_fix', 'escalated_to_specialist'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['error', 'integration'], environment='development', business_impact='low', affected_users=509, language='ja', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000930', created_at=datetime.datetime(2023, 10, 19, 14, 36, 10, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 19, 18, 56, 34, tzinfo=datetime.timezone.utc), customer_id='CUST-04639', customer_tier='premium', organization_id='ORG-290', product='Analytics Dashboard', product_version='3.7.12', product_module='report_builder', category='Feature Request', subcategory='UI/UX', priority='critical', severity='P1', channel='phone', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=3, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 10, 19, 18, 56, 34, tzinfo=datetime.timezone.utc), agent_id='AGENT-019', agent_actions=['applied_fix', 'escalated_to_specialist', 'viewed_logs'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['database', 'integration', 'error', 'security', 'authentication'], environment='development', business_impact='low', affected_users=77, language='it', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000931', created_at=datetime.datetime(2023, 12, 6, 21, 53, 46, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 7, 18, 29, 46, tzinfo=datetime.timezone.utc), customer_id='CUST-00714', customer_tier='free', organization_id='ORG-091', product='DataSync Pro', product_version='3.5.2', product_module='data_validator', category='Account Management', subcategory='License', priority='medium', severity='P3', channel='chat', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-12-06T21:53:46 ERROR ERROR_AUTH_401: Database connection lost\\n2023-12-06T21:53:47 INFO Attempting to reconnect...\\n2023-12-06T21:53:49 ERROR Connection failed', stack_trace='Stack trace:\\n  data_validator::processData() at data_validator.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='confused', previous_tickets=10, resolution='Root cause identified as License issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 12, 7, 18, 29, 46, tzinfo=datetime.timezone.utc), agent_id='AGENT-038', agent_actions=['viewed_logs', 'escalated_to_specialist', 'contacted_customer', 'ran_diagnostics', 'updated_documentation'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['security', 'api'], environment='sandbox', business_impact='critical', affected_users=13, language='fr', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000932', created_at=datetime.datetime(2024, 4, 5, 13, 14, 27, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 6, 0, 48, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-02508', customer_tier='enterprise', organization_id='ORG-472', product='Analytics Dashboard', product_version='2.4.2', product_module='export_module', category='Account Management', subcategory='Billing', priority='low', severity='P1', channel='email', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-04-05T13:14:27 ERROR ERROR_SERVER_500: Connection timeout after 30s\\n2024-04-05T13:14:28 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='frustrated', previous_tickets=0, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 4, 6, 0, 48, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-010', agent_actions=['updated_documentation', 'created_workaround', 'applied_fix'], escalated=True, transferred_count=1, satisfaction_score=1, resolution_helpful=False, tags=['timeout', 'api'], environment='staging', business_impact='medium', affected_users=27, language='en', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000933', created_at=datetime.datetime(2023, 4, 7, 8, 9, 30, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 8, 11, 54, 30, tzinfo=datetime.timezone.utc), customer_id='CUST-02026', customer_tier='professional', organization_id='ORG-202', product='API Gateway', product_version='2.2.9', product_module='cache_layer', category='Security', subcategory='Authentication', priority='medium', severity='P3', channel='email', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_AUTH_401 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-04-07T08:09:30 DEBUG Processing request ID-12345\\n2023-04-07T08:09:30 ERROR ERROR_AUTH_401: Invalid request format\\n2023-04-07T08:09:31 INFO Request rejected', stack_trace='at cache_layer.execute(cache_layer.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='satisfied', previous_tickets=6, resolution='Applied hotfix version 3.2.2 to address the ERROR_AUTH_401. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 4, 8, 11, 54, 30, tzinfo=datetime.timezone.utc), agent_id='AGENT-049', agent_actions=['verified_resolution', 'contacted_customer', 'ran_diagnostics', 'escalated_to_specialist'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['integration', 'security', 'performance', 'data'], environment='production', business_impact='low', affected_users=5, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000934', created_at=datetime.datetime(2024, 1, 8, 0, 2, 34, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 10, 3, 15, 46, tzinfo=datetime.timezone.utc), customer_id='CUST-03194', customer_tier='enterprise', organization_id='ORG-101', product='CloudBackup Enterprise', product_version='4.7.14', product_module='restore_module', category='Feature Request', subcategory='Documentation', priority='critical', severity='P4', channel='email', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-01-08T00:02:34 DEBUG Processing request ID-12345\\n2024-01-08T00:02:34 ERROR ERROR_SSL_CERT: Invalid request format\\n2024-01-08T00:02:35 INFO Request rejected', stack_trace='', customer_sentiment='neutral', previous_tickets=3, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 1, 10, 3, 15, 46, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['updated_documentation', 'viewed_logs', 'created_workaround'], escalated=False, transferred_count=1, satisfaction_score=1, resolution_helpful=False, tags=['error', 'bug', 'timeout', 'sync', 'configuration'], environment='development', business_impact='high', affected_users=758, language='fr', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000935', created_at=datetime.datetime(2023, 11, 25, 10, 44, 39, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 25, 22, 42, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-00448', customer_tier='free', organization_id='ORG-487', product='CloudBackup Enterprise', product_version='2.1.4', product_module='backup_service', category='Security', subcategory='Authorization', priority='critical', severity='P2', channel='chat', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Getting ERROR_SSL_CERT errors. We need to ensure our system meets compliance requirements.', error_logs='2023-11-25T10:44:39 ERROR ERROR_SSL_CERT: Database connection lost\\n2023-11-25T10:44:40 INFO Attempting to reconnect...\\n2023-11-25T10:44:42 ERROR Connection failed', stack_trace='ERROR: backup_service.service.ServiceException: Failed to process request\\n\\tat backup_service.handler.process(backup_service.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='satisfied', previous_tickets=5, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 11, 25, 22, 42, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-033', agent_actions=['checked_config', 'applied_fix'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=False, tags=['sync', 'performance'], environment='production', business_impact='critical', affected_users=715, language='de', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000936', created_at=datetime.datetime(2023, 6, 4, 4, 49, 6, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 6, 0, 17, 54, tzinfo=datetime.timezone.utc), customer_id='CUST-00642', customer_tier='starter', organization_id='ORG-437', product='CloudBackup Enterprise', product_version='4.6.3', product_module='backup_service', category='Feature Request', subcategory='API', priority='high', severity='P4', channel='chat', subject='Request: Add bulk operation support to CloudBackup Enterprise', description='We would like to request a feature for CloudBackup Enterprise that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-06-04T04:49:06 DEBUG Processing request ID-12345\\n2023-06-04T04:49:06 ERROR ERROR_RATELIMIT_429: Invalid request format\\n2023-06-04T04:49:07 INFO Request rejected', stack_trace='', customer_sentiment='satisfied', previous_tickets=9, resolution='Root cause identified as API issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 6, 6, 0, 17, 54, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['escalated_to_specialist', 'updated_documentation'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['performance', 'authentication', 'timeout'], environment='sandbox', business_impact='high', affected_users=404, language='it', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000937', created_at=datetime.datetime(2024, 9, 26, 7, 44, 8, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 27, 2, 30, 20, tzinfo=datetime.timezone.utc), customer_id='CUST-03419', customer_tier='enterprise', organization_id='ORG-375', product='CloudBackup Enterprise', product_version='3.1.13', product_module='restore_module', category='Security', subcategory='Authorization', priority='critical', severity='P3', channel='api', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Getting ERROR_SERVER_500 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-09-26T07:44:08 WARN Rate limit approaching threshold\\n2024-09-26T07:44:08 ERROR ERROR_SERVER_500: Rate limit exceeded\\n2024-09-26T07:44:10 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='angry', previous_tickets=8, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 9, 27, 2, 30, 20, tzinfo=datetime.timezone.utc), agent_id='AGENT-008', agent_actions=['consulted_kb', 'verified_resolution', 'applied_fix', 'created_workaround'], escalated=True, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['security', 'performance', 'authentication', 'bug', 'timeout'], environment='test', business_impact='medium', affected_users=70, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000938', created_at=datetime.datetime(2023, 3, 28, 17, 46, 47, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 29, 17, 47, 59, tzinfo=datetime.timezone.utc), customer_id='CUST-01833', customer_tier='free', organization_id='ORG-498', product='DataSync Pro', product_version='4.4.0', product_module='data_validator', category='Feature Request', subcategory='API', priority='medium', severity='P3', channel='portal', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-03-28T17:46:47 ERROR ERROR_NOTFOUND_404: Connection timeout after 30s\\n2023-03-28T17:46:48 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='frustrated', previous_tickets=6, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2023, 3, 29, 17, 47, 59, tzinfo=datetime.timezone.utc), agent_id='AGENT-015', agent_actions=['ran_diagnostics', 'updated_documentation', 'created_workaround'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['configuration', 'api', 'integration'], environment='development', business_impact='medium', affected_users=17, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000939', created_at=datetime.datetime(2024, 7, 11, 7, 6, 13, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 12, 21, 6, 49, tzinfo=datetime.timezone.utc), customer_id='CUST-00508', customer_tier='enterprise', organization_id='ORG-339', product='CloudBackup Enterprise', product_version='3.0.6', product_module='restore_module', category='Account Management', subcategory='Access Control', priority='low', severity='P2', channel='email', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-07-11T07:06:13 ERROR ERROR_AUTH_401: Connection timeout after 30s\\n2024-07-11T07:06:14 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='confused', previous_tickets=6, resolution='Applied hotfix version 3.2.2 to address the ERROR_AUTH_401. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 7, 12, 21, 6, 49, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['ran_diagnostics', 'updated_documentation'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['authentication', 'error', 'bug', 'timeout'], environment='staging', business_impact='high', affected_users=50, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000940', created_at=datetime.datetime(2024, 4, 14, 8, 25, 37, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 14, 18, 0, 25, tzinfo=datetime.timezone.utc), customer_id='CUST-03196', customer_tier='premium', organization_id='ORG-382', product='DataSync Pro', product_version='3.0.6', product_module='scheduler', category='Account Management', subcategory='Subscription', priority='low', severity='P1', channel='portal', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-04-14T08:25:37 WARN Rate limit approaching threshold\\n2024-04-14T08:25:37 ERROR ERROR_PARSING: Rate limit exceeded\\n2024-04-14T08:25:39 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='grateful', previous_tickets=1, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 4, 14, 18, 0, 25, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['applied_fix', 'contacted_customer', 'escalated_to_specialist', 'consulted_kb', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['sync', 'integration'], environment='production', business_impact='high', affected_users=49, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000941', created_at=datetime.datetime(2024, 7, 6, 10, 7, 35, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 6, 22, 53, 47, tzinfo=datetime.timezone.utc), customer_id='CUST-01072', customer_tier='free', organization_id='ORG-083', product='StreamProcessor', product_version='2.4.2', product_module='error_handler', category='Account Management', subcategory='Access Control', priority='high', severity='P2', channel='email', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-07-06T10:07:35 ERROR ERROR_TIMEOUT_429: Connection timeout after 30s\\n2024-07-06T10:07:36 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='confused', previous_tickets=9, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 7, 6, 22, 53, 47, tzinfo=datetime.timezone.utc), agent_id='AGENT-003', agent_actions=['escalated_to_specialist', 'viewed_logs', 'ran_diagnostics', 'updated_documentation'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['data', 'timeout', 'configuration', 'database'], environment='test', business_impact='medium', affected_users=457, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000942', created_at=datetime.datetime(2023, 10, 18, 9, 41, 41, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 20, 0, 55, 29, tzinfo=datetime.timezone.utc), customer_id='CUST-03921', customer_tier='free', organization_id='ORG-129', product='StreamProcessor', product_version='2.1.15', product_module='error_handler', category='Data Issue', subcategory='Corruption', priority='low', severity='P2', channel='email', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_INVALID_400 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-10-18T09:41:41 ERROR ERROR_INVALID_400: Connection timeout after 30s\\n2023-10-18T09:41:42 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='angry', previous_tickets=3, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 10, 20, 0, 55, 29, tzinfo=datetime.timezone.utc), agent_id='AGENT-010', agent_actions=['contacted_customer', 'verified_resolution', 'created_workaround', 'consulted_kb', 'viewed_logs', 'checked_config'], escalated=True, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['performance', 'sync', 'configuration', 'data'], environment='sandbox', business_impact='high', affected_users=23, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000943', created_at=datetime.datetime(2024, 6, 10, 21, 16, 58, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 11, 1, 51, 46, tzinfo=datetime.timezone.utc), customer_id='CUST-04150', customer_tier='starter', organization_id='ORG-369', product='StreamProcessor', product_version='3.7.11', product_module='batch_processor', category='Feature Request', subcategory='API', priority='low', severity='P1', channel='slack', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=4, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 6, 11, 1, 51, 46, tzinfo=datetime.timezone.utc), agent_id='AGENT-035', agent_actions=['ran_diagnostics', 'viewed_logs'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['database', 'integration', 'timeout'], environment='development', business_impact='critical', affected_users=49, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000944', created_at=datetime.datetime(2023, 1, 17, 0, 33, 58, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 1, 17, 1, 23, 46, tzinfo=datetime.timezone.utc), customer_id='CUST-04561', customer_tier='professional', organization_id='ORG-144', product='DataSync Pro', product_version='3.1.13', product_module='scheduler', category='Feature Request', subcategory='API', priority='high', severity='P0', channel='phone', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-01-17T00:33:58 WARN Rate limit approaching threshold\\n2023-01-17T00:33:58 ERROR ERROR_PERMISSION_403: Rate limit exceeded\\n2023-01-17T00:34:00 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'scheduler.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='angry', previous_tickets=1, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2023, 1, 17, 1, 23, 46, tzinfo=datetime.timezone.utc), agent_id='AGENT-026', agent_actions=['verified_resolution', 'viewed_logs', 'contacted_customer'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['authentication', 'configuration'], environment='test', business_impact='medium', affected_users=462, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000945', created_at=datetime.datetime(2024, 6, 5, 4, 39, 44, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 5, 12, 30, 8, tzinfo=datetime.timezone.utc), customer_id='CUST-04429', customer_tier='enterprise', organization_id='ORG-276', product='StreamProcessor', product_version='4.7.6', product_module='monitoring', category='Security', subcategory='Authorization', priority='low', severity='P1', channel='email', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='satisfied', previous_tickets=4, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 6, 5, 12, 30, 8, tzinfo=datetime.timezone.utc), agent_id='AGENT-024', agent_actions=['applied_fix', 'updated_documentation'], escalated=True, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['timeout', 'performance'], environment='staging', business_impact='low', affected_users=9, language='fr', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000946', created_at=datetime.datetime(2024, 9, 4, 23, 30, 5, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 5, 4, 39, 41, tzinfo=datetime.timezone.utc), customer_id='CUST-01047', customer_tier='starter', organization_id='ORG-234', product='API Gateway', product_version='2.7.11', product_module='cache_layer', category='Security', subcategory='Authorization', priority='medium', severity='P0', channel='chat', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=6, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 9, 5, 4, 39, 41, tzinfo=datetime.timezone.utc), agent_id='AGENT-010', agent_actions=['verified_resolution', 'consulted_kb', 'applied_fix'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['bug', 'data', 'database'], environment='staging', business_impact='critical', affected_users=26, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000947', created_at=datetime.datetime(2024, 12, 9, 5, 20, 21, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 9, 12, 5, 21, tzinfo=datetime.timezone.utc), customer_id='CUST-01343', customer_tier='professional', organization_id='ORG-385', product='StreamProcessor', product_version='3.4.6', product_module='event_handler', category='Data Issue', subcategory='Corruption', priority='high', severity='P1', channel='phone', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_SERVER_500 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-12-09T05:20:21 ERROR ERROR_SERVER_500: Connection timeout after 30s\\n2024-12-09T05:20:22 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='satisfied', previous_tickets=8, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 12, 9, 12, 5, 21, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['consulted_kb', 'ran_diagnostics', 'viewed_logs', 'verified_resolution', 'created_workaround'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['data', 'security', 'sync', 'timeout'], environment='test', business_impact='medium', affected_users=644, language='pt', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000948', created_at=datetime.datetime(2023, 12, 4, 10, 25, 54, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 5, 0, 47, 30, tzinfo=datetime.timezone.utc), customer_id='CUST-04526', customer_tier='premium', organization_id='ORG-488', product='API Gateway', product_version='4.3.2', product_module='rate_limiter', category='Security', subcategory='Vulnerability', priority='critical', severity='P3', channel='slack', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_CONFLICT_409 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-12-04T10:25:54 WARN Rate limit approaching threshold\\n2023-12-04T10:25:54 ERROR ERROR_CONFLICT_409: Rate limit exceeded\\n2023-12-04T10:25:56 INFO Backing off for 60 seconds', stack_trace='ERROR: rate_limiter.service.ServiceException: Failed to process request\\n\\tat rate_limiter.handler.process(rate_limiter.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='angry', previous_tickets=4, resolution='Applied hotfix version 3.2.2 to address the ERROR_CONFLICT_409. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 12, 5, 0, 47, 30, tzinfo=datetime.timezone.utc), agent_id='AGENT-034', agent_actions=['created_workaround', 'viewed_logs', 'verified_resolution'], escalated=False, transferred_count=1, satisfaction_score=2, resolution_helpful=False, tags=['data', 'sync', 'database'], environment='test', business_impact='low', affected_users=789, language='zh', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000949', created_at=datetime.datetime(2023, 3, 4, 2, 34, 5, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 4, 12, 34, 5, tzinfo=datetime.timezone.utc), customer_id='CUST-01564', customer_tier='starter', organization_id='ORG-071', product='CloudBackup Enterprise', product_version='4.2.6', product_module='backup_service', category='Security', subcategory='Authentication', priority='low', severity='P1', channel='chat', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Getting ERROR_CORRUPTION errors. We need to ensure our system meets compliance requirements.', error_logs='2023-03-04T02:34:05 DEBUG Processing request ID-12345\\n2023-03-04T02:34:05 ERROR ERROR_CORRUPTION: Invalid request format\\n2023-03-04T02:34:06 INFO Request rejected', stack_trace='at backup_service.execute(backup_service.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='neutral', previous_tickets=8, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 3, 4, 12, 34, 5, tzinfo=datetime.timezone.utc), agent_id='AGENT-010', agent_actions=['created_workaround', 'verified_resolution', 'consulted_kb', 'checked_config', 'viewed_logs'], escalated=True, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['bug', 'performance', 'sync', 'configuration', 'integration'], environment='sandbox', business_impact='low', affected_users=19, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000950', created_at=datetime.datetime(2024, 2, 28, 20, 8, 57, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 1, 23, 57, 33, tzinfo=datetime.timezone.utc), customer_id='CUST-04178', customer_tier='premium', organization_id='ORG-134', product='Analytics Dashboard', product_version='4.5.1', product_module='data_aggregator', category='Feature Request', subcategory='Enhancement', priority='low', severity='P3', channel='api', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-02-28T20:08:57 WARN Rate limit approaching threshold\\n2024-02-28T20:08:57 ERROR ERROR_CONNECTION_REFUSED: Rate limit exceeded\\n2024-02-28T20:08:59 INFO Backing off for 60 seconds', stack_trace='ERROR: data_aggregator.service.ServiceException: Failed to process request\\n\\tat data_aggregator.handler.process(data_aggregator.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='grateful', previous_tickets=3, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2024, 3, 1, 23, 57, 33, tzinfo=datetime.timezone.utc), agent_id='AGENT-021', agent_actions=['created_workaround', 'checked_config', 'viewed_logs', 'contacted_customer', 'consulted_kb', 'ran_diagnostics'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['timeout', 'api', 'configuration', 'security'], environment='staging', business_impact='medium', affected_users=50, language='zh', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000951', created_at=datetime.datetime(2023, 6, 13, 16, 0, 17, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 14, 23, 29, 41, tzinfo=datetime.timezone.utc), customer_id='CUST-00966', customer_tier='starter', organization_id='ORG-046', product='DataSync Pro', product_version='3.9.0', product_module='sync_engine', category='Technical Issue', subcategory='Compatibility', priority='low', severity='P3', channel='api', subject='DataSync Pro throwing ERROR_PERMISSION_403 during operation', description=\"We're experiencing issues with DataSync Pro. The system is throwing ERROR_PERMISSION_403 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-06-13T16:00:17 WARN Rate limit approaching threshold\\n2023-06-13T16:00:17 ERROR ERROR_PERMISSION_403: Rate limit exceeded\\n2023-06-13T16:00:19 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='frustrated', previous_tickets=8, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 6, 14, 23, 29, 41, tzinfo=datetime.timezone.utc), agent_id='AGENT-029', agent_actions=['escalated_to_specialist', 'contacted_customer', 'checked_config', 'applied_fix', 'viewed_logs'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['security', 'integration', 'performance', 'data'], environment='sandbox', business_impact='high', affected_users=18, language='pt', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000952', created_at=datetime.datetime(2023, 11, 21, 2, 52, 13, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 21, 12, 31, 49, tzinfo=datetime.timezone.utc), customer_id='CUST-00154', customer_tier='enterprise', organization_id='ORG-307', product='StreamProcessor', product_version='2.7.14', product_module='event_handler', category='Security', subcategory='Compliance', priority='critical', severity='P2', channel='slack', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Getting ERROR_SSL_CERT errors. We need to ensure our system meets compliance requirements.', error_logs='2023-11-21T02:52:13 DEBUG Processing request ID-12345\\n2023-11-21T02:52:13 ERROR ERROR_SSL_CERT: Invalid request format\\n2023-11-21T02:52:14 INFO Request rejected', stack_trace='', customer_sentiment='satisfied', previous_tickets=2, resolution='Applied hotfix version 3.2.2 to address the ERROR_SSL_CERT. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 11, 21, 12, 31, 49, tzinfo=datetime.timezone.utc), agent_id='AGENT-035', agent_actions=['updated_documentation', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['database', 'timeout', 'integration', 'authentication'], environment='staging', business_impact='medium', affected_users=109, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000953', created_at=datetime.datetime(2024, 12, 27, 16, 49, 23, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 27, 19, 34, 23, tzinfo=datetime.timezone.utc), customer_id='CUST-04600', customer_tier='professional', organization_id='ORG-183', product='StreamProcessor', product_version='3.0.14', product_module='batch_processor', category='Account Management', subcategory='Billing', priority='critical', severity='P1', channel='phone', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-12-27T16:49:23 WARN Rate limit approaching threshold\\n2024-12-27T16:49:23 ERROR ERROR_SSL_CERT: Rate limit exceeded\\n2024-12-27T16:49:25 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='neutral', previous_tickets=6, resolution='Root cause identified as Billing issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 12, 27, 19, 34, 23, tzinfo=datetime.timezone.utc), agent_id='AGENT-005', agent_actions=['contacted_customer', 'escalated_to_specialist', 'checked_config', 'ran_diagnostics', 'viewed_logs', 'consulted_kb'], escalated=True, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['bug', 'configuration', 'timeout', 'authentication'], environment='production', business_impact='medium', affected_users=345, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000954', created_at=datetime.datetime(2023, 2, 3, 8, 54, 2, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 3, 23, 49, 50, tzinfo=datetime.timezone.utc), customer_id='CUST-02453', customer_tier='starter', organization_id='ORG-128', product='Analytics Dashboard', product_version='2.6.12', product_module='visualization', category='Security', subcategory='Authentication', priority='critical', severity='P3', channel='slack', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_RATELIMIT_429 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-02-03T08:54:02 DEBUG Processing request ID-12345\\n2023-02-03T08:54:02 ERROR ERROR_RATELIMIT_429: Invalid request format\\n2023-02-03T08:54:03 INFO Request rejected', stack_trace='', customer_sentiment='grateful', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 2, 3, 23, 49, 50, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['updated_documentation', 'consulted_kb'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['integration', 'bug', 'security'], environment='staging', business_impact='high', affected_users=935, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000955', created_at=datetime.datetime(2023, 11, 27, 20, 5, 44, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 28, 5, 39, 56, tzinfo=datetime.timezone.utc), customer_id='CUST-00850', customer_tier='professional', organization_id='ORG-152', product='StreamProcessor', product_version='2.5.9', product_module='monitoring', category='Security', subcategory='Authentication', priority='high', severity='P2', channel='chat', subject='Security concern with StreamProcessor authentication', description='We have concerns about the authentication mechanism in StreamProcessor. Getting ERROR_PERMISSION_403 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-11-27T20:05:44 WARN Rate limit approaching threshold\\n2023-11-27T20:05:44 ERROR ERROR_PERMISSION_403: Rate limit exceeded\\n2023-11-27T20:05:46 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='confused', previous_tickets=7, resolution='Root cause identified as Authentication issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 11, 28, 5, 39, 56, tzinfo=datetime.timezone.utc), agent_id='AGENT-015', agent_actions=['escalated_to_specialist', 'consulted_kb', 'applied_fix', 'ran_diagnostics'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['integration', 'database', 'error', 'api', 'sync'], environment='production', business_impact='medium', affected_users=583, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000956', created_at=datetime.datetime(2024, 1, 12, 16, 34, 7, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 12, 22, 12, 31, tzinfo=datetime.timezone.utc), customer_id='CUST-03366', customer_tier='free', organization_id='ORG-416', product='API Gateway', product_version='3.4.15', product_module='auth_service', category='Security', subcategory='Authentication', priority='high', severity='P2', channel='phone', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Users are experiencing login issues. We need to ensure our system meets compliance requirements.', error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=4, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 1, 12, 22, 12, 31, tzinfo=datetime.timezone.utc), agent_id='AGENT-035', agent_actions=['applied_fix', 'updated_documentation'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['database', 'bug', 'api'], environment='test', business_impact='medium', affected_users=535, language='pt', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000957', created_at=datetime.datetime(2023, 3, 19, 10, 57, 9, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 3, 20, 2, 30, 45, tzinfo=datetime.timezone.utc), customer_id='CUST-00943', customer_tier='enterprise', organization_id='ORG-123', product='StreamProcessor', product_version='4.2.5', product_module='error_handler', category='Account Management', subcategory='Upgrade', priority='medium', severity='P3', channel='slack', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=9, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 3, 20, 2, 30, 45, tzinfo=datetime.timezone.utc), agent_id='AGENT-007', agent_actions=['viewed_logs', 'checked_config'], escalated=False, transferred_count=3, satisfaction_score=5, resolution_helpful=True, tags=['data', 'error', 'api'], environment='development', business_impact='high', affected_users=18, language='it', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000958', created_at=datetime.datetime(2023, 10, 9, 3, 57, 47, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 10, 9, 6, 24, 47, tzinfo=datetime.timezone.utc), customer_id='CUST-02997', customer_tier='professional', organization_id='ORG-281', product='Analytics Dashboard', product_version='4.1.9', product_module='report_builder', category='Data Issue', subcategory='Corruption', priority='medium', severity='P0', channel='api', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=5, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 10, 9, 6, 24, 47, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['applied_fix', 'viewed_logs', 'escalated_to_specialist', 'updated_documentation'], escalated=False, transferred_count=2, satisfaction_score=1, resolution_helpful=False, tags=['timeout', 'api', 'error'], environment='development', business_impact='medium', affected_users=33, language='en', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000959', created_at=datetime.datetime(2023, 9, 14, 9, 5, 29, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 14, 13, 15, 5, tzinfo=datetime.timezone.utc), customer_id='CUST-01387', customer_tier='free', organization_id='ORG-014', product='Analytics Dashboard', product_version='2.6.5', product_module='visualization', category='Security', subcategory='Authorization', priority='high', severity='P0', channel='slack', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_RATELIMIT_429 errors. We need to ensure our system meets compliance requirements.', error_logs='2023-09-14T09:05:29 ERROR ERROR_RATELIMIT_429: Database connection lost\\n2023-09-14T09:05:30 INFO Attempting to reconnect...\\n2023-09-14T09:05:32 ERROR Connection failed', stack_trace=\"Traceback (most recent call last):\\n  File 'visualization.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='frustrated', previous_tickets=2, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 9, 14, 13, 15, 5, tzinfo=datetime.timezone.utc), agent_id='AGENT-027', agent_actions=['applied_fix', 'escalated_to_specialist', 'consulted_kb'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['database', 'api'], environment='development', business_impact='medium', affected_users=605, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000960', created_at=datetime.datetime(2024, 7, 3, 4, 51, 36, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 4, 15, 51, tzinfo=datetime.timezone.utc), customer_id='CUST-01591', customer_tier='professional', organization_id='ORG-171', product='Analytics Dashboard', product_version='3.5.4', product_module='export_module', category='Feature Request', subcategory='Documentation', priority='medium', severity='P3', channel='slack', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=1, resolution='Root cause identified as Documentation issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 7, 4, 15, 51, tzinfo=datetime.timezone.utc), agent_id='AGENT-019', agent_actions=['applied_fix', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'data', 'timeout', 'authentication', 'error'], environment='test', business_impact='low', affected_users=9, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000961', created_at=datetime.datetime(2024, 9, 15, 14, 21, 23, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 16, 8, 10, 35, tzinfo=datetime.timezone.utc), customer_id='CUST-01449', customer_tier='premium', organization_id='ORG-090', product='CloudBackup Enterprise', product_version='3.3.15', product_module='compression_engine', category='Data Issue', subcategory='Corruption', priority='critical', severity='P4', channel='slack', subject='Data inconsistency in CloudBackup Enterprise', description=\"We've noticed data inconsistencies in CloudBackup Enterprise. Some records are showing different values when accessed through different interfaces. Error code ERROR_SERVER_500 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-09-15T14:21:23 ERROR ERROR_SERVER_500: Connection timeout after 30s\\n2024-09-15T14:21:24 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='grateful', previous_tickets=3, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 9, 16, 8, 10, 35, tzinfo=datetime.timezone.utc), agent_id='AGENT-048', agent_actions=['viewed_logs', 'escalated_to_specialist', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=False, tags=['timeout', 'error', 'performance'], environment='staging', business_impact='low', affected_users=186, language='ja', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000962', created_at=datetime.datetime(2024, 4, 4, 22, 32, 1, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 5, 23, 38, 1, tzinfo=datetime.timezone.utc), customer_id='CUST-03613', customer_tier='free', organization_id='ORG-442', product='CloudBackup Enterprise', product_version='2.7.2', product_module='compression_engine', category='Technical Issue', subcategory='Integration', priority='critical', severity='P3', channel='slack', subject='CloudBackup Enterprise throwing ERROR_AUTH_401 during operation', description=\"We're experiencing issues with CloudBackup Enterprise. The system is throwing ERROR_AUTH_401 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-04-04T22:32:01 ERROR ERROR_AUTH_401: Connection timeout after 30s\\n2024-04-04T22:32:02 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'compression_engine.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='angry', previous_tickets=0, resolution='Applied hotfix version 3.2.2 to address the ERROR_AUTH_401. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 4, 5, 23, 38, 1, tzinfo=datetime.timezone.utc), agent_id='AGENT-010', agent_actions=['checked_config', 'escalated_to_specialist', 'created_workaround', 'consulted_kb', 'viewed_logs', 'ran_diagnostics'], escalated=True, transferred_count=2, satisfaction_score=2, resolution_helpful=False, tags=['security', 'data', 'configuration'], environment='test', business_impact='low', affected_users=663, language='ja', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000963', created_at=datetime.datetime(2023, 7, 14, 5, 19, 49, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 7, 14, 8, 31, 49, tzinfo=datetime.timezone.utc), customer_id='CUST-03793', customer_tier='starter', organization_id='ORG-010', product='StreamProcessor', product_version='4.7.3', product_module='error_handler', category='Data Issue', subcategory='Import/Export', priority='low', severity='P1', channel='email', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=10, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 7, 14, 8, 31, 49, tzinfo=datetime.timezone.utc), agent_id='AGENT-006', agent_actions=['contacted_customer', 'verified_resolution'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=False, tags=['integration', 'configuration'], environment='test', business_impact='medium', affected_users=33, language='it', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000964', created_at=datetime.datetime(2023, 8, 14, 19, 3, 59, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 15, 16, 17, 11, tzinfo=datetime.timezone.utc), customer_id='CUST-00339', customer_tier='premium', organization_id='ORG-082', product='API Gateway', product_version='3.8.12', product_module='rate_limiter', category='Data Issue', subcategory='Sync Error', priority='critical', severity='P4', channel='portal', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_PERMISSION_403 appears in logs. This is causing reporting issues for our management team.\", error_logs='2023-08-14T19:03:59 WARN Rate limit approaching threshold\\n2023-08-14T19:03:59 ERROR ERROR_PERMISSION_403: Rate limit exceeded\\n2023-08-14T19:04:01 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='grateful', previous_tickets=3, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 8, 15, 16, 17, 11, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['applied_fix', 'consulted_kb'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['performance', 'sync'], environment='development', business_impact='high', affected_users=800, language='de', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000965', created_at=datetime.datetime(2024, 1, 28, 2, 46, 19, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 28, 4, 44, 31, tzinfo=datetime.timezone.utc), customer_id='CUST-00263', customer_tier='enterprise', organization_id='ORG-352', product='API Gateway', product_version='2.4.11', product_module='cache_layer', category='Security', subcategory='Compliance', priority='critical', severity='P0', channel='chat', subject='Security concern with API Gateway authentication', description='We have concerns about the authentication mechanism in API Gateway. Getting ERROR_PARSING errors. We need to ensure our system meets compliance requirements.', error_logs='2024-01-28T02:46:19 DEBUG Processing request ID-12345\\n2024-01-28T02:46:19 ERROR ERROR_PARSING: Invalid request format\\n2024-01-28T02:46:20 INFO Request rejected', stack_trace='Stack trace:\\n  cache_layer::processData() at cache_layer.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='neutral', previous_tickets=2, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2024, 1, 28, 4, 44, 31, tzinfo=datetime.timezone.utc), agent_id='AGENT-041', agent_actions=['viewed_logs', 'ran_diagnostics'], escalated=False, transferred_count=0, satisfaction_score=3, resolution_helpful=True, tags=['sync', 'bug', 'timeout', 'configuration'], environment='production', business_impact='low', affected_users=885, language='fr', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000966', created_at=datetime.datetime(2024, 8, 3, 3, 22, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 8, 4, 5, 56, 14, tzinfo=datetime.timezone.utc), customer_id='CUST-03451', customer_tier='free', organization_id='ORG-471', product='Analytics Dashboard', product_version='2.7.10', product_module='report_builder', category='Feature Request', subcategory='API', priority='high', severity='P3', channel='chat', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-08-03T03:22:38 DEBUG Processing request ID-12345\\n2024-08-03T03:22:38 ERROR ERROR_MEMORY_OOM: Invalid request format\\n2024-08-03T03:22:39 INFO Request rejected', stack_trace='Stack trace:\\n  report_builder::processData() at report_builder.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='satisfied', previous_tickets=7, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 8, 4, 5, 56, 14, tzinfo=datetime.timezone.utc), agent_id='AGENT-010', agent_actions=['contacted_customer', 'applied_fix', 'checked_config'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['timeout', 'error', 'integration', 'database'], environment='test', business_impact='medium', affected_users=376, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000967', created_at=datetime.datetime(2024, 7, 14, 0, 29, 59, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 14, 2, 36, 35, tzinfo=datetime.timezone.utc), customer_id='CUST-04547', customer_tier='free', organization_id='ORG-480', product='API Gateway', product_version='3.4.6', product_module='cache_layer', category='Data Issue', subcategory='Sync Error', priority='critical', severity='P1', channel='api', subject='Data inconsistency in API Gateway', description=\"We've noticed data inconsistencies in API Gateway. Some records are showing different values when accessed through different interfaces. Error code ERROR_SERVER_500 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-07-14T00:29:59 DEBUG Processing request ID-12345\\n2024-07-14T00:29:59 ERROR ERROR_SERVER_500: Invalid request format\\n2024-07-14T00:30:00 INFO Request rejected', stack_trace='', customer_sentiment='frustrated', previous_tickets=7, resolution='Root cause identified as Sync Error issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 7, 14, 2, 36, 35, tzinfo=datetime.timezone.utc), agent_id='AGENT-018', agent_actions=['created_workaround', 'ran_diagnostics', 'verified_resolution'], escalated=False, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['timeout', 'security', 'performance', 'integration', 'sync'], environment='staging', business_impact='low', affected_users=319, language='zh', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000968', created_at=datetime.datetime(2024, 6, 19, 23, 21, 54, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 20, 0, 31, 30, tzinfo=datetime.timezone.utc), customer_id='CUST-04813', customer_tier='enterprise', organization_id='ORG-328', product='CloudBackup Enterprise', product_version='4.6.12', product_module='restore_module', category='Account Management', subcategory='License', priority='low', severity='P0', channel='api', subject='License upgrade needed for CloudBackup Enterprise', description='We need to upgrade our license for CloudBackup Enterprise. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-06-19T23:21:54 ERROR ERROR_TIMEOUT_429: Database connection lost\\n2024-06-19T23:21:55 INFO Attempting to reconnect...\\n2024-06-19T23:21:57 ERROR Connection failed', stack_trace='ERROR: restore_module.service.ServiceException: Failed to process request\\n\\tat restore_module.handler.process(restore_module.java:123)\\n\\tat core.dispatcher.dispatch(dispatcher.java:78)', customer_sentiment='confused', previous_tickets=2, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 6, 20, 0, 31, 30, tzinfo=datetime.timezone.utc), agent_id='AGENT-023', agent_actions=['contacted_customer', 'updated_documentation'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=True, tags=['timeout', 'bug', 'security', 'performance', 'integration'], environment='test', business_impact='low', affected_users=26, language='es', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000969', created_at=datetime.datetime(2024, 9, 20, 2, 19, 7, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 9, 21, 8, 47, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-03443', customer_tier='starter', organization_id='ORG-164', product='CloudBackup Enterprise', product_version='2.7.3', product_module='compression_engine', category='Security', subcategory='Vulnerability', priority='medium', severity='P4', channel='portal', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Getting ERROR_DISK_FULL errors. We need to ensure our system meets compliance requirements.', error_logs='2024-09-20T02:19:07 WARN Rate limit approaching threshold\\n2024-09-20T02:19:07 ERROR ERROR_DISK_FULL: Rate limit exceeded\\n2024-09-20T02:19:09 INFO Backing off for 60 seconds', stack_trace='', customer_sentiment='satisfied', previous_tickets=3, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2024, 9, 21, 8, 47, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['updated_documentation', 'escalated_to_specialist', 'applied_fix'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['api', 'integration', 'error', 'authentication'], environment='staging', business_impact='critical', affected_users=16, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000970', created_at=datetime.datetime(2023, 11, 6, 14, 31, 56, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 11, 7, 0, 39, 8, tzinfo=datetime.timezone.utc), customer_id='CUST-01915', customer_tier='free', organization_id='ORG-199', product='API Gateway', product_version='3.9.10', product_module='auth_service', category='Technical Issue', subcategory='Integration', priority='medium', severity='P2', channel='chat', subject='Performance degradation in API Gateway', description=\"The API Gateway has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_RATELIMIT_429 in the logs. This is affecting our entire team's productivity.\", error_logs='2023-11-06T14:31:56 ERROR ERROR_RATELIMIT_429: Database connection lost\\n2023-11-06T14:31:57 INFO Attempting to reconnect...\\n2023-11-06T14:31:59 ERROR Connection failed', stack_trace='', customer_sentiment='neutral', previous_tickets=10, resolution='Root cause identified as Integration issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 11, 7, 0, 39, 8, tzinfo=datetime.timezone.utc), agent_id='AGENT-010', agent_actions=['checked_config', 'contacted_customer', 'created_workaround', 'ran_diagnostics', 'viewed_logs', 'updated_documentation'], escalated=True, transferred_count=0, satisfaction_score=4, resolution_helpful=True, tags=['integration', 'error', 'database', 'bug'], environment='development', business_impact='low', affected_users=24, language='de', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000971', created_at=datetime.datetime(2024, 4, 1, 12, 47, 18, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 2, 12, 41, 18, tzinfo=datetime.timezone.utc), customer_id='CUST-00543', customer_tier='enterprise', organization_id='ORG-023', product='Analytics Dashboard', product_version='3.1.11', product_module='export_module', category='Feature Request', subcategory='Documentation', priority='high', severity='P4', channel='api', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=5, resolution='Root cause identified as Documentation issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 4, 2, 12, 41, 18, tzinfo=datetime.timezone.utc), agent_id='AGENT-022', agent_actions=['escalated_to_specialist', 'contacted_customer', 'viewed_logs'], escalated=True, transferred_count=3, satisfaction_score=3, resolution_helpful=False, tags=['integration', 'security'], environment='sandbox', business_impact='low', affected_users=593, language='de', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000972', created_at=datetime.datetime(2024, 4, 11, 13, 49, 46, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 4, 12, 22, 13, 10, tzinfo=datetime.timezone.utc), customer_id='CUST-00215', customer_tier='free', organization_id='ORG-159', product='DataSync Pro', product_version='4.3.15', product_module='scheduler', category='Feature Request', subcategory='New Feature', priority='critical', severity='P4', channel='phone', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-04-11T13:49:46 DEBUG Processing request ID-12345\\n2024-04-11T13:49:46 ERROR ERROR_NOTFOUND_404: Invalid request format\\n2024-04-11T13:49:47 INFO Request rejected', stack_trace='', customer_sentiment='frustrated', previous_tickets=4, resolution='Root cause identified as New Feature issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 4, 12, 22, 13, 10, tzinfo=datetime.timezone.utc), agent_id='AGENT-046', agent_actions=['contacted_customer', 'escalated_to_specialist', 'updated_documentation'], escalated=True, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['error', 'authentication'], environment='test', business_impact='high', affected_users=118, language='es', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000973', created_at=datetime.datetime(2023, 9, 30, 10, 36, 8, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 9, 30, 21, 9, 8, tzinfo=datetime.timezone.utc), customer_id='CUST-04455', customer_tier='enterprise', organization_id='ORG-487', product='DataSync Pro', product_version='2.3.7', product_module='data_validator', category='Data Issue', subcategory='Corruption', priority='critical', severity='P3', channel='api', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='confused', previous_tickets=4, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2023, 9, 30, 21, 9, 8, tzinfo=datetime.timezone.utc), agent_id='AGENT-033', agent_actions=['ran_diagnostics', 'contacted_customer', 'updated_documentation', 'applied_fix', 'escalated_to_specialist'], escalated=True, transferred_count=1, satisfaction_score=2, resolution_helpful=True, tags=['configuration', 'api', 'sync', 'database', 'authentication'], environment='development', business_impact='high', affected_users=706, language='de', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000974', created_at=datetime.datetime(2024, 3, 6, 4, 52, 28, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 6, 7, 35, 40, tzinfo=datetime.timezone.utc), customer_id='CUST-04830', customer_tier='professional', organization_id='ORG-009', product='Analytics Dashboard', product_version='2.3.6', product_module='visualization', category='Security', subcategory='Compliance', priority='critical', severity='P1', channel='phone', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_CORRUPTION errors. We need to ensure our system meets compliance requirements.', error_logs='2024-03-06T04:52:28 DEBUG Processing request ID-12345\\n2024-03-06T04:52:28 ERROR ERROR_CORRUPTION: Invalid request format\\n2024-03-06T04:52:29 INFO Request rejected', stack_trace='Stack trace:\\n  visualization::processData() at visualization.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='neutral', previous_tickets=4, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 3, 6, 7, 35, 40, tzinfo=datetime.timezone.utc), agent_id='AGENT-048', agent_actions=['applied_fix', 'ran_diagnostics', 'escalated_to_specialist'], escalated=True, transferred_count=3, satisfaction_score=3, resolution_helpful=False, tags=['timeout', 'configuration', 'error', 'api'], environment='test', business_impact='medium', affected_users=881, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000975', created_at=datetime.datetime(2024, 6, 22, 15, 43, 24, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 22, 19, 59, 36, tzinfo=datetime.timezone.utc), customer_id='CUST-02766', customer_tier='starter', organization_id='ORG-436', product='DataSync Pro', product_version='4.1.8', product_module='api_connector', category='Data Issue', subcategory='Corruption', priority='critical', severity='P1', channel='email', subject='Data inconsistency in DataSync Pro', description=\"We've noticed data inconsistencies in DataSync Pro. Some records are showing different values when accessed through different interfaces. Error code ERROR_SERVER_500 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-06-22T15:43:24 ERROR ERROR_SERVER_500: Connection timeout after 30s\\n2024-06-22T15:43:25 RETRY_FAILED: Max retries exceeded', stack_trace='at api_connector.execute(api_connector.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='neutral', previous_tickets=5, resolution='Applied hotfix version 3.2.2 to address the ERROR_SERVER_500. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 6, 22, 19, 59, 36, tzinfo=datetime.timezone.utc), agent_id='AGENT-032', agent_actions=['updated_documentation', 'created_workaround', 'viewed_logs'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=False, tags=['configuration', 'performance', 'api', 'error'], environment='test', business_impact='critical', affected_users=974, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000976', created_at=datetime.datetime(2024, 7, 3, 19, 46, 19, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 5, 3, 4, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-01764', customer_tier='professional', organization_id='ORG-429', product='StreamProcessor', product_version='3.4.6', product_module='monitoring', category='Feature Request', subcategory='Documentation', priority='low', severity='P2', channel='slack', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=8, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 7, 5, 3, 4, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-029', agent_actions=['applied_fix', 'consulted_kb'], escalated=False, transferred_count=2, satisfaction_score=3, resolution_helpful=False, tags=['integration', 'authentication'], environment='development', business_impact='medium', affected_users=7, language='pt', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000977', created_at=datetime.datetime(2023, 5, 31, 23, 53, 33, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 4, 1, 58, 21, tzinfo=datetime.timezone.utc), customer_id='CUST-03450', customer_tier='enterprise', organization_id='ORG-195', product='StreamProcessor', product_version='3.7.9', product_module='event_handler', category='Technical Issue', subcategory='Performance', priority='low', severity='P4', channel='slack', subject='StreamProcessor throwing errors during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=5, resolution='Applied hotfix version 3.2.2 to address the reported issue. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 6, 4, 1, 58, 21, tzinfo=datetime.timezone.utc), agent_id='AGENT-040', agent_actions=['contacted_customer', 'escalated_to_specialist', 'consulted_kb', 'checked_config'], escalated=True, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['bug', 'database', 'security'], environment='staging', business_impact='critical', affected_users=2, language='es', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000978', created_at=datetime.datetime(2024, 11, 8, 22, 35, 19, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 9, 11, 23, 55, tzinfo=datetime.timezone.utc), customer_id='CUST-04708', customer_tier='premium', organization_id='ORG-020', product='StreamProcessor', product_version='3.7.2', product_module='batch_processor', category='Technical Issue', subcategory='Integration', priority='critical', severity='P2', channel='email', subject='StreamProcessor throwing ERROR_PARSING during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing ERROR_PARSING when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-11-08T22:35:19 ERROR ERROR_PARSING: Database connection lost\\n2024-11-08T22:35:20 INFO Attempting to reconnect...\\n2024-11-08T22:35:22 ERROR Connection failed', stack_trace=\"Traceback (most recent call last):\\n  File 'batch_processor.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='angry', previous_tickets=8, resolution='Root cause identified as Integration issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2024, 11, 9, 11, 23, 55, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['verified_resolution', 'consulted_kb'], escalated=True, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['sync', 'api', 'data', 'configuration'], environment='development', business_impact='high', affected_users=644, language='zh', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000979', created_at=datetime.datetime(2023, 5, 18, 0, 43, 30, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 19, 1, 58, 30, tzinfo=datetime.timezone.utc), customer_id='CUST-01496', customer_tier='enterprise', organization_id='ORG-317', product='Analytics Dashboard', product_version='2.5.11', product_module='data_aggregator', category='Account Management', subcategory='Access Control', priority='high', severity='P4', channel='slack', subject='License upgrade needed for Analytics Dashboard', description='We need to upgrade our license for Analytics Dashboard. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2023-05-18T00:43:30 ERROR ERROR_NOTFOUND_404: Connection timeout after 30s\\n2023-05-18T00:43:31 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='confused', previous_tickets=4, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 5, 19, 1, 58, 30, tzinfo=datetime.timezone.utc), agent_id='AGENT-013', agent_actions=['applied_fix', 'created_workaround'], escalated=False, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['performance', 'api', 'error', 'authentication', 'database'], environment='sandbox', business_impact='critical', affected_users=610, language='it', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000980', created_at=datetime.datetime(2023, 4, 2, 9, 39, 19, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 2, 12, 20, 43, tzinfo=datetime.timezone.utc), customer_id='CUST-00928', customer_tier='professional', organization_id='ORG-304', product='Analytics Dashboard', product_version='3.1.4', product_module='report_builder', category='Technical Issue', subcategory='Compatibility', priority='low', severity='P1', channel='slack', subject='Performance degradation in Analytics Dashboard', description=\"The Analytics Dashboard has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_DEADLOCK in the logs. This is affecting our entire team's productivity.\", error_logs='2023-04-02T09:39:19 ERROR ERROR_DEADLOCK: Connection timeout after 30s\\n2023-04-02T09:39:20 RETRY_FAILED: Max retries exceeded', stack_trace=\"Traceback (most recent call last):\\n  File 'report_builder.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='neutral', previous_tickets=2, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DATA_REPAIR', resolved_at=datetime.datetime(2023, 4, 2, 12, 20, 43, tzinfo=datetime.timezone.utc), agent_id='AGENT-022', agent_actions=['viewed_logs', 'contacted_customer'], escalated=True, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['integration', 'configuration'], environment='development', business_impact='high', affected_users=13, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000981', created_at=datetime.datetime(2023, 6, 7, 2, 25, 1, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 6, 7, 11, 0, 25, tzinfo=datetime.timezone.utc), customer_id='CUST-02167', customer_tier='free', organization_id='ORG-384', product='Analytics Dashboard', product_version='3.2.3', product_module='export_module', category='Data Issue', subcategory='Data Loss', priority='high', severity='P2', channel='chat', subject='Data inconsistency in Analytics Dashboard', description=\"We've noticed data inconsistencies in Analytics Dashboard. Some records are showing different values when accessed through different interfaces.  This is causing reporting issues for our management team.\", error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=8, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='ESCALATED', resolved_at=datetime.datetime(2023, 6, 7, 11, 0, 25, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['created_workaround', 'consulted_kb'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['api', 'sync'], environment='development', business_impact='critical', affected_users=17, language='ja', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000982', created_at=datetime.datetime(2023, 8, 4, 0, 18, 19, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 4, 20, 19, 31, tzinfo=datetime.timezone.utc), customer_id='CUST-01555', customer_tier='professional', organization_id='ORG-141', product='StreamProcessor', product_version='3.6.10', product_module='batch_processor', category='Technical Issue', subcategory='Configuration', priority='medium', severity='P3', channel='slack', subject='StreamProcessor throwing ERROR_NOTFOUND_404 during operation', description=\"We're experiencing issues with StreamProcessor. The system is throwing ERROR_NOTFOUND_404 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-08-04T00:18:19 ERROR ERROR_NOTFOUND_404: Connection timeout after 30s\\n2023-08-04T00:18:20 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='confused', previous_tickets=4, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2023, 8, 4, 20, 19, 31, tzinfo=datetime.timezone.utc), agent_id='AGENT-004', agent_actions=['applied_fix', 'viewed_logs', 'checked_config'], escalated=False, transferred_count=2, satisfaction_score=4, resolution_helpful=True, tags=['api', 'database', 'bug'], environment='staging', business_impact='high', affected_users=2, language='ja', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000983', created_at=datetime.datetime(2023, 8, 16, 1, 19, 6, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 17, 23, 46, 42, tzinfo=datetime.timezone.utc), customer_id='CUST-04464', customer_tier='starter', organization_id='ORG-208', product='DataSync Pro', product_version='2.5.14', product_module='sync_engine', category='Feature Request', subcategory='Enhancement', priority='medium', severity='P4', channel='chat', subject='Request: Add bulk operation support to DataSync Pro', description='We would like to request a feature for DataSync Pro that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-08-16T01:19:06 ERROR ERROR_CONNECTION_REFUSED: Database connection lost\\n2023-08-16T01:19:07 INFO Attempting to reconnect...\\n2023-08-16T01:19:09 ERROR Connection failed', stack_trace='', customer_sentiment='confused', previous_tickets=1, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2023, 8, 17, 23, 46, 42, tzinfo=datetime.timezone.utc), agent_id='AGENT-014', agent_actions=['verified_resolution', 'updated_documentation', 'ran_diagnostics', 'viewed_logs'], escalated=True, transferred_count=0, satisfaction_score=5, resolution_helpful=True, tags=['database', 'configuration'], environment='sandbox', business_impact='medium', affected_users=29, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000984', created_at=datetime.datetime(2023, 4, 24, 11, 5, 31, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 4, 27, 6, 19, 19, tzinfo=datetime.timezone.utc), customer_id='CUST-02650', customer_tier='starter', organization_id='ORG-417', product='API Gateway', product_version='2.5.12', product_module='auth_service', category='Feature Request', subcategory='API', priority='low', severity='P3', channel='phone', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-04-24T11:05:31 DEBUG Processing request ID-12345\\n2023-04-24T11:05:31 ERROR ERROR_SSL_CERT: Invalid request format\\n2023-04-24T11:05:32 INFO Request rejected', stack_trace='Stack trace:\\n  auth_service::processData() at auth_service.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='satisfied', previous_tickets=8, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 4, 27, 6, 19, 19, tzinfo=datetime.timezone.utc), agent_id='AGENT-015', agent_actions=['ran_diagnostics', 'verified_resolution', 'contacted_customer', 'updated_documentation', 'consulted_kb'], escalated=True, transferred_count=1, satisfaction_score=5, resolution_helpful=True, tags=['configuration', 'security', 'sync'], environment='development', business_impact='critical', affected_users=21, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000985', created_at=datetime.datetime(2024, 12, 26, 0, 45, 59, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 12, 26, 14, 45, 23, tzinfo=datetime.timezone.utc), customer_id='CUST-04332', customer_tier='enterprise', organization_id='ORG-456', product='DataSync Pro', product_version='4.3.0', product_module='api_connector', category='Technical Issue', subcategory='Compatibility', priority='critical', severity='P3', channel='api', subject='Performance degradation in DataSync Pro', description=\"The DataSync Pro has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing timeout errors in the logs. This is affecting our entire team's productivity.\", error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=5, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='CONFIG_CHANGE', resolved_at=datetime.datetime(2024, 12, 26, 14, 45, 23, tzinfo=datetime.timezone.utc), agent_id='AGENT-039', agent_actions=['consulted_kb', 'escalated_to_specialist', 'viewed_logs', 'ran_diagnostics', 'applied_fix'], escalated=True, transferred_count=2, satisfaction_score=3, resolution_helpful=False, tags=['sync', 'bug'], environment='production', business_impact='medium', affected_users=132, language='de', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000986', created_at=datetime.datetime(2024, 7, 5, 10, 53, 42, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 9, 8, 18, 54, tzinfo=datetime.timezone.utc), customer_id='CUST-04814', customer_tier='premium', organization_id='ORG-216', product='DataSync Pro', product_version='2.0.12', product_module='scheduler', category='Technical Issue', subcategory='Bug', priority='low', severity='P3', channel='phone', subject='DataSync Pro throwing ERROR_CONFLICT_409 during operation', description=\"We're experiencing issues with DataSync Pro. The system is throwing ERROR_CONFLICT_409 when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2024-07-05T10:53:42 ERROR ERROR_CONFLICT_409: Database connection lost\\n2024-07-05T10:53:43 INFO Attempting to reconnect...\\n2024-07-05T10:53:45 ERROR Connection failed', stack_trace='Stack trace:\\n  scheduler::processData() at scheduler.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='satisfied', previous_tickets=9, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2024, 7, 9, 8, 18, 54, tzinfo=datetime.timezone.utc), agent_id='AGENT-018', agent_actions=['updated_documentation', 'escalated_to_specialist', 'created_workaround', 'checked_config'], escalated=False, transferred_count=3, satisfaction_score=2, resolution_helpful=False, tags=['data', 'api', 'configuration'], environment='development', business_impact='medium', affected_users=21, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000987', created_at=datetime.datetime(2024, 2, 29, 4, 25, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 1, 20, 14, 12, tzinfo=datetime.timezone.utc), customer_id='CUST-01485', customer_tier='free', organization_id='ORG-032', product='CloudBackup Enterprise', product_version='4.9.3', product_module='backup_service', category='Security', subcategory='Compliance', priority='low', severity='P2', channel='email', subject='Security concern with CloudBackup Enterprise authentication', description='We have concerns about the authentication mechanism in CloudBackup Enterprise. Getting ERROR_CONFLICT_409 errors. We need to ensure our system meets compliance requirements.', error_logs='2024-02-29T04:25:00 ERROR ERROR_CONFLICT_409: Connection timeout after 30s\\n2024-02-29T04:25:01 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='grateful', previous_tickets=5, resolution='Issue was due to incorrect API configuration. Updated endpoint URLs and authentication tokens. Verified connectivity and ran test transactions successfully.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 3, 1, 20, 14, 12, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['consulted_kb', 'escalated_to_specialist', 'verified_resolution'], escalated=False, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['data', 'configuration', 'database', 'sync', 'api'], environment='production', business_impact='high', affected_users=34, language='zh', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000988', created_at=datetime.datetime(2024, 1, 26, 5, 37, 30, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 26, 7, 49, 30, tzinfo=datetime.timezone.utc), customer_id='CUST-02543', customer_tier='premium', organization_id='ORG-329', product='Analytics Dashboard', product_version='3.8.15', product_module='report_builder', category='Feature Request', subcategory='Enhancement', priority='medium', severity='P0', channel='phone', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2024-01-26T05:37:30 ERROR ERROR_DISK_FULL: Database connection lost\\n2024-01-26T05:37:31 INFO Attempting to reconnect...\\n2024-01-26T05:37:33 ERROR Connection failed', stack_trace='', customer_sentiment='angry', previous_tickets=4, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='USER_EDUCATION', resolved_at=datetime.datetime(2024, 1, 26, 7, 49, 30, tzinfo=datetime.timezone.utc), agent_id='AGENT-043', agent_actions=['ran_diagnostics', 'verified_resolution', 'checked_config'], escalated=True, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['integration', 'timeout', 'bug'], environment='sandbox', business_impact='medium', affected_users=12, language='en', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000989', created_at=datetime.datetime(2024, 3, 6, 6, 19, 38, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 6, 10, 45, 26, tzinfo=datetime.timezone.utc), customer_id='CUST-00508', customer_tier='enterprise', organization_id='ORG-339', product='StreamProcessor', product_version='3.5.14', product_module='error_handler', category='Data Issue', subcategory='Validation', priority='low', severity='P0', channel='phone', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_TIMEOUT_429 appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-03-06T06:19:38 DEBUG Processing request ID-12345\\n2024-03-06T06:19:38 ERROR ERROR_TIMEOUT_429: Invalid request format\\n2024-03-06T06:19:39 INFO Request rejected', stack_trace='Stack trace:\\n  error_handler::processData() at error_handler.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='angry', previous_tickets=7, resolution='Applied hotfix version 3.2.2 to address the ERROR_TIMEOUT_429. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 3, 6, 10, 45, 26, tzinfo=datetime.timezone.utc), agent_id='AGENT-027', agent_actions=['applied_fix', 'checked_config'], escalated=False, transferred_count=0, satisfaction_score=2, resolution_helpful=False, tags=['security', 'performance', 'data', 'integration'], environment='sandbox', business_impact='high', affected_users=32, language='en', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000990', created_at=datetime.datetime(2024, 1, 25, 8, 4, 40, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 1, 28, 8, 3, 28, tzinfo=datetime.timezone.utc), customer_id='CUST-02720', customer_tier='free', organization_id='ORG-440', product='StreamProcessor', product_version='3.6.14', product_module='batch_processor', category='Account Management', subcategory='License', priority='medium', severity='P4', channel='email', subject='License upgrade needed for StreamProcessor', description='We need to upgrade our license for StreamProcessor. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='2024-01-25T08:04:40 WARN Rate limit approaching threshold\\n2024-01-25T08:04:40 ERROR ERROR_CORRUPTION: Rate limit exceeded\\n2024-01-25T08:04:42 INFO Backing off for 60 seconds', stack_trace=\"Traceback (most recent call last):\\n  File 'batch_processor.py', line 234, in process\\n    result = handler.execute(data)\\nException: Connection timeout\", customer_sentiment='grateful', previous_tickets=4, resolution='Issue resolved by updating configuration settings. Changed timeout values from 30s to 120s in config.yaml. Applied optimization patches to improve query performance. Customer confirmed the issue is now resolved.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 1, 28, 8, 3, 28, tzinfo=datetime.timezone.utc), agent_id='AGENT-002', agent_actions=['ran_diagnostics', 'checked_config'], escalated=False, transferred_count=2, satisfaction_score=5, resolution_helpful=True, tags=['timeout', 'api'], environment='test', business_impact='critical', affected_users=43, language='ja', region='EU'),\n",
       "  Ticket(ticket_id='TK-2024-000991', created_at=datetime.datetime(2023, 2, 25, 12, 42, 48, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 2, 26, 17, 20, 36, tzinfo=datetime.timezone.utc), customer_id='CUST-04293', customer_tier='enterprise', organization_id='ORG-299', product='Analytics Dashboard', product_version='2.0.10', product_module='report_builder', category='Technical Issue', subcategory='Bug', priority='high', severity='P3', channel='slack', subject='Analytics Dashboard throwing errors during operation', description=\"We're experiencing issues with Analytics Dashboard. The system is throwing errors when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='', stack_trace='', customer_sentiment='angry', previous_tickets=8, resolution='Database index corruption was causing the performance issue. Rebuilt indexes and optimized query execution plans. Performance is now back to normal levels.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2023, 2, 26, 17, 20, 36, tzinfo=datetime.timezone.utc), agent_id='AGENT-027', agent_actions=['consulted_kb', 'created_workaround', 'contacted_customer', 'viewed_logs', 'verified_resolution'], escalated=True, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['database', 'timeout'], environment='staging', business_impact='low', affected_users=624, language='de', region='APAC'),\n",
       "  Ticket(ticket_id='TK-2024-000992', created_at=datetime.datetime(2023, 8, 9, 16, 46, 42, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 9, 21, 16, 6, tzinfo=datetime.timezone.utc), customer_id='CUST-01612', customer_tier='professional', organization_id='ORG-155', product='StreamProcessor', product_version='2.8.4', product_module='event_handler', category='Feature Request', subcategory='New Feature', priority='critical', severity='P2', channel='email', subject='Request: Add bulk operation support to StreamProcessor', description='We would like to request a feature for StreamProcessor that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='frustrated', previous_tickets=6, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='PATCH_APPLIED', resolved_at=datetime.datetime(2023, 8, 9, 21, 16, 6, tzinfo=datetime.timezone.utc), agent_id='AGENT-028', agent_actions=['applied_fix', 'contacted_customer'], escalated=True, transferred_count=0, satisfaction_score=3, resolution_helpful=False, tags=['authentication', 'data'], environment='staging', business_impact='low', affected_users=440, language='pt', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000993', created_at=datetime.datetime(2024, 2, 16, 19, 31, 45, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 18, 1, 49, 9, tzinfo=datetime.timezone.utc), customer_id='CUST-00831', customer_tier='enterprise', organization_id='ORG-123', product='Analytics Dashboard', product_version='2.6.4', product_module='report_builder', category='Feature Request', subcategory='New Feature', priority='low', severity='P3', channel='phone', subject='Request: Add bulk operation support to Analytics Dashboard', description='We would like to request a feature for Analytics Dashboard that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='', stack_trace='', customer_sentiment='grateful', previous_tickets=1, resolution='Root cause identified as New Feature issue. Implemented workaround by adjusting system parameters. Long-term fix scheduled for next release. Provided customer with detailed documentation.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 2, 18, 1, 49, 9, tzinfo=datetime.timezone.utc), agent_id='AGENT-001', agent_actions=['viewed_logs', 'checked_config', 'verified_resolution', 'updated_documentation'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=False, tags=['authentication', 'sync'], environment='production', business_impact='low', affected_users=32, language='de', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000994', created_at=datetime.datetime(2024, 2, 25, 22, 26, 27, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 2, 26, 3, 3, 39, tzinfo=datetime.timezone.utc), customer_id='CUST-00281', customer_tier='enterprise', organization_id='ORG-154', product='StreamProcessor', product_version='2.0.0', product_module='batch_processor', category='Data Issue', subcategory='Data Loss', priority='high', severity='P1', channel='api', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_MEMORY_OOM appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-02-25T22:26:27 ERROR ERROR_MEMORY_OOM: Connection timeout after 30s\\n2024-02-25T22:26:28 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='grateful', previous_tickets=9, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='FEATURE_ADDED', resolved_at=datetime.datetime(2024, 2, 26, 3, 3, 39, tzinfo=datetime.timezone.utc), agent_id='AGENT-009', agent_actions=['checked_config', 'consulted_kb', 'updated_documentation'], escalated=False, transferred_count=3, satisfaction_score=4, resolution_helpful=True, tags=['performance', 'api', 'data', 'configuration'], environment='sandbox', business_impact='critical', affected_users=658, language='it', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000995', created_at=datetime.datetime(2023, 5, 21, 23, 32, 36, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 5, 22, 0, 43, 24, tzinfo=datetime.timezone.utc), customer_id='CUST-03253', customer_tier='enterprise', organization_id='ORG-026', product='API Gateway', product_version='2.0.0', product_module='rate_limiter', category='Technical Issue', subcategory='Bug', priority='critical', severity='P0', channel='chat', subject='API Gateway throwing ERROR_SSL_CERT during operation', description=\"We're experiencing issues with API Gateway. The system is throwing ERROR_SSL_CERT when trying to perform standard operations. This started happening after the recent update. We've tried restarting the service but the issue persists. Our team is blocked and unable to proceed with critical tasks.\", error_logs='2023-05-21T23:32:36 ERROR ERROR_SSL_CERT: Connection timeout after 30s\\n2023-05-21T23:32:37 RETRY_FAILED: Max retries exceeded', stack_trace='', customer_sentiment='satisfied', previous_tickets=3, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='RESTART_REQUIRED', resolved_at=datetime.datetime(2023, 5, 22, 0, 43, 24, tzinfo=datetime.timezone.utc), agent_id='AGENT-030', agent_actions=['escalated_to_specialist', 'contacted_customer'], escalated=True, transferred_count=0, satisfaction_score=5, resolution_helpful=False, tags=['security', 'integration'], environment='test', business_impact='critical', affected_users=310, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000996', created_at=datetime.datetime(2024, 6, 13, 9, 31, 13, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 6, 16, 4, 19, 49, tzinfo=datetime.timezone.utc), customer_id='CUST-00047', customer_tier='premium', organization_id='ORG-485', product='Analytics Dashboard', product_version='4.9.8', product_module='visualization', category='Security', subcategory='Compliance', priority='medium', severity='P4', channel='chat', subject='Security concern with Analytics Dashboard authentication', description='We have concerns about the authentication mechanism in Analytics Dashboard. Getting ERROR_VALIDATION errors. We need to ensure our system meets compliance requirements.', error_logs='2024-06-13T09:31:13 ERROR ERROR_VALIDATION: Database connection lost\\n2024-06-13T09:31:14 INFO Attempting to reconnect...\\n2024-06-13T09:31:16 ERROR Connection failed', stack_trace='', customer_sentiment='angry', previous_tickets=4, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='ENVIRONMENT_ISSUE', resolved_at=datetime.datetime(2024, 6, 16, 4, 19, 49, tzinfo=datetime.timezone.utc), agent_id='AGENT-037', agent_actions=['contacted_customer', 'consulted_kb', 'updated_documentation', 'escalated_to_specialist', 'ran_diagnostics', 'created_workaround'], escalated=False, transferred_count=1, satisfaction_score=3, resolution_helpful=True, tags=['integration', 'authentication', 'api'], environment='staging', business_impact='high', affected_users=23, language='zh', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-000997', created_at=datetime.datetime(2024, 7, 4, 9, 56, 13, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 7, 4, 12, 25, 1, tzinfo=datetime.timezone.utc), customer_id='CUST-01243', customer_tier='enterprise', organization_id='ORG-043', product='StreamProcessor', product_version='2.4.2', product_module='error_handler', category='Data Issue', subcategory='Validation', priority='high', severity='P1', channel='portal', subject='Data inconsistency in StreamProcessor', description=\"We've noticed data inconsistencies in StreamProcessor. Some records are showing different values when accessed through different interfaces. Error code ERROR_MEMORY_OOM appears in logs. This is causing reporting issues for our management team.\", error_logs='2024-07-04T09:56:13 WARN Rate limit approaching threshold\\n2024-07-04T09:56:13 ERROR ERROR_MEMORY_OOM: Rate limit exceeded\\n2024-07-04T09:56:15 INFO Backing off for 60 seconds', stack_trace='Stack trace:\\n  error_handler::processData() at error_handler.cpp:445\\n  Core::runTask() at core.cpp:234\\n  main() at main.cpp:67', customer_sentiment='angry', previous_tickets=6, resolution='Applied hotfix version 3.2.2 to address the ERROR_MEMORY_OOM. The fix includes improved error handling and retry logic. Monitored system for 24 hours to ensure stability.', resolution_code='WORKAROUND', resolved_at=datetime.datetime(2024, 7, 4, 12, 25, 1, tzinfo=datetime.timezone.utc), agent_id='AGENT-026', agent_actions=['contacted_customer', 'verified_resolution', 'checked_config', 'consulted_kb', 'applied_fix'], escalated=False, transferred_count=3, satisfaction_score=3, resolution_helpful=True, tags=['bug', 'authentication', 'error', 'sync', 'data'], environment='sandbox', business_impact='low', affected_users=95, language='fr', region='MEA'),\n",
       "  Ticket(ticket_id='TK-2024-000998', created_at=datetime.datetime(2023, 8, 2, 3, 15, 5, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 8, 2, 5, 49, 17, tzinfo=datetime.timezone.utc), customer_id='CUST-03608', customer_tier='free', organization_id='ORG-473', product='DataSync Pro', product_version='3.5.15', product_module='sync_engine', category='Account Management', subcategory='Subscription', priority='medium', severity='P0', channel='slack', subject='License upgrade needed for DataSync Pro', description='We need to upgrade our license for DataSync Pro. Our team has grown and we need additional seats. Please provide information on pricing and the upgrade process.', error_logs='', stack_trace='', customer_sentiment='neutral', previous_tickets=2, resolution='Network connectivity issue between services. Updated firewall rules and DNS configurations. Implemented health checks to prevent future occurrences.', resolution_code='WONT_FIX', resolved_at=datetime.datetime(2023, 8, 2, 5, 49, 17, tzinfo=datetime.timezone.utc), agent_id='AGENT-041', agent_actions=['created_workaround', 'checked_config'], escalated=False, transferred_count=0, satisfaction_score=1, resolution_helpful=False, tags=['database', 'integration', 'sync', 'performance', 'security'], environment='test', business_impact='high', affected_users=4, language='es', region='LATAM'),\n",
       "  Ticket(ticket_id='TK-2024-000999', created_at=datetime.datetime(2024, 11, 26, 10, 24, 32, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 11, 26, 12, 44, 20, tzinfo=datetime.timezone.utc), customer_id='CUST-04428', customer_tier='starter', organization_id='ORG-279', product='API Gateway', product_version='3.1.7', product_module='rate_limiter', category='Technical Issue', subcategory='Configuration', priority='high', severity='P0', channel='email', subject='Performance degradation in API Gateway', description=\"The API Gateway has been running extremely slowly for the past 2 days. Operations that usually take seconds are now taking minutes. We're seeing ERROR_SERVER_500 in the logs. This is affecting our entire team's productivity.\", error_logs='2024-11-26T10:24:32 DEBUG Processing request ID-12345\\n2024-11-26T10:24:32 ERROR ERROR_SERVER_500: Invalid request format\\n2024-11-26T10:24:33 INFO Request rejected', stack_trace='', customer_sentiment='neutral', previous_tickets=3, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='DUPLICATE', resolved_at=datetime.datetime(2024, 11, 26, 12, 44, 20, tzinfo=datetime.timezone.utc), agent_id='AGENT-001', agent_actions=['updated_documentation', 'verified_resolution', 'consulted_kb'], escalated=False, transferred_count=1, satisfaction_score=4, resolution_helpful=True, tags=['authentication', 'api', 'configuration'], environment='production', business_impact='critical', affected_users=745, language='es', region='NA'),\n",
       "  Ticket(ticket_id='TK-2024-001000', created_at=datetime.datetime(2023, 12, 24, 3, 49, 7, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2023, 12, 24, 7, 10, 7, tzinfo=datetime.timezone.utc), customer_id='CUST-00473', customer_tier='professional', organization_id='ORG-465', product='API Gateway', product_version='2.1.5', product_module='rate_limiter', category='Feature Request', subcategory='UI/UX', priority='medium', severity='P0', channel='chat', subject='Request: Add bulk operation support to API Gateway', description='We would like to request a feature for API Gateway that allows bulk operations. Currently, we have to process items one by one, which is time-consuming. Having bulk support would greatly improve our workflow efficiency.', error_logs='2023-12-24T03:49:07 ERROR ERROR_PARSING: Database connection lost\\n2023-12-24T03:49:08 INFO Attempting to reconnect...\\n2023-12-24T03:49:10 ERROR Connection failed', stack_trace='at rate_limiter.execute(rate_limiter.py:156)\\nat DataProcessor.run(processor.py:89)\\nat Main.handle(main.py:45)', customer_sentiment='angry', previous_tickets=1, resolution='Resolved by restarting services and clearing cache. The issue was caused by memory leak in version 3.2.1. Recommended upgrade to latest version which includes the fix.', resolution_code='BUG_FIX', resolved_at=datetime.datetime(2023, 12, 24, 7, 10, 7, tzinfo=datetime.timezone.utc), agent_id='AGENT-011', agent_actions=['verified_resolution', 'viewed_logs', 'updated_documentation', 'created_workaround', 'escalated_to_specialist'], escalated=True, transferred_count=3, satisfaction_score=1, resolution_helpful=False, tags=['integration', 'sync', 'api', 'database', 'configuration'], environment='sandbox', business_impact='medium', affected_users=34, language='fr', region='MEA'),\n",
       "  ...],\n",
       " [])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "adf15952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_tier</th>\n",
       "      <th>organization_id</th>\n",
       "      <th>product</th>\n",
       "      <th>product_version</th>\n",
       "      <th>product_module</th>\n",
       "      <th>category</th>\n",
       "      <th>...</th>\n",
       "      <th>escalated</th>\n",
       "      <th>transferred_count</th>\n",
       "      <th>satisfaction_score</th>\n",
       "      <th>resolution_helpful</th>\n",
       "      <th>tags</th>\n",
       "      <th>environment</th>\n",
       "      <th>business_impact</th>\n",
       "      <th>affected_users</th>\n",
       "      <th>language</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TK-2024-000001</td>\n",
       "      <td>2023-11-02 12:30:10+00:00</td>\n",
       "      <td>2023-11-02 15:30:46+00:00</td>\n",
       "      <td>CUST-02387</td>\n",
       "      <td>starter</td>\n",
       "      <td>ORG-234</td>\n",
       "      <td>CloudBackup Enterprise</td>\n",
       "      <td>4.5.10</td>\n",
       "      <td>encryption_layer</td>\n",
       "      <td>Feature Request</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>[error, api, integration, timeout, bug]</td>\n",
       "      <td>production</td>\n",
       "      <td>high</td>\n",
       "      <td>222</td>\n",
       "      <td>de</td>\n",
       "      <td>APAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TK-2024-000002</td>\n",
       "      <td>2023-02-10 16:31:31+00:00</td>\n",
       "      <td>2023-02-12 09:59:43+00:00</td>\n",
       "      <td>CUST-03724</td>\n",
       "      <td>free</td>\n",
       "      <td>ORG-435</td>\n",
       "      <td>DataSync Pro</td>\n",
       "      <td>4.1.11</td>\n",
       "      <td>data_validator</td>\n",
       "      <td>Account Management</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>[database, bug, authentication, data, error]</td>\n",
       "      <td>production</td>\n",
       "      <td>medium</td>\n",
       "      <td>18</td>\n",
       "      <td>ja</td>\n",
       "      <td>MEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TK-2024-000003</td>\n",
       "      <td>2024-09-30 07:43:47+00:00</td>\n",
       "      <td>2024-09-30 11:58:47+00:00</td>\n",
       "      <td>CUST-00600</td>\n",
       "      <td>enterprise</td>\n",
       "      <td>ORG-208</td>\n",
       "      <td>API Gateway</td>\n",
       "      <td>3.1.4</td>\n",
       "      <td>request_router</td>\n",
       "      <td>Feature Request</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>[configuration, error, sync, performance]</td>\n",
       "      <td>staging</td>\n",
       "      <td>medium</td>\n",
       "      <td>591</td>\n",
       "      <td>ja</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TK-2024-000004</td>\n",
       "      <td>2024-11-27 18:17:26+00:00</td>\n",
       "      <td>2024-11-30 22:07:50+00:00</td>\n",
       "      <td>CUST-04795</td>\n",
       "      <td>starter</td>\n",
       "      <td>ORG-231</td>\n",
       "      <td>CloudBackup Enterprise</td>\n",
       "      <td>3.4.15</td>\n",
       "      <td>backup_service</td>\n",
       "      <td>Account Management</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>[authentication, api, performance]</td>\n",
       "      <td>production</td>\n",
       "      <td>critical</td>\n",
       "      <td>34</td>\n",
       "      <td>en</td>\n",
       "      <td>LATAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TK-2024-000005</td>\n",
       "      <td>2024-03-09 15:41:02+00:00</td>\n",
       "      <td>2024-03-10 10:53:38+00:00</td>\n",
       "      <td>CUST-01101</td>\n",
       "      <td>starter</td>\n",
       "      <td>ORG-241</td>\n",
       "      <td>StreamProcessor</td>\n",
       "      <td>2.8.8</td>\n",
       "      <td>monitoring</td>\n",
       "      <td>Feature Request</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>[data, integration, security, authentication]</td>\n",
       "      <td>development</td>\n",
       "      <td>medium</td>\n",
       "      <td>325</td>\n",
       "      <td>de</td>\n",
       "      <td>MEA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ticket_id                created_at                updated_at  \\\n",
       "0  TK-2024-000001 2023-11-02 12:30:10+00:00 2023-11-02 15:30:46+00:00   \n",
       "1  TK-2024-000002 2023-02-10 16:31:31+00:00 2023-02-12 09:59:43+00:00   \n",
       "2  TK-2024-000003 2024-09-30 07:43:47+00:00 2024-09-30 11:58:47+00:00   \n",
       "3  TK-2024-000004 2024-11-27 18:17:26+00:00 2024-11-30 22:07:50+00:00   \n",
       "4  TK-2024-000005 2024-03-09 15:41:02+00:00 2024-03-10 10:53:38+00:00   \n",
       "\n",
       "  customer_id customer_tier organization_id                 product  \\\n",
       "0  CUST-02387       starter         ORG-234  CloudBackup Enterprise   \n",
       "1  CUST-03724          free         ORG-435            DataSync Pro   \n",
       "2  CUST-00600    enterprise         ORG-208             API Gateway   \n",
       "3  CUST-04795       starter         ORG-231  CloudBackup Enterprise   \n",
       "4  CUST-01101       starter         ORG-241         StreamProcessor   \n",
       "\n",
       "  product_version    product_module            category  ... escalated  \\\n",
       "0          4.5.10  encryption_layer     Feature Request  ...      True   \n",
       "1          4.1.11    data_validator  Account Management  ...      True   \n",
       "2           3.1.4    request_router     Feature Request  ...     False   \n",
       "3          3.4.15    backup_service  Account Management  ...     False   \n",
       "4           2.8.8        monitoring     Feature Request  ...     False   \n",
       "\n",
       "  transferred_count satisfaction_score resolution_helpful  \\\n",
       "0                 0                  4               True   \n",
       "1                 3                  4               True   \n",
       "2                 3                  4               True   \n",
       "3                 2                  3              False   \n",
       "4                 2                  5               True   \n",
       "\n",
       "                                            tags  environment business_impact  \\\n",
       "0        [error, api, integration, timeout, bug]   production            high   \n",
       "1   [database, bug, authentication, data, error]   production          medium   \n",
       "2      [configuration, error, sync, performance]      staging          medium   \n",
       "3             [authentication, api, performance]   production        critical   \n",
       "4  [data, integration, security, authentication]  development          medium   \n",
       "\n",
       "  affected_users language  region  \n",
       "0            222       de    APAC  \n",
       "1             18       ja     MEA  \n",
       "2            591       ja      NA  \n",
       "3             34       en   LATAM  \n",
       "4            325       de     MEA  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_data = pd.DataFrame([ticket.model_dump() for ticket in json_data[0]])\n",
    "df_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ec75e9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110000 entries, 0 to 109999\n",
      "Data columns (total 35 columns):\n",
      " #   Column              Non-Null Count   Dtype              \n",
      "---  ------              --------------   -----              \n",
      " 0   ticket_id           110000 non-null  object             \n",
      " 1   created_at          110000 non-null  datetime64[ns, UTC]\n",
      " 2   updated_at          110000 non-null  datetime64[ns, UTC]\n",
      " 3   customer_id         110000 non-null  object             \n",
      " 4   customer_tier       110000 non-null  object             \n",
      " 5   organization_id     110000 non-null  object             \n",
      " 6   product             110000 non-null  object             \n",
      " 7   product_version     110000 non-null  object             \n",
      " 8   product_module      110000 non-null  object             \n",
      " 9   category            110000 non-null  object             \n",
      " 10  subcategory         110000 non-null  object             \n",
      " 11  priority            110000 non-null  object             \n",
      " 12  severity            110000 non-null  object             \n",
      " 13  channel             110000 non-null  object             \n",
      " 14  subject             110000 non-null  object             \n",
      " 15  description         110000 non-null  object             \n",
      " 16  error_logs          110000 non-null  object             \n",
      " 17  stack_trace         110000 non-null  object             \n",
      " 18  customer_sentiment  110000 non-null  object             \n",
      " 19  previous_tickets    110000 non-null  int64              \n",
      " 20  resolution          110000 non-null  object             \n",
      " 21  resolution_code     110000 non-null  object             \n",
      " 22  resolved_at         110000 non-null  datetime64[ns, UTC]\n",
      " 23  agent_id            110000 non-null  object             \n",
      " 24  agent_actions       110000 non-null  object             \n",
      " 25  escalated           110000 non-null  bool               \n",
      " 26  transferred_count   110000 non-null  int64              \n",
      " 27  satisfaction_score  110000 non-null  int64              \n",
      " 28  resolution_helpful  110000 non-null  bool               \n",
      " 29  tags                110000 non-null  object             \n",
      " 30  environment         110000 non-null  object             \n",
      " 31  business_impact     110000 non-null  object             \n",
      " 32  affected_users      110000 non-null  int64              \n",
      " 33  language            110000 non-null  object             \n",
      " 34  region              110000 non-null  object             \n",
      "dtypes: bool(2), datetime64[ns, UTC](3), int64(4), object(26)\n",
      "memory usage: 27.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d1eeec2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Feature Request', 'Account Management', 'Security', 'Data Issue',\n",
       "       'Technical Issue'], dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "16688120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_tier</th>\n",
       "      <th>organization_id</th>\n",
       "      <th>product</th>\n",
       "      <th>product_version</th>\n",
       "      <th>product_module</th>\n",
       "      <th>category</th>\n",
       "      <th>...</th>\n",
       "      <th>escalated</th>\n",
       "      <th>transferred_count</th>\n",
       "      <th>satisfaction_score</th>\n",
       "      <th>resolution_helpful</th>\n",
       "      <th>tags</th>\n",
       "      <th>environment</th>\n",
       "      <th>business_impact</th>\n",
       "      <th>affected_users</th>\n",
       "      <th>language</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows  35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ticket_id, created_at, updated_at, customer_id, customer_tier, organization_id, product, product_version, product_module, category, subcategory, priority, severity, channel, subject, description, error_logs, stack_trace, customer_sentiment, previous_tickets, resolution, resolution_code, resolved_at, agent_id, agent_actions, escalated, transferred_count, satisfaction_score, resolution_helpful, tags, environment, business_impact, affected_users, language, region]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 35 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data[df_data['category'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "55e3c8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['subject'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4cc92f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['description'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dff42d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Security              22085\n",
       "Data Issue            22050\n",
       "Feature Request       22047\n",
       "Account Management    21997\n",
       "Technical Issue       21821\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "42c9569b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Documentation', 'Upgrade', 'New Feature', 'API', 'Compliance',\n",
       "       'Corruption', 'Enhancement', 'Sync Error', 'UI/UX',\n",
       "       'Import/Export', 'Bug', 'Access Control', 'Vulnerability',\n",
       "       'Authentication', 'Billing', 'Integration', 'Configuration',\n",
       "       'Performance', 'Encryption', 'License', 'Authorization',\n",
       "       'Compatibility', 'Subscription', 'Validation', 'Data Loss'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['subcategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d877bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "def prepare_classification_dataset(records: List[Dict[str, Any]]) -> Tuple[List[Dict[str, Any]], List[str]]:\n",
    "    data = []\n",
    "    for r in records:\n",
    "        if hasattr(r, \"model_dump\"):\n",
    "            r = r.model_dump()\n",
    "        elif not isinstance(r, dict):\n",
    "            r = dict(r)\n",
    "        \n",
    "        #text = f\"{r.get('subject','')} \\n {r.get('description','')} \\n {r.get('error_logs','')}\"\n",
    "        #text = f\"{r.get('subject','')} \\n  {r.get('error_logs','')}\"\n",
    "\n",
    "        data.append({\n",
    "            \"subject\": r.get(\"subject\", \"\"),\n",
    "            \"description\": r.get(\"description\", \"\"),\n",
    "            \"error_logs\": r.get(\"error_logs\", \"\"),\n",
    "            # a few easy metadata signals\n",
    "            \"product\": r.get(\"product\", \"\"),\n",
    "            \"product_module\": r.get(\"product_module\", \"\"),\n",
    "            \"priority\": r.get(\"priority\", \"\"),\n",
    "            \"channel\": r.get(\"channel\", \"\"),\n",
    "            \"customer_tier\": r.get(\"customer_tier\", \"\"),\n",
    "            \"region\": r.get(\"region\", \"\"),\n",
    "            \"category\": r.get(\"category\",\"\")\n",
    "        })\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "31deade5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>description</th>\n",
       "      <th>error_logs</th>\n",
       "      <th>product</th>\n",
       "      <th>product_module</th>\n",
       "      <th>priority</th>\n",
       "      <th>channel</th>\n",
       "      <th>customer_tier</th>\n",
       "      <th>region</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Request: Add bulk operation support to CloudBa...</td>\n",
       "      <td>We would like to request a feature for CloudBa...</td>\n",
       "      <td></td>\n",
       "      <td>CloudBackup Enterprise</td>\n",
       "      <td>encryption_layer</td>\n",
       "      <td>critical</td>\n",
       "      <td>portal</td>\n",
       "      <td>starter</td>\n",
       "      <td>APAC</td>\n",
       "      <td>Feature Request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>License upgrade needed for DataSync Pro</td>\n",
       "      <td>We need to upgrade our license for DataSync Pr...</td>\n",
       "      <td>2023-02-10T16:31:31 WARN Rate limit approachin...</td>\n",
       "      <td>DataSync Pro</td>\n",
       "      <td>data_validator</td>\n",
       "      <td>medium</td>\n",
       "      <td>chat</td>\n",
       "      <td>free</td>\n",
       "      <td>MEA</td>\n",
       "      <td>Account Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Request: Add bulk operation support to API Gat...</td>\n",
       "      <td>We would like to request a feature for API Gat...</td>\n",
       "      <td>2024-09-30T07:43:47 DEBUG Processing request I...</td>\n",
       "      <td>API Gateway</td>\n",
       "      <td>request_router</td>\n",
       "      <td>high</td>\n",
       "      <td>phone</td>\n",
       "      <td>enterprise</td>\n",
       "      <td>NA</td>\n",
       "      <td>Feature Request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>License upgrade needed for CloudBackup Enterprise</td>\n",
       "      <td>We need to upgrade our license for CloudBackup...</td>\n",
       "      <td>2024-11-27T18:17:26 ERROR ERROR_SERVER_500: Co...</td>\n",
       "      <td>CloudBackup Enterprise</td>\n",
       "      <td>backup_service</td>\n",
       "      <td>low</td>\n",
       "      <td>portal</td>\n",
       "      <td>starter</td>\n",
       "      <td>LATAM</td>\n",
       "      <td>Account Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Request: Add bulk operation support to StreamP...</td>\n",
       "      <td>We would like to request a feature for StreamP...</td>\n",
       "      <td>2024-03-09T15:41:02 ERROR ERROR_RATELIMIT_429:...</td>\n",
       "      <td>StreamProcessor</td>\n",
       "      <td>monitoring</td>\n",
       "      <td>high</td>\n",
       "      <td>slack</td>\n",
       "      <td>starter</td>\n",
       "      <td>MEA</td>\n",
       "      <td>Feature Request</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             subject  \\\n",
       "0  Request: Add bulk operation support to CloudBa...   \n",
       "1            License upgrade needed for DataSync Pro   \n",
       "2  Request: Add bulk operation support to API Gat...   \n",
       "3  License upgrade needed for CloudBackup Enterprise   \n",
       "4  Request: Add bulk operation support to StreamP...   \n",
       "\n",
       "                                         description  \\\n",
       "0  We would like to request a feature for CloudBa...   \n",
       "1  We need to upgrade our license for DataSync Pr...   \n",
       "2  We would like to request a feature for API Gat...   \n",
       "3  We need to upgrade our license for CloudBackup...   \n",
       "4  We would like to request a feature for StreamP...   \n",
       "\n",
       "                                          error_logs                 product  \\\n",
       "0                                                     CloudBackup Enterprise   \n",
       "1  2023-02-10T16:31:31 WARN Rate limit approachin...            DataSync Pro   \n",
       "2  2024-09-30T07:43:47 DEBUG Processing request I...             API Gateway   \n",
       "3  2024-11-27T18:17:26 ERROR ERROR_SERVER_500: Co...  CloudBackup Enterprise   \n",
       "4  2024-03-09T15:41:02 ERROR ERROR_RATELIMIT_429:...         StreamProcessor   \n",
       "\n",
       "     product_module  priority channel customer_tier region            category  \n",
       "0  encryption_layer  critical  portal       starter   APAC     Feature Request  \n",
       "1    data_validator    medium    chat          free    MEA  Account Management  \n",
       "2    request_router      high   phone    enterprise     NA     Feature Request  \n",
       "3    backup_service       low  portal       starter  LATAM  Account Management  \n",
       "4        monitoring      high   slack       starter    MEA     Feature Request  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_data= prepare_classification_dataset(json_data[0])\n",
    "classification_data = pd.DataFrame(classification_data)\n",
    "classification_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "248980ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_data = classification_data.drop_duplicates(['subject','description','error_logs'],keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "82ce3e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "df = classification_data.copy()\n",
    "df = df[:10000]\n",
    "# 1) Create a group id so duplicates are kept together\n",
    "#df[\"text_key\"] = (df[\"subject\"].fillna(\"\") + \" || \" + df[\"description\"].fillna(\"\")).astype(str)\n",
    "df[\"text_key\"] = (df[\"description\"].fillna(\"\")).astype(str)\n",
    "\n",
    "df[\"group_id\"] = pd.util.hash_pandas_object(df[\"text_key\"], index=False)\n",
    "df[\"text\"] = df[\"subject\"] + df[\"description\"] + df[\"error_logs\"]\n",
    "\n",
    "X = df.drop(columns=[\"category\",\"subject\",\"description\",\"error_logs\"]) \n",
    "y = df[\"category\"]\n",
    "groups = df[\"group_id\"]\n",
    "\n",
    "# 2) Split 70/30 by groups (no duplicate leakage)\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.30, random_state=42)\n",
    "train_idx, tmp_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "X_tmp, y_tmp  = X.iloc[tmp_idx], y.iloc[tmp_idx]\n",
    "groups_tmp = groups.iloc[tmp_idx]\n",
    "\n",
    "# 3) Split remaining 30 into 15/15 by groups\n",
    "gss2 = GroupShuffleSplit(n_splits=1, test_size=0.50, random_state=44)\n",
    "val_idx_rel, test_idx_rel = next(gss2.split(X_tmp, y_tmp, groups=groups_tmp))\n",
    "\n",
    "X_val, y_val = X_tmp.iloc[val_idx_rel], y_tmp.iloc[val_idx_rel]\n",
    "X_test, y_test = X_tmp.iloc[test_idx_rel], y_tmp.iloc[test_idx_rel]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dfd6b59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76944, 10)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "75d88a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in ['product', 'product_module', 'priority', 'channel',\n",
    "#        'customer_tier', 'region',]:\n",
    "#     print(f\"Unique categories in {col} feature: {classification_data[col].unique()}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a5fbae9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7376, 9)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b33b49d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split: train/val/test = 70/15/15 (via 70/30 then 50/50 of remaining)\n",
    "# X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
    "#     classification_data.drop('category',axis=1), classification_data['category'], test_size=0.30, random_state=42, stratify=classification_data['subject','description']\n",
    "# )\n",
    "# X_val, X_test, y_val, y_test = train_test_split(\n",
    "#     X_tmp, y_tmp, test_size=0.50, random_state=42, stratify=y_tmp\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ab3db930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>product_module</th>\n",
       "      <th>priority</th>\n",
       "      <th>channel</th>\n",
       "      <th>customer_tier</th>\n",
       "      <th>region</th>\n",
       "      <th>text_key</th>\n",
       "      <th>group_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DataSync Pro</td>\n",
       "      <td>data_validator</td>\n",
       "      <td>medium</td>\n",
       "      <td>chat</td>\n",
       "      <td>free</td>\n",
       "      <td>MEA</td>\n",
       "      <td>We need to upgrade our license for DataSync Pr...</td>\n",
       "      <td>9757097747101013450</td>\n",
       "      <td>License upgrade needed for DataSync ProWe need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>API Gateway</td>\n",
       "      <td>request_router</td>\n",
       "      <td>high</td>\n",
       "      <td>phone</td>\n",
       "      <td>enterprise</td>\n",
       "      <td>NA</td>\n",
       "      <td>We would like to request a feature for API Gat...</td>\n",
       "      <td>6757513138608122457</td>\n",
       "      <td>Request: Add bulk operation support to API Gat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CloudBackup Enterprise</td>\n",
       "      <td>backup_service</td>\n",
       "      <td>low</td>\n",
       "      <td>portal</td>\n",
       "      <td>starter</td>\n",
       "      <td>LATAM</td>\n",
       "      <td>We need to upgrade our license for CloudBackup...</td>\n",
       "      <td>9308935704265343520</td>\n",
       "      <td>License upgrade needed for CloudBackup Enterpr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>StreamProcessor</td>\n",
       "      <td>batch_processor</td>\n",
       "      <td>low</td>\n",
       "      <td>email</td>\n",
       "      <td>premium</td>\n",
       "      <td>NA</td>\n",
       "      <td>We have concerns about the authentication mech...</td>\n",
       "      <td>8505384652536865832</td>\n",
       "      <td>Security concern with StreamProcessor authenti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>API Gateway</td>\n",
       "      <td>cache_layer</td>\n",
       "      <td>critical</td>\n",
       "      <td>api</td>\n",
       "      <td>premium</td>\n",
       "      <td>NA</td>\n",
       "      <td>We would like to request a feature for API Gat...</td>\n",
       "      <td>6757513138608122457</td>\n",
       "      <td>Request: Add bulk operation support to API Gat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  product   product_module  priority channel customer_tier  \\\n",
       "1            DataSync Pro   data_validator    medium    chat          free   \n",
       "2             API Gateway   request_router      high   phone    enterprise   \n",
       "3  CloudBackup Enterprise   backup_service       low  portal       starter   \n",
       "5         StreamProcessor  batch_processor       low   email       premium   \n",
       "7             API Gateway      cache_layer  critical     api       premium   \n",
       "\n",
       "  region                                           text_key  \\\n",
       "1    MEA  We need to upgrade our license for DataSync Pr...   \n",
       "2     NA  We would like to request a feature for API Gat...   \n",
       "3  LATAM  We need to upgrade our license for CloudBackup...   \n",
       "5     NA  We have concerns about the authentication mech...   \n",
       "7     NA  We would like to request a feature for API Gat...   \n",
       "\n",
       "              group_id                                               text  \n",
       "1  9757097747101013450  License upgrade needed for DataSync ProWe need...  \n",
       "2  6757513138608122457  Request: Add bulk operation support to API Gat...  \n",
       "3  9308935704265343520  License upgrade needed for CloudBackup Enterpr...  \n",
       "5  8505384652536865832  Security concern with StreamProcessor authenti...  \n",
       "7  6757513138608122457  Request: Add bulk operation support to API Gat...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7d02e746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7376"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['text'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0cce7307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "TEXT_COL = \"text\"\n",
    "CAT_COLS = [\n",
    "    \"product\",\n",
    "    \"product_module\",\n",
    "    \"priority\",\n",
    "    \"channel\",\n",
    "    \"customer_tier\",\n",
    "    \"region\",\n",
    "]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"text\",\n",
    "            TfidfVectorizer(\n",
    "                max_features=80_000,\n",
    "                ngram_range=(1, 2),\n",
    "                min_df=2,\n",
    "            ),\n",
    "            TEXT_COL,   # pandas column name\n",
    "        ),\n",
    "        (\n",
    "            \"cat\",\n",
    "            OneHotEncoder(\n",
    "                handle_unknown=\"ignore\",\n",
    "                \n",
    "            ),\n",
    "            CAT_COLS,   # list of pandas columns\n",
    "        ),\n",
    "    ],\n",
    "    remainder=\"drop\"   # ignore other dataframe columns\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "94fb87ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_pipe = Pipeline([\n",
    "    (\"preprocess\", preprocess)\n",
    "])\n",
    "\n",
    "X_transformed = preprocess_pipe.fit_transform(X_train)\n",
    "X_val_transformed = preprocess_pipe.transform(X_val)\n",
    "X_test_transformed = preprocess_pipe.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a9b57d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7376, 9)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fff016e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3a537e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7376, 7684)\n"
     ]
    }
   ],
   "source": [
    "print(X_transformed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "509c3796",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess_pipe.get_feature_names_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "faa6433f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- VALIDATION ---\n",
      "Weighted F1: 1.0\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     Data Issue      1.000     1.000     1.000       369\n",
      "       Security      1.000     1.000     1.000       215\n",
      "Technical Issue      1.000     1.000     1.000       319\n",
      "\n",
      "       accuracy                          1.000       903\n",
      "      macro avg      1.000     1.000     1.000       903\n",
      "   weighted avg      1.000     1.000     1.000       903\n",
      "\n",
      "\n",
      "--- TEST ---\n",
      "Weighted F1: 1.0\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     Data Issue      1.000     1.000     1.000       205\n",
      "Feature Request      1.000     1.000     1.000       791\n",
      "       Security      1.000     1.000     1.000       425\n",
      "Technical Issue      1.000     1.000     1.000       300\n",
      "\n",
      "       accuracy                          1.000      1721\n",
      "      macro avg      1.000     1.000     1.000      1721\n",
      "   weighted avg      1.000     1.000     1.000      1721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistric_model = LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        n_jobs=None,          # keep portable across OS\n",
    "        class_weight=\"balanced\"  # helps if categories are imbalanced\n",
    "    )\n",
    "\n",
    "logistric_model.fit(X=X_transformed,y=y_train)\n",
    "# Validation\n",
    "val_pred = logistric_model.predict(X_val_transformed)\n",
    "val_f1 = f1_score(y_val, val_pred, average=\"weighted\")\n",
    "print(\"\\n--- VALIDATION ---\")\n",
    "print(\"Weighted F1:\", round(val_f1, 4))\n",
    "print(classification_report(y_val, val_pred, digits=3))\n",
    "\n",
    "# Test\n",
    "test_pred = logistric_model.predict(X_test_transformed)\n",
    "test_f1 = f1_score(y_test, test_pred, average=\"weighted\")\n",
    "print(\"\\n--- TEST ---\")\n",
    "print(\"Weighted F1:\", round(test_f1, 4))\n",
    "print(classification_report(y_test, test_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "68922384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "276d0bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(model: SentenceTransformer, texts: list[str], batch_size: int = 64) -> np.ndarray:\n",
    "\n",
    "\n",
    "    emb = model.encode(\n",
    "        texts,\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "           device='cpu'   # often improves downstream linear/tree models\n",
    "    )\n",
    "    return emb\n",
    "\n",
    "\n",
    "\n",
    "def encode_text_parallel(\n",
    "    model: SentenceTransformer,\n",
    "    texts: list[str],\n",
    "    batch_size: int = 256,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Encode texts in parallel using multiple CPU processes.\n",
    "\n",
    "    Notes:\n",
    "    - Uses all available CPU cores by default\n",
    "    - Much faster than single-process encode() on large datasets\n",
    "    \"\"\"\n",
    "\n",
    "    # Start multiprocessing pool\n",
    "    pool = model.start_multi_process_pool()\n",
    "\n",
    "    try:\n",
    "        emb = model.encode_multi_process(\n",
    "            texts,\n",
    "            pool,\n",
    "            batch_size=batch_size,\n",
    "            normalize_embeddings=True,\n",
    "            show_progress_bar=True,\n",
    "        )\n",
    "    finally:\n",
    "        # Always clean up processes\n",
    "        model.stop_multi_process_pool(pool)\n",
    "\n",
    "    return emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dae44d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|| 29/29 [02:03<00:00,  4.28s/it]\n",
      "Batches: 100%|| 15/15 [00:17<00:00,  1.14s/it]\n",
      "Batches: 100%|| 27/27 [00:30<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# --- label encoding ---\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_val_enc = le.transform(y_val)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "\n",
    "# --- text embeddings ---\n",
    "embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "X_train_text = encode_text(embedder, X_train[\"text\"].tolist(), batch_size=256)\n",
    "X_val_text   = encode_text(embedder, X_val[\"text\"].tolist(), batch_size=64)\n",
    "X_test_text  = encode_text(embedder, X_test[\"text\"].tolist(), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c11a528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dense embeddings to sparse so we can hstack with OneHot output\n",
    "X_train_text_sp = csr_matrix(X_train_text)\n",
    "X_val_text_sp   = csr_matrix(X_val_text)\n",
    "X_test_text_sp  = csr_matrix(X_test_text)\n",
    "\n",
    "# --- categorical one-hot ---\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "X_train_cat = ohe.fit_transform(X_train[CAT_COLS])\n",
    "X_val_cat   = ohe.transform(X_val[CAT_COLS])\n",
    "X_test_cat  = ohe.transform(X_test[CAT_COLS])\n",
    "\n",
    "# --- combine ---\n",
    "X_train_final = hstack([X_train_text_sp, X_train_cat], format=\"csr\")\n",
    "X_val_final   = hstack([X_val_text_sp,   X_val_cat],   format=\"csr\")\n",
    "X_test_final  = hstack([X_test_text_sp,  X_test_cat],  format=\"csr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cd47a9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.08, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None, num_class=5, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=objective,-typing.Union%5Bstr%2C%20xgboost.sklearn._SklObjWProto%2C%20typing.Callable%5B%5Btyping.Any%2C%20typing.Any%5D%2C%20typing.Tuple%5Bnumpy.ndarray%2C%20numpy.ndarray%5D%5D%2C%20NoneType%5D\">\n",
       "            objective\n",
       "            <span class=\"param-doc-description\">objective: typing.Union[str, xgboost.sklearn._SklObjWProto, typing.Callable[[typing.Any, typing.Any], typing.Tuple[numpy.ndarray, numpy.ndarray]], NoneType]<br><br>Specify the learning task and the corresponding learning objective or a custom<br>objective function to be used.<br><br>For custom objective, see :doc:`/tutorials/custom_metric_obj` and<br>:ref:`custom-obj-metric` for more information, along with the end note for<br>function signatures.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;multi:softprob&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=base_score,-typing.Union%5Bfloat%2C%20typing.List%5Bfloat%5D%2C%20NoneType%5D\">\n",
       "            base_score\n",
       "            <span class=\"param-doc-description\">base_score: typing.Union[float, typing.List[float], NoneType]<br><br>The initial prediction score of all instances, global bias.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=callbacks,-typing.Optional%5Btyping.List%5Bxgboost.callback.TrainingCallback%5D%5D\">\n",
       "            callbacks\n",
       "            <span class=\"param-doc-description\">callbacks: typing.Optional[typing.List[xgboost.callback.TrainingCallback]]<br><br>List of callback functions that are applied at end of each iteration.<br>It is possible to use predefined callbacks by using<br>:ref:`Callback API <callback_api>`.<br><br>.. note::<br><br>   States in callback are not preserved during training, which means callback<br>   objects can not be reused for multiple training sessions without<br>   reinitialization or deepcopy.<br><br>.. code-block:: python<br><br>    for params in parameters_grid:<br>        # be sure to (re)initialize the callbacks before each run<br>        callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]<br>        reg = xgboost.XGBRegressor(**params, callbacks=callbacks)<br>        reg.fit(X, y)</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=colsample_bylevel,-typing.Optional%5Bfloat%5D\">\n",
       "            colsample_bylevel\n",
       "            <span class=\"param-doc-description\">colsample_bylevel: typing.Optional[float]<br><br>Subsample ratio of columns for each level.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=colsample_bynode,-typing.Optional%5Bfloat%5D\">\n",
       "            colsample_bynode\n",
       "            <span class=\"param-doc-description\">colsample_bynode: typing.Optional[float]<br><br>Subsample ratio of columns for each split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=colsample_bytree,-typing.Optional%5Bfloat%5D\">\n",
       "            colsample_bytree\n",
       "            <span class=\"param-doc-description\">colsample_bytree: typing.Optional[float]<br><br>Subsample ratio of columns when constructing each tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.9</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=device,-typing.Optional%5Bstr%5D\">\n",
       "            device\n",
       "            <span class=\"param-doc-description\">device: typing.Optional[str]<br><br>.. versionadded:: 2.0.0<br><br>Device ordinal, available options are `cpu`, `cuda`, and `gpu`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=early_stopping_rounds,-typing.Optional%5Bint%5D\">\n",
       "            early_stopping_rounds\n",
       "            <span class=\"param-doc-description\">early_stopping_rounds: typing.Optional[int]<br><br>.. versionadded:: 1.6.0<br><br>- Activates early stopping. Validation metric needs to improve at least once in<br>  every **early_stopping_rounds** round(s) to continue training.  Requires at<br>  least one item in **eval_set** in :py:meth:`fit`.<br><br>- If early stopping occurs, the model will have two additional attributes:<br>  :py:attr:`best_score` and :py:attr:`best_iteration`. These are used by the<br>  :py:meth:`predict` and :py:meth:`apply` methods to determine the optimal<br>  number of trees during inference. If users want to access the full model<br>  (including trees built after early stopping), they can specify the<br>  `iteration_range` in these inference methods. In addition, other utilities<br>  like model plotting can also use the entire model.<br><br>- If you prefer to discard the trees after `best_iteration`, consider using the<br>  callback function :py:class:`xgboost.callback.EarlyStopping`.<br><br>- If there's more than one item in **eval_set**, the last entry will be used for<br>  early stopping.  If there's more than one metric in **eval_metric**, the last<br>  metric will be used for early stopping.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=enable_categorical,-bool\">\n",
       "            enable_categorical\n",
       "            <span class=\"param-doc-description\">enable_categorical: bool<br><br>See the same parameter of :py:class:`DMatrix` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=eval_metric,-typing.Union%5Bstr%2C%20typing.List%5Btyping.Union%5Bstr%2C%20typing.Callable%5D%5D%2C%20typing.Callable%2C%20NoneType%5D\">\n",
       "            eval_metric\n",
       "            <span class=\"param-doc-description\">eval_metric: typing.Union[str, typing.List[typing.Union[str, typing.Callable]], typing.Callable, NoneType]<br><br>.. versionadded:: 1.6.0<br><br>Metric used for monitoring the training result and early stopping.  It can be a<br>string or list of strings as names of predefined metric in XGBoost (See<br>:doc:`/parameter`), one of the metrics in :py:mod:`sklearn.metrics`, or any<br>other user defined metric that looks like `sklearn.metrics`.<br><br>If custom objective is also provided, then custom metric should implement the<br>corresponding reverse link function.<br><br>Unlike the `scoring` parameter commonly used in scikit-learn, when a callable<br>object is provided, it's assumed to be a cost function and by default XGBoost<br>will minimize the result during early stopping.<br><br>For advanced usage on Early stopping like directly choosing to maximize instead<br>of minimize, see :py:obj:`xgboost.callback.EarlyStopping`.<br><br>See :doc:`/tutorials/custom_metric_obj` and :ref:`custom-obj-metric` for more<br>information.<br><br>.. code-block:: python<br><br>    from sklearn.datasets import load_diabetes<br>    from sklearn.metrics import mean_absolute_error<br>    X, y = load_diabetes(return_X_y=True)<br>    reg = xgb.XGBRegressor(<br>        tree_method=\"hist\",<br>        eval_metric=mean_absolute_error,<br>    )<br>    reg.fit(X, y, eval_set=[(X, y)])</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;mlogloss&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=feature_types,-typing.Optional%5Btyping.Sequence%5Bstr%5D%5D\">\n",
       "            feature_types\n",
       "            <span class=\"param-doc-description\">feature_types: typing.Optional[typing.Sequence[str]]<br><br>.. versionadded:: 1.7.0<br><br>Used for specifying feature types without constructing a dataframe. See<br>the :py:class:`DMatrix` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=feature_weights,-Optional%5BArrayLike%5D\">\n",
       "            feature_weights\n",
       "            <span class=\"param-doc-description\">feature_weights: Optional[ArrayLike]<br><br>Weight for each feature, defines the probability of each feature being selected<br>when colsample is being used.  All values must be greater than 0, otherwise a<br>`ValueError` is thrown.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=gamma,-typing.Optional%5Bfloat%5D\">\n",
       "            gamma\n",
       "            <span class=\"param-doc-description\">gamma: typing.Optional[float]<br><br>(min_split_loss) Minimum loss reduction required to make a further partition on<br>a leaf node of the tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=grow_policy,-typing.Optional%5Bstr%5D\">\n",
       "            grow_policy\n",
       "            <span class=\"param-doc-description\">grow_policy: typing.Optional[str]<br><br>Tree growing policy.<br><br>- depthwise: Favors splitting at nodes closest to the node,<br>- lossguide: Favors splitting at nodes with highest loss change.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=interaction_constraints,-typing.Union%5Bstr%2C%20typing.List%5Btyping.Tuple%5Bstr%5D%5D%2C%20NoneType%5D\">\n",
       "            interaction_constraints\n",
       "            <span class=\"param-doc-description\">interaction_constraints: typing.Union[str, typing.List[typing.Tuple[str]], NoneType]<br><br>Constraints for interaction representing permitted interactions.  The<br>constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,<br>3, 4]]``, where each inner list is a group of indices of features that are<br>allowed to interact with each other.  See :doc:`tutorial<br></tutorials/feature_interaction_constraint>` for more information</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=learning_rate,-typing.Optional%5Bfloat%5D\">\n",
       "            learning_rate\n",
       "            <span class=\"param-doc-description\">learning_rate: typing.Optional[float]<br><br>Boosting learning rate (xgb's \"eta\")</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.08</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_bin,-typing.Optional%5Bint%5D\">\n",
       "            max_bin\n",
       "            <span class=\"param-doc-description\">max_bin: typing.Optional[int]<br><br>If using histogram-based algorithm, maximum number of bins per feature</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_cat_threshold,-typing.Optional%5Bint%5D\">\n",
       "            max_cat_threshold\n",
       "            <span class=\"param-doc-description\">max_cat_threshold: typing.Optional[int]<br><br>.. versionadded:: 1.7.0<br><br>.. note:: This parameter is experimental<br><br>Maximum number of categories considered for each split. Used only by<br>partition-based splits for preventing over-fitting. Also, `enable_categorical`<br>needs to be set to have categorical feature support. See :doc:`Categorical Data<br></tutorials/categorical>` and :ref:`cat-param` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_cat_to_onehot,-Optional%5Bint%5D\">\n",
       "            max_cat_to_onehot\n",
       "            <span class=\"param-doc-description\">max_cat_to_onehot: Optional[int]<br><br>.. versionadded:: 1.6.0<br><br>.. note:: This parameter is experimental<br><br>A threshold for deciding whether XGBoost should use one-hot encoding based split<br>for categorical data.  When number of categories is lesser than the threshold<br>then one-hot encoding is chosen, otherwise the categories will be partitioned<br>into children nodes. Also, `enable_categorical` needs to be set to have<br>categorical feature support. See :doc:`Categorical Data<br></tutorials/categorical>` and :ref:`cat-param` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_delta_step,-typing.Optional%5Bfloat%5D\">\n",
       "            max_delta_step\n",
       "            <span class=\"param-doc-description\">max_delta_step: typing.Optional[float]<br><br>Maximum delta step we allow each tree's weight estimation to be.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_depth,-%20typing.Optional%5Bint%5D\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth:  typing.Optional[int]<br><br>Maximum tree depth for base learners.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">6</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_leaves,-typing.Optional%5Bint%5D\">\n",
       "            max_leaves\n",
       "            <span class=\"param-doc-description\">max_leaves: typing.Optional[int]<br><br>Maximum number of leaves; 0 indicates no limit.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=min_child_weight,-typing.Optional%5Bfloat%5D\">\n",
       "            min_child_weight\n",
       "            <span class=\"param-doc-description\">min_child_weight: typing.Optional[float]<br><br>Minimum sum of instance weight(hessian) needed in a child.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=missing,-float\">\n",
       "            missing\n",
       "            <span class=\"param-doc-description\">missing: float<br><br>Value in the data which needs to be present as a missing value. Default to<br>:py:data:`numpy.nan`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=monotone_constraints,-typing.Union%5Btyping.Dict%5Bstr%2C%20int%5D%2C%20str%2C%20NoneType%5D\">\n",
       "            monotone_constraints\n",
       "            <span class=\"param-doc-description\">monotone_constraints: typing.Union[typing.Dict[str, int], str, NoneType]<br><br>Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`<br>for more information.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=multi_strategy,-typing.Optional%5Bstr%5D\">\n",
       "            multi_strategy\n",
       "            <span class=\"param-doc-description\">multi_strategy: typing.Optional[str]<br><br>.. versionadded:: 2.0.0<br><br>.. note:: This parameter is working-in-progress.<br><br>The strategy used for training multi-target models, including multi-target<br>regression and multi-class classification. See :doc:`/tutorials/multioutput` for<br>more information.<br><br>- ``one_output_per_tree``: One model for each target.<br>- ``multi_output_tree``:  Use multi-target trees.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=n_estimators,-Optional%5Bint%5D\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: Optional[int]<br><br>Number of boosting rounds.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">500</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=n_jobs,-typing.Optional%5Bint%5D\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: typing.Optional[int]<br><br>Number of parallel threads used to run xgboost.  When used with other<br>Scikit-Learn algorithms like grid search, you may choose which algorithm to<br>parallelize and balance the threads.  Creating thread contention will<br>significantly slow down both algorithms.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=random_state,-typing.Union%5Bnumpy.random.mtrand.RandomState%2C%20numpy.random._generator.Generator%2C%20int%2C%20NoneType%5D\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: typing.Union[numpy.random.mtrand.RandomState, numpy.random._generator.Generator, int, NoneType]<br><br>Random number seed.<br><br>.. note::<br><br>   Using gblinear booster with shotgun updater is nondeterministic as<br>   it uses Hogwild algorithm.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=reg_alpha,-typing.Optional%5Bfloat%5D\">\n",
       "            reg_alpha\n",
       "            <span class=\"param-doc-description\">reg_alpha: typing.Optional[float]<br><br>L1 regularization term on weights (xgb's alpha).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=reg_lambda,-typing.Optional%5Bfloat%5D\">\n",
       "            reg_lambda\n",
       "            <span class=\"param-doc-description\">reg_lambda: typing.Optional[float]<br><br>L2 regularization term on weights (xgb's lambda).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=sampling_method,-typing.Optional%5Bstr%5D\">\n",
       "            sampling_method\n",
       "            <span class=\"param-doc-description\">sampling_method: typing.Optional[str]<br><br>Sampling method. Used only by the GPU version of ``hist`` tree method.<br><br>- ``uniform``: Select random training instances uniformly.<br>- ``gradient_based``: Select random training instances with higher probability<br>    when the gradient and hessian are larger. (cf. CatBoost)</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=scale_pos_weight,-typing.Optional%5Bfloat%5D\">\n",
       "            scale_pos_weight\n",
       "            <span class=\"param-doc-description\">scale_pos_weight: typing.Optional[float]<br><br>Balancing of positive and negative weights.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=subsample,-typing.Optional%5Bfloat%5D\">\n",
       "            subsample\n",
       "            <span class=\"param-doc-description\">subsample: typing.Optional[float]<br><br>Subsample ratio of the training instance.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.9</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=tree_method,-typing.Optional%5Bstr%5D\">\n",
       "            tree_method\n",
       "            <span class=\"param-doc-description\">tree_method: typing.Optional[str]<br><br>Specify which tree method to use.  Default to auto.  If this parameter is set to<br>default, XGBoost will choose the most conservative option available.  It's<br>recommended to study this option from the parameters document :doc:`tree method<br></treemethod>`</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;hist&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=validate_parameters,-typing.Optional%5Bbool%5D\">\n",
       "            validate_parameters\n",
       "            <span class=\"param-doc-description\">validate_parameters: typing.Optional[bool]<br><br>Give warnings for unknown parameter.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=verbosity,-typing.Optional%5Bint%5D\">\n",
       "            verbosity\n",
       "            <span class=\"param-doc-description\">verbosity: typing.Optional[int]<br><br>The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_class</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-1');</script></body>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='mlogloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.08, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None, num_class=5, ...)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- XGBoost ---\n",
    "xgb = XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=len(le.classes_),\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.08,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.0,\n",
    "    tree_method=\"hist\",\n",
    "    eval_metric=\"mlogloss\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "xgb.fit(X_train_final, y_train_enc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "07c3d8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL weighted F1: 1.0\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     Data Issue      1.000     1.000     1.000       369\n",
      "       Security      1.000     1.000     1.000       215\n",
      "Technical Issue      1.000     1.000     1.000       319\n",
      "\n",
      "       accuracy                          1.000       903\n",
      "      macro avg      1.000     1.000     1.000       903\n",
      "   weighted avg      1.000     1.000     1.000       903\n",
      "\n",
      "TEST weighted F1: 0.9965\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     Data Issue      1.000     1.000     1.000       205\n",
      "Feature Request      1.000     0.992     0.996       791\n",
      "       Security      1.000     1.000     1.000       425\n",
      "Technical Issue      0.980     1.000     0.990       300\n",
      "\n",
      "       accuracy                          0.997      1721\n",
      "      macro avg      0.995     0.998     0.997      1721\n",
      "   weighted avg      0.997     0.997     0.997      1721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# VAL\n",
    "val_pred_enc = xgb.predict(X_val_final)\n",
    "val_pred = le.inverse_transform(val_pred_enc)\n",
    "print(\"VAL weighted F1:\", round(f1_score(y_val, val_pred, average=\"weighted\"), 4))\n",
    "print(classification_report(y_val, val_pred, digits=3))\n",
    "\n",
    "# TEST\n",
    "test_pred_enc = xgb.predict(X_test_final)\n",
    "test_pred = le.inverse_transform(test_pred_enc)\n",
    "print(\"TEST weighted F1:\", round(f1_score(y_test, test_pred, average=\"weighted\"), 4))\n",
    "print(classification_report(y_test, test_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e00a9e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL weighted F1: 1.0\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Account Management      1.000     1.000     1.000      3299\n",
      "        Data Issue      1.000     1.000     1.000      3308\n",
      "   Feature Request      1.000     1.000     1.000      3307\n",
      "          Security      1.000     1.000     1.000      3313\n",
      "   Technical Issue      1.000     1.000     1.000      3273\n",
      "\n",
      "          accuracy                          1.000     16500\n",
      "         macro avg      1.000     1.000     1.000     16500\n",
      "      weighted avg      1.000     1.000     1.000     16500\n",
      "\n",
      "TEST weighted F1: 1.0\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Account Management      1.000     1.000     1.000      3300\n",
      "        Data Issue      1.000     1.000     1.000      3307\n",
      "   Feature Request      1.000     1.000     1.000      3307\n",
      "          Security      1.000     1.000     1.000      3313\n",
      "   Technical Issue      1.000     1.000     1.000      3273\n",
      "\n",
      "          accuracy                          1.000     16500\n",
      "         macro avg      1.000     1.000     1.000     16500\n",
      "      weighted avg      1.000     1.000     1.000     16500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict, List\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def prepare_classification_dataset(records: List[Any]) -> pd.DataFrame:\n",
    "    data = []\n",
    "    for r in records:\n",
    "        if hasattr(r, \"model_dump\"):     # Pydantic\n",
    "            r = r.model_dump()\n",
    "        elif not isinstance(r, dict):\n",
    "            r = dict(r)\n",
    "\n",
    "        text = f\"{r.get('subject','')}\\n{r.get('description','')}\\n{r.get('error_logs','')}\"\n",
    "\n",
    "        data.append({\n",
    "            \"text\": text,\n",
    "            \"product\": r.get(\"product\", \"\"),\n",
    "            \"product_module\": r.get(\"product_module\", \"\"),\n",
    "            \"priority\": r.get(\"priority\", \"\"),\n",
    "            \"channel\": r.get(\"channel\", \"\"),\n",
    "            \"customer_tier\": r.get(\"customer_tier\", \"\"),\n",
    "            \"region\": r.get(\"region\", \"\"),\n",
    "            \"category\": r.get(\"category\", \"\"),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# IMPORTANT: pass the list of records (not json_data[0] unless nested)\n",
    "classification_data = prepare_classification_dataset(json_data[0])\n",
    "\n",
    "X = classification_data.drop(\"category\", axis=1)\n",
    "y = classification_data[\"category\"]\n",
    "\n",
    "X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.50, random_state=42, stratify=y_tmp\n",
    ")\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"text\", TfidfVectorizer(max_features=80_000, ngram_range=(1, 2), min_df=2), \"text\"),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "         [\"product\",\"product_module\",\"priority\",\"channel\",\"customer_tier\",\"region\"]),\n",
    "    ],\n",
    ")\n",
    "\n",
    "X_train_t = preprocess.fit_transform(X_train)\n",
    "X_val_t = preprocess.transform(X_val)\n",
    "X_test_t = preprocess.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
    "model.fit(X_train_t, y_train)\n",
    "\n",
    "val_pred = model.predict(X_val_t)\n",
    "print(\"VAL weighted F1:\", round(f1_score(y_val, val_pred, average=\"weighted\"), 4))\n",
    "print(classification_report(y_val, val_pred, digits=3))\n",
    "\n",
    "test_pred = model.predict(X_test_t)\n",
    "print(\"TEST weighted F1:\", round(f1_score(y_test, test_pred, average=\"weighted\"), 4))\n",
    "print(classification_report(y_test, test_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e0ecd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.graph_rag_ingest import top_solutions_for_issue,build_support_graph\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38b0a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickets = json_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc455de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = build_support_graph(tickets[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5b34158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes: 110078\n",
      "edges: 517739\n",
      "[('DATA_REPAIR', 0.6649484536082474, 388), ('ENVIRONMENT_ISSUE', 0.6240208877284595, 383), ('DUPLICATE', 0.6222826086956522, 368), ('WORKAROUND', 0.6208955223880597, 335), ('CONFIG_CHANGE', 0.6186666666666667, 375)]\n"
     ]
    }
   ],
   "source": [
    "support_graph = build_support_graph(tickets[:])\n",
    "\n",
    "print(\"nodes:\", support_graph.number_of_nodes())\n",
    "print(\"edges:\", support_graph.number_of_edges())\n",
    "\n",
    "print(top_solutions_for_issue(support_graph, \"Account Management\", \"Upgrade\", top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97048284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeView(('ticket:TK-2024-000001', 'product:CloudBackup Enterprise', 'module:encryption_layer', 'issue:Feature Request|Documentation', 'solution:PATCH_APPLIED', 'ticket:TK-2024-000002', 'product:DataSync Pro', 'module:data_validator', 'issue:Account Management|Upgrade', 'solution:FEATURE_ADDED', 'error:ERROR_DISK_FULL', 'ticket:TK-2024-000003', 'product:API Gateway', 'module:request_router', 'issue:Feature Request|New Feature', 'solution:WORKAROUND', 'ticket:TK-2024-000004', 'module:backup_service', 'solution:CONFIG_CHANGE', 'error:ERROR_SERVER_500', 'ticket:TK-2024-000005', 'product:StreamProcessor', 'module:monitoring', 'issue:Feature Request|API', 'solution:DUPLICATE', 'error:ERROR_RATELIMIT_429', 'ticket:TK-2024-000006', 'module:batch_processor', 'issue:Security|Compliance', 'solution:WONT_FIX', 'error:ERROR_VALIDATION', 'ticket:TK-2024-000007', 'product:Analytics Dashboard', 'module:data_aggregator', 'issue:Data Issue|Corruption', 'solution:ENVIRONMENT_ISSUE', 'error:ERROR_INVALID_400', 'ticket:TK-2024-000008', 'module:cache_layer', 'solution:USER_EDUCATION', 'error:ERROR_DEADLOCK', 'ticket:TK-2024-000009', 'module:scheduler', 'issue:Feature Request|Enhancement', 'ticket:TK-2024-000010', 'issue:Data Issue|Sync Error', 'error:ERROR_CONNECTION_REFUSED', 'ticket:TK-2024-000011', 'solution:RESTART_REQUIRED', 'error:ERROR_MEMORY_OOM', 'ticket:TK-2024-000012', 'issue:Feature Request|UI/UX', 'solution:DATA_REPAIR', 'ticket:TK-2024-000013', 'ticket:TK-2024-000014', 'module:compression_engine', 'error:ERROR_NOTFOUND_404', 'ticket:TK-2024-000015', 'solution:ESCALATED', 'ticket:TK-2024-000016', 'ticket:TK-2024-000017', 'issue:Data Issue|Import/Export', 'ticket:TK-2024-000018', 'error:ERROR_SSL_CERT', 'ticket:TK-2024-000019', 'solution:BUG_FIX', 'ticket:TK-2024-000020', 'module:export_module', 'issue:Technical Issue|Bug', 'error:ERROR_TIMEOUT_429'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support_graph.nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe5d0c",
   "metadata": {},
   "source": [
    "#### Graph visuvalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51b1b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_subgraph(\n",
    "    support_graph: nx.Graph,\n",
    "    center_node: str,\n",
    "    hops: int = 2,\n",
    "    max_nodes: int = 80,\n",
    "    seed: int = 42,\n",
    "):\n",
    "    if center_node not in support_graph:\n",
    "        raise ValueError(f\"{center_node} not found in graph\")\n",
    "\n",
    "    # collect nodes within N hops (BFS)\n",
    "    nodes = {center_node}\n",
    "    frontier = {center_node}\n",
    "    for _ in range(hops):\n",
    "        nxt = set()\n",
    "        for n in frontier:\n",
    "            nxt.update(support_graph.neighbors(n))\n",
    "        nodes.update(nxt)\n",
    "        frontier = nxt\n",
    "\n",
    "    nodes = list(nodes)\n",
    "\n",
    "    # cap nodes for readability\n",
    "    if len(nodes) > max_nodes:\n",
    "        random.seed(seed)\n",
    "        nodes = [center_node] + random.sample([n for n in nodes if n != center_node], max_nodes - 1)\n",
    "\n",
    "    sub = support_graph.subgraph(nodes).copy()\n",
    "\n",
    "    # layout\n",
    "    plt.figure(figsize=(14, 9))\n",
    "    pos = nx.spring_layout(sub, seed=seed, k=0.7)\n",
    "\n",
    "    # optional: color by \"kind\" (we dont set colors explicitly; matplotlib will default)\n",
    "    kinds = nx.get_node_attributes(sub, \"kind\")\n",
    "    kind_values = sorted(set(kinds.values())) if kinds else []\n",
    "    if kind_values:\n",
    "        for kind in kind_values:\n",
    "            kind_nodes = [n for n in sub.nodes if kinds.get(n) == kind]\n",
    "            nx.draw_networkx_nodes(sub, pos, nodelist=kind_nodes, node_size=700, alpha=0.9)\n",
    "    else:\n",
    "        nx.draw_networkx_nodes(sub, pos, node_size=700, alpha=0.9)\n",
    "\n",
    "    nx.draw_networkx_edges(sub, pos, alpha=0.5, width=1.5)\n",
    "\n",
    "    # shorter labels\n",
    "    def short_label(node: str) -> str:\n",
    "        for prefix, tag in [(\"ticket:\", \"\"), (\"product:\", \"P:\"), (\"module:\", \"M:\"), (\"issue:\", \"I:\"), (\"solution:\", \"S:\"), (\"error:\", \"E:\")]:\n",
    "            if node.startswith(prefix):\n",
    "                return tag + node[len(prefix):]\n",
    "        return node\n",
    "\n",
    "    labels = {n: short_label(str(n)) for n in sub.nodes}\n",
    "    nx.draw_networkx_labels(sub, pos, labels=labels, font_size=9)\n",
    "\n",
    "    # show relationship labels if present\n",
    "    edge_rels = nx.get_edge_attributes(sub, \"rel\")\n",
    "    if edge_rels:\n",
    "        nx.draw_networkx_edge_labels(sub, pos, edge_labels=edge_rels, font_size=8)\n",
    "\n",
    "    plt.title(f\"Graph-RAG subgraph around: {short_label(center_node)} ({max_nodes} nodes, {hops}-hop)\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8063cc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# issue_node = \"issue:Account Management|Upgrade\"\n",
    "# visualize_subgraph(support_graph, center_node=issue_node, hops=2, max_nodes=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aacc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "### by using pyvis in HTML \n",
    "\n",
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def export_interactive_html(\n",
    "    support_graph: nx.Graph,\n",
    "    center_node: str,\n",
    "    hops: int = 2,\n",
    "    max_nodes: int = 200,\n",
    "    out_html: str = \"graph_rag.html\",\n",
    "):\n",
    "    # --- collect subgraph ---\n",
    "    nodes = {center_node}\n",
    "    frontier = {center_node}\n",
    "    for _ in range(hops):\n",
    "        nxt = set()\n",
    "        for n in frontier:\n",
    "            nxt.update(support_graph.neighbors(n))\n",
    "        nodes.update(nxt)\n",
    "        frontier = nxt\n",
    "\n",
    "    nodes = list(nodes)\n",
    "    if len(nodes) > max_nodes:\n",
    "        nodes = nodes[:max_nodes]\n",
    "\n",
    "    sub = support_graph.subgraph(nodes).copy()\n",
    "\n",
    "    # --- create interactive graph ---\n",
    "    net = Network(height=\"750px\", width=\"100%\", notebook=True, directed=False)\n",
    "    net.from_nx(sub)\n",
    "\n",
    "    # --- add relationship labels to edges ---\n",
    "    edge_lookup = {}\n",
    "    for u, v, data in sub.edges(data=True):\n",
    "        rel = data.get(\"rel\")\n",
    "        if rel:\n",
    "            edge_lookup[(u, v)] = rel\n",
    "            edge_lookup[(v, u)] = rel  # undirected graph\n",
    "\n",
    "    for edge in net.edges:\n",
    "        key = (edge[\"from\"], edge[\"to\"])\n",
    "        rel = edge_lookup.get(key)\n",
    "        if rel:\n",
    "            edge[\"label\"] = rel\n",
    "            edge[\"title\"] = rel\n",
    "\n",
    "    net.show(out_html)\n",
    "    return out_html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94f67f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "graph_rag.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'graph_rag.html'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_interactive_html(\n",
    "    support_graph,\n",
    "    center_node=\"issue:Account Management|Upgrade\",\n",
    "    hops=2,\n",
    "    out_html=\"graph_rag.html\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e8d23c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
